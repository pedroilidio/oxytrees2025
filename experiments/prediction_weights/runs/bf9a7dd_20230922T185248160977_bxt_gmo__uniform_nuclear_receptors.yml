active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: prediction_weights/runs
end: 2023-09-22 18:52:51.104599
estimator:
  call: bipartite_learn.ensemble.BipartiteExtraTreesRegressor
  final_params:
    estimator:
      call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
      params:
        bipartite_adapter: gmo
        bootstrap: true
        ccp_alpha: 0.0
        criterion: squared_error
        max_col_features: null
        max_depth: null
        max_features: 1.0
        max_leaf_nodes: null
        max_row_features: null
        max_samples: 0.7
        min_col_weight_fraction_leaf: 0.0
        min_cols_leaf: 5
        min_cols_split: 1
        min_impurity_decrease: 0.0
        min_row_weight_fraction_leaf: 0.0
        min_rows_leaf: 5
        min_rows_split: 1
        min_samples_leaf: 1
        min_samples_split: 2
        min_weight_fraction_leaf: 0.0
        n_estimators: 100
        n_jobs: 3
        oob_score: false
        prediction_weights: uniform
        random_state: 0
        verbose: 10
        warm_start: false
  name: bxt_gmo__uniform
  params:
    bipartite_adapter: gmo
    bootstrap: true
    max_samples: 0.7
    min_cols_leaf: 5
    min_rows_leaf: 5
    n_estimators: 100
    n_jobs: 3
    random_state: 0
    verbose: 10
hash: bf9a7dd668e36e6d55bec4d409a33680049cfe790127f58732e5edf0cd5aaf32
modify_params:
  prediction_weights: uniform
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/prediction_weights/runs/bf9a7dd_20230922T185248160977_bxt_gmo__uniform_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.7167928496978637
  - 0.6395690067088015
  - 0.7041434871520474
  - 0.7084513790512937
  - 0.6848362260935353
  - 0.6343400110830317
  - 0.7218026739332288
  - 0.6982878781986127
  - 0.7899171981326827
  - 0.7250814471666992
  - 0.803647228101589
  - 0.7773091765595135
  - 0.7369372527610227
  - 0.708007664624113
  - 0.7278628709635375
  - 0.7525328015816801
  LL_balanced_accuracy:
  - 0.830631623124541
  - 0.8561452513966481
  - 0.8452234993614305
  - 0.8362129583124058
  - 0.8240611961057024
  - 0.7943603851444292
  - 0.8157181571815718
  - 0.819047619047619
  - 0.8528214277545232
  - 0.8432539682539683
  - 0.8415584415584416
  - 0.8506578947368422
  - 0.8347539120552496
  - 0.8413333333333333
  - 0.8477026214392303
  - 0.8631578947368421
  LL_f1_macro:
  - 0.57350066167431
  - 0.5656468133746158
  - 0.5811827956989247
  - 0.5703254274682845
  - 0.5156370048491719
  - 0.46097372946688014
  - 0.5028623984083188
  - 0.5138286690316647
  - 0.60894316891399
  - 0.5424434389140271
  - 0.5512130347401665
  - 0.5851303070624132
  - 0.578256688726738
  - 0.553634223876818
  - 0.5981111980320267
  - 0.6036585365853658
  LL_f1_micro:
  - 0.7171052631578947
  - 0.7289473684210527
  - 0.7278562259306803
  - 0.7111681643132219
  - 0.6671052631578948
  - 0.6065789473684211
  - 0.6508344030808729
  - 0.6585365853658537
  - 0.75625
  - 0.70375
  - 0.7024390243902439
  - 0.7231707317073172
  - 0.70875
  - 0.7025
  - 0.7463414634146343
  - 0.7463414634146343
  LL_f1_weighted:
  - 0.7858140407384759
  - 0.8011360258020953
  - 0.7946705867737796
  - 0.7815895327356907
  - 0.7572734263393227
  - 0.7167965680078153
  - 0.7455364860713074
  - 0.7491067165303107
  - 0.8135526573063703
  - 0.784233484162896
  - 0.7799582291688549
  - 0.7894184619280215
  - 0.7764892245036485
  - 0.7791884301240635
  - 0.8070622950171481
  - 0.8066627007733492
  LL_matthews_corrcoef:
  - 0.35649059672477673
  - 0.3540665594088492
  - 0.3705020807887152
  - 0.3595454611154543
  - 0.3006400093805979
  - 0.24190375351045457
  - 0.2875971228582134
  - 0.3009457698237475
  - 0.39789520861155103
  - 0.3278656808037852
  - 0.34084650602013894
  - 0.38290539478229274
  - 0.3715710695170738
  - 0.3442651863295481
  - 0.38499121804208514
  - 0.4032468382625402
  LL_precision_macro:
  - 0.5960930055269678
  - 0.588
  - 0.5994079140923801
  - 0.5961242981662573
  - 0.5697278911564626
  - 0.5496987951807228
  - 0.5654952076677316
  - 0.5709677419354838
  - 0.6121818181818182
  - 0.5782918149466192
  - 0.5850340136054422
  - 0.6045296167247387
  - 0.6031093698460461
  - 0.5868055555555556
  - 0.6065696868749616
  - 0.6119402985074627
  LL_precision_micro:
  - 0.7171052631578947
  - 0.7289473684210527
  - 0.7278562259306803
  - 0.711168164313222
  - 0.6671052631578948
  - 0.6065789473684211
  - 0.6508344030808729
  - 0.6585365853658537
  - 0.75625
  - 0.70375
  - 0.7024390243902439
  - 0.723170731707317
  - 0.70875
  - 0.7025
  - 0.7463414634146341
  - 0.7463414634146341
  LL_precision_weighted:
  - 0.9391364488981171
  - 0.9522947368421053
  - 0.9427896560983541
  - 0.9412558966071514
  - 0.9535759040458288
  - 0.9608948953709575
  - 0.9542626534387085
  - 0.9515342250196696
  - 0.9396968181818182
  - 0.9536120996441281
  - 0.9493943919031027
  - 0.942126285374352
  - 0.9368152856594705
  - 0.9483506944444444
  - 0.9403104594288736
  - 0.943210775391336
  LL_recall_macro:
  - 0.830631623124541
  - 0.8561452513966481
  - 0.8452234993614305
  - 0.8362129583124058
  - 0.8240611961057024
  - 0.7943603851444292
  - 0.8157181571815718
  - 0.819047619047619
  - 0.8528214277545232
  - 0.8432539682539683
  - 0.8415584415584416
  - 0.8506578947368422
  - 0.8347539120552496
  - 0.8413333333333333
  - 0.8477026214392303
  - 0.8631578947368421
  LL_recall_micro:
  - 0.7171052631578947
  - 0.7289473684210527
  - 0.7278562259306803
  - 0.711168164313222
  - 0.6671052631578948
  - 0.6065789473684211
  - 0.6508344030808729
  - 0.6585365853658537
  - 0.75625
  - 0.70375
  - 0.7024390243902439
  - 0.723170731707317
  - 0.70875
  - 0.7025
  - 0.7463414634146341
  - 0.7463414634146341
  LL_recall_weighted:
  - 0.7171052631578947
  - 0.7289473684210527
  - 0.7278562259306803
  - 0.711168164313222
  - 0.6671052631578948
  - 0.606578947368421
  - 0.6508344030808729
  - 0.6585365853658537
  - 0.75625
  - 0.70375
  - 0.7024390243902439
  - 0.723170731707317
  - 0.70875
  - 0.7025
  - 0.7463414634146341
  - 0.7463414634146341
  LL_roc_auc:
  - 0.9540840415486308
  - 0.9542280345352971
  - 0.9573690932311621
  - 0.9563159216474133
  - 0.9662810814478103
  - 0.9774915593347505
  - 0.9709498314495341
  - 0.9611935683364254
  - 0.9638143598892929
  - 0.9687650312650313
  - 0.9718441558441558
  - 0.9663377192982456
  - 0.9649335606259289
  - 0.95408
  - 0.9557451168177465
  - 0.9684758771929824
  LT_average_precision:
  - 0.2405506098882577
  - 0.28901597826487824
  - 0.3774876419125912
  - 0.29010329854107575
  - 0.1555378653227698
  - 0.14818522601659193
  - 0.07384005058390784
  - 0.10631107842717592
  - 0.31144636128597675
  - 0.24367394173745258
  - 0.293325661253338
  - 0.28779471579830695
  - 0.2459400586821712
  - 0.27251443954068905
  - 0.42192127246764943
  - 0.24822645101706592
  LT_balanced_accuracy:
  - 0.6819389110225764
  - 0.7100414937759336
  - 0.6383620689655172
  - 0.7426425505824648
  - 0.7145669291338583
  - 0.6144308943089432
  - 0.7115248226950355
  - 0.6223155929038282
  - 0.6865671641791045
  - 0.6863563167910994
  - 0.7285315799960151
  - 0.7785688207374954
  - 0.7484276729559749
  - 0.6705460401112575
  - 0.6597796143250689
  - 0.7342047930283224
  LT_f1_macro:
  - 0.5050423835887069
  - 0.5994365102496843
  - 0.4883774453394707
  - 0.524310776942356
  - 0.3712813992534272
  - 0.4957345971563981
  - 0.4143479582531158
  - 0.4607590685176892
  - 0.45504903061606405
  - 0.5728147439939788
  - 0.4831391001440791
  - 0.528870858688303
  - 0.4879672299027138
  - 0.5516196870598676
  - 0.49442571947109154
  - 0.5365418894830659
  LT_f1_micro:
  - 0.6954887218045113
  - 0.7669172932330828
  - 0.6720647773279352
  - 0.7044534412955465
  - 0.4548872180451128
  - 0.6691729323308271
  - 0.5263157894736842
  - 0.6842105263157895
  - 0.6285714285714286
  - 0.7321428571428571
  - 0.5807692307692308
  - 0.7423076923076923
  - 0.6428571428571429
  - 0.7035714285714286
  - 0.6538461538461539
  - 0.7076923076923077
  LT_f1_weighted:
  - 0.7774383582488879
  - 0.8097612144613938
  - 0.7577027902144492
  - 0.783858431503861
  - 0.5798649884038178
  - 0.746997826319353
  - 0.6455407949400301
  - 0.7825853819501732
  - 0.7361992450247559
  - 0.7833887414889876
  - 0.6714874937395044
  - 0.8191449524106726
  - 0.739411893789774
  - 0.7623012427752834
  - 0.7390159749506392
  - 0.7813519813519814
  LT_matthews_corrcoef:
  - 0.1794537750435501
  - 0.2796764903772835
  - 0.13950931937296043
  - 0.23902448054824796
  - 0.18110781353208713
  - 0.12754935021942573
  - 0.18197989328061004
  - 0.09827733411363537
  - 0.15473993950690831
  - 0.24175570716133568
  - 0.24919948701721775
  - 0.24853421513937665
  - 0.22871449629483617
  - 0.21558360163397677
  - 0.16808840617124374
  - 0.24684531256933484
  LT_precision_macro:
  - 0.5442506459948321
  - 0.5930993893915986
  - 0.5351665205959685
  - 0.558865089989588
  - 0.5382165605095541
  - 0.5355429292929292
  - 0.5391404199475066
  - 0.5197408077154912
  - 0.5320855614973262
  - 0.5784060113328406
  - 0.5679341388296612
  - 0.5554344667247894
  - 0.552641398795245
  - 0.5681286549707603
  - 0.5442073170731707
  - 0.5650420168067227
  LT_precision_micro:
  - 0.6954887218045113
  - 0.7669172932330827
  - 0.6720647773279352
  - 0.7044534412955465
  - 0.4548872180451128
  - 0.6691729323308271
  - 0.5263157894736842
  - 0.6842105263157895
  - 0.6285714285714286
  - 0.7321428571428571
  - 0.5807692307692308
  - 0.7423076923076923
  - 0.6428571428571429
  - 0.7035714285714286
  - 0.6538461538461539
  - 0.7076923076923077
  LT_precision_weighted:
  - 0.9239547512191331
  - 0.8864171021241031
  - 0.9112035042774468
  - 0.9339691951190577
  - 0.9583353287677793
  - 0.8867101465785676
  - 0.947696505042133
  - 0.9429269375971573
  - 0.9437585943468296
  - 0.8779277971351143
  - 0.9176903941829314
  - 0.9525400710884582
  - 0.9415023645792877
  - 0.8742293233082706
  - 0.9053705440900562
  - 0.9232527472527472
  LT_recall_macro:
  - 0.6819389110225764
  - 0.7100414937759336
  - 0.6383620689655172
  - 0.7426425505824648
  - 0.7145669291338583
  - 0.6144308943089432
  - 0.7115248226950355
  - 0.6223155929038282
  - 0.6865671641791045
  - 0.6863563167910994
  - 0.7285315799960151
  - 0.7785688207374954
  - 0.7484276729559749
  - 0.6705460401112575
  - 0.6597796143250689
  - 0.7342047930283224
  LT_recall_micro:
  - 0.6954887218045113
  - 0.7669172932330827
  - 0.6720647773279352
  - 0.7044534412955465
  - 0.4548872180451128
  - 0.6691729323308271
  - 0.5263157894736842
  - 0.6842105263157895
  - 0.6285714285714286
  - 0.7321428571428571
  - 0.5807692307692308
  - 0.7423076923076923
  - 0.6428571428571429
  - 0.7035714285714286
  - 0.6538461538461539
  - 0.7076923076923077
  LT_recall_weighted:
  - 0.6954887218045113
  - 0.7669172932330827
  - 0.6720647773279352
  - 0.7044534412955465
  - 0.4548872180451128
  - 0.6691729323308271
  - 0.5263157894736842
  - 0.6842105263157895
  - 0.6285714285714286
  - 0.7321428571428571
  - 0.5807692307692308
  - 0.7423076923076923
  - 0.6428571428571429
  - 0.7035714285714286
  - 0.6538461538461539
  - 0.7076923076923077
  LT_roc_auc:
  - 0.7575033200531208
  - 0.7359336099585062
  - 0.7402298850574712
  - 0.7942979767014101
  - 0.6991469816272966
  - 0.6146341463414634
  - 0.6567375886524822
  - 0.7600373482726425
  - 0.7938432835820896
  - 0.7001903088859611
  - 0.7700737198645148
  - 0.7981014968966776
  - 0.7849056603773585
  - 0.7293222075830772
  - 0.7995867768595041
  - 0.7831033648027113
  TL_average_precision:
  - 0.23626073943526593
  - 0.4127047718956542
  - 0.42765214946409813
  - 0.3363851064791852
  - 0.3156142055438127
  - 0.19344345307686736
  - 0.2589251481490653
  - 0.3468399275193031
  - 0.04338663642201473
  - 0.11405446550950882
  - 0.10991838527357271
  - 0.11740791401651496
  - 0.1886295527078829
  - 0.31488315608555495
  - 0.37773811469604346
  - 0.337528941053032
  TL_balanced_accuracy:
  - 0.6844783715012722
  - 0.6869778161912994
  - 0.7106227106227107
  - 0.6252581577860388
  - 0.5169711102474414
  - 0.455078125
  - 0.5222222222222221
  - 0.49933172948409515
  - 0.44340901389359544
  - 0.34005421890884446
  - 0.3961988304093567
  - 0.3877517332452955
  - 0.6565217391304348
  - 0.5104230533415083
  - 0.6582278481012658
  - 0.6488940244305051
  TL_f1_macro:
  - 0.5181907571288102
  - 0.4858781539477214
  - 0.5067921440261866
  - 0.4712301587301587
  - 0.4467577850716047
  - 0.3949948400412797
  - 0.4458650398325572
  - 0.423624634858812
  - 0.36481550340121177
  - 0.3221615514968932
  - 0.32142388020491264
  - 0.3389101048675517
  - 0.44304308344263943
  - 0.3965714285714286
  - 0.452087433958355
  - 0.484714304653321
  TL_f1_micro:
  - 0.7
  - 0.6821428571428572
  - 0.7073170731707317
  - 0.6376306620209059
  - 0.5678571428571428
  - 0.5214285714285715
  - 0.5853658536585366
  - 0.5400696864111498
  - 0.49583333333333335
  - 0.4375
  - 0.40243902439024387
  - 0.459349593495935
  - 0.6166666666666667
  - 0.5875
  - 0.6504065040650406
  - 0.6788617886178862
  TL_f1_weighted:
  - 0.7761061946902654
  - 0.7740355794480943
  - 0.7905951858209253
  - 0.7306495769039324
  - 0.6482819071879964
  - 0.624155978180746
  - 0.6715851066482044
  - 0.6303371682346673
  - 0.622043169506478
  - 0.5714790058369421
  - 0.5215789423098488
  - 0.5912595096127357
  - 0.7280967275417886
  - 0.7162000000000001
  - 0.7576060014200061
  - 0.7675781885752041
  TL_matthews_corrcoef:
  - 0.19376007543309293
  - 0.1666199449782384
  - 0.19558077687313016
  - 0.12537473124801757
  - 0.021568615078294943
  - -0.05048782890557569
  - 0.026439850072238334
  - -0.0008097813110130521
  - -0.05124375463886919
  - -0.1451354130967791
  - -0.10958453966810075
  - -0.10053407527009443
  - 0.1276884796138123
  - 0.007136655392300841
  - 0.12364128658164225
  - 0.1413279471410964
  TL_precision_macro:
  - 0.5508771929824562
  - 0.5371196522534889
  - 0.5454032712915962
  - 0.5313728533002275
  - 0.5068528980958359
  - 0.4858141447368421
  - 0.5078644888082274
  - 0.49975468550681973
  - 0.4883995554320645
  - 0.46707589285714285
  - 0.4710774662230973
  - 0.477489406779661
  - 0.5260416666666666
  - 0.501221615406726
  - 0.5241537250411508
  - 0.5335365853658537
  TL_precision_micro:
  - 0.7
  - 0.6821428571428572
  - 0.7073170731707317
  - 0.6376306620209059
  - 0.5678571428571428
  - 0.5214285714285715
  - 0.5853658536585366
  - 0.5400696864111498
  - 0.49583333333333335
  - 0.4375
  - 0.4024390243902439
  - 0.45934959349593496
  - 0.6166666666666667
  - 0.5875
  - 0.6504065040650406
  - 0.6788617886178862
  TL_precision_weighted:
  - 0.9147368421052631
  - 0.9375098048828316
  - 0.9373254646252046
  - 0.9070166559606537
  - 0.8091012016859475
  - 0.8300869360902255
  - 0.8361884526286278
  - 0.8181041754065297
  - 0.8861066731499492
  - 0.8626534598214286
  - 0.8314292858455776
  - 0.8765652990216343
  - 0.9414062499999999
  - 0.9443787726358149
  - 0.9474718664741932
  - 0.9234334721395994
  TL_recall_macro:
  - 0.6844783715012722
  - 0.6869778161912994
  - 0.7106227106227107
  - 0.6252581577860388
  - 0.5169711102474414
  - 0.455078125
  - 0.5222222222222221
  - 0.49933172948409515
  - 0.44340901389359544
  - 0.34005421890884446
  - 0.3961988304093567
  - 0.3877517332452955
  - 0.6565217391304348
  - 0.5104230533415083
  - 0.6582278481012658
  - 0.6488940244305051
  TL_recall_micro:
  - 0.7
  - 0.6821428571428572
  - 0.7073170731707317
  - 0.6376306620209059
  - 0.5678571428571428
  - 0.5214285714285715
  - 0.5853658536585366
  - 0.5400696864111498
  - 0.49583333333333335
  - 0.4375
  - 0.4024390243902439
  - 0.45934959349593496
  - 0.6166666666666667
  - 0.5875
  - 0.6504065040650406
  - 0.6788617886178862
  TL_recall_weighted:
  - 0.7
  - 0.6821428571428572
  - 0.7073170731707317
  - 0.6376306620209059
  - 0.5678571428571428
  - 0.5214285714285715
  - 0.5853658536585366
  - 0.5400696864111498
  - 0.49583333333333335
  - 0.4375
  - 0.4024390243902439
  - 0.45934959349593496
  - 0.6166666666666667
  - 0.5875
  - 0.6504065040650406
  - 0.6788617886178862
  TL_roc_auc:
  - 0.678011026293469
  - 0.704119850187266
  - 0.7216117216117217
  - 0.6448781495249896
  - 0.5463142894157275
  - 0.5244140625
  - 0.5604700854700855
  - 0.5168404170008019
  - 0.3614029142663504
  - 0.31548627583869876
  - 0.36708089668615984
  - 0.36876857048530864
  - 0.676304347826087
  - 0.46750459840588593
  - 0.670182841068917
  - 0.6115879828326181
  TT_average_precision:
  - 0.07998047703930057
  - 0.0911121672598714
  - 0.08082910158898401
  - 0.10138146167557932
  - 0.06901441881941764
  - 0.1581219825271334
  - 0.16423859195515733
  - 0.09868381958351648
  - 0.13992488992488994
  - 0.21341698252589092
  - 0.018867924528301886
  - 0.13534294799000682
  - 0.07804802955665024
  - 0.06920956458999937
  - 0.05313494938848999
  - -0.0
  TT_balanced_accuracy:
  - 0.5649122807017544
  - 0.43472222222222223
  - 0.4583333333333333
  - 0.668560606060606
  - 0.46195652173913043
  - 0.6131221719457014
  - 0.5469135802469136
  - 0.4299698795180723
  - 0.47435897435897434
  - 0.6153846153846154
  - 0.577922077922078
  - 0.625
  - 0.7283950617283951
  - 0.3076923076923077
  - 0.30405405405405406
  - 0.6666666666666666
  TT_f1_macro:
  - 0.35
  - 0.4397865853658537
  - 0.4232394366197183
  - 0.4574721780604133
  - 0.33943187289359655
  - 0.5678588926996571
  - 0.4252631578947368
  - 0.4362315744499039
  - 0.2762923351158645
  - 0.4457478005865103
  - 0.14975683380848565
  - 0.3856017585638395
  - 0.3735593220338983
  - 0.3636363636363637
  - 0.36585365853658536
  - 0.4
  TT_f1_micro:
  - 0.46938775510204084
  - 0.6938775510204082
  - 0.6043956043956044
  - 0.6703296703296703
  - 0.42857142857142855
  - 0.7244897959183674
  - 0.5054945054945055
  - 0.6813186813186813
  - 0.30952380952380953
  - 0.5714285714285714
  - 0.16666666666666666
  - 0.44871794871794873
  - 0.47619047619047616
  - 0.5714285714285714
  - 0.5769230769230769
  - 0.6666666666666666
  TT_f1_weighted:
  - 0.6115160349854227
  - 0.7554753608760578
  - 0.6967497291440954
  - 0.7748912454794806
  - 0.552376367012862
  - 0.7590016898479138
  - 0.5928050896471948
  - 0.7425904580358756
  - 0.40921823274764446
  - 0.6719731881022204
  - 0.2665884062831908
  - 0.5522285005706877
  - 0.6090072639225181
  - 0.6753246753246754
  - 0.6941838649155723
  - 0.8
  TT_matthews_corrcoef:
  - 0.044878166178569386
  - -0.0831266204956934
  - -0.046188775643785596
  - 0.12700814443190836
  - -0.036860489038724284
  - 0.1738224822264873
  - 0.05872132082230018
  - -0.09126001472437248
  - -0.029235267310234306
  - 0.1194070900728051
  - 0.048592953074986255
  - 0.13612945512202274
  - 0.17075367167606953
  - -0.20672455764868078
  - -0.1788607694502003
  - 0.0
  TT_precision_macro:
  - 0.5077568134171908
  - 0.473536036036036
  - 0.4871995820271683
  - 0.5239247311827957
  - 0.4910714285714286
  - 0.5667735042735043
  - 0.5183752417794971
  - 0.4702685421994885
  - 0.49166666666666664
  - 0.5308924485125859
  - 0.5075757575757576
  - 0.5370624571036376
  - 0.5319148936170213
  - 0.4444444444444444
  - 0.45918367346938777
  - 0.5
  TT_precision_micro:
  - 0.46938775510204084
  - 0.6938775510204082
  - 0.6043956043956044
  - 0.6703296703296703
  - 0.42857142857142855
  - 0.7244897959183674
  - 0.5054945054945055
  - 0.6813186813186813
  - 0.30952380952380953
  - 0.5714285714285714
  - 0.16666666666666666
  - 0.44871794871794873
  - 0.47619047619047616
  - 0.5714285714285714
  - 0.5769230769230769
  - 0.6666666666666666
  TT_precision_weighted:
  - 0.9490009840414152
  - 0.8348961206104063
  - 0.8481633309219516
  - 0.9530426562684626
  - 0.875
  - 0.8136337868480726
  - 0.8232193338576317
  - 0.8220187740648098
  - 0.855952380952381
  - 0.8957175547564565
  - 0.9873737373737373
  - 0.9014835541946045
  - 0.9665653495440729
  - 0.8253968253968254
  - 0.8712715855572998
  - 1.0
  TT_recall_macro:
  - 0.5649122807017544
  - 0.43472222222222223
  - 0.4583333333333333
  - 0.668560606060606
  - 0.46195652173913043
  - 0.6131221719457014
  - 0.5469135802469136
  - 0.4299698795180723
  - 0.47435897435897434
  - 0.6153846153846154
  - 0.577922077922078
  - 0.625
  - 0.7283950617283951
  - 0.3076923076923077
  - 0.30405405405405406
  - 0.3333333333333333
  TT_recall_micro:
  - 0.46938775510204084
  - 0.6938775510204082
  - 0.6043956043956044
  - 0.6703296703296703
  - 0.42857142857142855
  - 0.7244897959183674
  - 0.5054945054945055
  - 0.6813186813186813
  - 0.30952380952380953
  - 0.5714285714285714
  - 0.16666666666666666
  - 0.44871794871794873
  - 0.47619047619047616
  - 0.5714285714285714
  - 0.5769230769230769
  - 0.6666666666666666
  TT_recall_weighted:
  - 0.46938775510204084
  - 0.6938775510204082
  - 0.6043956043956044
  - 0.6703296703296703
  - 0.42857142857142855
  - 0.7244897959183674
  - 0.5054945054945055
  - 0.6813186813186813
  - 0.30952380952380953
  - 0.5714285714285714
  - 0.16666666666666666
  - 0.44871794871794873
  - 0.47619047619047616
  - 0.5714285714285714
  - 0.5769230769230769
  - 0.6666666666666666
  TT_roc_auc:
  - 0.6491228070175439
  - 0.5083333333333334
  - 0.4608843537414966
  - 0.7916666666666666
  - 0.519927536231884
  - 0.5466063348416289
  - 0.5925925925925927
  - 0.5346385542168675
  - 0.5972222222222222
  - 0.7115384615384616
  - 0.33116883116883117
  - 0.576388888888889
  - 0.7160493827160495
  - 0.40705128205128205
  - 0.4307432432432432
  - .nan
  fit_time:
  - 0.28186559677124023
  - 0.3167545795440674
  - 0.298245906829834
  - 0.2943236827850342
  - 0.2935335636138916
  - 0.285322904586792
  - 0.297835111618042
  - 0.2956817150115967
  - 0.2761220932006836
  - 0.28749990463256836
  - 0.2822446823120117
  - 0.2953803539276123
  - 0.2868356704711914
  - 0.3040599822998047
  - 0.29578256607055664
  - 0.28815650939941406
  score_time:
  - 0.841606855392456
  - 0.8407557010650635
  - 0.8277933597564697
  - 0.8538980484008789
  - 0.8492946624755859
  - 0.8258986473083496
  - 0.8447582721710205
  - 0.8141865730285645
  - 0.8399612903594971
  - 0.8423621654510498
  - 0.853234052658081
  - 0.842932939529419
  - 0.8433220386505127
  - 0.8566734790802002
  - 0.8393638134002686
  - 0.9467136859893799
start: 2023-09-22 18:52:48.160977
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
