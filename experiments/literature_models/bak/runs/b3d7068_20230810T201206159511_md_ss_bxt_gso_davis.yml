active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: ../missing_data_simulation/datasets/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: null
  - force_download: false
    path: ../missing_data_simulation/datasets/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: null
  name: davis
  pairwise: true
  y:
    force_download: false
    path: ../missing_data_simulation/datasets/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: null
directory: runs
end: 2023-08-10 20:12:25.593599
estimator:
  call: missing_data_simulation.estimators.md_ss_bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        bipartiteextratreesregressorss:
          call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
          params:
            axis_decision_only: false
            bipartite_adapter: gmosa
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error_gso
            max_col_features: null
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_row_features: null
            max_samples: null
            min_col_weight_fraction_leaf: 0.0
            min_cols_leaf: 1
            min_cols_split: 1
            min_impurity_decrease: 0.0
            min_row_weight_fraction_leaf: 0.0
            min_rows_leaf: 1
            min_rows_split: 1
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            prediction_weights: null
            preprocess_X_targets: null
            random_state: null
            ss_adapter: null
            supervision: 0.5
            unsupervised_criterion_cols: mean_distance
            unsupervised_criterion_rows: mean_distance
            update_supervision: null
            verbose: 0
            warm_start: false
        bipartiteextratreesregressorss__axis_decision_only: false
        bipartiteextratreesregressorss__bipartite_adapter: gmosa
        bipartiteextratreesregressorss__bootstrap: false
        bipartiteextratreesregressorss__ccp_alpha: 0.0
        bipartiteextratreesregressorss__criterion: squared_error_gso
        bipartiteextratreesregressorss__max_col_features: null
        bipartiteextratreesregressorss__max_depth: null
        bipartiteextratreesregressorss__max_features: 1.0
        bipartiteextratreesregressorss__max_leaf_nodes: null
        bipartiteextratreesregressorss__max_row_features: null
        bipartiteextratreesregressorss__max_samples: null
        bipartiteextratreesregressorss__min_col_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_cols_leaf: 1
        bipartiteextratreesregressorss__min_cols_split: 1
        bipartiteextratreesregressorss__min_impurity_decrease: 0.0
        bipartiteextratreesregressorss__min_row_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_rows_leaf: 1
        bipartiteextratreesregressorss__min_rows_split: 1
        bipartiteextratreesregressorss__min_samples_leaf: 1
        bipartiteextratreesregressorss__min_samples_split: 2
        bipartiteextratreesregressorss__min_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__n_estimators: 100
        bipartiteextratreesregressorss__n_jobs: 3
        bipartiteextratreesregressorss__oob_score: false
        bipartiteextratreesregressorss__prediction_weights: null
        bipartiteextratreesregressorss__preprocess_X_targets: null
        bipartiteextratreesregressorss__random_state: null
        bipartiteextratreesregressorss__ss_adapter: null
        bipartiteextratreesregressorss__supervision: 0.5
        bipartiteextratreesregressorss__unsupervised_criterion_cols: mean_distance
        bipartiteextratreesregressorss__unsupervised_criterion_rows: mean_distance
        bipartiteextratreesregressorss__update_supervision: null
        bipartiteextratreesregressorss__verbose: 0
        bipartiteextratreesregressorss__warm_start: false
        memory: null
        minmaxscaler:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: sklearn.preprocessing._data.MinMaxScaler
              params:
                clip: true
                copy: true
                feature_range:
                - 0
                - 1
            transformers__clip: true
            transformers__copy: true
            transformers__feature_range:
            - 0
            - 1
        minmaxscaler__ndim: 2
        minmaxscaler__transformers:
          call: sklearn.preprocessing._data.MinMaxScaler
          params:
            clip: true
            copy: true
            feature_range:
            - 0
            - 1
        minmaxscaler__transformers__clip: true
        minmaxscaler__transformers__copy: true
        minmaxscaler__transformers__feature_range:
        - 0
        - 1
        positivedropper:
          call: missing_data_simulation.positive_dropper.PositiveDropper
          params:
            drop: 0.0
            random_state:
              call: numpy.random.mtrand.RandomState
              params: {}
        positivedropper__drop: 0.0
        positivedropper__random_state:
          call: numpy.random.mtrand.RandomState
          params: {}
        similaritydistanceswitcher:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
              params: {}
        similaritydistanceswitcher__ndim: 2
        similaritydistanceswitcher__transformers:
          call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
          params: {}
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
              samplers__sampling_strategy: auto
        - - minmaxscaler
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: sklearn.preprocessing._data.MinMaxScaler
                params:
                  clip: true
                  copy: true
                  feature_range:
                  - 0
                  - 1
              transformers__clip: true
              transformers__copy: true
              transformers__feature_range:
              - 0
              - 1
        - - similaritydistanceswitcher
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                params: {}
        - - positivedropper
          - call: missing_data_simulation.positive_dropper.PositiveDropper
            params:
              drop: 0.0
              random_state:
                call: numpy.random.mtrand.RandomState
                params: {}
        - - bipartiteextratreesregressorss
          - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
            params:
              axis_decision_only: false
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              preprocess_X_targets: null
              random_state: null
              ss_adapter: null
              supervision: 0.5
              unsupervised_criterion_cols: mean_distance
              unsupervised_criterion_rows: mean_distance
              update_supervision: null
              verbose: 0
              warm_start: false
        symmetryenforcer:
          call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
          params:
            ndim: 2
            samplers:
              call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
              params:
                sampling_strategy: auto
            samplers__sampling_strategy: auto
        symmetryenforcer__ndim: 2
        symmetryenforcer__samplers:
          call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
          params:
            sampling_strategy: auto
        symmetryenforcer__samplers__sampling_strategy: auto
        verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: b3d70683b818f0f31d5d1a9c5a0099eb8ff6f4c07041930409d6cdc0cde00168
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/b3d7068_20230810T201206159511_md_ss_bxt_gso_davis.yml
results:
  LL_average_precision:
  - 0.9918003048851222
  - 0.9830803419583618
  - 0.9866117202228516
  - 0.9896871300562
  - 0.9922844103630667
  - 0.9855066417886618
  - 0.9885001829176884
  - 0.9911034059762622
  - 0.992623096530956
  - 0.9848775972762893
  - 0.988258149424812
  - 0.9923490511737285
  - 0.9938660514675135
  - 0.9854665789379059
  - 0.9886488088866275
  - 0.9907889253217435
  LL_balanced_accuracy:
  - 0.9961992460292937
  - 0.9934059097978227
  - 0.9941817281505323
  - 0.995020413212916
  - 0.9952624361052238
  - 0.9924760173051602
  - 0.9931677793723093
  - 0.994828660436137
  - 0.9959654894171683
  - 0.9930438580073617
  - 0.993781481251166
  - 0.9954680903898684
  - 0.9957870428161278
  - 0.9923776662484316
  - 0.993188351456068
  - 0.9941602648179377
  LL_f1_macro:
  - 0.9577115452776911
  - 0.9385670344845771
  - 0.9430508503686148
  - 0.9499490163526076
  - 0.9560898877327435
  - 0.9391752683804356
  - 0.9425929178474859
  - 0.9543957079871016
  - 0.9590524174137081
  - 0.9386356039741437
  - 0.9442950491089873
  - 0.9570325364769583
  - 0.9614571943551631
  - 0.938983089420615
  - 0.9441165343765789
  - 0.9509811672944286
  LL_f1_micro:
  - 0.9927137017949174
  - 0.9874415022806706
  - 0.988896763524687
  - 0.9904913772738011
  - 0.990995794088028
  - 0.9857828327705704
  - 0.9870659107016301
  - 0.9901960784313726
  - 0.9922990344173923
  - 0.9867898821159884
  - 0.9881880463028585
  - 0.9913772738010866
  - 0.9920028434334459
  - 0.9856051181802026
  - 0.9871249704701157
  - 0.9889558232931727
  LL_f1_weighted:
  - 0.9929940290023415
  - 0.9881296464775737
  - 0.9894641036822266
  - 0.9909197072238183
  - 0.9913483087226703
  - 0.9865398074916663
  - 0.9877194425700497
  - 0.9905922163792295
  - 0.9925831748559223
  - 0.987507977878034
  - 0.9887721181218055
  - 0.9917085151572316
  - 0.9922772420643727
  - 0.9863728840373847
  - 0.9877561700842528
  - 0.989432322029787
  LL_matthews_corrcoef:
  - 0.9187389955638309
  - 0.8839156091618314
  - 0.8919708946240671
  - 0.904484376968046
  - 0.9157498280164594
  - 0.8850171592871974
  - 0.891155474023728
  - 0.9126327975152552
  - 0.9212231324002763
  - 0.8840428980670745
  - 0.8942229648341667
  - 0.9174883987370158
  - 0.9256908560224896
  - 0.88467372969156
  - 0.8939061667409682
  - 0.906376930757222
  LL_precision_macro:
  - 0.925273390036452
  - 0.8958742632612966
  - 0.9024896265560166
  - 0.913160733549083
  - 0.9233097880928356
  - 0.8976109215017065
  - 0.9025800711743772
  - 0.9208015267175573
  - 0.9277777777777778
  - 0.8962790697674419
  - 0.9048525214081826
  - 0.9247422680412372
  - 0.932092555331992
  - 0.8973817567567568
  - 0.9050522648083623
  - 0.9156137184115524
  LL_precision_micro:
  - 0.9927137017949174
  - 0.9874415022806706
  - 0.988896763524687
  - 0.9904913772738011
  - 0.990995794088028
  - 0.9857828327705704
  - 0.9870659107016301
  - 0.9901960784313726
  - 0.9922990344173923
  - 0.9867898821159884
  - 0.9881880463028585
  - 0.9913772738010866
  - 0.9920028434334459
  - 0.9856051181802026
  - 0.9871249704701157
  - 0.9889558232931727
  LL_precision_weighted:
  - 0.993802662523016
  - 0.9900568279353835
  - 0.9910621249949761
  - 0.9921428209188043
  - 0.9923768630069176
  - 0.9886941980735253
  - 0.989585986819373
  - 0.9917489896722048
  - 0.9934113961126578
  - 0.9895302135468113
  - 0.990435801525911
  - 0.99267512743515
  - 0.9930889763675353
  - 0.9885594731482861
  - 0.9895698802588917
  - 0.9908197773041624
  LL_recall_macro:
  - 0.9961992460292937
  - 0.9934059097978227
  - 0.9941817281505323
  - 0.995020413212916
  - 0.9952624361052238
  - 0.9924760173051602
  - 0.9931677793723093
  - 0.994828660436137
  - 0.9959654894171683
  - 0.9930438580073617
  - 0.993781481251166
  - 0.9954680903898684
  - 0.9957870428161278
  - 0.9923776662484316
  - 0.993188351456068
  - 0.9941602648179377
  LL_recall_micro:
  - 0.9927137017949174
  - 0.9874415022806706
  - 0.988896763524687
  - 0.9904913772738011
  - 0.990995794088028
  - 0.9857828327705704
  - 0.9870659107016301
  - 0.9901960784313726
  - 0.9922990344173923
  - 0.9867898821159884
  - 0.9881880463028585
  - 0.9913772738010866
  - 0.9920028434334459
  - 0.9856051181802026
  - 0.9871249704701157
  - 0.9889558232931727
  LL_recall_weighted:
  - 0.9927137017949174
  - 0.9874415022806706
  - 0.988896763524687
  - 0.9904913772738011
  - 0.990995794088028
  - 0.9857828327705704
  - 0.9870659107016301
  - 0.9901960784313726
  - 0.9922990344173923
  - 0.9867898821159884
  - 0.9881880463028585
  - 0.9913772738010866
  - 0.9920028434334459
  - 0.9856051181802026
  - 0.9871249704701157
  - 0.9889558232931727
  LL_roc_auc:
  - 0.9996837560807649
  - 0.9992272574663585
  - 0.9994132593808307
  - 0.9995732509547647
  - 0.9996376837975524
  - 0.9992072033792263
  - 0.9994034927937558
  - 0.9995637922874238
  - 0.9996887260216663
  - 0.99926508643225
  - 0.9994309068858295
  - 0.99965976021081
  - 0.9997030421935845
  - 0.9991983087481349
  - 0.9993912723275182
  - 0.9995294697978745
  LT_average_precision:
  - 0.6894993345457937
  - 0.6291753998933372
  - 0.5927499433895689
  - 0.5042279051460683
  - 0.6923842053097636
  - 0.6153261588433862
  - 0.5779760306561103
  - 0.5040194309446148
  - 0.6790300120160648
  - 0.6031335072610604
  - 0.575768074599344
  - 0.4786483525599874
  - 0.6597697135661734
  - 0.6206873540554936
  - 0.6194922564712737
  - 0.5279268216324547
  LT_balanced_accuracy:
  - 0.899063658216007
  - 0.8747516838325864
  - 0.8697974860335196
  - 0.8604365671641792
  - 0.8919894053986045
  - 0.8757101103993219
  - 0.871333514530378
  - 0.8661836401690242
  - 0.8808051176927971
  - 0.853647164571085
  - 0.8478262504361637
  - 0.8492970946579195
  - 0.8928600022965814
  - 0.8725626740947076
  - 0.8842957489718211
  - 0.8828508834389527
  LT_f1_macro:
  - 0.7337318318485002
  - 0.6912736527970544
  - 0.6909645420008443
  - 0.694806561878111
  - 0.7229631670204664
  - 0.7078008404623801
  - 0.7094057082478408
  - 0.7121056328135974
  - 0.713518889019654
  - 0.7017793395805444
  - 0.6837151904341467
  - 0.6830936255523844
  - 0.7351214144851548
  - 0.7092636507923835
  - 0.7064293786053781
  - 0.7134991086019907
  LT_f1_micro:
  - 0.9077901430842608
  - 0.9175057410351528
  - 0.906951871657754
  - 0.9081996434937611
  - 0.893305069775658
  - 0.9130895601483836
  - 0.906060606060606
  - 0.9023172905525847
  - 0.8936583642465995
  - 0.915915915915916
  - 0.903921568627451
  - 0.8937611408199644
  - 0.899311075781664
  - 0.9079667903197315
  - 0.8992869875222816
  - 0.9019607843137255
  LT_f1_weighted:
  - 0.924979209433084
  - 0.9359460371255468
  - 0.9272150752929439
  - 0.9272599080848841
  - 0.9135665080849035
  - 0.930741361546042
  - 0.9245116506441223
  - 0.9207544731667584
  - 0.9142847153864192
  - 0.9324325999359467
  - 0.9242910114297798
  - 0.9161451400372892
  - 0.9172883148915352
  - 0.9261812447764053
  - 0.9200275572958391
  - 0.9213454138155039
  LT_matthews_corrcoef:
  - 0.5350832463413955
  - 0.4585008097180667
  - 0.4585733348849887
  - 0.45897682121509187
  - 0.5202228974432731
  - 0.4840690966177413
  - 0.48607171896096185
  - 0.4882959824220603
  - 0.500528263729979
  - 0.4636365413892709
  - 0.4378533037577072
  - 0.44049411168511987
  - 0.5363975803876861
  - 0.48597790587428835
  - 0.490490470199035
  - 0.4990888822840859
  LT_precision_macro:
  - 0.6793661704220315
  - 0.6402415263102834
  - 0.6421653144016227
  - 0.6461142830693665
  - 0.6726015163273834
  - 0.6559200057534165
  - 0.6590657096171803
  - 0.6627823722132073
  - 0.6644729358618112
  - 0.6519585508144214
  - 0.6377954620813794
  - 0.6388753767185561
  - 0.6830947173062901
  - 0.6584797279892844
  - 0.6565076519840136
  - 0.6626545237287513
  LT_precision_micro:
  - 0.9077901430842608
  - 0.9175057410351528
  - 0.906951871657754
  - 0.9081996434937611
  - 0.893305069775658
  - 0.9130895601483837
  - 0.906060606060606
  - 0.9023172905525847
  - 0.8936583642465995
  - 0.9159159159159159
  - 0.903921568627451
  - 0.8937611408199644
  - 0.899311075781664
  - 0.9079667903197315
  - 0.8992869875222816
  - 0.9019607843137255
  LT_precision_weighted:
  - 0.9578496027901165
  - 0.9667168687890614
  - 0.9617782646896118
  - 0.9596105826406812
  - 0.952896722151362
  - 0.9614756234147644
  - 0.9572078036502777
  - 0.953737608136851
  - 0.9529294637131562
  - 0.9600379963711014
  - 0.9581742071088298
  - 0.9543650945153088
  - 0.9524799258375886
  - 0.9583219772121154
  - 0.9577981235884291
  - 0.9568335574414902
  LT_recall_macro:
  - 0.899063658216007
  - 0.8747516838325864
  - 0.8697974860335196
  - 0.8604365671641792
  - 0.8919894053986045
  - 0.8757101103993219
  - 0.871333514530378
  - 0.8661836401690242
  - 0.8808051176927971
  - 0.853647164571085
  - 0.8478262504361637
  - 0.8492970946579195
  - 0.8928600022965814
  - 0.8725626740947076
  - 0.8842957489718211
  - 0.8828508834389527
  LT_recall_micro:
  - 0.9077901430842608
  - 0.9175057410351528
  - 0.906951871657754
  - 0.9081996434937611
  - 0.893305069775658
  - 0.9130895601483837
  - 0.906060606060606
  - 0.9023172905525847
  - 0.8936583642465995
  - 0.9159159159159159
  - 0.903921568627451
  - 0.8937611408199644
  - 0.899311075781664
  - 0.9079667903197315
  - 0.8992869875222816
  - 0.9019607843137255
  LT_recall_weighted:
  - 0.9077901430842608
  - 0.9175057410351528
  - 0.906951871657754
  - 0.9081996434937611
  - 0.893305069775658
  - 0.9130895601483837
  - 0.906060606060606
  - 0.9023172905525847
  - 0.8936583642465995
  - 0.9159159159159159
  - 0.903921568627451
  - 0.8937611408199644
  - 0.899311075781664
  - 0.9079667903197315
  - 0.8992869875222816
  - 0.9019607843137255
  LT_roc_auc:
  - 0.9350857301867355
  - 0.91150378698535
  - 0.9231486654252016
  - 0.912001119402985
  - 0.9379977743527781
  - 0.916412670073352
  - 0.9298239873277822
  - 0.9069468278215327
  - 0.9253095948759226
  - 0.9001987649354126
  - 0.9248177888606804
  - 0.9015676919144585
  - 0.9347923648151094
  - 0.9066818726198647
  - 0.9385501482292674
  - 0.9241482849993388
  TL_average_precision:
  - 0.3647179958072993
  - 0.3713690052364441
  - 0.37175953568690145
  - 0.36380531928976184
  - 0.23351350751490899
  - 0.22266284972400324
  - 0.264992246246274
  - 0.21742579357609515
  - 0.35367855756183975
  - 0.34865437866400834
  - 0.31638200710637654
  - 0.3419631638706778
  - 0.14914073204082978
  - 0.16985549253047025
  - 0.18466462570387726
  - 0.18221568214029288
  TL_balanced_accuracy:
  - 0.7438789518224587
  - 0.7809760222689921
  - 0.7501647787443457
  - 0.7535196319352722
  - 0.7499182261897663
  - 0.7639831183309445
  - 0.7693234476367007
  - 0.7633611368551128
  - 0.7428122336379217
  - 0.7511449960827554
  - 0.7452143360750605
  - 0.7118768306072962
  - 0.7276341251367193
  - 0.7400398970034804
  - 0.7583651818661044
  - 0.7432742695900592
  TL_f1_macro:
  - 0.628890368273713
  - 0.6343388197230875
  - 0.6178687586031312
  - 0.6269487659566522
  - 0.570520884684146
  - 0.5867849588704244
  - 0.5882528297286822
  - 0.6004689957645086
  - 0.6298246092577944
  - 0.6475112738248685
  - 0.6291126803551929
  - 0.6088532889793477
  - 0.5873302238258675
  - 0.5879846471803957
  - 0.5927259328575608
  - 0.5835331793596564
  TL_f1_micro:
  - 0.8489425981873112
  - 0.8341922871867781
  - 0.8247696669029058
  - 0.839475549255847
  - 0.8338368580060423
  - 0.8354362893193531
  - 0.8336286321757619
  - 0.8515237420269313
  - 0.8761329305135952
  - 0.8766660742846988
  - 0.8683557760453579
  - 0.8586109142452162
  - 0.8755997867424915
  - 0.8512528878620935
  - 0.8564847625797307
  - 0.8582565556343019
  TL_f1_weighted:
  - 0.8784995789880761
  - 0.8690225188961954
  - 0.8613870922822303
  - 0.8721029004947375
  - 0.8808703738944518
  - 0.8794131111078006
  - 0.8780632220611755
  - 0.8892324567091726
  - 0.9010857343009476
  - 0.8988895947172149
  - 0.8950087130238563
  - 0.8874078023024781
  - 0.9080860440986069
  - 0.8897071417811412
  - 0.8944632466480484
  - 0.8966123498785805
  TL_matthews_corrcoef:
  - 0.3185915750519633
  - 0.3521369356028021
  - 0.3143387154513013
  - 0.3242058850748141
  - 0.2513782055925645
  - 0.2799948865949746
  - 0.2855215650146335
  - 0.29271049496960405
  - 0.31364837968484793
  - 0.34188328838150217
  - 0.3156164490593985
  - 0.2717629040355545
  - 0.24947966186191922
  - 0.26336874761481627
  - 0.27833213917566346
  - 0.2574762407646427
  TL_precision_macro:
  - 0.6040481260637677
  - 0.6103300740881551
  - 0.598743744550618
  - 0.6036502135108612
  - 0.563211678486142
  - 0.5742444602281817
  - 0.5756734744075961
  - 0.5813326473378709
  - 0.6012874275371421
  - 0.6163512957630605
  - 0.6015578294802185
  - 0.5871438795338657
  - 0.568355416444432
  - 0.5722412170706679
  - 0.574960545320546
  - 0.5681268251981644
  TL_precision_micro:
  - 0.8489425981873112
  - 0.8341922871867781
  - 0.8247696669029058
  - 0.8394755492558469
  - 0.8338368580060423
  - 0.8354362893193531
  - 0.8336286321757619
  - 0.8515237420269313
  - 0.8761329305135952
  - 0.8766660742846988
  - 0.8683557760453579
  - 0.8586109142452162
  - 0.8755997867424915
  - 0.8512528878620935
  - 0.8564847625797307
  - 0.8582565556343019
  TL_precision_weighted:
  - 0.9249375770067738
  - 0.928690164622878
  - 0.9219780068262126
  - 0.9250161868472061
  - 0.9515389946637719
  - 0.9476768081383814
  - 0.947713060134889
  - 0.9470357965408969
  - 0.9380980984573773
  - 0.9325794267618874
  - 0.9352539701940149
  - 0.92936923908226
  - 0.9536441271489001
  - 0.9467023373335678
  - 0.9511950702379133
  - 0.9524163058772673
  TL_recall_macro:
  - 0.7438789518224587
  - 0.7809760222689921
  - 0.7501647787443457
  - 0.7535196319352722
  - 0.7499182261897663
  - 0.7639831183309445
  - 0.7693234476367007
  - 0.7633611368551128
  - 0.7428122336379217
  - 0.7511449960827554
  - 0.7452143360750605
  - 0.7118768306072962
  - 0.7276341251367193
  - 0.7400398970034804
  - 0.7583651818661044
  - 0.7432742695900592
  TL_recall_micro:
  - 0.8489425981873112
  - 0.8341922871867781
  - 0.8247696669029058
  - 0.8394755492558469
  - 0.8338368580060423
  - 0.8354362893193531
  - 0.8336286321757619
  - 0.8515237420269313
  - 0.8761329305135952
  - 0.8766660742846988
  - 0.8683557760453579
  - 0.8586109142452162
  - 0.8755997867424915
  - 0.8512528878620935
  - 0.8564847625797307
  - 0.8582565556343019
  TL_recall_weighted:
  - 0.8489425981873112
  - 0.8341922871867781
  - 0.8247696669029058
  - 0.8394755492558469
  - 0.8338368580060423
  - 0.8354362893193531
  - 0.8336286321757619
  - 0.8515237420269313
  - 0.8761329305135952
  - 0.8766660742846988
  - 0.8683557760453579
  - 0.8586109142452162
  - 0.8755997867424915
  - 0.8512528878620935
  - 0.8564847625797307
  - 0.8582565556343019
  TL_roc_auc:
  - 0.7947535699897041
  - 0.8433575592725244
  - 0.8342099763482217
  - 0.8074988257946322
  - 0.8171196878966243
  - 0.808864013832958
  - 0.8062928265425
  - 0.8059976700127666
  - 0.7669604314427381
  - 0.7890653744595653
  - 0.7830164312068728
  - 0.7881170660968628
  - 0.7816520365332662
  - 0.7822630466974146
  - 0.788245832235108
  - 0.7882034632034631
  TT_average_precision:
  - 0.335012871601602
  - 0.28225560147399453
  - 0.3006549161155163
  - 0.301719432485686
  - 0.27898549894016367
  - 0.24632136395591678
  - 0.14899121105349292
  - 0.17177378451737071
  - 0.28219883920930977
  - 0.2473855358244485
  - 0.2303003030315578
  - 0.27019525238560627
  - 0.2332715301825594
  - 0.1545685415872663
  - 0.09440854305790622
  - 0.1549104411220254
  TT_balanced_accuracy:
  - 0.7518433218959395
  - 0.6879040077569489
  - 0.7483341459450674
  - 0.7491805157593123
  - 0.7460952805955854
  - 0.6970860927152318
  - 0.6743104541646767
  - 0.7253677708272984
  - 0.7713444025345602
  - 0.7175934058509561
  - 0.6959338792577751
  - 0.7543785310734463
  - 0.7678817972629284
  - 0.726857472068476
  - 0.6294268058810996
  - 0.6617793609397197
  TT_f1_macro:
  - 0.5902183360379984
  - 0.6053248189274891
  - 0.6182516656253287
  - 0.610778732961586
  - 0.5704334365325078
  - 0.5755735492577597
  - 0.5440470094847975
  - 0.5551775459414632
  - 0.6377543178203394
  - 0.6342045044742596
  - 0.6300047167201634
  - 0.6137693631669535
  - 0.5971864277906498
  - 0.5709511351168876
  - 0.5398634768881135
  - 0.5468992745257337
  TT_f1_micro:
  - 0.7758346581875993
  - 0.8484366719660837
  - 0.8411764705882353
  - 0.8160427807486631
  - 0.7880233174350821
  - 0.8600953895071543
  - 0.8288770053475935
  - 0.8229946524064171
  - 0.8457869634340223
  - 0.9051404345521992
  - 0.8871657754010697
  - 0.8475935828877005
  - 0.8330683624801272
  - 0.8786433492315845
  - 0.8572192513368984
  - 0.8272727272727273
  TT_f1_weighted:
  - 0.8268426081326472
  - 0.8760145189009142
  - 0.8750285928254299
  - 0.8556445337090564
  - 0.8427853276696841
  - 0.8954534434410595
  - 0.8770552861092302
  - 0.8741216947846338
  - 0.8770645989633523
  - 0.9216568490089209
  - 0.9041558902465686
  - 0.8821449280698039
  - 0.8753768258350957
  - 0.9138796916489748
  - 0.8954327283632492
  - 0.8732074669817861
  TT_matthews_corrcoef:
  - 0.29644673591587256
  - 0.25437809472403433
  - 0.30951778813562997
  - 0.3072350364273089
  - 0.264207947390673
  - 0.22094417978338396
  - 0.1766932508391524
  - 0.22134494721103692
  - 0.3475068421511575
  - 0.3012953673400453
  - 0.28623336397817106
  - 0.30582755339122947
  - 0.2965173934223941
  - 0.2266163009692856
  - 0.13885450719592712
  - 0.17281188662984384
  TT_precision_macro:
  - 0.5872374404983101
  - 0.5860921167247387
  - 0.5964439070670172
  - 0.5947038006973085
  - 0.5709134276117086
  - 0.5619225967540574
  - 0.544777154992971
  - 0.554348482788829
  - 0.6112617435755734
  - 0.604298770021957
  - 0.6045372282790255
  - 0.5919205838819986
  - 0.5820535078347578
  - 0.5565938465644859
  - 0.5372422351717778
  - 0.5461491935483871
  TT_precision_micro:
  - 0.7758346581875993
  - 0.8484366719660837
  - 0.8411764705882353
  - 0.8160427807486631
  - 0.7880233174350821
  - 0.8600953895071543
  - 0.8288770053475936
  - 0.8229946524064171
  - 0.8457869634340223
  - 0.9051404345521993
  - 0.8871657754010696
  - 0.8475935828877005
  - 0.8330683624801272
  - 0.8786433492315845
  - 0.8572192513368984
  - 0.8272727272727273
  TT_precision_weighted:
  - 0.9187671858174843
  - 0.9155713030103275
  - 0.928811728482797
  - 0.9218654317951136
  - 0.9340594224307046
  - 0.9447209271399621
  - 0.9445528401825376
  - 0.9497663542532176
  - 0.928787658527959
  - 0.94420053263547
  - 0.9271530561065237
  - 0.9362543809300004
  - 0.9427946871267952
  - 0.9619437859638518
  - 0.9448264285299842
  - 0.9374365835777125
  TT_recall_macro:
  - 0.7518433218959395
  - 0.6879040077569489
  - 0.7483341459450674
  - 0.7491805157593123
  - 0.7460952805955854
  - 0.6970860927152318
  - 0.6743104541646767
  - 0.7253677708272984
  - 0.7713444025345602
  - 0.7175934058509561
  - 0.6959338792577751
  - 0.7543785310734463
  - 0.7678817972629284
  - 0.726857472068476
  - 0.6294268058810996
  - 0.6617793609397197
  TT_recall_micro:
  - 0.7758346581875993
  - 0.8484366719660837
  - 0.8411764705882353
  - 0.8160427807486631
  - 0.7880233174350821
  - 0.8600953895071543
  - 0.8288770053475936
  - 0.8229946524064171
  - 0.8457869634340223
  - 0.9051404345521993
  - 0.8871657754010696
  - 0.8475935828877005
  - 0.8330683624801272
  - 0.8786433492315845
  - 0.8572192513368984
  - 0.8272727272727273
  TT_recall_weighted:
  - 0.7758346581875993
  - 0.8484366719660837
  - 0.8411764705882353
  - 0.8160427807486631
  - 0.7880233174350821
  - 0.8600953895071543
  - 0.8288770053475936
  - 0.8229946524064171
  - 0.8457869634340223
  - 0.9051404345521993
  - 0.8871657754010696
  - 0.8475935828877005
  - 0.8330683624801272
  - 0.8786433492315845
  - 0.8572192513368984
  - 0.8272727272727273
  TT_roc_auc:
  - 0.8071365931324553
  - 0.7502447811703865
  - 0.8173045668779456
  - 0.7814166189111746
  - 0.8108129435325875
  - 0.6919977924944813
  - 0.6920628831353882
  - 0.7599605414588699
  - 0.8059652948719149
  - 0.7922099858117695
  - 0.788134854952522
  - 0.8454293785310735
  - 0.8049685115659441
  - 0.7297997983580584
  - 0.6288472192627318
  - 0.7047402978323403
  fit_time:
  - 13.118448734283447
  - 14.275783777236938
  - 11.70588207244873
  - 11.940051555633545
  - 13.692710161209106
  - 11.657704591751099
  - 12.929874658584595
  - 10.461881637573242
  - 11.285114526748657
  - 12.219525575637817
  - 12.794313669204712
  - 12.742171287536621
  - 12.260457277297974
  - 12.624233722686768
  - 12.73461651802063
  - 12.27746319770813
  score_time:
  - 0.8036487102508545
  - 0.7036664485931396
  - 0.9201076030731201
  - 0.908902645111084
  - 0.7388167381286621
  - 0.8816804885864258
  - 0.8248744010925293
  - 0.9974832534790039
  - 0.9824087619781494
  - 0.9435348510742188
  - 0.9141602516174316
  - 0.9212648868560791
  - 0.9398608207702637
  - 0.9391934871673584
  - 0.9298281669616699
  - 0.8520159721374512
start: 2023-08-10 20:12:06.159511
wrapper: null
