active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: runs
end: 2023-08-03 06:04:51.450485
estimator:
  call: y_reconstruction.estimators.bxt_gso_nrlmf
  final_params:
    memory: /tmp
    steps:
    - - symmetryenforcer
      - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
        params:
          ndim: 2
          samplers:
            call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
            params:
              sampling_strategy: auto
          samplers__sampling_strategy: auto
    - - regressorassampler
      - call: y_reconstruction.estimators.RegressorAsSampler
        params:
          estimator:
            call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
            params:
              cv:
                call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                params: {}
              diagonal: false
              error_score: .nan
              estimator:
                call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
                params:
                  alpha_cols: same
                  alpha_rows: 0.1
                  keep_positives: true
                  lambda_cols: same
                  lambda_rows: 0.625
                  learning_rate: 1.0
                  max_iter: 100
                  n_components_cols: same
                  n_components_rows: 10
                  n_neighbors: 5
                  positive_importance: 5
                  random_state: null
                  resample_X: false
                  tol: 1.0e-05
                  verbose: false
              estimator__alpha_cols: same
              estimator__alpha_rows: 0.1
              estimator__keep_positives: true
              estimator__lambda_cols: same
              estimator__lambda_rows: 0.625
              estimator__learning_rate: 1.0
              estimator__max_iter: 100
              estimator__n_components_cols: same
              estimator__n_components_rows: 10
              estimator__n_neighbors: 5
              estimator__positive_importance: 5
              estimator__random_state: null
              estimator__resample_X: false
              estimator__tol: 1.0e-05
              estimator__verbose: false
              n_iter: 100
              n_jobs: 3
              pairwise: true
              param_distributions:
                alpha_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                alpha_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                learning_rate:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                n_components_rows:
                - 50
                - 100
                n_neighbors:
                - 3
                - 5
                - 10
              pre_dispatch: 2*n_jobs
              random_state: 0
              refit: true
              return_train_score: false
              scoring: null
              train_test_combinations: null
              verbose: 1
          estimator__cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          estimator__diagonal: false
          estimator__error_score: .nan
          estimator__estimator:
            call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
            params:
              alpha_cols: same
              alpha_rows: 0.1
              keep_positives: true
              lambda_cols: same
              lambda_rows: 0.625
              learning_rate: 1.0
              max_iter: 100
              n_components_cols: same
              n_components_rows: 10
              n_neighbors: 5
              positive_importance: 5
              random_state: null
              resample_X: false
              tol: 1.0e-05
              verbose: false
          estimator__estimator__alpha_cols: same
          estimator__estimator__alpha_rows: 0.1
          estimator__estimator__keep_positives: true
          estimator__estimator__lambda_cols: same
          estimator__estimator__lambda_rows: 0.625
          estimator__estimator__learning_rate: 1.0
          estimator__estimator__max_iter: 100
          estimator__estimator__n_components_cols: same
          estimator__estimator__n_components_rows: 10
          estimator__estimator__n_neighbors: 5
          estimator__estimator__positive_importance: 5
          estimator__estimator__random_state: null
          estimator__estimator__resample_X: false
          estimator__estimator__tol: 1.0e-05
          estimator__estimator__verbose: false
          estimator__n_iter: 100
          estimator__n_jobs: 3
          estimator__pairwise: true
          estimator__param_distributions:
            alpha_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            alpha_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            learning_rate:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            n_components_rows:
            - 50
            - 100
            n_neighbors:
            - 3
            - 5
            - 10
          estimator__pre_dispatch: 2*n_jobs
          estimator__random_state: 0
          estimator__refit: true
          estimator__return_train_score: false
          estimator__scoring: null
          estimator__train_test_combinations: null
          estimator__verbose: 1
    - - regressortobinaryclassifier
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error_gso
          estimator__max_col_features: null
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: null
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: bxt_gso_nrlmf
  params:
    regressortobinaryclassifier__estimator__min_cols_leaf: 1
    regressortobinaryclassifier__estimator__min_rows_leaf: 1
    regressortobinaryclassifier__estimator__min_samples_leaf: 1
hash: c2ff130745f4e374f5b0ce0f9bdeb35d337a788b598d2351aeb0cbd2a710ca46
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/c2ff130_20230803T060358714975_bxt_gso_nrlmf_gpcr.yml
results:
  LL_average_precision:
  - 0.9979634180696209
  - 0.992871113819471
  - 0.9978176491153631
  - 0.9969921943932777
  - 0.9921174155869478
  - 0.9956222590586034
  - 0.9899204689215192
  - 0.9833072560562174
  - 0.9936746509846988
  - 0.9951691059166884
  - 0.9910043393317414
  - 0.9908191788874987
  - 0.994561099378361
  - 0.9919819321952549
  - 0.9910610177279666
  - 0.9947459577515493
  LL_balanced_accuracy:
  - 0.960036528091842
  - 0.955407014979905
  - 0.9593453469139026
  - 0.9576015840220385
  - 0.9577843273231623
  - 0.9575925765328246
  - 0.9574117442969903
  - 0.9393314428117212
  - 0.9583770090845563
  - 0.9563723661503278
  - 0.956973293768546
  - 0.9561706537697556
  - 0.9566675264379675
  - 0.9525746816360534
  - 0.9532417346500643
  - 0.9533115510560547
  LL_f1_macro:
  - 0.6984900878247288
  - 0.6947428494399106
  - 0.6998387313605978
  - 0.6717714440754059
  - 0.6766004203597118
  - 0.6778572722332911
  - 0.6780028521738977
  - 0.6136443361738312
  - 0.7092276166577369
  - 0.7041980101169636
  - 0.7011740883651406
  - 0.6808169284620512
  - 0.696415931238396
  - 0.6932336571657316
  - 0.6806716955027732
  - 0.6670237691142259
  LL_f1_micro:
  - 0.9224930420848445
  - 0.9213966433330522
  - 0.9212279666020072
  - 0.9174211938296445
  - 0.917854431981108
  - 0.9175170785190183
  - 0.9171797250569284
  - 0.8816230717639169
  - 0.9196255376570802
  - 0.9180231087121532
  - 0.9168423715948385
  - 0.914906103286385
  - 0.9161676646706587
  - 0.9154191616766467
  - 0.9094311377245509
  - 0.9120370370370371
  LL_f1_weighted:
  - 0.9426357734904262
  - 0.9419390151785108
  - 0.9415341185921355
  - 0.9408696872406268
  - 0.9407995943011198
  - 0.9404355580875565
  - 0.9401635482461971
  - 0.9197130631725338
  - 0.9395054919216423
  - 0.938597490781128
  - 0.9379531555980631
  - 0.9381660653467567
  - 0.937820621395949
  - 0.9373706465843509
  - 0.9339097692052933
  - 0.9371145322696918
  LL_matthews_corrcoef:
  - 0.5083852641602543
  - 0.5010484913020697
  - 0.5105599271384382
  - 0.46920871104224776
  - 0.47639049728216576
  - 0.47832654982387535
  - 0.4785969509085393
  - 0.38748091060999784
  - 0.5246860423604258
  - 0.5168704131918525
  - 0.5131235756799992
  - 0.4831524627854718
  - 0.5061651851954617
  - 0.4997748817874583
  - 0.4837673138406155
  - 0.4622753182184168
  LL_precision_macro:
  - 0.6404538341158059
  - 0.637816053759711
  - 0.6418711656441718
  - 0.6202775636083269
  - 0.623938223938224
  - 0.625
  - 0.6251908396946565
  - 0.5854374633000587
  - 0.6501468428781204
  - 0.6463470642880227
  - 0.644043321299639
  - 0.6279325513196481
  - 0.6402569593147751
  - 0.6379744286416629
  - 0.6290871934604905
  - 0.6178540836517937
  LL_precision_micro:
  - 0.9224930420848444
  - 0.9213966433330522
  - 0.9212279666020072
  - 0.9174211938296445
  - 0.9178544319811082
  - 0.9175170785190183
  - 0.9171797250569284
  - 0.8816230717639169
  - 0.9196255376570802
  - 0.9180231087121532
  - 0.9168423715948385
  - 0.914906103286385
  - 0.9161676646706587
  - 0.9154191616766467
  - 0.9094311377245509
  - 0.9120370370370371
  LL_precision_weighted:
  - 0.978227701180328
  - 0.9779235243888942
  - 0.9776490396033304
  - 0.9801352447762908
  - 0.979638048390684
  - 0.9793792696297545
  - 0.9792633204722692
  - 0.979772351076512
  - 0.9758640564623684
  - 0.9758709329008056
  - 0.9760433980262387
  - 0.9782274413833932
  - 0.9764838631089
  - 0.976251220904226
  - 0.9766174395079051
  - 0.9791236371004102
  LL_recall_macro:
  - 0.960036528091842
  - 0.955407014979905
  - 0.9593453469139026
  - 0.9576015840220385
  - 0.9577843273231623
  - 0.9575925765328246
  - 0.9574117442969903
  - 0.9393314428117212
  - 0.9583770090845563
  - 0.9563723661503278
  - 0.956973293768546
  - 0.9561706537697556
  - 0.9566675264379675
  - 0.9525746816360534
  - 0.9532417346500643
  - 0.9533115510560547
  LL_recall_micro:
  - 0.9224930420848444
  - 0.9213966433330522
  - 0.9212279666020072
  - 0.9174211938296445
  - 0.9178544319811082
  - 0.9175170785190183
  - 0.9171797250569284
  - 0.8816230717639169
  - 0.9196255376570802
  - 0.9180231087121532
  - 0.9168423715948385
  - 0.914906103286385
  - 0.9161676646706587
  - 0.9154191616766467
  - 0.9094311377245509
  - 0.9120370370370371
  LL_recall_weighted:
  - 0.9224930420848444
  - 0.9213966433330522
  - 0.9212279666020072
  - 0.9174211938296445
  - 0.9178544319811082
  - 0.9175170785190183
  - 0.9171797250569284
  - 0.8816230717639169
  - 0.9196255376570802
  - 0.9180231087121532
  - 0.9168423715948385
  - 0.914906103286385
  - 0.9161676646706587
  - 0.9154191616766467
  - 0.9094311377245509
  - 0.9120370370370371
  LL_roc_auc:
  - 0.9999268372215393
  - 0.9992239678480088
  - 0.9999188271583153
  - 0.9998957008900191
  - 0.9996521791730938
  - 0.9997132296881226
  - 0.9995927554903963
  - 0.9991445109168617
  - 0.9996369252954574
  - 0.9995259926316552
  - 0.9995445937237928
  - 0.9993766503978773
  - 0.9996296201495389
  - 0.9991823258971273
  - 0.9994507704281567
  - 0.9995903230480999
  LT_average_precision:
  - 0.2634009267112575
  - 0.29883986055733247
  - 0.2893327096500722
  - 0.3338084470050748
  - 0.32139960739434664
  - 0.41546353219856064
  - 0.2989100266185527
  - 0.3650126303343501
  - 0.2912567694990595
  - 0.36492334357723966
  - 0.3096253061987129
  - 0.3370789285668507
  - 0.23723200742568612
  - 0.34745787125939187
  - 0.2473430667357637
  - 0.27585565686704133
  LT_balanced_accuracy:
  - 0.83400163774841
  - 0.7886171628671682
  - 0.8519007731958763
  - 0.789075294207259
  - 0.8090463110827212
  - 0.7965957903780069
  - 0.7970447345632323
  - 0.7987940792161717
  - 0.8018169527871986
  - 0.7671178264596248
  - 0.8162041354471492
  - 0.7678320287417347
  - 0.7947379758734137
  - 0.7733567474254419
  - 0.8078800135108216
  - 0.7447257383966245
  LT_f1_macro:
  - 0.5896768507483817
  - 0.5562667679001866
  - 0.5739214601769912
  - 0.5975231811697576
  - 0.5874325613713827
  - 0.5555150867330443
  - 0.5661857088066866
  - 0.5801121094164431
  - 0.5698999491674388
  - 0.5550347587950284
  - 0.5875121730854698
  - 0.603866166454448
  - 0.5636278580199988
  - 0.5456368910823945
  - 0.5797957084725408
  - 0.5929722279770225
  LT_f1_micro:
  - 0.8714788732394366
  - 0.8402917505030181
  - 0.8596579476861167
  - 0.8519846350832266
  - 0.8815392354124748
  - 0.8508551307847082
  - 0.8672032193158954
  - 0.8460947503201024
  - 0.8528672032193158
  - 0.8375251509054327
  - 0.8609154929577465
  - 0.8548015364916773
  - 0.8554067460317462
  - 0.8330853174603174
  - 0.8583829365079364
  - 0.8542929292929293
  LT_f1_weighted:
  - 0.9114186439536469
  - 0.8918109001294983
  - 0.9059935943092181
  - 0.8923050973458441
  - 0.9180725934926465
  - 0.9003366623860823
  - 0.9104653977586439
  - 0.8918800504756552
  - 0.8992826070622439
  - 0.8887087004860424
  - 0.9028930802226589
  - 0.8915375703935239
  - 0.9020453489987434
  - 0.8878502031843306
  - 0.9019148426858707
  - 0.8914362120831827
  LT_matthews_corrcoef:
  - 0.30757196331479486
  - 0.2494551515434791
  - 0.29700064756247235
  - 0.3028422228631756
  - 0.28891675318213444
  - 0.24792363186499516
  - 0.257563190866031
  - 0.2860855946750006
  - 0.2705869555238358
  - 0.23826292958480189
  - 0.2998249942919287
  - 0.29875820654617324
  - 0.25718788436314466
  - 0.22968521443899298
  - 0.28565702661241993
  - 0.2716532380395553
  LT_precision_macro:
  - 0.5708084197244089
  - 0.5539017430680478
  - 0.5626663759867817
  - 0.5793161970138422
  - 0.5675245806824755
  - 0.5518096760230413
  - 0.5558323289138878
  - 0.5684794087078743
  - 0.5606471073141487
  - 0.5531312570624269
  - 0.5710735701440409
  - 0.5833138463667038
  - 0.5561054337052913
  - 0.5482476637477873
  - 0.5662595274718771
  - 0.5753859016024049
  LT_precision_micro:
  - 0.8714788732394366
  - 0.8402917505030181
  - 0.8596579476861167
  - 0.8519846350832266
  - 0.8815392354124748
  - 0.8508551307847082
  - 0.8672032193158954
  - 0.8460947503201024
  - 0.8528672032193159
  - 0.8375251509054326
  - 0.8609154929577465
  - 0.8548015364916773
  - 0.855406746031746
  - 0.8330853174603174
  - 0.8583829365079365
  - 0.8542929292929293
  LT_precision_weighted:
  - 0.9707809254258
  - 0.967209595579806
  - 0.9746224270536012
  - 0.9546657460898376
  - 0.9706168619583319
  - 0.9712270225086409
  - 0.9717254646130431
  - 0.9615430268553081
  - 0.9675440806183021
  - 0.9633864423980195
  - 0.9660625262704557
  - 0.9479239631836208
  - 0.9692925161371914
  - 0.9671652915884806
  - 0.9665846035371772
  - 0.9467154638178569
  LT_recall_macro:
  - 0.83400163774841
  - 0.7886171628671682
  - 0.8519007731958763
  - 0.789075294207259
  - 0.8090463110827212
  - 0.7965957903780069
  - 0.7970447345632323
  - 0.7987940792161717
  - 0.8018169527871986
  - 0.7671178264596248
  - 0.8162041354471492
  - 0.7678320287417347
  - 0.7947379758734137
  - 0.7733567474254419
  - 0.8078800135108216
  - 0.7447257383966245
  LT_recall_micro:
  - 0.8714788732394366
  - 0.8402917505030181
  - 0.8596579476861167
  - 0.8519846350832266
  - 0.8815392354124748
  - 0.8508551307847082
  - 0.8672032193158954
  - 0.8460947503201024
  - 0.8528672032193159
  - 0.8375251509054326
  - 0.8609154929577465
  - 0.8548015364916773
  - 0.855406746031746
  - 0.8330853174603174
  - 0.8583829365079365
  - 0.8542929292929293
  LT_recall_weighted:
  - 0.8714788732394366
  - 0.8402917505030181
  - 0.8596579476861167
  - 0.8519846350832266
  - 0.8815392354124748
  - 0.8508551307847082
  - 0.8672032193158954
  - 0.8460947503201024
  - 0.8528672032193159
  - 0.8375251509054326
  - 0.8609154929577465
  - 0.8548015364916773
  - 0.855406746031746
  - 0.8330853174603174
  - 0.8583829365079365
  - 0.8542929292929293
  LT_roc_auc:
  - 0.8822367102030761
  - 0.809813927777501
  - 0.9059707903780068
  - 0.8712222195293378
  - 0.869838390290642
  - 0.8396236039518901
  - 0.87275970929659
  - 0.8828282705696265
  - 0.8602706199083948
  - 0.8185061893276456
  - 0.8917494720819801
  - 0.870558828780575
  - 0.8631668102772991
  - 0.8336781951306625
  - 0.8781059733421096
  - 0.8584928169580067
  TL_average_precision:
  - 0.43121933455156
  - 0.4566000696241005
  - 0.4343421392087964
  - 0.34908373455224945
  - 0.55376822649198
  - 0.573407982778399
  - 0.5957988101352996
  - 0.44750057848834024
  - 0.5214949864081364
  - 0.5434819786648072
  - 0.5304963943304999
  - 0.4923951032251052
  - 0.5352992377573942
  - 0.4946544782427616
  - 0.5597458897321514
  - 0.514705461833494
  TL_balanced_accuracy:
  - 0.8144648133803827
  - 0.8170467911753736
  - 0.8244159361474144
  - 0.7812789290828163
  - 0.7882599422718949
  - 0.784012154813946
  - 0.782029643917667
  - 0.7224075975359343
  - 0.8463810709091182
  - 0.8664916812647115
  - 0.8468133316854118
  - 0.8331971518617952
  - 0.8653028538147932
  - 0.8400956531315388
  - 0.845656168103612
  - 0.8289583491389121
  TL_f1_macro:
  - 0.5477449554017009
  - 0.5514212562062046
  - 0.5350607496445
  - 0.5165041649483246
  - 0.603217682010641
  - 0.5912894422229947
  - 0.58481489592562
  - 0.5393672994198426
  - 0.5688622754491018
  - 0.5859278394145997
  - 0.5654903217972432
  - 0.560349994006952
  - 0.6330148971702696
  - 0.6336009534668666
  - 0.6317529858836846
  - 0.6104254670106664
  TL_f1_micro:
  - 0.7934131736526946
  - 0.7984031936127745
  - 0.7826846307385229
  - 0.7718253968253969
  - 0.8483033932135727
  - 0.8400698602794411
  - 0.8338323353293413
  - 0.8132440476190477
  - 0.8682634730538922
  - 0.8784930139720559
  - 0.8545409181636726
  - 0.8700396825396826
  - 0.906534756573809
  - 0.911481385055975
  - 0.9002863837542305
  - 0.8990683229813665
  TL_f1_weighted:
  - 0.8586142173591195
  - 0.8618511425632179
  - 0.8537124721873727
  - 0.847811783923283
  - 0.8881395469075098
  - 0.8837476503379603
  - 0.8800417570743618
  - 0.8705916716388875
  - 0.9129047294632292
  - 0.9185264201670654
  - 0.9034381282556384
  - 0.9150654883192639
  - 0.9331773725531043
  - 0.9357388098763098
  - 0.9277128131099115
  - 0.9287483761208671
  TL_matthews_corrcoef:
  - 0.26991435113006057
  - 0.27425451346044744
  - 0.2610751690665719
  - 0.21779137495907858
  - 0.311250150649116
  - 0.2956315364909267
  - 0.28799270331893845
  - 0.20261137602414586
  - 0.283098910430106
  - 0.3138939266384043
  - 0.2839997928161703
  - 0.26344863355551
  - 0.3730560873355965
  - 0.3604459437766207
  - 0.36393225089241454
  - 0.32563485821761906
  TL_precision_macro:
  - 0.5579188464385014
  - 0.5593094933042718
  - 0.5525253511838635
  - 0.5421584040806344
  - 0.5840184865052466
  - 0.5769315713135938
  - 0.5735204604849647
  - 0.5461442978445972
  - 0.5578445242954264
  - 0.5672112098427888
  - 0.558140702036787
  - 0.5520751619082368
  - 0.5952434691139199
  - 0.5955034834970158
  - 0.5957936639509915
  - 0.5805862361937129
  TL_precision_micro:
  - 0.7934131736526946
  - 0.7984031936127745
  - 0.7826846307385229
  - 0.7718253968253969
  - 0.8483033932135728
  - 0.8400698602794411
  - 0.8338323353293413
  - 0.8132440476190477
  - 0.8682634730538922
  - 0.8784930139720559
  - 0.8545409181636726
  - 0.8700396825396826
  - 0.9065347565738089
  - 0.911481385055975
  - 0.9002863837542306
  - 0.8990683229813664
  TL_precision_weighted:
  - 0.9635768165429504
  - 0.9637132271292415
  - 0.9678271384531532
  - 0.9664508756139613
  - 0.9508916208365168
  - 0.9521434992571371
  - 0.9524554681698167
  - 0.954726502544326
  - 0.9770520983049239
  - 0.9771869009759019
  - 0.9752399752462704
  - 0.9782267808458175
  - 0.9737229195203804
  - 0.97192393157102
  - 0.9695597699233885
  - 0.9720715895238448
  TL_recall_macro:
  - 0.8144648133803827
  - 0.8170467911753736
  - 0.8244159361474144
  - 0.7812789290828163
  - 0.7882599422718949
  - 0.784012154813946
  - 0.782029643917667
  - 0.7224075975359343
  - 0.8463810709091182
  - 0.8664916812647115
  - 0.8468133316854118
  - 0.8331971518617952
  - 0.8653028538147932
  - 0.8400956531315388
  - 0.845656168103612
  - 0.8289583491389121
  TL_recall_micro:
  - 0.7934131736526946
  - 0.7984031936127745
  - 0.7826846307385229
  - 0.7718253968253969
  - 0.8483033932135728
  - 0.8400698602794411
  - 0.8338323353293413
  - 0.8132440476190477
  - 0.8682634730538922
  - 0.8784930139720559
  - 0.8545409181636726
  - 0.8700396825396826
  - 0.9065347565738089
  - 0.911481385055975
  - 0.9002863837542306
  - 0.8990683229813664
  TL_recall_weighted:
  - 0.7934131736526946
  - 0.7984031936127745
  - 0.7826846307385229
  - 0.7718253968253969
  - 0.8483033932135728
  - 0.8400698602794411
  - 0.8338323353293413
  - 0.8132440476190477
  - 0.8682634730538922
  - 0.8784930139720559
  - 0.8545409181636726
  - 0.8700396825396826
  - 0.9065347565738089
  - 0.911481385055975
  - 0.9002863837542306
  - 0.8990683229813664
  TL_roc_auc:
  - 0.8846028057492039
  - 0.8930659551883409
  - 0.8900192367726096
  - 0.8531351633348503
  - 0.833569722136392
  - 0.8546659307714982
  - 0.8667562371513413
  - 0.7970844908805411
  - 0.8648003478730264
  - 0.887585975555562
  - 0.8820198025240664
  - 0.8418544025524298
  - 0.9132048498967543
  - 0.8947789332368411
  - 0.9098641232101484
  - 0.8836582960321675
  TT_average_precision:
  - 0.10705077218612234
  - 0.14435564058379557
  - 0.1370089845148642
  - 0.1805763546128392
  - 0.07080763750819354
  - 0.09379009842479813
  - 0.09708731816282869
  - 0.2371471717487924
  - 0.1444215345053782
  - 0.25705494188239586
  - 0.11414304090465836
  - 0.17866234192529643
  - 0.23180659307785711
  - 0.29260550321981443
  - 0.22704715958978663
  - 0.279796364195886
  TT_balanced_accuracy:
  - 0.7655590480466996
  - 0.7208801077682983
  - 0.7617004872127167
  - 0.7997191504300509
  - 0.6565950920245398
  - 0.6550878459292311
  - 0.7334804191947049
  - 0.719285139639122
  - 0.7856925418569254
  - 0.7160032683553169
  - 0.7728304222252784
  - 0.7059678540582672
  - 0.7668459826733207
  - 0.783013844515442
  - 0.82972288202692
  - 0.809030612244898
  TT_f1_macro:
  - 0.5034241256124595
  - 0.48147249050649377
  - 0.5303835056461819
  - 0.5261655097720671
  - 0.5223968385258708
  - 0.5124736114190935
  - 0.5448564813113308
  - 0.564341012677599
  - 0.5593929571239132
  - 0.5235313939121645
  - 0.5312854923564967
  - 0.5524556814879396
  - 0.6095252065913647
  - 0.6001619651774868
  - 0.5834603834603835
  - 0.6145278969957082
  TT_f1_micro:
  - 0.7663690476190478
  - 0.7351190476190476
  - 0.7775297619047619
  - 0.7348484848484848
  - 0.8273809523809523
  - 0.7894345238095238
  - 0.8080357142857142
  - 0.781060606060606
  - 0.8675595238095238
  - 0.8497023809523809
  - 0.8608630952380952
  - 0.8621212121212121
  - 0.9037267080745341
  - 0.8928571428571429
  - 0.8967391304347826
  - 0.8877470355731225
  TT_f1_weighted:
  - 0.8464892794779056
  - 0.8257841999486415
  - 0.8472376803366689
  - 0.8148912698093025
  - 0.8813353114428383
  - 0.854231894230582
  - 0.8657188338417434
  - 0.8357642628221599
  - 0.9114266507398596
  - 0.9024998428833515
  - 0.9114548656893078
  - 0.90386119257087
  - 0.9289890910283661
  - 0.923135954341245
  - 0.9306753241535851
  - 0.9185322906240988
  TT_matthews_corrcoef:
  - 0.1933779300080181
  - 0.1553035442499316
  - 0.2252682888321279
  - 0.26024622796650476
  - 0.14130919422250052
  - 0.13957722959610583
  - 0.21753909894121914
  - 0.24194272133571143
  - 0.24227438723119177
  - 0.16516953879237137
  - 0.19659503192145858
  - 0.19586635218600312
  - 0.292956655482889
  - 0.2908535245026567
  - 0.2869731617857407
  - 0.32537816654643786
  TT_precision_macro:
  - 0.5352040573360637
  - 0.5272989622065598
  - 0.5484769845996766
  - 0.5564929693961952
  - 0.5318788541097494
  - 0.531404464522987
  - 0.5506715506715506
  - 0.566735347985348
  - 0.5513636778254127
  - 0.5315747265684987
  - 0.5354154113945236
  - 0.5465650672699132
  - 0.5804055593529278
  - 0.5747275922671353
  - 0.5624415229230142
  - 0.5856476244343891
  TT_precision_micro:
  - 0.7663690476190477
  - 0.7351190476190477
  - 0.7775297619047619
  - 0.7348484848484849
  - 0.8273809523809523
  - 0.7894345238095238
  - 0.8080357142857143
  - 0.781060606060606
  - 0.8675595238095238
  - 0.8497023809523809
  - 0.8608630952380952
  - 0.8621212121212121
  - 0.9037267080745341
  - 0.8928571428571429
  - 0.8967391304347826
  - 0.8877470355731225
  TT_precision_weighted:
  - 0.9689783626317807
  - 0.966336096289895
  - 0.9574998012159003
  - 0.9568020151891119
  - 0.9544067412305646
  - 0.9470456682706299
  - 0.9525208587708588
  - 0.925791742979243
  - 0.9725208004847472
  - 0.97258430753843
  - 0.9788975801541075
  - 0.9604418635696168
  - 0.9644680589106874
  - 0.9662716545317599
  - 0.977964051135433
  - 0.9644706955448644
  TT_recall_macro:
  - 0.7655590480466996
  - 0.7208801077682983
  - 0.7617004872127167
  - 0.7997191504300509
  - 0.6565950920245398
  - 0.6550878459292311
  - 0.7334804191947049
  - 0.719285139639122
  - 0.7856925418569254
  - 0.7160032683553169
  - 0.7728304222252784
  - 0.7059678540582672
  - 0.7668459826733207
  - 0.783013844515442
  - 0.82972288202692
  - 0.809030612244898
  TT_recall_micro:
  - 0.7663690476190477
  - 0.7351190476190477
  - 0.7775297619047619
  - 0.7348484848484849
  - 0.8273809523809523
  - 0.7894345238095238
  - 0.8080357142857143
  - 0.781060606060606
  - 0.8675595238095238
  - 0.8497023809523809
  - 0.8608630952380952
  - 0.8621212121212121
  - 0.9037267080745341
  - 0.8928571428571429
  - 0.8967391304347826
  - 0.8877470355731225
  TT_recall_weighted:
  - 0.7663690476190477
  - 0.7351190476190477
  - 0.7775297619047619
  - 0.7348484848484849
  - 0.8273809523809523
  - 0.7894345238095238
  - 0.8080357142857143
  - 0.781060606060606
  - 0.8675595238095238
  - 0.8497023809523809
  - 0.8608630952380952
  - 0.8621212121212121
  - 0.9037267080745341
  - 0.8928571428571429
  - 0.8967391304347826
  - 0.8877470355731225
  TT_roc_auc:
  - 0.7953075886843286
  - 0.7893578805568029
  - 0.8118571498876294
  - 0.8561523608916974
  - 0.7277223926380367
  - 0.7167604455453664
  - 0.7776219368056103
  - 0.7977975363333367
  - 0.8138508371385084
  - 0.7685304073771448
  - 0.8106862879933985
  - 0.7941480061511238
  - 0.8576274115842462
  - 0.7969027334043308
  - 0.9015676959619952
  - 0.9006122448979592
  fit_time:
  - 49.06443643569946
  - 50.83032488822937
  - 51.08798289299011
  - 51.964019536972046
  - 49.26213335990906
  - 51.34608006477356
  - 50.61422085762024
  - 50.443257093429565
  - 50.623960733413696
  - 51.72953009605408
  - 49.577879667282104
  - 50.82510447502136
  - 50.900609254837036
  - 51.61580967903137
  - 50.00144124031067
  - 49.523905515670776
  score_time:
  - 0.9012911319732666
  - 0.8565459251403809
  - 0.7765579223632812
  - 0.7091693878173828
  - 0.8955914974212646
  - 0.8064396381378174
  - 0.8519973754882812
  - 0.8291735649108887
  - 0.8265750408172607
  - 0.6804285049438477
  - 0.9351174831390381
  - 0.8801021575927734
  - 0.8223540782928467
  - 0.7450137138366699
  - 0.9081459045410156
  - 0.7908868789672852
start: 2023-08-03 06:03:58.714975
