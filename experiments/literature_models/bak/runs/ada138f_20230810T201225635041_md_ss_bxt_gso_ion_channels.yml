active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: runs
end: 2023-08-10 20:12:33.695676
estimator:
  call: missing_data_simulation.estimators.md_ss_bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        bipartiteextratreesregressorss:
          call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
          params:
            axis_decision_only: false
            bipartite_adapter: gmosa
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error_gso
            max_col_features: null
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_row_features: null
            max_samples: null
            min_col_weight_fraction_leaf: 0.0
            min_cols_leaf: 1
            min_cols_split: 1
            min_impurity_decrease: 0.0
            min_row_weight_fraction_leaf: 0.0
            min_rows_leaf: 1
            min_rows_split: 1
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            prediction_weights: null
            preprocess_X_targets: null
            random_state: null
            ss_adapter: null
            supervision: 0.5
            unsupervised_criterion_cols: mean_distance
            unsupervised_criterion_rows: mean_distance
            update_supervision: null
            verbose: 0
            warm_start: false
        bipartiteextratreesregressorss__axis_decision_only: false
        bipartiteextratreesregressorss__bipartite_adapter: gmosa
        bipartiteextratreesregressorss__bootstrap: false
        bipartiteextratreesregressorss__ccp_alpha: 0.0
        bipartiteextratreesregressorss__criterion: squared_error_gso
        bipartiteextratreesregressorss__max_col_features: null
        bipartiteextratreesregressorss__max_depth: null
        bipartiteextratreesregressorss__max_features: 1.0
        bipartiteextratreesregressorss__max_leaf_nodes: null
        bipartiteextratreesregressorss__max_row_features: null
        bipartiteextratreesregressorss__max_samples: null
        bipartiteextratreesregressorss__min_col_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_cols_leaf: 1
        bipartiteextratreesregressorss__min_cols_split: 1
        bipartiteextratreesregressorss__min_impurity_decrease: 0.0
        bipartiteextratreesregressorss__min_row_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_rows_leaf: 1
        bipartiteextratreesregressorss__min_rows_split: 1
        bipartiteextratreesregressorss__min_samples_leaf: 1
        bipartiteextratreesregressorss__min_samples_split: 2
        bipartiteextratreesregressorss__min_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__n_estimators: 100
        bipartiteextratreesregressorss__n_jobs: 3
        bipartiteextratreesregressorss__oob_score: false
        bipartiteextratreesregressorss__prediction_weights: null
        bipartiteextratreesregressorss__preprocess_X_targets: null
        bipartiteextratreesregressorss__random_state: null
        bipartiteextratreesregressorss__ss_adapter: null
        bipartiteextratreesregressorss__supervision: 0.5
        bipartiteextratreesregressorss__unsupervised_criterion_cols: mean_distance
        bipartiteextratreesregressorss__unsupervised_criterion_rows: mean_distance
        bipartiteextratreesregressorss__update_supervision: null
        bipartiteextratreesregressorss__verbose: 0
        bipartiteextratreesregressorss__warm_start: false
        memory: null
        minmaxscaler:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: sklearn.preprocessing._data.MinMaxScaler
              params:
                clip: true
                copy: true
                feature_range:
                - 0
                - 1
            transformers__clip: true
            transformers__copy: true
            transformers__feature_range:
            - 0
            - 1
        minmaxscaler__ndim: 2
        minmaxscaler__transformers:
          call: sklearn.preprocessing._data.MinMaxScaler
          params:
            clip: true
            copy: true
            feature_range:
            - 0
            - 1
        minmaxscaler__transformers__clip: true
        minmaxscaler__transformers__copy: true
        minmaxscaler__transformers__feature_range:
        - 0
        - 1
        positivedropper:
          call: missing_data_simulation.positive_dropper.PositiveDropper
          params:
            drop: 0.0
            random_state:
              call: numpy.random.mtrand.RandomState
              params: {}
        positivedropper__drop: 0.0
        positivedropper__random_state:
          call: numpy.random.mtrand.RandomState
          params: {}
        similaritydistanceswitcher:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
              params: {}
        similaritydistanceswitcher__ndim: 2
        similaritydistanceswitcher__transformers:
          call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
          params: {}
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
              samplers__sampling_strategy: auto
        - - minmaxscaler
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: sklearn.preprocessing._data.MinMaxScaler
                params:
                  clip: true
                  copy: true
                  feature_range:
                  - 0
                  - 1
              transformers__clip: true
              transformers__copy: true
              transformers__feature_range:
              - 0
              - 1
        - - similaritydistanceswitcher
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                params: {}
        - - positivedropper
          - call: missing_data_simulation.positive_dropper.PositiveDropper
            params:
              drop: 0.0
              random_state:
                call: numpy.random.mtrand.RandomState
                params: {}
        - - bipartiteextratreesregressorss
          - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
            params:
              axis_decision_only: false
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              preprocess_X_targets: null
              random_state: null
              ss_adapter: null
              supervision: 0.5
              unsupervised_criterion_cols: mean_distance
              unsupervised_criterion_rows: mean_distance
              update_supervision: null
              verbose: 0
              warm_start: false
        symmetryenforcer:
          call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
          params:
            ndim: 2
            samplers:
              call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
              params:
                sampling_strategy: auto
            samplers__sampling_strategy: auto
        symmetryenforcer__ndim: 2
        symmetryenforcer__samplers:
          call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
          params:
            sampling_strategy: auto
        symmetryenforcer__samplers__sampling_strategy: auto
        verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: ada138fd8f921318a096ca5e36d9c655b5258d32b4d95a3013d142c076ca4102
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/ada138f_20230810T201225635041_md_ss_bxt_gso_ion_channels.yml
results:
  LL_average_precision:
  - 0.9999898545137269
  - 0.9998399470899471
  - 0.9999649049773173
  - 0.9998125722216542
  - 0.999988012818293
  - 0.9998303302250579
  - 0.9999794400847363
  - 0.999810691991176
  - 0.9999822462529706
  - 0.9997706857716627
  - 0.9999753769785498
  - 0.9997382158402652
  - 0.9999986463437746
  - 0.9999287850733514
  - 0.9999807356035684
  - 0.9999180999180999
  LL_balanced_accuracy:
  - 0.9995894022561265
  - 0.9991147385239885
  - 0.9990792685538092
  - 0.999679158110883
  - 0.9981864501921499
  - 0.999568630834268
  - 0.9994219405669265
  - 0.9995508982035928
  - 0.9995252481657315
  - 0.9995036471146791
  - 0.9993360178204249
  - 0.9992300124053557
  - 0.9995250841896209
  - 0.9995904289717612
  - 0.999464874352498
  - 0.9995299948726714
  LL_f1_macro:
  - 0.9944784444422803
  - 0.9879685090098106
  - 0.9868097843173956
  - 0.9951840340868545
  - 0.9758614891312796
  - 0.9938949408296476
  - 0.9916124227865379
  - 0.9932495557926233
  - 0.993382000893851
  - 0.9930927541636816
  - 0.9905016144659617
  - 0.9885717647485225
  - 0.9934405901882544
  - 0.9941099121452239
  - 0.992179423829225
  - 0.9927226334108614
  LL_f1_micro:
  - 0.9992090254360768
  - 0.998293160151534
  - 0.9982212294200381
  - 0.999379498634897
  - 0.9965030598226552
  - 0.9991673951958703
  - 0.9988830975428146
  - 0.9991312980888558
  - 0.9990841347154573
  - 0.9990425044752508
  - 0.9987176305121205
  - 0.9985107967237528
  - 0.9990841347154573
  - 0.9992090254360768
  - 0.9989658310581616
  - 0.9990899313311823
  LL_f1_weighted:
  - 0.9992130679402993
  - 0.998312183641414
  - 0.998243052508293
  - 0.9993822878015955
  - 0.996581117353744
  - 0.9991721189824279
  - 0.9988918196389811
  - 0.9991367719017616
  - 0.9990897608958438
  - 0.9990486426405495
  - 0.998728958915689
  - 0.9985266681374819
  - 0.9990897070856201
  - 0.9992133602527445
  - 0.9989733651485174
  - 0.999096126296433
  LL_matthews_corrcoef:
  - 0.9890172439023739
  - 0.9762201704440013
  - 0.9739591329493208
  - 0.9904140401387802
  - 0.9528378888468162
  - 0.9878635845245473
  - 0.9833633719468153
  - 0.9865891085643497
  - 0.9868505287371612
  - 0.9862797138357358
  - 0.9811805148729976
  - 0.9773992487441059
  - 0.9869661919544315
  - 0.9882884545625915
  - 0.9844794038781127
  - 0.985549756919217
  LL_precision_macro:
  - 0.9894795127353266
  - 0.9773480662983425
  - 0.9751732101616628
  - 0.9907749077490775
  - 0.9556025369978858
  - 0.9883585564610011
  - 0.9840613931523022
  - 0.987116564417178
  - 0.9873997709049256
  - 0.9868571428571429
  - 0.9819976771196284
  - 0.978391356542617
  - 0.9875141884222474
  - 0.9887573964497041
  - 0.9851190476190477
  - 0.9861111111111112
  LL_precision_micro:
  - 0.9992090254360768
  - 0.998293160151534
  - 0.9982212294200381
  - 0.999379498634897
  - 0.9965030598226552
  - 0.9991673951958703
  - 0.9988830975428146
  - 0.9991312980888558
  - 0.9990841347154573
  - 0.9990425044752508
  - 0.9987176305121205
  - 0.9985107967237528
  - 0.9990841347154573
  - 0.9992090254360768
  - 0.9989658310581616
  - 0.9990899313311823
  LL_precision_weighted:
  - 0.9992256683117297
  - 0.9983704865977077
  - 0.9983095517467566
  - 0.9993909469995668
  - 0.9968135703669436
  - 0.9991867806395054
  - 0.9989187012811191
  - 0.9991536818190816
  - 0.9991072149402682
  - 0.9990676729290443
  - 0.9987638017712659
  - 0.9985751560490167
  - 0.9991070053582042
  - 0.9992268106629578
  - 0.9989966098957163
  - 0.9991152110164271
  LL_recall_macro:
  - 0.9995894022561265
  - 0.9991147385239885
  - 0.9990792685538092
  - 0.999679158110883
  - 0.9981864501921499
  - 0.999568630834268
  - 0.9994219405669265
  - 0.9995508982035928
  - 0.9995252481657315
  - 0.9995036471146791
  - 0.9993360178204249
  - 0.9992300124053557
  - 0.9995250841896209
  - 0.9995904289717612
  - 0.999464874352498
  - 0.9995299948726714
  LL_recall_micro:
  - 0.9992090254360768
  - 0.998293160151534
  - 0.9982212294200381
  - 0.999379498634897
  - 0.9965030598226552
  - 0.9991673951958703
  - 0.9988830975428146
  - 0.9991312980888558
  - 0.9990841347154573
  - 0.9990425044752508
  - 0.9987176305121205
  - 0.9985107967237528
  - 0.9990841347154573
  - 0.9992090254360768
  - 0.9989658310581616
  - 0.9990899313311823
  LL_recall_weighted:
  - 0.9992090254360768
  - 0.998293160151534
  - 0.9982212294200381
  - 0.999379498634897
  - 0.9965030598226552
  - 0.9991673951958703
  - 0.9988830975428146
  - 0.9991312980888558
  - 0.9990841347154573
  - 0.9990425044752508
  - 0.9987176305121205
  - 0.9985107967237528
  - 0.9990841347154573
  - 0.9992090254360768
  - 0.9989658310581616
  - 0.9990899313311823
  LL_roc_auc:
  - 0.9999996577537262
  - 0.9999969761563178
  - 0.9999987771799721
  - 0.9999967567361251
  - 0.9999995742135298
  - 0.9999968894118562
  - 0.9999993211587507
  - 0.9999967409549378
  - 0.9999993660508569
  - 0.9999957193489682
  - 0.9999991742157114
  - 0.999995464662502
  - 0.99999994973904
  - 0.9999987212322936
  - 0.999999317140278
  - 0.9999986404810367
  LT_average_precision:
  - 0.4709661087241369
  - 0.1748740489310256
  - 0.2781949031698667
  - 0.3344923234697534
  - 0.5007130890821225
  - 0.16394084516554996
  - 0.24836138103566813
  - 0.31140478863268967
  - 0.480214115317944
  - 0.1428236828350427
  - 0.20539379436320154
  - 0.30815102222861196
  - 0.453540092753917
  - 0.16367388131571736
  - 0.2855181981940428
  - 0.3528143850027598
  LT_balanced_accuracy:
  - 0.8090566900416283
  - 0.6965796916115388
  - 0.7325522466039707
  - 0.7206919145590355
  - 0.8068621634601802
  - 0.6735120825140756
  - 0.6923128117517101
  - 0.7182608896805385
  - 0.8175353515480903
  - 0.6686076133095177
  - 0.6641833544256681
  - 0.71765849767939
  - 0.8301211989330801
  - 0.6791529057303436
  - 0.7031243564403309
  - 0.7386115112624411
  LT_f1_macro:
  - 0.601115261328717
  - 0.5909247160320723
  - 0.6146967607905515
  - 0.6433376304897789
  - 0.6013961042654182
  - 0.5704976865031424
  - 0.5882114498933166
  - 0.6440647478560451
  - 0.6192482583034311
  - 0.5606953993496284
  - 0.5660774019002239
  - 0.6346799359028422
  - 0.6127146209088088
  - 0.5755459059896485
  - 0.5877276806488068
  - 0.6517211050735551
  LT_f1_micro:
  - 0.8813663830311999
  - 0.9004809470958195
  - 0.8951734539969834
  - 0.916289592760181
  - 0.8806264644222469
  - 0.8848193365396473
  - 0.888763197586727
  - 0.920940170940171
  - 0.8888888888888888
  - 0.8772968306819583
  - 0.8765711412770236
  - 0.9137757667169433
  - 0.890368726106795
  - 0.8891355284252066
  - 0.8871292106586224
  - 0.9177978883861236
  LT_f1_weighted:
  - 0.915753529639979
  - 0.9240465405295071
  - 0.9186429239058304
  - 0.9298587564017842
  - 0.9150211279099599
  - 0.9138183067030268
  - 0.9148077730452261
  - 0.9334482953690819
  - 0.9191958003277878
  - 0.9099043865818163
  - 0.907297564817135
  - 0.9288663667149446
  - 0.921951577280641
  - 0.916625235643015
  - 0.9147730687391747
  - 0.931648879982205
  LT_matthews_corrcoef:
  - 0.30852594058200306
  - 0.23235340164709228
  - 0.2841779701466005
  - 0.3143929415378417
  - 0.3080811035435874
  - 0.19620986435452087
  - 0.22858775223702482
  - 0.3137634155755865
  - 0.33591120246207923
  - 0.1826233723327916
  - 0.18693948489042342
  - 0.30090023744048133
  - 0.33234544332670646
  - 0.20495523274558103
  - 0.2341835164286918
  - 0.3349272629432341
  LT_precision_macro:
  - 0.5769990256473564
  - 0.5686593091259662
  - 0.5868161025059554
  - 0.6119693509006829
  - 0.5773262213972423
  - 0.5554692075505698
  - 0.5679262603422348
  - 0.6127635385086085
  - 0.5888376171262548
  - 0.5494510530508749
  - 0.55321241476236
  - 0.6039942775690573
  - 0.5836461684806975
  - 0.5586184288479008
  - 0.5674979607664843
  - 0.6175302386598474
  LT_precision_micro:
  - 0.8813663830311999
  - 0.9004809470958195
  - 0.8951734539969834
  - 0.916289592760181
  - 0.8806264644222469
  - 0.8848193365396473
  - 0.888763197586727
  - 0.9209401709401709
  - 0.8888888888888888
  - 0.8772968306819583
  - 0.8765711412770236
  - 0.9137757667169432
  - 0.890368726106795
  - 0.8891355284252066
  - 0.8871292106586224
  - 0.9177978883861236
  LT_precision_weighted:
  - 0.9665055331429308
  - 0.955165071567144
  - 0.9514908095104573
  - 0.9481295696828863
  - 0.9658420595050577
  - 0.951766798046082
  - 0.949643660227515
  - 0.9501019597404113
  - 0.9648800810440615
  - 0.9525819015614525
  - 0.9475991465074873
  - 0.9491901297207757
  - 0.9691034237258522
  - 0.9526505301052611
  - 0.9521565627653752
  - 0.9507763135077596
  LT_recall_macro:
  - 0.8090566900416283
  - 0.6965796916115388
  - 0.7325522466039707
  - 0.7206919145590355
  - 0.8068621634601802
  - 0.6735120825140756
  - 0.6923128117517101
  - 0.7182608896805385
  - 0.8175353515480903
  - 0.6686076133095177
  - 0.6641833544256681
  - 0.71765849767939
  - 0.8301211989330801
  - 0.6791529057303436
  - 0.7031243564403309
  - 0.7386115112624411
  LT_recall_micro:
  - 0.8813663830311999
  - 0.9004809470958195
  - 0.8951734539969834
  - 0.916289592760181
  - 0.8806264644222469
  - 0.8848193365396473
  - 0.888763197586727
  - 0.9209401709401709
  - 0.8888888888888888
  - 0.8772968306819583
  - 0.8765711412770236
  - 0.9137757667169432
  - 0.890368726106795
  - 0.8891355284252066
  - 0.8871292106586224
  - 0.9177978883861236
  LT_recall_weighted:
  - 0.8813663830311999
  - 0.9004809470958195
  - 0.8951734539969834
  - 0.916289592760181
  - 0.8806264644222469
  - 0.8848193365396473
  - 0.888763197586727
  - 0.9209401709401709
  - 0.8888888888888888
  - 0.8772968306819583
  - 0.8765711412770236
  - 0.9137757667169432
  - 0.890368726106795
  - 0.8891355284252066
  - 0.8871292106586224
  - 0.9177978883861236
  LT_roc_auc:
  - 0.8491605216568401
  - 0.7206047266556821
  - 0.7525568181818181
  - 0.7783452113343347
  - 0.8856013116826179
  - 0.6988423660196007
  - 0.7507729041022579
  - 0.7568212836921343
  - 0.8701406684209232
  - 0.6875172174778506
  - 0.7162245030894067
  - 0.7606214460892402
  - 0.8760370542548759
  - 0.7245152287695309
  - 0.7604272644423666
  - 0.7707117191592456
  TL_average_precision:
  - 0.777840209356694
  - 0.7555540882878796
  - 0.7388243705662724
  - 0.7420679417484672
  - 0.8302610355480801
  - 0.8363091638460028
  - 0.8293269594238618
  - 0.8335099248846415
  - 0.7484900746691547
  - 0.7478683835031021
  - 0.7274330138829641
  - 0.7122620009933548
  - 0.788024960567505
  - 0.8231912491139182
  - 0.8322623643045737
  - 0.8149964766557293
  TL_balanced_accuracy:
  - 0.9113055024657049
  - 0.8903942313735349
  - 0.8958118952338605
  - 0.8881840317826477
  - 0.9277115459375405
  - 0.9298963326423976
  - 0.9233319924463366
  - 0.9271045540439052
  - 0.8912878431872994
  - 0.8983863989089028
  - 0.8960346837319171
  - 0.8790834882081517
  - 0.8920333226853174
  - 0.9160750176977339
  - 0.9193783384439105
  - 0.9005555997409473
  TL_f1_macro:
  - 0.7479847705552218
  - 0.732998627281509
  - 0.7414151653904439
  - 0.7385890952599059
  - 0.7792846398090973
  - 0.7929762322782494
  - 0.790311024781357
  - 0.7731927381144742
  - 0.7822631931227109
  - 0.7822033704786262
  - 0.7687815011705528
  - 0.7561885948312734
  - 0.7697129342022453
  - 0.7943425669078875
  - 0.7823395497916712
  - 0.7568738951717675
  TL_f1_micro:
  - 0.9469214437367304
  - 0.9442987386037217
  - 0.9455199801439563
  - 0.948746587242492
  - 0.9534157612089421
  - 0.9582864993131011
  - 0.959915611814346
  - 0.9564408041697692
  - 0.956662919945048
  - 0.9595354065192956
  - 0.9569372052618516
  - 0.9560685033507073
  - 0.9532908704883227
  - 0.9582864993131011
  - 0.9569372052618516
  - 0.9493670886075949
  TL_f1_weighted:
  - 0.9569046307378266
  - 0.9549186234631001
  - 0.9555840951890731
  - 0.9581418633546546
  - 0.961128261664644
  - 0.9646632475593092
  - 0.9659770976762949
  - 0.9639549109788844
  - 0.9624794891203954
  - 0.9652296670537504
  - 0.9635895667904611
  - 0.9629174585494271
  - 0.9602755115108172
  - 0.9641572010470126
  - 0.9636869275669895
  - 0.9580118317437647
  TL_matthews_corrcoef:
  - 0.5515403704337408
  - 0.5202876078465044
  - 0.5350439434723449
  - 0.5266885021488155
  - 0.6047167400156997
  - 0.6256867221066829
  - 0.6184987391643108
  - 0.5944394372082809
  - 0.5935456758313986
  - 0.595815993609598
  - 0.5744285741904192
  - 0.5481274734102977
  - 0.5748539896189695
  - 0.6221479180799812
  - 0.6051018326387338
  - 0.5596196710416277
  TL_precision_macro:
  - 0.6848971010566243
  - 0.6733498942378255
  - 0.6808131747008876
  - 0.678652878263605
  - 0.7137435493199292
  - 0.7276617898868278
  - 0.725910572064982
  - 0.706833573397214
  - 0.725087793699686
  - 0.7227715976331361
  - 0.7082950057158373
  - 0.6981382310578147
  - 0.7107327937822405
  - 0.7325710602098973
  - 0.718268443013375
  - 0.6954623630397876
  TL_precision_micro:
  - 0.9469214437367304
  - 0.9442987386037217
  - 0.9455199801439563
  - 0.948746587242492
  - 0.9534157612089422
  - 0.9582864993131011
  - 0.959915611814346
  - 0.9564408041697692
  - 0.956662919945048
  - 0.9595354065192956
  - 0.9569372052618516
  - 0.9560685033507074
  - 0.9532908704883227
  - 0.9582864993131011
  - 0.9569372052618516
  - 0.9493670886075949
  TL_precision_weighted:
  - 0.9746090833213975
  - 0.9729756598995062
  - 0.972978546797322
  - 0.9740262939942105
  - 0.9756304873366571
  - 0.976792799589784
  - 0.9772617209428763
  - 0.977786426841652
  - 0.9726428405954427
  - 0.975245174476278
  - 0.9751634018629143
  - 0.9743718153215343
  - 0.9724782477935587
  - 0.9750522478726311
  - 0.976132530908241
  - 0.9732448110470908
  TL_recall_macro:
  - 0.9113055024657049
  - 0.8903942313735349
  - 0.8958118952338605
  - 0.8881840317826477
  - 0.9277115459375405
  - 0.9298963326423976
  - 0.9233319924463366
  - 0.9271045540439052
  - 0.8912878431872994
  - 0.8983863989089028
  - 0.8960346837319171
  - 0.8790834882081517
  - 0.8920333226853174
  - 0.9160750176977339
  - 0.9193783384439105
  - 0.9005555997409473
  TL_recall_micro:
  - 0.9469214437367304
  - 0.9442987386037217
  - 0.9455199801439563
  - 0.948746587242492
  - 0.9534157612089422
  - 0.9582864993131011
  - 0.959915611814346
  - 0.9564408041697692
  - 0.956662919945048
  - 0.9595354065192956
  - 0.9569372052618516
  - 0.9560685033507074
  - 0.9532908704883227
  - 0.9582864993131011
  - 0.9569372052618516
  - 0.9493670886075949
  TL_recall_weighted:
  - 0.9469214437367304
  - 0.9442987386037217
  - 0.9455199801439563
  - 0.948746587242492
  - 0.9534157612089422
  - 0.9582864993131011
  - 0.959915611814346
  - 0.9564408041697692
  - 0.956662919945048
  - 0.9595354065192956
  - 0.9569372052618516
  - 0.9560685033507074
  - 0.9532908704883227
  - 0.9582864993131011
  - 0.9569372052618516
  - 0.9493670886075949
  TL_roc_auc:
  - 0.9407444943521185
  - 0.918811178235867
  - 0.9211531991878813
  - 0.9159415810409772
  - 0.951315501378506
  - 0.947595489484821
  - 0.9438119461857352
  - 0.9520934027280996
  - 0.900952616634749
  - 0.9082123877157504
  - 0.9106682099241945
  - 0.8881111213470906
  - 0.9161798370234165
  - 0.9286225170359551
  - 0.9435778097382692
  - 0.9311644870644109
  TT_average_precision:
  - 0.28391749408687383
  - 0.11013567407693058
  - 0.15075481192995155
  - 0.2161692194418874
  - 0.49688401717354397
  - 0.1267971448238704
  - 0.266866451231583
  - 0.38782351910554635
  - 0.35282604202892687
  - 0.12384621612850857
  - 0.16087334788650942
  - 0.29397934719475405
  - 0.4568516055018016
  - 0.08979304182423914
  - 0.1785935522252939
  - 0.22044529263505383
  TT_balanced_accuracy:
  - 0.7248281130634071
  - 0.6766870774333461
  - 0.6779840590979782
  - 0.6996627938567752
  - 0.8059651947905189
  - 0.6900924307918698
  - 0.6930407755799354
  - 0.7468644544431946
  - 0.7547005307050796
  - 0.6254017804553792
  - 0.6097413793103448
  - 0.6582361776696946
  - 0.8338400692127055
  - 0.637624140565317
  - 0.6482752818441865
  - 0.6416070265514365
  TT_f1_macro:
  - 0.5679032510295215
  - 0.5714655546101113
  - 0.5623678085646776
  - 0.6084480073822021
  - 0.611141136353916
  - 0.5816144639674052
  - 0.5958935801041064
  - 0.6698947762794332
  - 0.5875323691170552
  - 0.5654584175531194
  - 0.5552832749395754
  - 0.6182980976821866
  - 0.632405307173763
  - 0.5521215443358789
  - 0.5569354969468647
  - 0.593264221767024
  TT_f1_micro:
  - 0.8638549759526452
  - 0.8830928597854236
  - 0.8804675716440422
  - 0.9034690799396682
  - 0.8904920458749538
  - 0.8967813540510544
  - 0.8966817496229261
  - 0.9238310708898945
  - 0.9019607843137255
  - 0.9012208657047724
  - 0.8868778280542986
  - 0.9200603318250378
  - 0.8893821679615243
  - 0.8823529411764706
  - 0.8593514328808446
  - 0.9110105580693816
  TT_f1_weighted:
  - 0.9030153293622315
  - 0.9125656374549325
  - 0.912966928243482
  - 0.9232055026911236
  - 0.9209755584809161
  - 0.9224407214875323
  - 0.9195563744027665
  - 0.9349667123560453
  - 0.9303392811090183
  - 0.9217114191483707
  - 0.9103356086676547
  - 0.9295303934563229
  - 0.9186047578829644
  - 0.9125162570447193
  - 0.8939960699960564
  - 0.9248374037617197
  TT_matthews_corrcoef:
  - 0.22551804584464236
  - 0.1995251404976282
  - 0.18923901418139386
  - 0.25688854123989335
  - 0.318265479369559
  - 0.2173178866119193
  - 0.2376665461540678
  - 0.3645781939265715
  - 0.25690682981079205
  - 0.16025087316377482
  - 0.14011710284701143
  - 0.24833527049299914
  - 0.362480960187923
  - 0.1536005827478521
  - 0.16962776310711525
  - 0.20489172280022702
  TT_precision_macro:
  - 0.5565525239577611
  - 0.5563287964644958
  - 0.5503014211916473
  - 0.5826289682539683
  - 0.5827650637090324
  - 0.562110658016125
  - 0.5731521449174528
  - 0.6346055062752524
  - 0.5647830601498183
  - 0.5511961278709474
  - 0.5447251588999968
  - 0.5974341131703191
  - 0.5983947544168539
  - 0.542857922533733
  - 0.5485137806835533
  - 0.5741146451104887
  TT_precision_micro:
  - 0.8638549759526452
  - 0.8830928597854236
  - 0.8804675716440422
  - 0.9034690799396682
  - 0.8904920458749538
  - 0.8967813540510544
  - 0.8966817496229261
  - 0.9238310708898945
  - 0.9019607843137255
  - 0.9012208657047724
  - 0.8868778280542986
  - 0.9200603318250377
  - 0.8893821679615243
  - 0.8823529411764706
  - 0.8593514328808446
  - 0.9110105580693816
  TT_precision_weighted:
  - 0.9575814322025017
  - 0.9513578964926228
  - 0.955608833471139
  - 0.9494740866432043
  - 0.9658783717362771
  - 0.9561058115384524
  - 0.9499401708327203
  - 0.9503607539750504
  - 0.9688623728064243
  - 0.9467193748808411
  - 0.938972501365386
  - 0.9409660587781455
  - 0.9640539256060376
  - 0.950606088594451
  - 0.9397846810267417
  - 0.9416647803011451
  TT_recall_macro:
  - 0.7248281130634071
  - 0.6766870774333461
  - 0.6779840590979782
  - 0.6996627938567752
  - 0.8059651947905189
  - 0.6900924307918698
  - 0.6930407755799354
  - 0.7468644544431946
  - 0.7547005307050796
  - 0.6254017804553792
  - 0.6097413793103448
  - 0.6582361776696946
  - 0.8338400692127055
  - 0.637624140565317
  - 0.6482752818441865
  - 0.6416070265514365
  TT_recall_micro:
  - 0.8638549759526452
  - 0.8830928597854236
  - 0.8804675716440422
  - 0.9034690799396682
  - 0.8904920458749538
  - 0.8967813540510544
  - 0.8966817496229261
  - 0.9238310708898945
  - 0.9019607843137255
  - 0.9012208657047724
  - 0.8868778280542986
  - 0.9200603318250377
  - 0.8893821679615243
  - 0.8823529411764706
  - 0.8593514328808446
  - 0.9110105580693816
  TT_recall_weighted:
  - 0.8638549759526452
  - 0.8830928597854236
  - 0.8804675716440422
  - 0.9034690799396682
  - 0.8904920458749538
  - 0.8967813540510544
  - 0.8966817496229261
  - 0.9238310708898945
  - 0.9019607843137255
  - 0.9012208657047724
  - 0.8868778280542986
  - 0.9200603318250377
  - 0.8893821679615243
  - 0.8823529411764706
  - 0.8593514328808446
  - 0.9110105580693816
  TT_roc_auc:
  - 0.7823214847436301
  - 0.7165476038610367
  - 0.69350699844479
  - 0.7390308120115705
  - 0.8590582064393404
  - 0.6993860939942979
  - 0.7487042792746433
  - 0.796472511248594
  - 0.8360121304018197
  - 0.6290093903034178
  - 0.6178271943573668
  - 0.7189668121021386
  - 0.8983829769702962
  - 0.6779647687952186
  - 0.6922560622207266
  - 0.6966505044811026
  fit_time:
  - 4.3870861530303955
  - 3.7061657905578613
  - 4.434708833694458
  - 4.542932510375977
  - 4.9799511432647705
  - 4.238787889480591
  - 4.372579097747803
  - 4.2576985359191895
  - 4.418498992919922
  - 4.073845863342285
  - 4.112930774688721
  - 4.385835647583008
  - 4.898181915283203
  - 3.905083417892456
  - 4.940509796142578
  - 4.728163957595825
  score_time:
  - 1.2600562572479248
  - 1.1853089332580566
  - 1.3168561458587646
  - 1.240436315536499
  - 1.1921334266662598
  - 1.3714659214019775
  - 1.358616590499878
  - 1.3744750022888184
  - 1.3265867233276367
  - 1.3127269744873047
  - 1.2936387062072754
  - 1.3296782970428467
  - 1.2336046695709229
  - 1.1822850704193115
  - 1.183525562286377
  - 1.2511050701141357
start: 2023-08-10 20:12:25.635041
wrapper: null
