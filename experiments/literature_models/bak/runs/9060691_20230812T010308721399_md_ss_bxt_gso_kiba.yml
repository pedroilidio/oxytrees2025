active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
directory: runs
end: 2023-08-12 03:08:33.472645
estimator:
  call: missing_data_simulation.estimators.md_ss_bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        bipartiteextratreesregressorss:
          call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
          params:
            axis_decision_only: false
            bipartite_adapter: gmosa
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error_gso
            max_col_features: null
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_row_features: null
            max_samples: null
            min_col_weight_fraction_leaf: 0.0
            min_cols_leaf: 1
            min_cols_split: 1
            min_impurity_decrease: 0.0
            min_row_weight_fraction_leaf: 0.0
            min_rows_leaf: 1
            min_rows_split: 1
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            prediction_weights: null
            preprocess_X_targets: null
            random_state: null
            ss_adapter: null
            supervision: 0.5
            unsupervised_criterion_cols: mean_distance
            unsupervised_criterion_rows: mean_distance
            update_supervision: null
            verbose: 0
            warm_start: false
        bipartiteextratreesregressorss__axis_decision_only: false
        bipartiteextratreesregressorss__bipartite_adapter: gmosa
        bipartiteextratreesregressorss__bootstrap: false
        bipartiteextratreesregressorss__ccp_alpha: 0.0
        bipartiteextratreesregressorss__criterion: squared_error_gso
        bipartiteextratreesregressorss__max_col_features: null
        bipartiteextratreesregressorss__max_depth: null
        bipartiteextratreesregressorss__max_features: 1.0
        bipartiteextratreesregressorss__max_leaf_nodes: null
        bipartiteextratreesregressorss__max_row_features: null
        bipartiteextratreesregressorss__max_samples: null
        bipartiteextratreesregressorss__min_col_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_cols_leaf: 1
        bipartiteextratreesregressorss__min_cols_split: 1
        bipartiteextratreesregressorss__min_impurity_decrease: 0.0
        bipartiteextratreesregressorss__min_row_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_rows_leaf: 1
        bipartiteextratreesregressorss__min_rows_split: 1
        bipartiteextratreesregressorss__min_samples_leaf: 1
        bipartiteextratreesregressorss__min_samples_split: 2
        bipartiteextratreesregressorss__min_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__n_estimators: 100
        bipartiteextratreesregressorss__n_jobs: 3
        bipartiteextratreesregressorss__oob_score: false
        bipartiteextratreesregressorss__prediction_weights: null
        bipartiteextratreesregressorss__preprocess_X_targets: null
        bipartiteextratreesregressorss__random_state: null
        bipartiteextratreesregressorss__ss_adapter: null
        bipartiteextratreesregressorss__supervision: 0.5
        bipartiteextratreesregressorss__unsupervised_criterion_cols: mean_distance
        bipartiteextratreesregressorss__unsupervised_criterion_rows: mean_distance
        bipartiteextratreesregressorss__update_supervision: null
        bipartiteextratreesregressorss__verbose: 0
        bipartiteextratreesregressorss__warm_start: false
        memory: null
        minmaxscaler:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: sklearn.preprocessing._data.MinMaxScaler
              params:
                clip: true
                copy: true
                feature_range:
                - 0
                - 1
            transformers__clip: true
            transformers__copy: true
            transformers__feature_range:
            - 0
            - 1
        minmaxscaler__ndim: 2
        minmaxscaler__transformers:
          call: sklearn.preprocessing._data.MinMaxScaler
          params:
            clip: true
            copy: true
            feature_range:
            - 0
            - 1
        minmaxscaler__transformers__clip: true
        minmaxscaler__transformers__copy: true
        minmaxscaler__transformers__feature_range:
        - 0
        - 1
        positivedropper:
          call: missing_data_simulation.positive_dropper.PositiveDropper
          params:
            drop: 0.0
            random_state:
              call: numpy.random.mtrand.RandomState
              params: {}
        positivedropper__drop: 0.0
        positivedropper__random_state:
          call: numpy.random.mtrand.RandomState
          params: {}
        similaritydistanceswitcher:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
              params: {}
        similaritydistanceswitcher__ndim: 2
        similaritydistanceswitcher__transformers:
          call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
          params: {}
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
              samplers__sampling_strategy: auto
        - - minmaxscaler
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: sklearn.preprocessing._data.MinMaxScaler
                params:
                  clip: true
                  copy: true
                  feature_range:
                  - 0
                  - 1
              transformers__clip: true
              transformers__copy: true
              transformers__feature_range:
              - 0
              - 1
        - - similaritydistanceswitcher
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                params: {}
        - - positivedropper
          - call: missing_data_simulation.positive_dropper.PositiveDropper
            params:
              drop: 0.0
              random_state:
                call: numpy.random.mtrand.RandomState
                params: {}
        - - bipartiteextratreesregressorss
          - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
            params:
              axis_decision_only: false
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              preprocess_X_targets: null
              random_state: null
              ss_adapter: null
              supervision: 0.5
              unsupervised_criterion_cols: mean_distance
              unsupervised_criterion_rows: mean_distance
              update_supervision: null
              verbose: 0
              warm_start: false
        symmetryenforcer:
          call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
          params:
            ndim: 2
            samplers:
              call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
              params:
                sampling_strategy: auto
            samplers__sampling_strategy: auto
        symmetryenforcer__ndim: 2
        symmetryenforcer__samplers:
          call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
          params:
            sampling_strategy: auto
        symmetryenforcer__samplers__sampling_strategy: auto
        verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: 90606917e9814d5a7eab2e0ed053ed8a62650b57f9491f46af6b396a3302ec2a
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/9060691_20230812T010308721399_md_ss_bxt_gso_kiba.yml
results:
  LL_average_precision:
  - 0.9999795946977527
  - 0.9999810618751587
  - 0.999980748156465
  - 0.9999803741654643
  - 0.9999707354847034
  - 0.9999698282651348
  - 0.9999709949874033
  - 0.9999703934840248
  - 0.9999013940906621
  - 0.9998930021782552
  - 0.999897007328668
  - 0.9998949259199099
  - 0.9999441744850166
  - 0.999937436048087
  - 0.9999378941380332
  - 0.9999362082547164
  LL_balanced_accuracy:
  - 0.999445880199759
  - 0.9994846226847753
  - 0.9994459005839886
  - 0.9994614872080394
  - 0.9993154884001789
  - 0.9993309423244976
  - 0.999306688041866
  - 0.999316240098059
  - 0.9987820795646738
  - 0.998774626601495
  - 0.998720534389371
  - 0.998757863068648
  - 0.9990457725943673
  - 0.9990259103290005
  - 0.9989746668822022
  - 0.998988861425866
  LL_f1_macro:
  - 0.9985934836591619
  - 0.998654232145427
  - 0.998625876263775
  - 0.9986230748756806
  - 0.998279920403774
  - 0.9982708513366617
  - 0.9982936346547722
  - 0.9982680029870262
  - 0.9969078151054599
  - 0.996800602410352
  - 0.9968223476673067
  - 0.996815551563818
  - 0.9976512277873979
  - 0.9975165002831174
  - 0.9975101355353511
  - 0.9974745957658215
  LL_f1_micro:
  - 0.999109692529914
  - 0.9991662871498038
  - 0.9991148687361354
  - 0.9991332324553027
  - 0.9989028161053296
  - 0.998920213312962
  - 0.9988945041061276
  - 0.9989018495937946
  - 0.9980420624101842
  - 0.9980167183299299
  - 0.9979542816847611
  - 0.9979983546107626
  - 0.9984863252407112
  - 0.9984327284472634
  - 0.9983703312191684
  - 0.9983813424947146
  LL_f1_weighted:
  - 0.9991104511514022
  - 0.9991669792355076
  - 0.9991155942933891
  - 0.9991339589124067
  - 0.9989039517994127
  - 0.9989213575014202
  - 0.9988956235007271
  - 0.9989030002020369
  - 0.9980457291952127
  - 0.9980206303942942
  - 0.997958161486907
  - 0.9980022393374428
  - 0.9984884348299686
  - 0.9984350926141329
  - 0.9983727162051407
  - 0.9983837919155977
  LL_matthews_corrcoef:
  - 0.9971909163008925
  - 0.9973120797552466
  - 0.9972555219358838
  - 0.9972499344539215
  - 0.9965657443210935
  - 0.9965476683914706
  - 0.9965930792678799
  - 0.9965419914382683
  - 0.9938346729183185
  - 0.9936215870819919
  - 0.993664803598983
  - 0.9936512963339841
  - 0.9953133469701855
  - 0.9950452943021664
  - 0.9950326285134129
  - 0.9949619032257473
  LL_precision_macro:
  - 0.9977464841412328
  - 0.9978288315861963
  - 0.997810961541955
  - 0.997789848286196
  - 0.9972523914370826
  - 0.9972189640167997
  - 0.9972884348593769
  - 0.9972279394040533
  - 0.9950595648688454
  - 0.9948546927108146
  - 0.9949514175911827
  - 0.9949009187702326
  - 0.9962714409476667
  - 0.9960239123957092
  - 0.9960622239565781
  - 0.9959775985990003
  LL_precision_micro:
  - 0.999109692529914
  - 0.9991662871498038
  - 0.9991148687361354
  - 0.9991332324553027
  - 0.9989028161053296
  - 0.9989202133129619
  - 0.9988945041061276
  - 0.9989018495937946
  - 0.9980420624101842
  - 0.9980167183299299
  - 0.9979542816847611
  - 0.9979983546107626
  - 0.9984863252407112
  - 0.9984327284472634
  - 0.9983703312191684
  - 0.9983813424947146
  LL_precision_weighted:
  - 0.99911370517392
  - 0.999169907411817
  - 0.9991187439088894
  - 0.9991370638308514
  - 0.9989088453690579
  - 0.9989262191642235
  - 0.9989004993543855
  - 0.9989079378727334
  - 0.9980614085374908
  - 0.998037127517197
  - 0.9979749376397605
  - 0.9980187677156285
  - 0.9984975438822125
  - 0.9984451916652503
  - 0.9983831657605362
  - 0.9983943642751487
  LL_recall_macro:
  - 0.999445880199759
  - 0.9994846226847753
  - 0.9994459005839886
  - 0.9994614872080394
  - 0.9993154884001789
  - 0.9993309423244976
  - 0.999306688041866
  - 0.999316240098059
  - 0.9987820795646738
  - 0.998774626601495
  - 0.998720534389371
  - 0.998757863068648
  - 0.9990457725943673
  - 0.9990259103290005
  - 0.9989746668822022
  - 0.998988861425866
  LL_recall_micro:
  - 0.999109692529914
  - 0.9991662871498038
  - 0.9991148687361354
  - 0.9991332324553027
  - 0.9989028161053296
  - 0.9989202133129619
  - 0.9988945041061276
  - 0.9989018495937946
  - 0.9980420624101842
  - 0.9980167183299299
  - 0.9979542816847611
  - 0.9979983546107626
  - 0.9984863252407112
  - 0.9984327284472634
  - 0.9983703312191684
  - 0.9983813424947146
  LL_recall_weighted:
  - 0.999109692529914
  - 0.9991662871498038
  - 0.9991148687361354
  - 0.9991332324553027
  - 0.9989028161053296
  - 0.9989202133129619
  - 0.9988945041061276
  - 0.9989018495937946
  - 0.9980420624101842
  - 0.9980167183299299
  - 0.9979542816847611
  - 0.9979983546107626
  - 0.9984863252407112
  - 0.9984327284472634
  - 0.9983703312191684
  - 0.9983813424947146
  LL_roc_auc:
  - 0.999997491257503
  - 0.9999977522978241
  - 0.9999975634427023
  - 0.9999976090412969
  - 0.9999962925423879
  - 0.9999963334302325
  - 0.9999962173239928
  - 0.9999962616985839
  - 0.9999878457920367
  - 0.999987259042357
  - 0.9999869492492699
  - 0.9999872019693816
  - 0.9999928689089517
  - 0.9999923008509621
  - 0.9999918597204577
  - 0.9999919095444735
  LT_average_precision:
  - 0.45912659397823347
  - 0.4127459211198087
  - 0.41587780432456267
  - 0.3848970326897378
  - 0.4650320952700101
  - 0.42027484355755584
  - 0.42021579029433986
  - 0.3866068511093838
  - 0.4585667850190437
  - 0.42118009359638725
  - 0.4092302542811214
  - 0.3881271659611998
  - 0.46272269759284307
  - 0.4179554782941771
  - 0.42051835088129186
  - 0.3875862944510673
  LT_balanced_accuracy:
  - 0.7378277809356927
  - 0.7050635074116212
  - 0.7224792293960065
  - 0.7023843376171344
  - 0.7408853143963249
  - 0.7064471649251436
  - 0.7205410135595942
  - 0.7016092835013936
  - 0.7375680247720835
  - 0.7062934335259952
  - 0.7192157736104134
  - 0.7019039156891558
  - 0.7385343833121909
  - 0.7031341582191726
  - 0.7160137666473854
  - 0.7043179806268363
  LT_f1_macro:
  - 0.6703827296008394
  - 0.6546232490084195
  - 0.6465545575441622
  - 0.6548752170110627
  - 0.6735748675771007
  - 0.657555134414243
  - 0.6473055367284097
  - 0.65560740963487
  - 0.6711962217237288
  - 0.6579448012062157
  - 0.6457945345762542
  - 0.6575051526181185
  - 0.673711518401598
  - 0.6544169744050619
  - 0.6439312410498987
  - 0.656329525891646
  LT_f1_micro:
  - 0.7370226762803059
  - 0.7190100963083641
  - 0.7214039520785539
  - 0.7317994924139154
  - 0.7390811858757924
  - 0.7218583413682659
  - 0.7212709600913212
  - 0.7320876417195864
  - 0.7394514997712767
  - 0.7247730824217841
  - 0.7225454666356351
  - 0.7363544679766378
  - 0.7385492859630792
  - 0.7167065390749602
  - 0.7162745879851145
  - 0.7292552720184299
  LT_f1_weighted:
  - 0.760966438339665
  - 0.7408420286688525
  - 0.7505339815965504
  - 0.7530715402142301
  - 0.7625761824121965
  - 0.7429534113324412
  - 0.7497000603998751
  - 0.7528476153495999
  - 0.7631137210909731
  - 0.7457516968895752
  - 0.7513165590901599
  - 0.7564447067561414
  - 0.7614991389340032
  - 0.7380363112198283
  - 0.744874536601491
  - 0.750441629414259
  LT_matthews_corrcoef:
  - 0.3931398412570621
  - 0.3491470461864145
  - 0.3565359785192274
  - 0.3436713027959261
  - 0.3990827620084922
  - 0.3529626732969174
  - 0.35553983231005093
  - 0.3437210838188872
  - 0.3930027701561681
  - 0.3524732938856988
  - 0.35212168894185597
  - 0.3452428913819643
  - 0.39720425942363247
  - 0.34764973210305355
  - 0.3490966794928916
  - 0.34768231537662164
  LT_precision_macro:
  - 0.6624693866456037
  - 0.6486169594475955
  - 0.6428424400827962
  - 0.6458981037713584
  - 0.6652934419554186
  - 0.6508650515812112
  - 0.6432937238280412
  - 0.6465014177544233
  - 0.6625336337861527
  - 0.6505591098794947
  - 0.6414014167196946
  - 0.647585862367924
  - 0.6653548028522446
  - 0.6487444766686187
  - 0.641042505674994
  - 0.647910369971828
  LT_precision_micro:
  - 0.7370226762803058
  - 0.7190100963083641
  - 0.7214039520785539
  - 0.7317994924139154
  - 0.7390811858757924
  - 0.7218583413682659
  - 0.7212709600913212
  - 0.7320876417195864
  - 0.7394514997712767
  - 0.7247730824217841
  - 0.7225454666356352
  - 0.7363544679766377
  - 0.7385492859630791
  - 0.7167065390749602
  - 0.7162745879851143
  - 0.7292552720184299
  LT_precision_weighted:
  - 0.8206407439666225
  - 0.7912376265371694
  - 0.8215146672030617
  - 0.7974679669399755
  - 0.8216133564962604
  - 0.7911790073065714
  - 0.8186359875164094
  - 0.7958622113962005
  - 0.8210806905884203
  - 0.7926866106335636
  - 0.8198614635832291
  - 0.7970559829299725
  - 0.818753929335568
  - 0.7874888949541665
  - 0.814649829555947
  - 0.7958738467391219
  LT_recall_macro:
  - 0.7378277809356927
  - 0.7050635074116212
  - 0.7224792293960065
  - 0.7023843376171344
  - 0.7408853143963249
  - 0.7064471649251436
  - 0.7205410135595942
  - 0.7016092835013936
  - 0.7375680247720835
  - 0.7062934335259952
  - 0.7192157736104134
  - 0.7019039156891558
  - 0.7385343833121909
  - 0.7031341582191726
  - 0.7160137666473854
  - 0.7043179806268363
  LT_recall_micro:
  - 0.7370226762803058
  - 0.7190100963083641
  - 0.7214039520785539
  - 0.7317994924139154
  - 0.7390811858757924
  - 0.7218583413682659
  - 0.7212709600913212
  - 0.7320876417195864
  - 0.7394514997712767
  - 0.7247730824217841
  - 0.7225454666356352
  - 0.7363544679766377
  - 0.7385492859630791
  - 0.7167065390749602
  - 0.7162745879851143
  - 0.7292552720184299
  LT_recall_weighted:
  - 0.7370226762803058
  - 0.7190100963083641
  - 0.7214039520785539
  - 0.7317994924139154
  - 0.7390811858757924
  - 0.7218583413682659
  - 0.7212709600913212
  - 0.7320876417195864
  - 0.7394514997712767
  - 0.7247730824217841
  - 0.7225454666356352
  - 0.7363544679766377
  - 0.7385492859630791
  - 0.7167065390749602
  - 0.7162745879851143
  - 0.7292552720184299
  LT_roc_auc:
  - 0.8097109218462849
  - 0.7680416794095264
  - 0.78085199046364
  - 0.7645761046710846
  - 0.8135044581254017
  - 0.7718787742827432
  - 0.7775234980986413
  - 0.7663170816426501
  - 0.8115417596815566
  - 0.7693639782142074
  - 0.7783698208256608
  - 0.7662134394852116
  - 0.8127773002757422
  - 0.768402600089995
  - 0.7773370484960174
  - 0.762642919204035
  TL_average_precision:
  - 0.7045113421327391
  - 0.6933774726530979
  - 0.7016840349354436
  - 0.6911985050214723
  - 0.663286470626591
  - 0.6530354415459617
  - 0.656317266455337
  - 0.645644701861956
  - 0.6969781636517194
  - 0.6853452757142333
  - 0.6919822745264431
  - 0.6770642089744087
  - 0.6748953825256766
  - 0.6666067004822313
  - 0.6659399409890352
  - 0.6552166000743953
  TL_balanced_accuracy:
  - 0.8180485976077551
  - 0.8155731047500743
  - 0.8179610254592373
  - 0.8103201400616624
  - 0.819916531952508
  - 0.8200444030881149
  - 0.8138360032196015
  - 0.8132573066631101
  - 0.8237056180239057
  - 0.8230885744557268
  - 0.8221449918671614
  - 0.8178352129689199
  - 0.8189161791135381
  - 0.8162847680281446
  - 0.8085277537276265
  - 0.810807205847034
  TL_f1_macro:
  - 0.7351014619239802
  - 0.7319378098840785
  - 0.7362364446064924
  - 0.7240287943066956
  - 0.7285979549121797
  - 0.7263698352316148
  - 0.7250036606281094
  - 0.7174529028905967
  - 0.7428534205266553
  - 0.7398360252467235
  - 0.745122014849681
  - 0.7341081806873514
  - 0.7306860494117903
  - 0.7230901285311095
  - 0.7216720087262641
  - 0.7164930400312896
  TL_f1_micro:
  - 0.7839026227184123
  - 0.784564393939394
  - 0.7831439393939394
  - 0.773773343904158
  - 0.778519847598795
  - 0.7794771846370684
  - 0.7727713178294574
  - 0.7674859055673009
  - 0.7909356725146199
  - 0.7910390239605356
  - 0.7917437455954898
  - 0.7822300035236082
  - 0.787187767013993
  - 0.7822470323463219
  - 0.7759586955562421
  - 0.7730903314063811
  TL_f1_weighted:
  - 0.8027352643121141
  - 0.8039166532963983
  - 0.8016360109460015
  - 0.7942365101558203
  - 0.799176782405438
  - 0.8007910067621744
  - 0.7933902870066205
  - 0.7899494355004938
  - 0.8086971150168081
  - 0.809491116053311
  - 0.8087367128766725
  - 0.8012458148149535
  - 0.8073699828806226
  - 0.8040030370719471
  - 0.7969047428378128
  - 0.795718068244541
  TL_matthews_corrcoef:
  - 0.5300614277968186
  - 0.5229887991958908
  - 0.5320455781813603
  - 0.5131622025260755
  - 0.5256801331961725
  - 0.5220298559257102
  - 0.518449177911488
  - 0.510490371857906
  - 0.5422513396529052
  - 0.5373213228734451
  - 0.5436688128786222
  - 0.5294216193345631
  - 0.5227855193244899
  - 0.5124944907805808
  - 0.5069884102061968
  - 0.5034719588440023
  TL_precision_macro:
  - 0.7208507751262846
  - 0.716682980874573
  - 0.7225685497566021
  - 0.7121482076937438
  - 0.7159466414181501
  - 0.7128729387612416
  - 0.7141162480719403
  - 0.707976329854521
  - 0.7270863548417437
  - 0.7234017440115573
  - 0.7293810128660427
  - 0.7204658574490922
  - 0.7142449310466596
  - 0.7076061113517446
  - 0.7082772497594525
  - 0.7038916799333882
  TL_precision_micro:
  - 0.7839026227184122
  - 0.7845643939393939
  - 0.7831439393939394
  - 0.7737733439041579
  - 0.778519847598795
  - 0.7794771846370684
  - 0.7727713178294574
  - 0.7674859055673009
  - 0.7909356725146199
  - 0.7910390239605356
  - 0.7917437455954898
  - 0.7822300035236082
  - 0.787187767013993
  - 0.7822470323463219
  - 0.775958695556242
  - 0.7730903314063811
  TL_precision_weighted:
  - 0.863147969448412
  - 0.8635236950257988
  - 0.8619859422167427
  - 0.8599062559092141
  - 0.866855572940863
  - 0.8687778172379494
  - 0.8618663838110782
  - 0.8644623800738902
  - 0.8657394791334841
  - 0.8672536663803426
  - 0.8632774684322084
  - 0.8629346610141624
  - 0.8682543010284172
  - 0.8690838875777057
  - 0.8609995815708202
  - 0.8652792868655466
  TL_recall_macro:
  - 0.8180485976077551
  - 0.8155731047500743
  - 0.8179610254592373
  - 0.8103201400616624
  - 0.819916531952508
  - 0.8200444030881149
  - 0.8138360032196015
  - 0.8132573066631101
  - 0.8237056180239057
  - 0.8230885744557268
  - 0.8221449918671614
  - 0.8178352129689199
  - 0.8189161791135381
  - 0.8162847680281446
  - 0.8085277537276265
  - 0.810807205847034
  TL_recall_micro:
  - 0.7839026227184122
  - 0.7845643939393939
  - 0.7831439393939394
  - 0.7737733439041579
  - 0.778519847598795
  - 0.7794771846370684
  - 0.7727713178294574
  - 0.7674859055673009
  - 0.7909356725146199
  - 0.7910390239605356
  - 0.7917437455954898
  - 0.7822300035236082
  - 0.787187767013993
  - 0.7822470323463219
  - 0.775958695556242
  - 0.7730903314063811
  TL_recall_weighted:
  - 0.7839026227184122
  - 0.7845643939393939
  - 0.7831439393939394
  - 0.7737733439041579
  - 0.778519847598795
  - 0.7794771846370684
  - 0.7727713178294574
  - 0.7674859055673009
  - 0.7909356725146199
  - 0.7910390239605356
  - 0.7917437455954898
  - 0.7822300035236082
  - 0.787187767013993
  - 0.7822470323463219
  - 0.775958695556242
  - 0.7730903314063811
  TL_roc_auc:
  - 0.8992922214700363
  - 0.8971440332472067
  - 0.8972930956374682
  - 0.89382606838771
  - 0.9002108828919663
  - 0.8994335142416969
  - 0.8955821426361437
  - 0.8957316092079874
  - 0.9067819515293114
  - 0.9054427434213104
  - 0.9044359723040671
  - 0.9011202071308222
  - 0.8979062811903862
  - 0.8961532358951196
  - 0.8928124125500723
  - 0.8919571118087073
  TT_average_precision:
  - 0.3568600919995039
  - 0.3309114806461588
  - 0.32501676628692133
  - 0.298041409915926
  - 0.3246144295321213
  - 0.3279828614007034
  - 0.3077909893684042
  - 0.2833481635241821
  - 0.3437024674684982
  - 0.3312726287939241
  - 0.31439197888261994
  - 0.2876153896653816
  - 0.3339389762935879
  - 0.31275806659091876
  - 0.30660636208601494
  - 0.27953592872904315
  TT_balanced_accuracy:
  - 0.6500381563903682
  - 0.6178275859491412
  - 0.6387252872832101
  - 0.5997455287276745
  - 0.6408906517640907
  - 0.6227610146346928
  - 0.6448230400570308
  - 0.5943287306301005
  - 0.6502257068152626
  - 0.6187950011019689
  - 0.6395294780922438
  - 0.6000634210377713
  - 0.6473421452901703
  - 0.6181884852763342
  - 0.6436116168535568
  - 0.5999003810071099
  TT_f1_macro:
  - 0.5789181276003698
  - 0.5733565657454887
  - 0.5690862820873223
  - 0.5604184811703894
  - 0.566290159810974
  - 0.572587842901608
  - 0.5652894685765969
  - 0.5504555461733943
  - 0.586744681879299
  - 0.5789998635340908
  - 0.578153647465915
  - 0.56506413631962
  - 0.5803974483496517
  - 0.5720715033714172
  - 0.5719068213194343
  - 0.5615120701029572
  TT_f1_micro:
  - 0.6364942528735632
  - 0.6365962254120149
  - 0.6362639553429027
  - 0.6367955874534822
  - 0.6234652560083594
  - 0.6342038809144073
  - 0.6328083466241361
  - 0.6258971291866029
  - 0.6473027690700105
  - 0.6437732589048378
  - 0.6516480595427964
  - 0.6475943646996278
  - 0.6518353726362626
  - 0.6448616798162389
  - 0.6537834148939712
  - 0.6512866606744565
  TT_f1_weighted:
  - 0.6728682903342154
  - 0.6669580297379736
  - 0.6753110132555759
  - 0.6685945213806719
  - 0.6625092802395625
  - 0.6663680243244314
  - 0.6749841637942078
  - 0.6611121758441593
  - 0.68107127678695
  - 0.6718170389759848
  - 0.6877107530662717
  - 0.6772574033057757
  - 0.6888344625062389
  - 0.6770118005286502
  - 0.6946064100917497
  - 0.6835254611879562
  TT_matthews_corrcoef:
  - 0.2415461334681904
  - 0.19765023797423847
  - 0.21975678207564028
  - 0.16600237315469787
  - 0.22455488681018732
  - 0.20375886638722093
  - 0.2249631044978066
  - 0.15453343834464522
  - 0.2447335306671425
  - 0.20155744710563864
  - 0.22357199364140584
  - 0.16793505857009308
  - 0.23441086247888118
  - 0.19530156628979245
  - 0.2223508395498784
  - 0.16462750812852972
  TT_precision_macro:
  - 0.59721616153699
  - 0.5828872463451285
  - 0.5870299932586359
  - 0.5690677272567954
  - 0.5894752358637112
  - 0.5845497973337708
  - 0.5873624776233147
  - 0.5632908537173665
  - 0.5996741874319477
  - 0.5854947685232796
  - 0.5895589179867565
  - 0.570460772789027
  - 0.5932327480706207
  - 0.5806819329862496
  - 0.5860652796266308
  - 0.5678231057764441
  TT_precision_micro:
  - 0.6364942528735632
  - 0.6365962254120149
  - 0.6362639553429027
  - 0.6367955874534822
  - 0.6234652560083594
  - 0.6342038809144073
  - 0.6328083466241361
  - 0.6258971291866029
  - 0.6473027690700105
  - 0.6437732589048378
  - 0.6516480595427964
  - 0.6475943646996278
  - 0.6518353726362626
  - 0.6448616798162389
  - 0.6537834148939712
  - 0.6512866606744565
  TT_precision_weighted:
  - 0.7712642602701314
  - 0.7357937853552714
  - 0.7729436081226579
  - 0.7334201746720822
  - 0.7698556263760928
  - 0.7426574175524507
  - 0.7840700013532852
  - 0.7355104894924912
  - 0.7673752866820492
  - 0.7327667947100797
  - 0.7712846549011677
  - 0.7341515176128813
  - 0.7777539067358586
  - 0.7464061570906936
  - 0.7884589230163574
  - 0.7448202644988622
  TT_recall_macro:
  - 0.6500381563903682
  - 0.6178275859491412
  - 0.6387252872832101
  - 0.5997455287276745
  - 0.6408906517640907
  - 0.6227610146346928
  - 0.6448230400570308
  - 0.5943287306301005
  - 0.6502257068152626
  - 0.6187950011019689
  - 0.6395294780922438
  - 0.6000634210377713
  - 0.6473421452901703
  - 0.6181884852763342
  - 0.6436116168535568
  - 0.5999003810071099
  TT_recall_micro:
  - 0.6364942528735632
  - 0.6365962254120149
  - 0.6362639553429027
  - 0.6367955874534822
  - 0.6234652560083594
  - 0.6342038809144073
  - 0.6328083466241361
  - 0.6258971291866029
  - 0.6473027690700105
  - 0.6437732589048378
  - 0.6516480595427964
  - 0.6475943646996278
  - 0.6518353726362626
  - 0.6448616798162389
  - 0.6537834148939712
  - 0.6512866606744565
  TT_recall_weighted:
  - 0.6364942528735632
  - 0.6365962254120148
  - 0.6362639553429027
  - 0.6367955874534821
  - 0.6234652560083594
  - 0.6342038809144073
  - 0.6328083466241361
  - 0.6258971291866029
  - 0.6473027690700105
  - 0.6437732589048378
  - 0.6516480595427964
  - 0.6475943646996278
  - 0.6518353726362626
  - 0.6448616798162389
  - 0.6537834148939712
  - 0.6512866606744565
  TT_roc_auc:
  - 0.7117151859013102
  - 0.6747781214278604
  - 0.6908350817581359
  - 0.6549277883160843
  - 0.7008289085094378
  - 0.6788050916058019
  - 0.7001673179709591
  - 0.6536905014177742
  - 0.7143943468491726
  - 0.6792500981572264
  - 0.7014217713390812
  - 0.6613278531205437
  - 0.7131170524640886
  - 0.6746878641830248
  - 0.699808334526373
  - 0.6598102536857415
  fit_time:
  - 7210.42676782608
  - 7118.178472042084
  - 6224.846706151962
  - 5284.940969944
  - 7388.604917764664
  - 7081.991829156876
  - 5586.458013534546
  - 6008.448559761047
  - 7488.177582740784
  - 6895.8297996521
  - 5717.144498586655
  - 5683.358359575272
  - 7036.35714507103
  - 6413.733500242233
  - 5355.851028442383
  - 4458.034503936768
  score_time:
  - 32.587291955947876
  - 32.77721834182739
  - 38.70745325088501
  - 54.26316237449646
  - 32.62224817276001
  - 33.53965997695923
  - 42.81718826293945
  - 40.72554922103882
  - 35.682878732681274
  - 37.527106523513794
  - 41.97430872917175
  - 42.9276385307312
  - 35.53082990646362
  - 37.55396509170532
  - 51.94202637672424
  - 60.82254672050476
start: 2023-08-12 01:03:08.721399
wrapper: null
