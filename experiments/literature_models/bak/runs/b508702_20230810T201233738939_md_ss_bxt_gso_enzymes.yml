active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: runs
end: 2023-08-10 20:14:38.936627
estimator:
  call: missing_data_simulation.estimators.md_ss_bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        bipartiteextratreesregressorss:
          call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
          params:
            axis_decision_only: false
            bipartite_adapter: gmosa
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error_gso
            max_col_features: null
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_row_features: null
            max_samples: null
            min_col_weight_fraction_leaf: 0.0
            min_cols_leaf: 1
            min_cols_split: 1
            min_impurity_decrease: 0.0
            min_row_weight_fraction_leaf: 0.0
            min_rows_leaf: 1
            min_rows_split: 1
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            prediction_weights: null
            preprocess_X_targets: null
            random_state: null
            ss_adapter: null
            supervision: 0.5
            unsupervised_criterion_cols: mean_distance
            unsupervised_criterion_rows: mean_distance
            update_supervision: null
            verbose: 0
            warm_start: false
        bipartiteextratreesregressorss__axis_decision_only: false
        bipartiteextratreesregressorss__bipartite_adapter: gmosa
        bipartiteextratreesregressorss__bootstrap: false
        bipartiteextratreesregressorss__ccp_alpha: 0.0
        bipartiteextratreesregressorss__criterion: squared_error_gso
        bipartiteextratreesregressorss__max_col_features: null
        bipartiteextratreesregressorss__max_depth: null
        bipartiteextratreesregressorss__max_features: 1.0
        bipartiteextratreesregressorss__max_leaf_nodes: null
        bipartiteextratreesregressorss__max_row_features: null
        bipartiteextratreesregressorss__max_samples: null
        bipartiteextratreesregressorss__min_col_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_cols_leaf: 1
        bipartiteextratreesregressorss__min_cols_split: 1
        bipartiteextratreesregressorss__min_impurity_decrease: 0.0
        bipartiteextratreesregressorss__min_row_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_rows_leaf: 1
        bipartiteextratreesregressorss__min_rows_split: 1
        bipartiteextratreesregressorss__min_samples_leaf: 1
        bipartiteextratreesregressorss__min_samples_split: 2
        bipartiteextratreesregressorss__min_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__n_estimators: 100
        bipartiteextratreesregressorss__n_jobs: 3
        bipartiteextratreesregressorss__oob_score: false
        bipartiteextratreesregressorss__prediction_weights: null
        bipartiteextratreesregressorss__preprocess_X_targets: null
        bipartiteextratreesregressorss__random_state: null
        bipartiteextratreesregressorss__ss_adapter: null
        bipartiteextratreesregressorss__supervision: 0.5
        bipartiteextratreesregressorss__unsupervised_criterion_cols: mean_distance
        bipartiteextratreesregressorss__unsupervised_criterion_rows: mean_distance
        bipartiteextratreesregressorss__update_supervision: null
        bipartiteextratreesregressorss__verbose: 0
        bipartiteextratreesregressorss__warm_start: false
        memory: null
        minmaxscaler:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: sklearn.preprocessing._data.MinMaxScaler
              params:
                clip: true
                copy: true
                feature_range:
                - 0
                - 1
            transformers__clip: true
            transformers__copy: true
            transformers__feature_range:
            - 0
            - 1
        minmaxscaler__ndim: 2
        minmaxscaler__transformers:
          call: sklearn.preprocessing._data.MinMaxScaler
          params:
            clip: true
            copy: true
            feature_range:
            - 0
            - 1
        minmaxscaler__transformers__clip: true
        minmaxscaler__transformers__copy: true
        minmaxscaler__transformers__feature_range:
        - 0
        - 1
        positivedropper:
          call: missing_data_simulation.positive_dropper.PositiveDropper
          params:
            drop: 0.0
            random_state:
              call: numpy.random.mtrand.RandomState
              params: {}
        positivedropper__drop: 0.0
        positivedropper__random_state:
          call: numpy.random.mtrand.RandomState
          params: {}
        similaritydistanceswitcher:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
              params: {}
        similaritydistanceswitcher__ndim: 2
        similaritydistanceswitcher__transformers:
          call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
          params: {}
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
              samplers__sampling_strategy: auto
        - - minmaxscaler
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: sklearn.preprocessing._data.MinMaxScaler
                params:
                  clip: true
                  copy: true
                  feature_range:
                  - 0
                  - 1
              transformers__clip: true
              transformers__copy: true
              transformers__feature_range:
              - 0
              - 1
        - - similaritydistanceswitcher
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                params: {}
        - - positivedropper
          - call: missing_data_simulation.positive_dropper.PositiveDropper
            params:
              drop: 0.0
              random_state:
                call: numpy.random.mtrand.RandomState
                params: {}
        - - bipartiteextratreesregressorss
          - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
            params:
              axis_decision_only: false
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              preprocess_X_targets: null
              random_state: null
              ss_adapter: null
              supervision: 0.5
              unsupervised_criterion_cols: mean_distance
              unsupervised_criterion_rows: mean_distance
              update_supervision: null
              verbose: 0
              warm_start: false
        symmetryenforcer:
          call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
          params:
            ndim: 2
            samplers:
              call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
              params:
                sampling_strategy: auto
            samplers__sampling_strategy: auto
        symmetryenforcer__ndim: 2
        symmetryenforcer__samplers:
          call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
          params:
            sampling_strategy: auto
        symmetryenforcer__samplers__sampling_strategy: auto
        verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: b5087027621da4882571f1d273a77dedf6c3dae4342433c67ce504a1c6bda9e8
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/b508702_20230810T201233738939_md_ss_bxt_gso_enzymes.yml
results:
  LL_average_precision:
  - 0.9999983350669449
  - 1.0
  - 0.9999985378593896
  - 0.9999984057742856
  - 0.9999982245894363
  - 1.0
  - 0.9999984549303174
  - 0.99999829125477
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999985588467892
  - 1.0
  - 0.9999986681264001
  - 0.9999985343169532
  LL_balanced_accuracy:
  - 0.9980886873421189
  - 0.9995321338947727
  - 0.9987247918678155
  - 0.9987890670049591
  - 0.9987464553896332
  - 0.9997357663080783
  - 0.9982637624147058
  - 0.998425392741637
  - 0.9982349253495152
  - 0.9995472968456616
  - 0.9997874472413688
  - 0.9986493951111138
  - 0.9996527968130402
  - 0.9998753693323443
  - 0.9997417982989064
  - 0.9989494841542133
  LL_f1_macro:
  - 0.9147698351396354
  - 0.9787506736040137
  - 0.9430008732832287
  - 0.9434330701214498
  - 0.9389972944800238
  - 0.9874286146062657
  - 0.9236287873760491
  - 0.9266646277717416
  - 0.9196638473815795
  - 0.9795234779531001
  - 0.9896116798749581
  - 0.937978319683995
  - 0.983275815462475
  - 0.9944461151522179
  - 0.9878956615238883
  - 0.9520509440910249
  LL_f1_micro:
  - 0.9962130805504299
  - 0.9990741408748768
  - 0.9974749296587547
  - 0.997601183175817
  - 0.9975155878770336
  - 0.9994769497150278
  - 0.9965610946781136
  - 0.9968797345068898
  - 0.9965025266230085
  - 0.999104201236082
  - 0.9995791549431258
  - 0.9973246278527282
  - 0.9993125655776258
  - 0.9997535050381166
  - 0.9994889738595099
  - 0.9979198230045933
  LL_f1_weighted:
  - 0.9965285884718034
  - 0.999093381376756
  - 0.9976156323614702
  - 0.9977339685506701
  - 0.9976640255078939
  - 0.9994833869377039
  - 0.9968177469062907
  - 0.997103639397035
  - 0.9967773159607979
  - 0.9991221383646266
  - 0.9995834373455046
  - 0.9974869406712347
  - 0.9993238235954417
  - 0.9997548433180896
  - 0.9994950275109877
  - 0.9980173779706876
  LL_matthews_corrcoef:
  - 0.8419083778890124
  - 0.9583680116025326
  - 0.8918303595497655
  - 0.8926107090835206
  - 0.8846196752015008
  - 0.9751656690495923
  - 0.8573525122381948
  - 0.8626881732580206
  - 0.8504153402780004
  - 0.9598529248474124
  - 0.9794348672789004
  - 0.8827929355265044
  - 0.9670931431312733
  - 0.9889532570121083
  - 0.9760775311903036
  - 0.9082968143691224
  LL_precision_macro:
  - 0.8557648139641709
  - 0.959664745940283
  - 0.8986975397973951
  - 0.8993440968718467
  - 0.8922594142259415
  - 0.9757254464285714
  - 0.8688073394495412
  - 0.873291015625
  - 0.8628841607565012
  - 0.9610762800417973
  - 0.9798503166378814
  - 0.8907170923379175
  - 0.9679595278246206
  - 0.989136195018548
  - 0.976609796367639
  - 0.9133700550826239
  LL_precision_micro:
  - 0.9962130805504299
  - 0.9990741408748768
  - 0.9974749296587547
  - 0.997601183175817
  - 0.9975155878770336
  - 0.9994769497150278
  - 0.9965610946781136
  - 0.9968797345068898
  - 0.9965025266230085
  - 0.999104201236082
  - 0.9995791549431258
  - 0.9973246278527282
  - 0.9993125655776258
  - 0.9997535050381166
  - 0.9994889738595099
  - 0.9979198230045933
  LL_precision_weighted:
  - 0.997305494613053
  - 0.9991488304009475
  - 0.9979865213342604
  - 0.9980840933235713
  - 0.9980509319118989
  - 0.999502343339354
  - 0.9974634129552324
  - 0.9976704658501145
  - 0.9974616446176445
  - 0.9991739368765333
  - 0.9995961147324068
  - 0.9979093727473922
  - 0.9993566170245907
  - 0.9997588607845062
  - 0.999512879870485
  - 0.9982802342416541
  LL_recall_macro:
  - 0.9980886873421189
  - 0.9995321338947727
  - 0.9987247918678155
  - 0.9987890670049591
  - 0.9987464553896332
  - 0.9997357663080783
  - 0.9982637624147058
  - 0.998425392741637
  - 0.9982349253495152
  - 0.9995472968456616
  - 0.9997874472413688
  - 0.9986493951111138
  - 0.9996527968130402
  - 0.9998753693323443
  - 0.9997417982989064
  - 0.9989494841542133
  LL_recall_micro:
  - 0.9962130805504299
  - 0.9990741408748768
  - 0.9974749296587547
  - 0.997601183175817
  - 0.9975155878770336
  - 0.9994769497150278
  - 0.9965610946781136
  - 0.9968797345068898
  - 0.9965025266230085
  - 0.999104201236082
  - 0.9995791549431258
  - 0.9973246278527282
  - 0.9993125655776258
  - 0.9997535050381166
  - 0.9994889738595099
  - 0.9979198230045933
  LL_recall_weighted:
  - 0.9962130805504299
  - 0.9990741408748768
  - 0.9974749296587547
  - 0.997601183175817
  - 0.9975155878770336
  - 0.9994769497150278
  - 0.9965610946781136
  - 0.9968797345068898
  - 0.9965025266230085
  - 0.999104201236082
  - 0.9995791549431258
  - 0.9973246278527282
  - 0.9993125655776258
  - 0.9997535050381166
  - 0.9994889738595099
  - 0.9979198230045933
  LL_roc_auc:
  - 0.9999999921407579
  - 1.0
  - 0.9999999926528497
  - 0.9999999923312197
  - 0.9999999918864426
  - 1.0
  - 0.9999999924493025
  - 0.9999999920629814
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999999926831423
  - 1.0
  - 0.9999999929846026
  - 0.9999999926440389
  LT_average_precision:
  - 0.2064715601470202
  - 0.39340676946052394
  - 0.2780649485632065
  - 0.26609943107608647
  - 0.24800036628082067
  - 0.41472690535367174
  - 0.3051751554748518
  - 0.28973600283968864
  - 0.24566537416409698
  - 0.409841013713772
  - 0.30618555807288206
  - 0.2778541390706134
  - 0.2688330086571928
  - 0.4513928715494028
  - 0.34577083362488453
  - 0.32386952708245964
  LT_balanced_accuracy:
  - 0.6996497923138523
  - 0.7788682907578651
  - 0.751813341456129
  - 0.7408618226922179
  - 0.7086871574126881
  - 0.7871634331890125
  - 0.7372613498891127
  - 0.769089561454215
  - 0.6724333260185795
  - 0.7760061064836379
  - 0.710181354832056
  - 0.7447451676023626
  - 0.6804259807739859
  - 0.7788658181361534
  - 0.7333397767532603
  - 0.7782665361144181
  LT_f1_macro:
  - 0.5173919418769075
  - 0.5416986259766564
  - 0.517445969505691
  - 0.5227919691167261
  - 0.5274544353932381
  - 0.5532909198805265
  - 0.5175226183058084
  - 0.5311959627705104
  - 0.5174604430725672
  - 0.5408875826830384
  - 0.5493409063141875
  - 0.5207113322188021
  - 0.5587693099161153
  - 0.5426025474702447
  - 0.561496330890797
  - 0.5299976712180464
  LT_f1_micro:
  - 0.8893610154905336
  - 0.9295017909475741
  - 0.8880748218097616
  - 0.8904808422880712
  - 0.9048156913367756
  - 0.9412062665074713
  - 0.8945149969246355
  - 0.897789355620681
  - 0.8956002581755593
  - 0.9296826947429357
  - 0.9400484822171569
  - 0.8863743261333623
  - 0.9455321285140562
  - 0.9269510474329752
  - 0.9411339049893267
  - 0.8862476934766091
  LT_f1_weighted:
  - 0.9314978107063889
  - 0.9567972643576886
  - 0.9322871066165574
  - 0.932628435391798
  - 0.9404372371749945
  - 0.963406422623643
  - 0.9362007268568444
  - 0.936982045589074
  - 0.9346510919418409
  - 0.9569455103028572
  - 0.9610754879535319
  - 0.9303374949437929
  - 0.962492811290565
  - 0.9550308182504291
  - 0.9611513467779336
  - 0.9296112107103428
  LT_matthews_corrcoef:
  - 0.13455832565807913
  - 0.1879438651107244
  - 0.15394272272930465
  - 0.15824263045630363
  - 0.14827031111717334
  - 0.2060806019971061
  - 0.14626061344612798
  - 0.1795508346967338
  - 0.12181034822157864
  - 0.18548629932878044
  - 0.17137518922239306
  - 0.15786362452870048
  - 0.1715247878796319
  - 0.19052067820281476
  - 0.19891252858996986
  - 0.1857587618826326
  LT_precision_macro:
  - 0.5226721285232329
  - 0.5316662897893151
  - 0.5235277068167576
  - 0.5259907628924325
  - 0.5263361740024434
  - 0.5369730348741305
  - 0.5225407204498705
  - 0.5299514612031682
  - 0.5215123162042694
  - 0.5311634112710524
  - 0.5349334691277426
  - 0.5254559918317034
  - 0.5407656823187886
  - 0.5325408551910962
  - 0.5423911801285962
  - 0.5310011384210965
  LT_precision_micro:
  - 0.8893610154905336
  - 0.9295017909475741
  - 0.8880748218097616
  - 0.8904808422880712
  - 0.9048156913367756
  - 0.9412062665074713
  - 0.8945149969246354
  - 0.897789355620681
  - 0.8956002581755593
  - 0.9296826947429357
  - 0.9400484822171569
  - 0.8863743261333623
  - 0.9455321285140562
  - 0.9269510474329752
  - 0.9411339049893267
  - 0.8862476934766091
  LT_precision_weighted:
  - 0.983051630691253
  - 0.9897452120876379
  - 0.986828760662458
  - 0.9848613740198469
  - 0.9837179966696674
  - 0.9902829309854834
  - 0.9870035848580527
  - 0.9858560972473037
  - 0.9817631643148496
  - 0.9897866347092885
  - 0.9861334344248643
  - 0.9850197864008481
  - 0.9826607150066324
  - 0.9891229244472155
  - 0.985524129931747
  - 0.9847162427107905
  LT_recall_macro:
  - 0.6996497923138523
  - 0.7788682907578651
  - 0.751813341456129
  - 0.7408618226922179
  - 0.7086871574126881
  - 0.7871634331890125
  - 0.7372613498891127
  - 0.769089561454215
  - 0.6724333260185795
  - 0.7760061064836379
  - 0.710181354832056
  - 0.7447451676023626
  - 0.6804259807739859
  - 0.7788658181361534
  - 0.7333397767532603
  - 0.7782665361144181
  LT_recall_micro:
  - 0.8893610154905336
  - 0.9295017909475741
  - 0.8880748218097616
  - 0.8904808422880712
  - 0.9048156913367756
  - 0.9412062665074713
  - 0.8945149969246354
  - 0.897789355620681
  - 0.8956002581755593
  - 0.9296826947429357
  - 0.9400484822171569
  - 0.8863743261333623
  - 0.9455321285140562
  - 0.9269510474329752
  - 0.9411339049893267
  - 0.8862476934766091
  LT_recall_weighted:
  - 0.8893610154905336
  - 0.9295017909475741
  - 0.8880748218097616
  - 0.8904808422880712
  - 0.9048156913367756
  - 0.9412062665074713
  - 0.8945149969246354
  - 0.897789355620681
  - 0.8956002581755593
  - 0.9296826947429357
  - 0.9400484822171569
  - 0.8863743261333623
  - 0.9455321285140562
  - 0.9269510474329752
  - 0.9411339049893267
  - 0.8862476934766091
  LT_roc_auc:
  - 0.7142482597744398
  - 0.8081159376772786
  - 0.7723727122449169
  - 0.7611318021561757
  - 0.7216583236559843
  - 0.8158706171057528
  - 0.7575221096206509
  - 0.7904242343549018
  - 0.6880099341323831
  - 0.8073888027680002
  - 0.7688416516006501
  - 0.771033813375395
  - 0.7013155140308901
  - 0.8255432754435674
  - 0.7877668744836437
  - 0.8035250946090275
  TL_average_precision:
  - 0.6263368801073719
  - 0.637832659171644
  - 0.6571171867841759
  - 0.6151024342956639
  - 0.7381676913382784
  - 0.7482907052691429
  - 0.7382374296430226
  - 0.7232724189511792
  - 0.7665695500661922
  - 0.7723858330892169
  - 0.7652873172312544
  - 0.7519193461503454
  - 0.7439514564644159
  - 0.7501875311526018
  - 0.7539511393815926
  - 0.7451829698422598
  TL_balanced_accuracy:
  - 0.8344138478261227
  - 0.8282617924691179
  - 0.8431804472525843
  - 0.8222912404091527
  - 0.8766700948986246
  - 0.8798871381519133
  - 0.8755513573486977
  - 0.8635353213186361
  - 0.8886114782455612
  - 0.8935408622908623
  - 0.8987507808916589
  - 0.8843389985211079
  - 0.8797012229476684
  - 0.8899650144885624
  - 0.9001297162916622
  - 0.8846621045616156
  TL_f1_macro:
  - 0.6331929777785482
  - 0.7442565160821785
  - 0.6420244320928316
  - 0.6273139102275658
  - 0.6545142774956938
  - 0.7639382537349012
  - 0.63294603236306
  - 0.6415229629380299
  - 0.655861361701767
  - 0.7717843697971668
  - 0.7608087629917002
  - 0.641098774007564
  - 0.7156432747081227
  - 0.7478924059316947
  - 0.7422207023718262
  - 0.6241823295202886
  TL_f1_micro:
  - 0.9658634538152611
  - 0.9852644109371618
  - 0.9659836952600822
  - 0.9651359930740928
  - 0.9658272730561888
  - 0.9842543828006636
  - 0.9567852247312604
  - 0.9626109227328475
  - 0.9672383226600094
  - 0.9860760406897049
  - 0.9856070990549023
  - 0.9644686530553351
  - 0.9850573465031296
  - 0.9855710266214559
  - 0.9852103022869922
  - 0.9628453935502489
  TL_f1_weighted:
  - 0.9757659030668144
  - 0.9871316478461883
  - 0.9756022339776599
  - 0.9752923506143477
  - 0.9755511691498683
  - 0.9866277077912532
  - 0.9701049288299717
  - 0.973582483571986
  - 0.9767192095677164
  - 0.988205954553693
  - 0.9880662882940681
  - 0.9752951660689814
  - 0.9882418863251127
  - 0.9881670631219125
  - 0.9880902459010714
  - 0.9749294723283358
  TL_matthews_corrcoef:
  - 0.3421197909740407
  - 0.5065460221939174
  - 0.3590338527770727
  - 0.3284363754929238
  - 0.39179595533315326
  - 0.5563284726561166
  - 0.36119856730504846
  - 0.3676035358918647
  - 0.3983497917180356
  - 0.5735031860512636
  - 0.5582001457142128
  - 0.3748937516993709
  - 0.481029767869176
  - 0.5346925191030315
  - 0.5299161916462567
  - 0.34933633807251885
  TL_precision_macro:
  - 0.5875008258008644
  - 0.69541481714219
  - 0.5939049037262554
  - 0.5836746700049821
  - 0.6018823054274667
  - 0.7036798159274089
  - 0.5868485777446439
  - 0.592929319158068
  - 0.6020830350136569
  - 0.7089401228225312
  - 0.6953522209904005
  - 0.5914201561668421
  - 0.652349810582625
  - 0.6832831660294562
  - 0.6754500845197059
  - 0.5793136857327008
  TL_precision_micro:
  - 0.9658634538152611
  - 0.9852644109371618
  - 0.9659836952600822
  - 0.9651359930740928
  - 0.9658272730561888
  - 0.9842543828006637
  - 0.9567852247312604
  - 0.9626109227328475
  - 0.9672383226600094
  - 0.9860760406897049
  - 0.9856070990549023
  - 0.9644686530553351
  - 0.9850573465031296
  - 0.9855710266214559
  - 0.9852103022869922
  - 0.9628453935502489
  TL_precision_weighted:
  - 0.9890796116231771
  - 0.9897907668002672
  - 0.9887542368030099
  - 0.9887836149377912
  - 0.9892960460012048
  - 0.990365111109495
  - 0.9885220197426884
  - 0.9887687410126257
  - 0.9901733409229286
  - 0.9916404330848422
  - 0.9920278457650307
  - 0.9903134787352599
  - 0.99301679705214
  - 0.9922474065195928
  - 0.9926410068642042
  - 0.9912282814913512
  TL_recall_macro:
  - 0.8344138478261227
  - 0.8282617924691179
  - 0.8431804472525843
  - 0.8222912404091527
  - 0.8766700948986246
  - 0.8798871381519133
  - 0.8755513573486977
  - 0.8635353213186361
  - 0.8886114782455612
  - 0.8935408622908623
  - 0.8987507808916589
  - 0.8843389985211079
  - 0.8797012229476684
  - 0.8899650144885624
  - 0.9001297162916622
  - 0.8846621045616156
  TL_recall_micro:
  - 0.9658634538152611
  - 0.9852644109371618
  - 0.9659836952600822
  - 0.9651359930740928
  - 0.9658272730561888
  - 0.9842543828006637
  - 0.9567852247312604
  - 0.9626109227328475
  - 0.9672383226600094
  - 0.9860760406897049
  - 0.9856070990549023
  - 0.9644686530553351
  - 0.9850573465031296
  - 0.9855710266214559
  - 0.9852103022869922
  - 0.9628453935502489
  TL_recall_weighted:
  - 0.9658634538152611
  - 0.9852644109371618
  - 0.9659836952600822
  - 0.9651359930740928
  - 0.9658272730561888
  - 0.9842543828006637
  - 0.9567852247312604
  - 0.9626109227328475
  - 0.9672383226600094
  - 0.9860760406897049
  - 0.9856070990549023
  - 0.9644686530553351
  - 0.9850573465031296
  - 0.9855710266214559
  - 0.9852103022869922
  - 0.9628453935502489
  TL_roc_auc:
  - 0.8441504167029268
  - 0.8402569428988454
  - 0.8536353497812762
  - 0.8322637471718287
  - 0.8883944286709536
  - 0.889457576091445
  - 0.8910009552648993
  - 0.8763473513053939
  - 0.9007092215134416
  - 0.9090943399782413
  - 0.9075165996408533
  - 0.8972464190310451
  - 0.8914537352146481
  - 0.898260745530857
  - 0.9063638764961298
  - 0.8984208852921519
  TT_average_precision:
  - 0.15713167407069525
  - 0.24567573194449396
  - 0.19822151340260852
  - 0.16357695601177044
  - 0.1729591432178532
  - 0.33896779595065746
  - 0.2245507486387495
  - 0.20784061976722956
  - 0.16700850571340634
  - 0.32791625471482777
  - 0.21037748183857066
  - 0.2029898144657585
  - 0.14503342985817796
  - 0.2039631271976885
  - 0.0996793179041556
  - 0.10647338045075223
  TT_balanced_accuracy:
  - 0.6285000102654649
  - 0.6856334099113882
  - 0.6872592203876478
  - 0.6711799425763622
  - 0.6643189373353052
  - 0.7412672451549327
  - 0.6923589926478657
  - 0.753904212802847
  - 0.6401902173913043
  - 0.738852719115877
  - 0.6367550524189659
  - 0.6815929343148331
  - 0.6024426068980524
  - 0.6622545168342318
  - 0.5849127357385041
  - 0.7063966823830664
  TT_f1_macro:
  - 0.5114216387074842
  - 0.5452681312887105
  - 0.5160068846815834
  - 0.5196050228124918
  - 0.5129365135954179
  - 0.5536604011010617
  - 0.5123195853068163
  - 0.5273862059440583
  - 0.509459785256436
  - 0.5477338729942205
  - 0.5458282970426314
  - 0.5148569468277456
  - 0.5413515487650683
  - 0.5255940345973404
  - 0.5176525565917823
  - 0.5144467876288485
  TT_f1_micro:
  - 0.9015705679862306
  - 0.950396179311842
  - 0.901009443178118
  - 0.9009551720395094
  - 0.8863489672977625
  - 0.9414957125800499
  - 0.8854336263974818
  - 0.8857049820905244
  - 0.8999031841652324
  - 0.9406273743623141
  - 0.9514816020840116
  - 0.8887984369912081
  - 0.9539049053356282
  - 0.9448062520351677
  - 0.9499077390643655
  - 0.9000325626831651
  TT_f1_weighted:
  - 0.938063371411003
  - 0.9677734518408929
  - 0.9392894833742562
  - 0.9378195618076326
  - 0.9288994987565653
  - 0.9624951792588726
  - 0.9296276267971889
  - 0.9289426504163505
  - 0.9380600991969535
  - 0.9624980036454104
  - 0.9663435986739052
  - 0.9309382241314684
  - 0.9665157066281782
  - 0.9658866654863741
  - 0.9673287901036492
  - 0.9395774131820366
  TT_matthews_corrcoef:
  - 0.09306535752713105
  - 0.1524821351561888
  - 0.1233310768656017
  - 0.12275065998413867
  - 0.11489763359961089
  - 0.18976773799093402
  - 0.12521164576921331
  - 0.17264092887577168
  - 0.09554881199922428
  - 0.1796684518836227
  - 0.13255589464022924
  - 0.12383149721715797
  - 0.11011381233114394
  - 0.11442613408164669
  - 0.07057744449777176
  - 0.12798289778416314
  TT_precision_macro:
  - 0.5168505059917113
  - 0.5313127921758386
  - 0.5203068165206249
  - 0.5220056805425963
  - 0.5200851259460312
  - 0.5373152542516395
  - 0.5203759075939527
  - 0.5293465890089744
  - 0.5162806928406786
  - 0.5337872986350607
  - 0.5321214187210437
  - 0.5211107328609735
  - 0.5295898650796852
  - 0.520174076531638
  - 0.5146655729217582
  - 0.5198399774842691
  TT_precision_micro:
  - 0.9015705679862306
  - 0.950396179311842
  - 0.9010094431781179
  - 0.9009551720395094
  - 0.8863489672977625
  - 0.9414957125800499
  - 0.8854336263974818
  - 0.8857049820905243
  - 0.8999031841652324
  - 0.9406273743623141
  - 0.9514816020840117
  - 0.8887984369912081
  - 0.9539049053356282
  - 0.9448062520351677
  - 0.9499077390643655
  - 0.9000325626831651
  TT_precision_weighted:
  - 0.9809669791866932
  - 0.9879591021525795
  - 0.9850726988481642
  - 0.9820600733214517
  - 0.9805557650941383
  - 0.9877702203044647
  - 0.9835326108000632
  - 0.9835090434749703
  - 0.9830051564273065
  - 0.9885912555308002
  - 0.9833785735892063
  - 0.9821932655587737
  - 0.9806635114778949
  - 0.9897733796781555
  - 0.9864639209996408
  - 0.9869278278127717
  TT_recall_macro:
  - 0.6285000102654649
  - 0.6856334099113882
  - 0.6872592203876478
  - 0.6711799425763622
  - 0.6643189373353052
  - 0.7412672451549327
  - 0.6923589926478657
  - 0.753904212802847
  - 0.6401902173913043
  - 0.738852719115877
  - 0.6367550524189659
  - 0.6815929343148331
  - 0.6024426068980524
  - 0.6622545168342318
  - 0.5849127357385041
  - 0.7063966823830664
  TT_recall_micro:
  - 0.9015705679862306
  - 0.950396179311842
  - 0.9010094431781179
  - 0.9009551720395094
  - 0.8863489672977625
  - 0.9414957125800499
  - 0.8854336263974818
  - 0.8857049820905243
  - 0.8999031841652324
  - 0.9406273743623141
  - 0.9514816020840117
  - 0.8887984369912081
  - 0.9539049053356282
  - 0.9448062520351677
  - 0.9499077390643655
  - 0.9000325626831651
  TT_recall_weighted:
  - 0.9015705679862306
  - 0.950396179311842
  - 0.9010094431781179
  - 0.9009551720395094
  - 0.8863489672977625
  - 0.9414957125800499
  - 0.8854336263974817
  - 0.8857049820905243
  - 0.8999031841652324
  - 0.9406273743623141
  - 0.9514816020840117
  - 0.8887984369912081
  - 0.9539049053356282
  - 0.9448062520351677
  - 0.9499077390643655
  - 0.9000325626831651
  TT_roc_auc:
  - 0.6377441897468537
  - 0.6812732848946748
  - 0.7016108563648482
  - 0.6842647003342124
  - 0.6740987846502615
  - 0.7682812328917115
  - 0.7081046307472841
  - 0.772418383704061
  - 0.6512156080163043
  - 0.7778950030016887
  - 0.6988745395730427
  - 0.7016947859303924
  - 0.6190649755713404
  - 0.719696492267359
  - 0.6440672801987469
  - 0.7186095662035628
  fit_time:
  - 105.45720887184143
  - 88.5809555053711
  - 90.2586727142334
  - 75.95559310913086
  - 97.52125692367554
  - 78.52906131744385
  - 91.62735557556152
  - 85.72327327728271
  - 78.12119841575623
  - 92.58684968948364
  - 92.65984606742859
  - 75.32155013084412
  - 77.13593173027039
  - 92.52528119087219
  - 111.66315865516663
  - 93.36128616333008
  score_time:
  - 14.575854063034058
  - 16.459184885025024
  - 18.344825983047485
  - 16.658790111541748
  - 15.924877405166626
  - 18.90791964530945
  - 19.37580108642578
  - 18.805288076400757
  - 18.00678277015686
  - 15.643043518066406
  - 18.504559755325317
  - 16.94462513923645
  - 18.0901780128479
  - 18.374481678009033
  - 13.293952465057373
  - 15.314738988876343
start: 2023-08-10 20:12:33.738939
wrapper: null
