active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: runs
end: 2023-08-10 20:12:02.616578
estimator:
  call: missing_data_simulation.estimators.md_ss_bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        bipartiteextratreesregressorss:
          call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
          params:
            axis_decision_only: false
            bipartite_adapter: gmosa
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error_gso
            max_col_features: null
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_row_features: null
            max_samples: null
            min_col_weight_fraction_leaf: 0.0
            min_cols_leaf: 1
            min_cols_split: 1
            min_impurity_decrease: 0.0
            min_row_weight_fraction_leaf: 0.0
            min_rows_leaf: 1
            min_rows_split: 1
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            prediction_weights: null
            preprocess_X_targets: null
            random_state: null
            ss_adapter: null
            supervision: 0.5
            unsupervised_criterion_cols: mean_distance
            unsupervised_criterion_rows: mean_distance
            update_supervision: null
            verbose: 0
            warm_start: false
        bipartiteextratreesregressorss__axis_decision_only: false
        bipartiteextratreesregressorss__bipartite_adapter: gmosa
        bipartiteextratreesregressorss__bootstrap: false
        bipartiteextratreesregressorss__ccp_alpha: 0.0
        bipartiteextratreesregressorss__criterion: squared_error_gso
        bipartiteextratreesregressorss__max_col_features: null
        bipartiteextratreesregressorss__max_depth: null
        bipartiteextratreesregressorss__max_features: 1.0
        bipartiteextratreesregressorss__max_leaf_nodes: null
        bipartiteextratreesregressorss__max_row_features: null
        bipartiteextratreesregressorss__max_samples: null
        bipartiteextratreesregressorss__min_col_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_cols_leaf: 1
        bipartiteextratreesregressorss__min_cols_split: 1
        bipartiteextratreesregressorss__min_impurity_decrease: 0.0
        bipartiteextratreesregressorss__min_row_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_rows_leaf: 1
        bipartiteextratreesregressorss__min_rows_split: 1
        bipartiteextratreesregressorss__min_samples_leaf: 1
        bipartiteextratreesregressorss__min_samples_split: 2
        bipartiteextratreesregressorss__min_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__n_estimators: 100
        bipartiteextratreesregressorss__n_jobs: 3
        bipartiteextratreesregressorss__oob_score: false
        bipartiteextratreesregressorss__prediction_weights: null
        bipartiteextratreesregressorss__preprocess_X_targets: null
        bipartiteextratreesregressorss__random_state: null
        bipartiteextratreesregressorss__ss_adapter: null
        bipartiteextratreesregressorss__supervision: 0.5
        bipartiteextratreesregressorss__unsupervised_criterion_cols: mean_distance
        bipartiteextratreesregressorss__unsupervised_criterion_rows: mean_distance
        bipartiteextratreesregressorss__update_supervision: null
        bipartiteextratreesregressorss__verbose: 0
        bipartiteextratreesregressorss__warm_start: false
        memory: null
        minmaxscaler:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: sklearn.preprocessing._data.MinMaxScaler
              params:
                clip: true
                copy: true
                feature_range:
                - 0
                - 1
            transformers__clip: true
            transformers__copy: true
            transformers__feature_range:
            - 0
            - 1
        minmaxscaler__ndim: 2
        minmaxscaler__transformers:
          call: sklearn.preprocessing._data.MinMaxScaler
          params:
            clip: true
            copy: true
            feature_range:
            - 0
            - 1
        minmaxscaler__transformers__clip: true
        minmaxscaler__transformers__copy: true
        minmaxscaler__transformers__feature_range:
        - 0
        - 1
        positivedropper:
          call: missing_data_simulation.positive_dropper.PositiveDropper
          params:
            drop: 0.0
            random_state:
              call: numpy.random.mtrand.RandomState
              params: {}
        positivedropper__drop: 0.0
        positivedropper__random_state:
          call: numpy.random.mtrand.RandomState
          params: {}
        similaritydistanceswitcher:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
              params: {}
        similaritydistanceswitcher__ndim: 2
        similaritydistanceswitcher__transformers:
          call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
          params: {}
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
              samplers__sampling_strategy: auto
        - - minmaxscaler
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: sklearn.preprocessing._data.MinMaxScaler
                params:
                  clip: true
                  copy: true
                  feature_range:
                  - 0
                  - 1
              transformers__clip: true
              transformers__copy: true
              transformers__feature_range:
              - 0
              - 1
        - - similaritydistanceswitcher
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                params: {}
        - - positivedropper
          - call: missing_data_simulation.positive_dropper.PositiveDropper
            params:
              drop: 0.0
              random_state:
                call: numpy.random.mtrand.RandomState
                params: {}
        - - bipartiteextratreesregressorss
          - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
            params:
              axis_decision_only: false
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              preprocess_X_targets: null
              random_state: null
              ss_adapter: null
              supervision: 0.5
              unsupervised_criterion_cols: mean_distance
              unsupervised_criterion_rows: mean_distance
              update_supervision: null
              verbose: 0
              warm_start: false
        symmetryenforcer:
          call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
          params:
            ndim: 2
            samplers:
              call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
              params:
                sampling_strategy: auto
            samplers__sampling_strategy: auto
        symmetryenforcer__ndim: 2
        symmetryenforcer__samplers:
          call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
          params:
            sampling_strategy: auto
        symmetryenforcer__samplers__sampling_strategy: auto
        verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: 60d973c8f23db7aedb69785bc274bfd6818604c637959e4995dbd3c62f591169
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/60d973c_20230810T201200285596_md_ss_bxt_gso_nuclear_receptors.yml
results:
  LL_average_precision:
  - 0.9921531701192718
  - 1.0
  - 1.0
  - 0.9924242424242424
  - 0.981318111053451
  - 1.0
  - 1.0
  - 0.9836363636363636
  - 0.9838097647356439
  - 1.0
  - 1.0
  - 0.9843137254901961
  - 0.9939817043813193
  - 1.0
  - 1.0
  - 0.9935897435897436
  LL_balanced_accuracy:
  - 0.9964589235127479
  - 1.0
  - 1.0
  - 0.9965469613259669
  - 0.9958275382475661
  - 1.0
  - 1.0
  - 0.9959183673469387
  - 0.9946018893387314
  - 1.0
  - 1.0
  - 0.9947368421052631
  - 0.9966124661246613
  - 1.0
  - 1.0
  - 0.9967105263157895
  LL_f1_macro:
  - 0.9760992760596512
  - 1.0
  - 1.0
  - 0.9765283678327157
  - 0.9638141188420519
  - 1.0
  - 1.0
  - 0.9660359260551099
  - 0.9655402640477266
  - 1.0
  - 1.0
  - 0.9661044973544973
  - 0.978920630905517
  - 1.0
  - 1.0
  - 0.9783498349834985
  LL_f1_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_f1_weighted:
  - 0.9935549148925676
  - 1.0
  - 1.0
  - 0.9937099270134935
  - 0.9923578626607149
  - 1.0
  - 1.0
  - 0.9925278488828433
  - 0.9902903232753978
  - 1.0
  - 1.0
  - 0.9905229707058975
  - 0.9938605020051748
  - 1.0
  - 1.0
  - 0.9940143282620947
  LL_matthews_corrcoef:
  - 0.9532954771575798
  - 1.0
  - 1.0
  - 0.9541153472008888
  - 0.9300864537292473
  - 1.0
  - 1.0
  - 0.9342463949786545
  - 0.9333219673061774
  - 1.0
  - 1.0
  - 0.9343794815169456
  - 0.9586989457846643
  - 1.0
  - 1.0
  - 0.9576032835067954
  LL_precision_macro:
  - 0.9576271186440678
  - 1.0
  - 1.0
  - 0.9583333333333333
  - 0.9361702127659575
  - 1.0
  - 1.0
  - 0.94
  - 0.9402985074626866
  - 1.0
  - 1.0
  - 0.9411764705882353
  - 0.9626865671641791
  - 1.0
  - 1.0
  - 0.9615384615384616
  LL_precision_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_precision_weighted:
  - 0.993978590544157
  - 1.0
  - 1.0
  - 0.9941163885323063
  - 0.9931131019036955
  - 1.0
  - 1.0
  - 0.9932220795892169
  - 0.9911940298507463
  - 1.0
  - 1.0
  - 0.9913916786226686
  - 0.9942164179104478
  - 1.0
  - 1.0
  - 0.9943714821763602
  LL_recall_macro:
  - 0.9964589235127479
  - 1.0
  - 1.0
  - 0.9965469613259669
  - 0.9958275382475661
  - 1.0
  - 1.0
  - 0.9959183673469387
  - 0.9946018893387314
  - 1.0
  - 1.0
  - 0.9947368421052631
  - 0.9966124661246613
  - 1.0
  - 1.0
  - 0.9967105263157895
  LL_recall_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_recall_weighted:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_roc_auc:
  - 0.9996721225474766
  - 1.0
  - 1.0
  - 0.9996860873932698
  - 0.9993893958411072
  - 1.0
  - 1.0
  - 0.999443413729128
  - 0.9992680527916923
  - 1.0
  - 1.0
  - 0.999298245614035
  - 0.9997268117842469
  - 1.0
  - 1.0
  - 0.9997258771929824
  LT_average_precision:
  - 0.354428681054068
  - 0.3681935819800281
  - 0.23708507622981304
  - 0.4678962543181915
  - 0.26356823431126836
  - 0.3799068564161443
  - 0.16820883174082352
  - 0.26240387167382073
  - 0.361090351857409
  - 0.37592035509163596
  - 0.30135473567897975
  - 0.40056479984403726
  - 0.3481961926961927
  - 0.4152204491434386
  - 0.3282717253443087
  - 0.45018778396387504
  LT_balanced_accuracy:
  - 0.7402390438247012
  - 0.7460580912863071
  - 0.6998563218390805
  - 0.8113120784794605
  - 0.687007874015748
  - 0.6491869918699187
  - 0.6296099290780142
  - 0.7724089635854341
  - 0.7375621890547264
  - 0.7019470062948323
  - 0.8448894202032278
  - 0.7659729828404527
  - 0.7654088050314465
  - 0.6873810569462743
  - 0.7568870523415978
  - 0.7953280077463084
  LT_f1_macro:
  - 0.6290097629009763
  - 0.6886461178306672
  - 0.6049663299663299
  - 0.6270393694987663
  - 0.5805809128630706
  - 0.6123212667900895
  - 0.5425925925925926
  - 0.6008080808080808
  - 0.6126302083333334
  - 0.6571428571428571
  - 0.6790952667987027
  - 0.6275783040488923
  - 0.6228522619008509
  - 0.6524477006448488
  - 0.6316431089585186
  - 0.6748891667613959
  LT_f1_micro:
  - 0.8646616541353384
  - 0.8646616541353384
  - 0.8461538461538461
  - 0.8340080971659919
  - 0.8571428571428571
  - 0.8609022556390977
  - 0.8218623481781376
  - 0.8704453441295547
  - 0.8785714285714286
  - 0.85
  - 0.8346153846153846
  - 0.8846153846153846
  - 0.8535714285714285
  - 0.8535714285714285
  - 0.8346153846153846
  - 0.873076923076923
  LT_f1_weighted:
  - 0.8913392267279077
  - 0.8787428970397121
  - 0.8761460761460761
  - 0.8733771486244316
  - 0.8904327208061648
  - 0.8760738652871592
  - 0.865272154745839
  - 0.9049801660327976
  - 0.9060825892857143
  - 0.8646938775510205
  - 0.8664067899149274
  - 0.9107950872656755
  - 0.886230306045346
  - 0.8658465856749287
  - 0.8672171490991298
  - 0.895531693496909
  LT_matthews_corrcoef:
  - 0.3133363964507831
  - 0.3977067707277416
  - 0.261802347866972
  - 0.3610250276389315
  - 0.22183912735402844
  - 0.23867590267371552
  - 0.1483512626594161
  - 0.29272456558159426
  - 0.28748763530694077
  - 0.33067484375842754
  - 0.45146988282110123
  - 0.32165746661721895
  - 0.32257228026768286
  - 0.31612744851511965
  - 0.33348544126808416
  - 0.4046885275068718
  LT_precision_macro:
  - 0.6021687563537784
  - 0.6607046070460705
  - 0.5857371794871795
  - 0.6046691403834261
  - 0.5657894736842105
  - 0.5954610482507479
  - 0.5424506387921022
  - 0.5786388140161725
  - 0.586976320582878
  - 0.6353645373368659
  - 0.647746671218846
  - 0.5972500333733813
  - 0.5980118914901523
  - 0.6333333333333333
  - 0.6082309701131637
  - 0.6386363636363637
  LT_precision_micro:
  - 0.8646616541353384
  - 0.8646616541353384
  - 0.8461538461538461
  - 0.8340080971659919
  - 0.8571428571428571
  - 0.8609022556390977
  - 0.8218623481781376
  - 0.8704453441295547
  - 0.8785714285714286
  - 0.85
  - 0.8346153846153846
  - 0.8846153846153846
  - 0.8535714285714285
  - 0.8535714285714285
  - 0.8346153846153846
  - 0.8730769230769231
  LT_precision_weighted:
  - 0.9316811173987153
  - 0.9001324449334719
  - 0.9201183431952663
  - 0.9417512312249154
  - 0.9368816778789079
  - 0.8954096125995832
  - 0.9247132841484573
  - 0.9561738162532601
  - 0.9458626073380172
  - 0.8854037876557748
  - 0.9306451401108281
  - 0.9497910312888287
  - 0.9378517014386578
  - 0.882202380952381
  - 0.9212563333754938
  - 0.9329895104895104
  LT_recall_macro:
  - 0.7402390438247012
  - 0.7460580912863071
  - 0.6998563218390805
  - 0.8113120784794605
  - 0.687007874015748
  - 0.6491869918699187
  - 0.6296099290780142
  - 0.7724089635854341
  - 0.7375621890547264
  - 0.7019470062948323
  - 0.8448894202032278
  - 0.7659729828404527
  - 0.7654088050314465
  - 0.6873810569462743
  - 0.7568870523415978
  - 0.7953280077463084
  LT_recall_micro:
  - 0.8646616541353384
  - 0.8646616541353384
  - 0.8461538461538461
  - 0.8340080971659919
  - 0.8571428571428571
  - 0.8609022556390977
  - 0.8218623481781376
  - 0.8704453441295547
  - 0.8785714285714286
  - 0.85
  - 0.8346153846153846
  - 0.8846153846153846
  - 0.8535714285714285
  - 0.8535714285714285
  - 0.8346153846153846
  - 0.8730769230769231
  LT_recall_weighted:
  - 0.8646616541353384
  - 0.8646616541353384
  - 0.8461538461538461
  - 0.8340080971659919
  - 0.8571428571428571
  - 0.8609022556390977
  - 0.8218623481781376
  - 0.8704453441295547
  - 0.8785714285714286
  - 0.85
  - 0.8346153846153846
  - 0.8846153846153846
  - 0.8535714285714285
  - 0.8535714285714285
  - 0.8346153846153846
  - 0.8730769230769231
  LT_roc_auc:
  - 0.7414342629482072
  - 0.7858921161825725
  - 0.7922413793103449
  - 0.8169834457388105
  - 0.6806102362204725
  - 0.7247967479674797
  - 0.7742907801418439
  - 0.8338001867413631
  - 0.7599502487562189
  - 0.7536231884057971
  - 0.8667065152420801
  - 0.8123402701715955
  - 0.7723270440251571
  - 0.796369492021666
  - 0.8624885215794307
  - 0.8261922052771726
  TL_average_precision:
  - 0.3630508026503775
  - 0.3981337488422509
  - 0.4985077770945777
  - 0.3912645151154642
  - 0.4118405704618628
  - 0.258327497665733
  - 0.371415297525213
  - 0.3825043053386199
  - 0.05960480420031382
  - 0.12432626896912612
  - 0.1434289419553647
  - 0.15929598856428126
  - 0.3147012578616352
  - 0.30654761904761907
  - 0.36908667332287354
  - 0.3361475922451532
  TL_balanced_accuracy:
  - 0.7357930449533503
  - 0.7608758282915586
  - 0.8241758241758241
  - 0.731309376290789
  - 0.6675087446560435
  - 0.6263020833333334
  - 0.6544159544159545
  - 0.6567094359796846
  - 0.5404947475432057
  - 0.48339545916638427
  - 0.5497076023391813
  - 0.5916143941895016
  - 0.5608695652173913
  - 0.5698957694665849
  - 0.580168776371308
  - 0.5787388577088148
  TL_f1_macro:
  - 0.6705882352941176
  - 0.644730164100829
  - 0.7174185463659148
  - 0.6570093796400247
  - 0.6606060606060606
  - 0.6447201466234316
  - 0.6570093796400246
  - 0.6591333265465404
  - 0.5088372093023256
  - 0.4836909122623409
  - 0.5324886877828053
  - 0.5443556248781438
  - 0.49921752738654146
  - 0.5018892022776862
  - 0.5030730218764774
  - 0.5269230769230768
  TL_f1_micro:
  - 0.8928571428571429
  - 0.8928571428571429
  - 0.9233449477351916
  - 0.8850174216027874
  - 0.8607142857142858
  - 0.9035714285714286
  - 0.8850174216027874
  - 0.8780487804878049
  - 0.8166666666666667
  - 0.8458333333333333
  - 0.8292682926829268
  - 0.845528455284553
  - 0.8000000000000002
  - 0.8375
  - 0.8089430894308943
  - 0.8211382113821138
  TL_f1_weighted:
  - 0.9063865546218487
  - 0.9140645769388791
  - 0.935112170670579
  - 0.9015821084120481
  - 0.8635064935064936
  - 0.8959900102716963
  - 0.8840430282610663
  - 0.8770969741663212
  - 0.8555503875968993
  - 0.8692554799697657
  - 0.8504668358900782
  - 0.8756457383251938
  - 0.854981742305686
  - 0.8869046351977011
  - 0.8644117545314361
  - 0.8605691056910568
  TL_matthews_corrcoef:
  - 0.36353569093381266
  - 0.3404753671794719
  - 0.4706814286279978
  - 0.3427688387909773
  - 0.3218407176792887
  - 0.2961172983969374
  - 0.3141114691987002
  - 0.31835017827861767
  - 0.050765002885786566
  - -0.02418510127210921
  - 0.07696169273016998
  - 0.12028087389831715
  - 0.06286946134619316
  - 0.06587817087815967
  - 0.07854682872148545
  - 0.0964608903316959
  TL_precision_macro:
  - 0.6401209677419355
  - 0.6110906637222426
  - 0.6708494208494209
  - 0.626984126984127
  - 0.6545911047345767
  - 0.6735629613061955
  - 0.6597406424992632
  - 0.6616795366795367
  - 0.5159099986686193
  - 0.4911933860531991
  - 0.5297897196261683
  - 0.5394793000426803
  - 0.5162337662337663
  - 0.5155228758169934
  - 0.5192394239423942
  - 0.5295429208472687
  TL_precision_micro:
  - 0.8928571428571429
  - 0.8928571428571429
  - 0.9233449477351916
  - 0.8850174216027874
  - 0.8607142857142858
  - 0.9035714285714286
  - 0.8850174216027874
  - 0.8780487804878049
  - 0.8166666666666667
  - 0.8458333333333333
  - 0.8292682926829268
  - 0.8455284552845529
  - 0.8
  - 0.8375
  - 0.8089430894308943
  - 0.8211382113821138
  TL_precision_weighted:
  - 0.9256192396313364
  - 0.9455237744711429
  - 0.9539504661455882
  - 0.9254466014047896
  - 0.8665479606476737
  - 0.8904815158002364
  - 0.8831001724189277
  - 0.8761754537015861
  - 0.9036324501841743
  - 0.8948792834890966
  - 0.8753419193070435
  - 0.9135393786716355
  - 0.926948051948052
  - 0.9486587690631808
  - 0.9372928146473184
  - 0.9113938965476612
  TL_recall_macro:
  - 0.7357930449533503
  - 0.7608758282915586
  - 0.8241758241758241
  - 0.731309376290789
  - 0.6675087446560435
  - 0.6263020833333334
  - 0.6544159544159545
  - 0.6567094359796846
  - 0.5404947475432057
  - 0.48339545916638427
  - 0.5497076023391813
  - 0.5916143941895016
  - 0.5608695652173913
  - 0.5698957694665849
  - 0.580168776371308
  - 0.5787388577088148
  TL_recall_micro:
  - 0.8928571428571429
  - 0.8928571428571429
  - 0.9233449477351916
  - 0.8850174216027874
  - 0.8607142857142858
  - 0.9035714285714286
  - 0.8850174216027874
  - 0.8780487804878049
  - 0.8166666666666667
  - 0.8458333333333333
  - 0.8292682926829268
  - 0.8455284552845529
  - 0.8
  - 0.8375
  - 0.8089430894308943
  - 0.8211382113821138
  TL_recall_weighted:
  - 0.8928571428571429
  - 0.8928571428571429
  - 0.9233449477351916
  - 0.8850174216027874
  - 0.8607142857142858
  - 0.9035714285714286
  - 0.8850174216027874
  - 0.8780487804878049
  - 0.8166666666666667
  - 0.8458333333333333
  - 0.8292682926829268
  - 0.8455284552845529
  - 0.8
  - 0.8375
  - 0.8089430894308943
  - 0.8211382113821138
  TL_roc_auc:
  - 0.7549830364715862
  - 0.7422932872371075
  - 0.805729984301413
  - 0.7109665427509295
  - 0.6198989506412749
  - 0.553466796875
  - 0.5977207977207977
  - 0.6001737503341352
  - 0.41850220264317184
  - 0.3713995255845476
  - 0.48830409356725146
  - 0.4719379333113239
  - 0.6078260869565217
  - 0.4895769466584917
  - 0.655883731833099
  - 0.5850115549686365
  TT_average_precision:
  - 0.06207482993197279
  - 0.2539102933191603
  - 0.12778231757144076
  - 0.4458689458689459
  - 0.21220186187682621
  - 0.3564778427147765
  - 0.38971306471306466
  - 0.20849059226668332
  - 0.13821217097079166
  - 0.1797993672993673
  - 0.01282051282051282
  - 0.1627638234781092
  - 0.03571428571428571
  - 0.14947089947089948
  - 0.06261904761904762
  - -0.0
  TT_balanced_accuracy:
  - 0.46842105263157896
  - 0.6319444444444444
  - 0.5595238095238095
  - 0.7651515151515151
  - 0.7119565217391304
  - 0.6570135746606335
  - 0.6944444444444444
  - 0.5384036144578312
  - 0.532051282051282
  - 0.5961538461538461
  - 0.42857142857142855
  - 0.611111111111111
  - 0.3950617283950617
  - 0.4807692307692307
  - 0.39864864864864863
  - 0.9358974358974359
  TT_f1_macro:
  - 0.47593582887700536
  - 0.6
  - 0.5272080940661745
  - 0.57825311942959
  - 0.6597222222222222
  - 0.6676356589147288
  - 0.6640295358649789
  - 0.544378698224852
  - 0.5241830065359477
  - 0.5549275874249382
  - 0.45833333333333337
  - 0.5821428571428571
  - 0.43243243243243235
  - 0.471064467766117
  - 0.43065693430656937
  - 0.48344370860927155
  TT_f1_micro:
  - 0.9081632653061225
  - 0.8469387755102041
  - 0.7912087912087912
  - 0.8571428571428571
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.8461538461538461
  - 0.8791208791208791
  - 0.8452380952380952
  - 0.8214285714285714
  - 0.8461538461538461
  - 0.8461538461538461
  - 0.7619047619047619
  - 0.75
  - 0.7564102564102565
  - 0.9358974358974359
  TT_f1_weighted:
  - 0.9227327294554186
  - 0.8629737609329445
  - 0.8261500599482552
  - 0.8985994397759105
  - 0.9095804988662132
  - 0.8520210409745295
  - 0.8570269393054205
  - 0.8662461798556472
  - 0.8591970121381886
  - 0.8501286773981933
  - 0.90491452991453
  - 0.8631868131868131
  - 0.8339768339768338
  - 0.8002998500749625
  - 0.8171439266329777
  - 0.9668874172185431
  TT_matthews_corrcoef:
  - -0.04538167656120387
  - 0.21301305143216562
  - 0.08333333333333333
  - 0.262431940540739
  - 0.33574146603571364
  - 0.3374367401753192
  - 0.337099931231621
  - 0.0954447200861461
  - 0.053376051268362375
  - 0.13693634517621384
  - -0.04617570965396101
  - 0.17712297710801908
  - -0.096940482558378
  - -0.02465401844283986
  - -0.11344607913018796
  - 0.0
  TT_precision_macro:
  - 0.483695652173913
  - 0.5859728506787331
  - 0.5291666666666667
  - 0.564935064935065
  - 0.6329545454545454
  - 0.6812957157784744
  - 0.6461038961038961
  - 0.5593023255813954
  - 0.5222222222222223
  - 0.5487540628385699
  - 0.4925373134328358
  - 0.5705882352941176
  - 0.47761194029850745
  - 0.49209833187006147
  - 0.46825396825396826
  - 0.5
  TT_precision_micro:
  - 0.9081632653061225
  - 0.8469387755102041
  - 0.7912087912087912
  - 0.8571428571428571
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.8461538461538461
  - 0.8791208791208791
  - 0.8452380952380952
  - 0.8214285714285714
  - 0.8461538461538461
  - 0.8461538461538461
  - 0.7619047619047619
  - 0.75
  - 0.7564102564102564
  - 0.9358974358974359
  TT_precision_weighted:
  - 0.9377772848269742
  - 0.8831840428479083
  - 0.8711538461538462
  - 0.9591836734693878
  - 0.9251391465677179
  - 0.8478877444394685
  - 0.8715570144141573
  - 0.8554306158957321
  - 0.8746031746031746
  - 0.8872465562606406
  - 0.9724454649827783
  - 0.8841628959276019
  - 0.9211087420042643
  - 0.8634767339771731
  - 0.8884818884818885
  - 1.0
  TT_recall_macro:
  - 0.46842105263157896
  - 0.6319444444444444
  - 0.5595238095238095
  - 0.7651515151515151
  - 0.7119565217391304
  - 0.6570135746606335
  - 0.6944444444444444
  - 0.5384036144578312
  - 0.532051282051282
  - 0.5961538461538461
  - 0.42857142857142855
  - 0.611111111111111
  - 0.3950617283950617
  - 0.4807692307692307
  - 0.39864864864864863
  - 0.46794871794871795
  TT_recall_micro:
  - 0.9081632653061225
  - 0.8469387755102041
  - 0.7912087912087912
  - 0.8571428571428571
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.8461538461538461
  - 0.8791208791208791
  - 0.8452380952380952
  - 0.8214285714285714
  - 0.8461538461538461
  - 0.8461538461538461
  - 0.7619047619047619
  - 0.75
  - 0.7564102564102564
  - 0.9358974358974359
  TT_recall_weighted:
  - 0.9081632653061225
  - 0.8469387755102041
  - 0.7912087912087912
  - 0.8571428571428571
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.8461538461538461
  - 0.8791208791208791
  - 0.8452380952380952
  - 0.8214285714285714
  - 0.8461538461538461
  - 0.8461538461538461
  - 0.7619047619047619
  - 0.7499999999999999
  - 0.7564102564102564
  - 0.9358974358974359
  TT_roc_auc:
  - 0.4649122807017544
  - 0.6541666666666667
  - 0.5272108843537414
  - 0.8977272727272727
  - 0.7355072463768115
  - 0.7393665158371039
  - 0.7271604938271605
  - 0.7349397590361446
  - 0.642094017094017
  - 0.7991452991452992
  - 0.2272727272727273
  - 0.6585648148148149
  - 0.1728395061728395
  - 0.45085470085470086
  - 0.5405405405405406
  - .nan
  fit_time:
  - 0.4433932304382324
  - 0.4442007541656494
  - 0.43459153175354004
  - 0.4018099308013916
  - 0.44176459312438965
  - 0.4164154529571533
  - 0.4241163730621338
  - 0.43254947662353516
  - 0.424832820892334
  - 0.4295926094055176
  - 0.41066431999206543
  - 0.4660050868988037
  - 0.4586007595062256
  - 0.46235132217407227
  - 0.4523487091064453
  - 0.45097875595092773
  score_time:
  - 0.33398914337158203
  - 0.32471394538879395
  - 0.3439054489135742
  - 0.3685646057128906
  - 0.3462977409362793
  - 0.3463442325592041
  - 0.3552536964416504
  - 0.351489782333374
  - 0.35365843772888184
  - 0.335284948348999
  - 0.338392972946167
  - 0.36813902854919434
  - 0.343975305557251
  - 0.3387796878814697
  - 0.3639206886291504
  - 0.42781853675842285
start: 2023-08-10 20:12:00.285596
wrapper: null
