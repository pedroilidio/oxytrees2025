active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
    url: null
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
    url: null
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: utils.read_table_to_array
      params: {}
    url: null
directory: runs
end: 2023-08-11 01:12:03.707016
estimator:
  call: missing_data_simulation.estimators.md_ss_bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        bipartiteextratreesregressorss:
          call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
          params:
            axis_decision_only: false
            bipartite_adapter: gmosa
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error_gso
            max_col_features: null
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_row_features: null
            max_samples: null
            min_col_weight_fraction_leaf: 0.0
            min_cols_leaf: 1
            min_cols_split: 1
            min_impurity_decrease: 0.0
            min_row_weight_fraction_leaf: 0.0
            min_rows_leaf: 1
            min_rows_split: 1
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            prediction_weights: null
            preprocess_X_targets: null
            random_state: null
            ss_adapter: null
            supervision: 0.5
            unsupervised_criterion_cols: mean_distance
            unsupervised_criterion_rows: mean_distance
            update_supervision: null
            verbose: 0
            warm_start: false
        bipartiteextratreesregressorss__axis_decision_only: false
        bipartiteextratreesregressorss__bipartite_adapter: gmosa
        bipartiteextratreesregressorss__bootstrap: false
        bipartiteextratreesregressorss__ccp_alpha: 0.0
        bipartiteextratreesregressorss__criterion: squared_error_gso
        bipartiteextratreesregressorss__max_col_features: null
        bipartiteextratreesregressorss__max_depth: null
        bipartiteextratreesregressorss__max_features: 1.0
        bipartiteextratreesregressorss__max_leaf_nodes: null
        bipartiteextratreesregressorss__max_row_features: null
        bipartiteextratreesregressorss__max_samples: null
        bipartiteextratreesregressorss__min_col_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_cols_leaf: 1
        bipartiteextratreesregressorss__min_cols_split: 1
        bipartiteextratreesregressorss__min_impurity_decrease: 0.0
        bipartiteextratreesregressorss__min_row_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__min_rows_leaf: 1
        bipartiteextratreesregressorss__min_rows_split: 1
        bipartiteextratreesregressorss__min_samples_leaf: 1
        bipartiteextratreesregressorss__min_samples_split: 2
        bipartiteextratreesregressorss__min_weight_fraction_leaf: 0.0
        bipartiteextratreesregressorss__n_estimators: 100
        bipartiteextratreesregressorss__n_jobs: 3
        bipartiteextratreesregressorss__oob_score: false
        bipartiteextratreesregressorss__prediction_weights: null
        bipartiteextratreesregressorss__preprocess_X_targets: null
        bipartiteextratreesregressorss__random_state: null
        bipartiteextratreesregressorss__ss_adapter: null
        bipartiteextratreesregressorss__supervision: 0.5
        bipartiteextratreesregressorss__unsupervised_criterion_cols: mean_distance
        bipartiteextratreesregressorss__unsupervised_criterion_rows: mean_distance
        bipartiteextratreesregressorss__update_supervision: null
        bipartiteextratreesregressorss__verbose: 0
        bipartiteextratreesregressorss__warm_start: false
        memory: null
        minmaxscaler:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: sklearn.preprocessing._data.MinMaxScaler
              params:
                clip: true
                copy: true
                feature_range:
                - 0
                - 1
            transformers__clip: true
            transformers__copy: true
            transformers__feature_range:
            - 0
            - 1
        minmaxscaler__ndim: 2
        minmaxscaler__transformers:
          call: sklearn.preprocessing._data.MinMaxScaler
          params:
            clip: true
            copy: true
            feature_range:
            - 0
            - 1
        minmaxscaler__transformers__clip: true
        minmaxscaler__transformers__copy: true
        minmaxscaler__transformers__feature_range:
        - 0
        - 1
        positivedropper:
          call: missing_data_simulation.positive_dropper.PositiveDropper
          params:
            drop: 0.0
            random_state:
              call: numpy.random.mtrand.RandomState
              params: {}
        positivedropper__drop: 0.0
        positivedropper__random_state:
          call: numpy.random.mtrand.RandomState
          params: {}
        similaritydistanceswitcher:
          call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
          params:
            ndim: 2
            transformers:
              call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
              params: {}
        similaritydistanceswitcher__ndim: 2
        similaritydistanceswitcher__transformers:
          call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
          params: {}
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
              samplers__sampling_strategy: auto
        - - minmaxscaler
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: sklearn.preprocessing._data.MinMaxScaler
                params:
                  clip: true
                  copy: true
                  feature_range:
                  - 0
                  - 1
              transformers__clip: true
              transformers__copy: true
              transformers__feature_range:
              - 0
              - 1
        - - similaritydistanceswitcher
          - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                params: {}
        - - positivedropper
          - call: missing_data_simulation.positive_dropper.PositiveDropper
            params:
              drop: 0.0
              random_state:
                call: numpy.random.mtrand.RandomState
                params: {}
        - - bipartiteextratreesregressorss
          - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
            params:
              axis_decision_only: false
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              preprocess_X_targets: null
              random_state: null
              ss_adapter: null
              supervision: 0.5
              unsupervised_criterion_cols: mean_distance
              unsupervised_criterion_rows: mean_distance
              update_supervision: null
              verbose: 0
              warm_start: false
        symmetryenforcer:
          call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
          params:
            ndim: 2
            samplers:
              call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
              params:
                sampling_strategy: auto
            samplers__sampling_strategy: auto
        symmetryenforcer__ndim: 2
        symmetryenforcer__samplers:
          call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
          params:
            sampling_strategy: auto
        symmetryenforcer__samplers__sampling_strategy: auto
        verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: cd977031cf47c79a9a00d61dfa928c45e8b4d6287324dd0359df5bcfaa15a58f
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/cd97703_20230810T224751188938_md_ss_bxt_gso_mirna.yml
results:
  LL_average_precision:
  - 0.9999999574061432
  - 0.9999999447705892
  - 0.9999999989288516
  - 0.9999999577852506
  - 0.9999999666784143
  - 0.9999999672892359
  - 0.9999999903000732
  - 0.9999999773240815
  - 0.9999999757517867
  - 0.9999999389068782
  - 0.9999999901545192
  - 0.9999999385236996
  - 0.9999999413574494
  - 0.9999998890104351
  - 0.999999960940419
  - 0.9999999082560732
  LL_balanced_accuracy:
  - 0.9999901385776377
  - 0.9999888992495893
  - 0.9999987687458445
  - 0.999990169236592
  - 0.9999913786308281
  - 0.999991372510353
  - 0.999996309926789
  - 0.9999926328662571
  - 0.9999913826851061
  - 0.9999876811487083
  - 0.9999963119772228
  - 0.9999877265675627
  - 0.9999876864274878
  - 0.9999839865980144
  - 0.9999926217231228
  - 0.9999852722064444
  LL_f1_macro:
  - 0.9999306092537311
  - 0.9999224967642167
  - 0.9999912022713281
  - 0.9999309120743053
  - 0.9999392203603554
  - 0.9999397372434241
  - 0.9999735329050767
  - 0.9999481607669657
  - 0.9999388722012175
  - 0.999913397741542
  - 0.9999733498828177
  - 0.9999131685891792
  - 0.999912947460996
  - 0.9998873283397841
  - 0.9999469020922882
  - 0.9998957774405421
  LL_f1_micro:
  - 0.9999816784382701
  - 0.9999793882430539
  - 0.9999977098047838
  - 0.9999817371612243
  - 0.9999839800437116
  - 0.9999839800437116
  - 0.9999931343044478
  - 0.9999863126197646
  - 0.9999839800437116
  - 0.9999771143481594
  - 0.9999931343044478
  - 0.9999771876996076
  - 0.9999771143481594
  - 0.9999702486526072
  - 0.9999862686088956
  - 0.9999726252395291
  LL_f1_weighted:
  - 0.9999816795289383
  - 0.9999793896117232
  - 0.9999977098221124
  - 0.9999817382434265
  - 0.9999839808792835
  - 0.999983980870905
  - 0.9999931344608278
  - 0.9999863132284704
  - 0.9999839808849259
  - 0.99997711604818
  - 0.9999931344620985
  - 0.9999771894004433
  - 0.9999771160586058
  - 0.9999702515283131
  - 0.999986269236689
  - 0.9999726276894212
  LL_matthews_corrcoef:
  - 0.9998612281364537
  - 0.9998450055403222
  - 0.9999824046974538
  - 0.9998618336937488
  - 0.9998784481082605
  - 0.9998794817492889
  - 0.9999470672111034
  - 0.9998963269080599
  - 0.9998777518748565
  - 0.9998268104807319
  - 0.999946701186027
  - 0.9998263522554716
  - 0.9998259100759893
  - 0.9997746820644088
  - 0.9998938098228308
  - 0.9997915766018347
  LL_precision_macro:
  - 0.9998710966452902
  - 0.9998561151079137
  - 0.9999836360661103
  - 0.9998716714789861
  - 0.999887074917726
  - 0.9998881145706796
  - 0.9999507583218437
  - 0.9999036979969184
  - 0.9998863747037626
  - 0.9998391403661165
  - 0.9999503902632623
  - 0.9998386368037178
  - 0.9998382348183377
  - 0.9997907141477236
  - 0.9999011922798234
  - 0.9998063204106007
  LL_precision_micro:
  - 0.9999816784382701
  - 0.9999793882430539
  - 0.9999977098047838
  - 0.9999817371612243
  - 0.9999839800437116
  - 0.9999839800437116
  - 0.9999931343044478
  - 0.9999863126197646
  - 0.9999839800437116
  - 0.9999771143481594
  - 0.9999931343044478
  - 0.9999771876996076
  - 0.9999771143481594
  - 0.9999702486526072
  - 0.9999862686088956
  - 0.9999726252395291
  LL_precision_weighted:
  - 0.9999816831616916
  - 0.9999793941744947
  - 0.9999977098797369
  - 0.9999817418485105
  - 0.9999839836618214
  - 0.999983983628511
  - 0.9999931349806046
  - 0.9999863152560089
  - 0.9999839836842561
  - 0.9999771217109146
  - 0.9999931349856586
  - 0.999977195061739
  - 0.9999771217523626
  - 0.9999702611056794
  - 0.9999862713224305
  - 0.9999726358433939
  LL_recall_macro:
  - 0.9999901385776377
  - 0.9999888992495893
  - 0.9999987687458445
  - 0.999990169236592
  - 0.9999913786308281
  - 0.999991372510353
  - 0.999996309926789
  - 0.9999926328662571
  - 0.9999913826851061
  - 0.9999876811487083
  - 0.9999963119772228
  - 0.9999877265675627
  - 0.9999876864274878
  - 0.9999839865980144
  - 0.9999926217231228
  - 0.9999852722064444
  LL_recall_micro:
  - 0.9999816784382701
  - 0.9999793882430539
  - 0.9999977098047838
  - 0.9999817371612243
  - 0.9999839800437116
  - 0.9999839800437116
  - 0.9999931343044478
  - 0.9999863126197646
  - 0.9999839800437116
  - 0.9999771143481594
  - 0.9999931343044478
  - 0.9999771876996076
  - 0.9999771143481594
  - 0.9999702486526072
  - 0.9999862686088956
  - 0.9999726252395291
  LL_recall_weighted:
  - 0.9999816784382701
  - 0.9999793882430539
  - 0.9999977098047838
  - 0.9999817371612243
  - 0.9999839800437116
  - 0.9999839800437116
  - 0.9999931343044478
  - 0.9999863126197646
  - 0.9999839800437116
  - 0.9999771143481594
  - 0.9999931343044478
  - 0.9999771876996076
  - 0.9999771143481594
  - 0.9999702486526072
  - 0.9999862686088956
  - 0.9999726252395291
  LL_roc_auc:
  - 0.9999999979735497
  - 0.999999997396357
  - 0.9999999999597023
  - 0.9999999979888609
  - 0.9999999985293803
  - 0.9999999985418883
  - 0.9999999996365534
  - 0.999999998975013
  - 0.999999998920697
  - 0.9999999973834384
  - 0.9999999996340401
  - 0.9999999973849221
  - 0.9999999972901293
  - 0.9999999950402635
  - 0.9999999985416503
  - 0.9999999958781646
  LT_average_precision:
  - 0.15129680552701316
  - 0.13070577836975397
  - 0.1367841960429504
  - 0.15666396030322682
  - 0.150012798187499
  - 0.12392371152389277
  - 0.13264414874682898
  - 0.15172250860915132
  - 0.15024929337975607
  - 0.12453104461183591
  - 0.13300747408160488
  - 0.15264034321413078
  - 0.14523370564503385
  - 0.12553729482995707
  - 0.13135236372986944
  - 0.14839392870937998
  LT_balanced_accuracy:
  - 0.5930969320485644
  - 0.5896739060100451
  - 0.592658247936743
  - 0.5993021342209495
  - 0.5922797502266864
  - 0.5848355628644812
  - 0.5888019593626959
  - 0.595669327554824
  - 0.5901283864306612
  - 0.5834140222276614
  - 0.5883453136037416
  - 0.5957340354256638
  - 0.5897416424071531
  - 0.5845633602343404
  - 0.5845035543112522
  - 0.5930767147175517
  LT_f1_macro:
  - 0.5441572351671098
  - 0.5407254460219
  - 0.540272487791074
  - 0.5490176183942682
  - 0.546459004874495
  - 0.5372431358337844
  - 0.5392380878205132
  - 0.548584192190095
  - 0.542927290486055
  - 0.5353422465702599
  - 0.5376602360568714
  - 0.5457861759765645
  - 0.5443836975625276
  - 0.540311843302373
  - 0.538474281730722
  - 0.5482933140406451
  LT_f1_micro:
  - 0.80370644312952
  - 0.8034119548542625
  - 0.7888382095112865
  - 0.808169446518961
  - 0.8097933205584452
  - 0.801779359430605
  - 0.7900424308787299
  - 0.8115675638323603
  - 0.8055023268546401
  - 0.7999178757185874
  - 0.7874965781549411
  - 0.8069515945133539
  - 0.8096838215165617
  - 0.8085546126471393
  - 0.7944566110046537
  - 0.8140206612997961
  LT_f1_weighted:
  - 0.8395411005221882
  - 0.8401617567627392
  - 0.828396383689882
  - 0.8427859067438216
  - 0.8433188315994812
  - 0.8391666093377425
  - 0.8287896720422621
  - 0.8448357127057338
  - 0.8408521579359547
  - 0.8382004767292208
  - 0.8273190206252292
  - 0.8423681709003075
  - 0.8435634142106316
  - 0.8431892192749549
  - 0.8316982738767281
  - 0.846282850872879
  LT_matthews_corrcoef:
  - 0.12559711601142293
  - 0.11966326035693109
  - 0.123316749083952
  - 0.13470654220419875
  - 0.12651825379938234
  - 0.11272335492832462
  - 0.11905436768116183
  - 0.13108071218385145
  - 0.12186632957112355
  - 0.11005194323461451
  - 0.11755633295687253
  - 0.12889542564302625
  - 0.1225142723326944
  - 0.1146258551214725
  - 0.11431816298710934
  - 0.12852135442835352
  LT_precision_macro:
  - 0.5423607824749743
  - 0.5399204643702222
  - 0.5410298622714518
  - 0.5456834403786244
  - 0.5433650625005049
  - 0.5374446585761294
  - 0.5399032368364484
  - 0.5448998481168882
  - 0.5411951297235399
  - 0.5362991433762154
  - 0.5391064643232014
  - 0.5433859041818975
  - 0.5418137737470615
  - 0.5388439113166684
  - 0.538662996175911
  - 0.544365925984342
  LT_precision_micro:
  - 0.80370644312952
  - 0.8034119548542625
  - 0.7888382095112865
  - 0.808169446518961
  - 0.8097933205584451
  - 0.801779359430605
  - 0.7900424308787298
  - 0.8115675638323602
  - 0.8055023268546401
  - 0.7999178757185874
  - 0.7874965781549411
  - 0.8069515945133539
  - 0.8096838215165617
  - 0.8085546126471393
  - 0.7944566110046537
  - 0.8140206612997961
  LT_precision_weighted:
  - 0.8874312807564458
  - 0.8891285275324672
  - 0.882641958498594
  - 0.8891040135417648
  - 0.887528753898735
  - 0.888794918950376
  - 0.8814536931228153
  - 0.888807035898782
  - 0.8877398124394626
  - 0.8891120575477437
  - 0.8816951148783101
  - 0.8896505294510448
  - 0.8881153078152172
  - 0.88852890751124
  - 0.8815568262959466
  - 0.8885470041275746
  LT_recall_macro:
  - 0.5930969320485644
  - 0.5896739060100451
  - 0.592658247936743
  - 0.5993021342209495
  - 0.5922797502266864
  - 0.5848355628644812
  - 0.5888019593626959
  - 0.595669327554824
  - 0.5901283864306612
  - 0.5834140222276614
  - 0.5883453136037416
  - 0.5957340354256638
  - 0.5897416424071531
  - 0.5845633602343404
  - 0.5845035543112522
  - 0.5930767147175517
  LT_recall_micro:
  - 0.80370644312952
  - 0.8034119548542625
  - 0.7888382095112865
  - 0.808169446518961
  - 0.8097933205584451
  - 0.801779359430605
  - 0.7900424308787298
  - 0.8115675638323602
  - 0.8055023268546401
  - 0.7999178757185874
  - 0.7874965781549411
  - 0.8069515945133539
  - 0.8096838215165617
  - 0.8085546126471393
  - 0.7944566110046537
  - 0.8140206612997961
  LT_recall_weighted:
  - 0.80370644312952
  - 0.8034119548542625
  - 0.7888382095112865
  - 0.808169446518961
  - 0.8097933205584451
  - 0.801779359430605
  - 0.7900424308787298
  - 0.8115675638323602
  - 0.8055023268546401
  - 0.7999178757185874
  - 0.7874965781549411
  - 0.806951594513354
  - 0.8096838215165617
  - 0.8085546126471393
  - 0.7944566110046537
  - 0.8140206612997961
  LT_roc_auc:
  - 0.6422151560403427
  - 0.6370792570272965
  - 0.6263508642866562
  - 0.6486371126764832
  - 0.6421298644031719
  - 0.6265582661666287
  - 0.6237679224963686
  - 0.6454556996909535
  - 0.6396748822271363
  - 0.6275954520007723
  - 0.6232993053832686
  - 0.6439142929395645
  - 0.6378327509678356
  - 0.6281824821310938
  - 0.6194886686489258
  - 0.6430556248414532
  TL_average_precision:
  - 0.2785233147972919
  - 0.28779115776196146
  - 0.28211750524699286
  - 0.28786339027112867
  - 0.2512007007043911
  - 0.2573897813754408
  - 0.24071011757420685
  - 0.2558978676320629
  - 0.2995375329614146
  - 0.3004836319961879
  - 0.2925441630041306
  - 0.29784353080913273
  - 0.29447149489619007
  - 0.3065264683814459
  - 0.30020734944614175
  - 0.3011538202835346
  TL_balanced_accuracy:
  - 0.6385962854970406
  - 0.6476387055534141
  - 0.6388042645981991
  - 0.6436906971411074
  - 0.6417661939553183
  - 0.6512404522213275
  - 0.6385738808090078
  - 0.6472275323054049
  - 0.6633906591557224
  - 0.6624156432824224
  - 0.6502341087317309
  - 0.6617702742576267
  - 0.6542173117271453
  - 0.6586242771248987
  - 0.6505820310709889
  - 0.6569926490015598
  TL_f1_macro:
  - 0.51531348657218
  - 0.5210202941102947
  - 0.48458417364184114
  - 0.5168521342364122
  - 0.5138164077276849
  - 0.5200592859728075
  - 0.4859764826360328
  - 0.5172758234760269
  - 0.5353764650764634
  - 0.5333174090189681
  - 0.49857354451004243
  - 0.5330477776577065
  - 0.5234330298240668
  - 0.5275437948077994
  - 0.4933002220810761
  - 0.5284574233222051
  TL_f1_micro:
  - 0.7066687691537717
  - 0.7115364838645541
  - 0.6461788439520358
  - 0.7064949975397736
  - 0.7006898067991315
  - 0.7071756396515239
  - 0.6474358974358975
  - 0.7045940170940171
  - 0.7275675378569271
  - 0.7235207629098305
  - 0.6637397971803116
  - 0.7245233399079553
  - 0.7112430263555666
  - 0.714059966471542
  - 0.6546912358809465
  - 0.7182911461757615
  TL_f1_weighted:
  - 0.7772139085194345
  - 0.7804922022890357
  - 0.7336885974566985
  - 0.777121842503596
  - 0.7727916759208955
  - 0.7774101583210702
  - 0.7341797814858165
  - 0.7756759974686795
  - 0.7913369505325085
  - 0.7883465790977976
  - 0.7456210054976576
  - 0.7893000824920697
  - 0.7801142285421094
  - 0.7815321150880531
  - 0.7392720492560437
  - 0.7848229012548259
  TL_matthews_corrcoef:
  - 0.15410575139567725
  - 0.16516462181903407
  - 0.14503537785141746
  - 0.15958148600057595
  - 0.15689453113268328
  - 0.1683101569441841
  - 0.14568149792321852
  - 0.16328972378195483
  - 0.18676308449598616
  - 0.18512408339097333
  - 0.16099773222464656
  - 0.18407304985399311
  - 0.17267462706992898
  - 0.17926141075360155
  - 0.15947012680044018
  - 0.17766099293690532
  TL_precision_macro:
  - 0.5428376967825256
  - 0.5461927517556621
  - 0.5378865535749116
  - 0.5443074102583405
  - 0.5434093157412108
  - 0.5468266070923932
  - 0.5382884182669385
  - 0.5452760660239094
  - 0.5533697120610969
  - 0.5527518863927331
  - 0.5431331306856623
  - 0.5523626603188397
  - 0.5483352460560541
  - 0.5506458626129295
  - 0.5422207104673725
  - 0.5502625897009572
  TL_precision_micro:
  - 0.7066687691537717
  - 0.7115364838645541
  - 0.6461788439520358
  - 0.7064949975397736
  - 0.7006898067991315
  - 0.7071756396515239
  - 0.6474358974358975
  - 0.7045940170940171
  - 0.727567537856927
  - 0.7235207629098305
  - 0.6637397971803116
  - 0.7245233399079553
  - 0.7112430263555666
  - 0.714059966471542
  - 0.6546912358809465
  - 0.7182911461757615
  TL_precision_weighted:
  - 0.8980018066818926
  - 0.8991204198238542
  - 0.9020104503297008
  - 0.8989866930576479
  - 0.8983035771590222
  - 0.8998837216222492
  - 0.900873868961786
  - 0.8994495643508765
  - 0.9005678406297001
  - 0.9001111155766045
  - 0.9008872865149311
  - 0.9005629913307094
  - 0.8999056866180947
  - 0.8993006937142306
  - 0.9023887673962147
  - 0.8996221495238371
  TL_recall_macro:
  - 0.6385962854970406
  - 0.6476387055534141
  - 0.6388042645981991
  - 0.6436906971411074
  - 0.6417661939553183
  - 0.6512404522213275
  - 0.6385738808090078
  - 0.6472275323054049
  - 0.6633906591557224
  - 0.6624156432824224
  - 0.6502341087317309
  - 0.6617702742576267
  - 0.6542173117271453
  - 0.6586242771248987
  - 0.6505820310709889
  - 0.6569926490015598
  TL_recall_micro:
  - 0.7066687691537717
  - 0.7115364838645541
  - 0.6461788439520358
  - 0.7064949975397736
  - 0.7006898067991315
  - 0.7071756396515239
  - 0.6474358974358975
  - 0.7045940170940171
  - 0.727567537856927
  - 0.7235207629098305
  - 0.6637397971803116
  - 0.7245233399079553
  - 0.7112430263555666
  - 0.714059966471542
  - 0.6546912358809465
  - 0.7182911461757615
  TL_recall_weighted:
  - 0.7066687691537717
  - 0.7115364838645541
  - 0.6461788439520358
  - 0.7064949975397736
  - 0.7006898067991315
  - 0.7071756396515239
  - 0.6474358974358975
  - 0.7045940170940171
  - 0.727567537856927
  - 0.7235207629098305
  - 0.6637397971803116
  - 0.7245233399079553
  - 0.7112430263555666
  - 0.714059966471542
  - 0.6546912358809465
  - 0.7182911461757615
  TL_roc_auc:
  - 0.6948016780300447
  - 0.7077199064654007
  - 0.7000161735462477
  - 0.7024841080817308
  - 0.6990148738484404
  - 0.7085164481815236
  - 0.6971065443914098
  - 0.7046553605942267
  - 0.7215673637347179
  - 0.7233263261428735
  - 0.7149627566938086
  - 0.7201150060499057
  - 0.7144687326210307
  - 0.7222825728467771
  - 0.7169183542908889
  - 0.7184286309950406
  TT_average_precision:
  - 0.10319531436994972
  - 0.09018894876663355
  - 0.09927657721203359
  - 0.09989883181937403
  - 0.10312629298544752
  - 0.08869967348681984
  - 0.09563823708147667
  - 0.09452763211554599
  - 0.10765989680825719
  - 0.09551680921343977
  - 0.09967958890436748
  - 0.10334507385418804
  - 0.11976176706512129
  - 0.09774810258853414
  - 0.11167147551193506
  - 0.1114244707797422
  TT_balanced_accuracy:
  - 0.5428691424785832
  - 0.535498401425041
  - 0.54277343591876
  - 0.5443070299004631
  - 0.5404764092034533
  - 0.5369526611214674
  - 0.5393685830159469
  - 0.5382178215793989
  - 0.5517827115183898
  - 0.5458156450172388
  - 0.5439347258244694
  - 0.5474210675547045
  - 0.5521091536827196
  - 0.5403980050704088
  - 0.5553966393623149
  - 0.552437463480889
  TT_f1_macro:
  - 0.529027243586897
  - 0.5222170058541524
  - 0.52100038180186
  - 0.5300596936942027
  - 0.5277531841366953
  - 0.5228772334670058
  - 0.5196327093057497
  - 0.5276321092173463
  - 0.5382108766255871
  - 0.5302151986246058
  - 0.523623373243533
  - 0.5349211200388159
  - 0.5360180901163487
  - 0.5264498324588476
  - 0.5326419959613558
  - 0.5393515660898063
  TT_f1_micro:
  - 0.840515827456126
  - 0.837604559619485
  - 0.8066877152698049
  - 0.8411410354606993
  - 0.8409146942800789
  - 0.8340729783037475
  - 0.8104248849441157
  - 0.8451995685005393
  - 0.8459072978303747
  - 0.836250821827745
  - 0.8127465483234714
  - 0.8439756036843415
  - 0.8376890203813281
  - 0.8394148586456279
  - 0.8163214990138067
  - 0.8493693469421625
  TT_f1_weighted:
  - 0.8591814276743717
  - 0.8580181222985351
  - 0.8363493245823199
  - 0.8598044912754056
  - 0.8589687891628248
  - 0.8552268154413221
  - 0.83887520078927
  - 0.8610602649033584
  - 0.8617529277771402
  - 0.8563031508707365
  - 0.8400591495454859
  - 0.8598392731973336
  - 0.8565213543554706
  - 0.85896726323352
  - 0.8422057574674322
  - 0.8643508611464578
  TT_matthews_corrcoef:
  - 0.06742754985939668
  - 0.05479064864092095
  - 0.06195918726419494
  - 0.06962210580433345
  - 0.06415444777971813
  - 0.05680759539984737
  - 0.057484191093612635
  - 0.06202192225037295
  - 0.08396674341801291
  - 0.07121247251096377
  - 0.06477686663273557
  - 0.07708260002090447
  - 0.08213300669046324
  - 0.0628930482651833
  - 0.08259841472264155
  - 0.0856409126664027
  TT_precision_macro:
  - 0.5265136775380611
  - 0.5211419039870848
  - 0.5224376461931355
  - 0.5273502739154444
  - 0.5254209380903373
  - 0.5218326826619125
  - 0.5209839418423344
  - 0.5251631220766967
  - 0.5340384550822652
  - 0.5276718588116388
  - 0.5238765712771231
  - 0.5313243012671974
  - 0.5323639433346464
  - 0.5244785324992698
  - 0.5307893140866893
  - 0.534967203958137
  TT_precision_micro:
  - 0.840515827456126
  - 0.837604559619485
  - 0.8066877152698049
  - 0.8411410354606993
  - 0.8409146942800789
  - 0.8340729783037475
  - 0.8104248849441157
  - 0.8451995685005393
  - 0.8459072978303748
  - 0.8362508218277449
  - 0.8127465483234714
  - 0.8439756036843415
  - 0.8376890203813281
  - 0.8394148586456279
  - 0.8163214990138067
  - 0.8493693469421625
  TT_precision_weighted:
  - 0.880547101811462
  - 0.8814059146646558
  - 0.8725507415248469
  - 0.8811961777383397
  - 0.8795172770320767
  - 0.8796186748838863
  - 0.8732031716899358
  - 0.8788481408169531
  - 0.8797722618608721
  - 0.8795241670090829
  - 0.8730175325837242
  - 0.8778088392106776
  - 0.8783481376095251
  - 0.8813882572995957
  - 0.873659941256861
  - 0.8812991176411301
  TT_recall_macro:
  - 0.5428691424785832
  - 0.535498401425041
  - 0.54277343591876
  - 0.5443070299004631
  - 0.5404764092034533
  - 0.5369526611214674
  - 0.5393685830159469
  - 0.5382178215793989
  - 0.5517827115183898
  - 0.5458156450172388
  - 0.5439347258244694
  - 0.5474210675547045
  - 0.5521091536827196
  - 0.5403980050704088
  - 0.5553966393623149
  - 0.552437463480889
  TT_recall_micro:
  - 0.840515827456126
  - 0.837604559619485
  - 0.8066877152698049
  - 0.8411410354606993
  - 0.8409146942800789
  - 0.8340729783037475
  - 0.8104248849441157
  - 0.8451995685005393
  - 0.8459072978303748
  - 0.8362508218277449
  - 0.8127465483234714
  - 0.8439756036843415
  - 0.8376890203813281
  - 0.8394148586456279
  - 0.8163214990138067
  - 0.8493693469421625
  TT_recall_weighted:
  - 0.840515827456126
  - 0.837604559619485
  - 0.8066877152698049
  - 0.8411410354606993
  - 0.8409146942800789
  - 0.8340729783037475
  - 0.8104248849441157
  - 0.8451995685005393
  - 0.8459072978303748
  - 0.8362508218277449
  - 0.8127465483234714
  - 0.8439756036843415
  - 0.8376890203813281
  - 0.8394148586456279
  - 0.8163214990138067
  - 0.8493693469421625
  TT_roc_auc:
  - 0.5600938331329408
  - 0.5586493816083363
  - 0.5582680506243342
  - 0.5707092986390478
  - 0.5700476478782638
  - 0.5570013096858598
  - 0.5570685235191993
  - 0.5591582581987695
  - 0.5851993978773564
  - 0.5680395081360715
  - 0.5674199105735809
  - 0.5763312800479328
  - 0.581768327862668
  - 0.5616660466332505
  - 0.5754667431865234
  - 0.5879844372886784
  fit_time:
  - 6806.541811704636
  - 8115.539461374283
  - 6823.151498794556
  - 7516.513124704361
  - 6821.388109922409
  - 7920.845863103867
  - 5789.419125795364
  - 6867.723776102066
  - 7739.087498426437
  - 8577.131765842438
  - 7507.614229440689
  - 8080.875263214111
  - 5739.280575990677
  - 7732.377906084061
  - 6588.471953868866
  - 7420.319241285324
  score_time:
  - 86.84339809417725
  - 63.08667874336243
  - 88.02620792388916
  - 72.26527237892151
  - 87.28346133232117
  - 63.70067048072815
  - 107.5866117477417
  - 93.75176906585693
  - 71.26842856407166
  - 73.51473355293274
  - 74.37083864212036
  - 67.15377163887024
  - 112.85228610038757
  - 69.66966009140015
  - 83.78833937644958
  - 72.77816605567932
start: 2023-08-10 22:47:51.188938
wrapper: null
