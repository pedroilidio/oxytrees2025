active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 8
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: runs
end: 2023-08-08 09:14:46.843416
estimator:
  call: y_reconstruction.estimators.bxt_gmosa
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.PositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error
          estimator__max_col_features: null
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: null
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: bxt_gmosa__drop70
  params:
    estimator__min_cols_leaf: 1
    estimator__min_rows_leaf: 1
    estimator__min_samples_leaf: 1
hash: 383728226718882fb5e2fa8c8fd95de575ce4e0acf29ff9a5c2fbebea45aa7ae
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/3837282_20230808T091445787011_bxt_gmosa__drop70_nuclear_receptors.yml
results:
  LL_average_precision:
  - 0.35252140011865407
  - 0.3576555023923445
  - 0.3623116055721961
  - 0.3871221846189754
  - 0.34019576379974326
  - 0.33329346092503986
  - 0.35301668806161746
  - 0.3510109114249037
  - 0.3655770782889427
  - 0.3556818181818182
  - 0.34268292682926826
  - 0.36689642983386356
  - 0.3758467741935484
  - 0.34375
  - 0.37081438610996276
  - 0.3781455671699574
  LL_balanced_accuracy:
  - 0.6631255901794145
  - 0.6590909090909091
  - 0.6574074074074074
  - 0.6720366649924661
  - 0.6564503544896367
  - 0.6515151515151515
  - 0.6585365853658537
  - 0.657730364873222
  - 0.6596674214872252
  - 0.6590909090909091
  - 0.65
  - 0.6646929824561404
  - 0.6673223183844742
  - 0.65
  - 0.6610169491525424
  - 0.6660087719298246
  LL_f1_macro:
  - 0.7195597195597195
  - 0.7311193924241709
  - 0.726995463026985
  - 0.7408586199145877
  - 0.7174755069491912
  - 0.7247720867251343
  - 0.7314322301024428
  - 0.7226524254561637
  - 0.7236842105263158
  - 0.7316516838856837
  - 0.7196581196581197
  - 0.7271552491275313
  - 0.7296550029184972
  - 0.7193685793034327
  - 0.730785646278604
  - 0.7337641254682093
  LL_f1_micro:
  - 0.9460526315789474
  - 0.9605263157894737
  - 0.9525032092426188
  - 0.9525032092426188
  - 0.9592105263157895
  - 0.969736842105263
  - 0.9640564826700898
  - 0.9589216944801028
  - 0.9475
  - 0.9625000000000001
  - 0.9573170731707317
  - 0.947560975609756
  - 0.945
  - 0.95625
  - 0.9512195121951219
  - 0.9500000000000001
  LL_f1_weighted:
  - 0.9357725726146777
  - 0.9507226011157428
  - 0.940718199906491
  - 0.9419811060800036
  - 0.9506139751292106
  - 0.9618788373999034
  - 0.9550723736054083
  - 0.9497206659228422
  - 0.9356874999999999
  - 0.9531665101301491
  - 0.9462997706900147
  - 0.9364958305896172
  - 0.9335390617799761
  - 0.9449699323477826
  - 0.9393362849219944
  - 0.9385883638609747
  LL_matthews_corrcoef:
  - 0.48927571481512044
  - 0.5526176822228344
  - 0.5472919980739969
  - 0.5572701139035151
  - 0.492398205634455
  - 0.541975436470486
  - 0.5527051915086619
  - 0.5134439621166511
  - 0.5220391105873595
  - 0.5532065382625239
  - 0.5356832289134414
  - 0.5195106231823204
  - 0.5245313055856808
  - 0.5353729576861872
  - 0.5531295556928645
  - 0.5473440694548802
  LL_precision_macro:
  - 0.8668810099699134
  - 0.9798927613941019
  - 0.9757217847769029
  - 0.9512845849802372
  - 0.8874327956989247
  - 0.9846666666666667
  - 0.9817232375979112
  - 0.9178407601572739
  - 0.9267070114310165
  - 0.9809160305343512
  - 0.9782608695652174
  - 0.9096885058098303
  - 0.9110824742268041
  - 0.9777070063694268
  - 0.9750312109862671
  - 0.951159187079087
  LL_precision_micro:
  - 0.9460526315789474
  - 0.9605263157894737
  - 0.9525032092426188
  - 0.9525032092426188
  - 0.9592105263157895
  - 0.9697368421052631
  - 0.9640564826700898
  - 0.9589216944801027
  - 0.9475
  - 0.9625
  - 0.9573170731707317
  - 0.947560975609756
  - 0.945
  - 0.95625
  - 0.9512195121951219
  - 0.95
  LL_precision_weighted:
  - 0.9391777848846056
  - 0.9621137293636236
  - 0.954809483859447
  - 0.9523877779863716
  - 0.9542807371250708
  - 0.9706649122807017
  - 0.9653703449223582
  - 0.9558419992698237
  - 0.9454152148664344
  - 0.9639312977099237
  - 0.9591728525980912
  - 0.9439400934841818
  - 0.9415721649484535
  - 0.9582006369426752
  - 0.9536554916110959
  - 0.9501162166994457
  LL_recall_macro:
  - 0.6631255901794145
  - 0.6590909090909091
  - 0.6574074074074074
  - 0.6720366649924661
  - 0.6564503544896367
  - 0.6515151515151515
  - 0.6585365853658537
  - 0.657730364873222
  - 0.6596674214872252
  - 0.6590909090909091
  - 0.65
  - 0.6646929824561404
  - 0.6673223183844742
  - 0.65
  - 0.6610169491525424
  - 0.6660087719298246
  LL_recall_micro:
  - 0.9460526315789474
  - 0.9605263157894737
  - 0.9525032092426188
  - 0.9525032092426188
  - 0.9592105263157895
  - 0.9697368421052631
  - 0.9640564826700898
  - 0.9589216944801027
  - 0.9475
  - 0.9625
  - 0.9573170731707317
  - 0.947560975609756
  - 0.945
  - 0.95625
  - 0.9512195121951219
  - 0.95
  LL_recall_weighted:
  - 0.9460526315789474
  - 0.9605263157894737
  - 0.9525032092426188
  - 0.9525032092426188
  - 0.9592105263157895
  - 0.9697368421052631
  - 0.9640564826700898
  - 0.9589216944801027
  - 0.9475
  - 0.9625
  - 0.9573170731707317
  - 0.947560975609756
  - 0.945
  - 0.95625
  - 0.9512195121951219
  - 0.95
  LL_roc_auc:
  - 0.6638469205749659
  - 0.6590909090909091
  - 0.6574074074074074
  - 0.672212456052235
  - 0.656959191288714
  - 0.6515151515151515
  - 0.6585365853658537
  - 0.6581014223871366
  - 0.6600105217411195
  - 0.6590909090909091
  - 0.65
  - 0.6651206140350877
  - 0.6677812745869394
  - 0.65
  - 0.6610169491525424
  - 0.666173245614035
  LT_average_precision:
  - 0.13844611528822054
  - 0.1279217273954116
  - 0.21925847802008794
  - 0.2424355615145089
  - 0.0633484753550543
  - 0.19919317524580682
  - 0.09207313154681575
  - 0.10241415504573398
  - 0.26130952380952377
  - 0.2656044572711239
  - 0.26569032819032823
  - 0.21445498945498948
  - 0.10566564260112646
  - 0.3418430335097002
  - 0.223740440845704
  - 0.392995297666578
  LT_balanced_accuracy:
  - 0.5760956175298805
  - 0.547551867219917
  - 0.6762931034482759
  - 0.690680564071122
  - 0.5121391076115486
  - 0.5878048780487805
  - 0.5599290780141845
  - 0.5901027077497666
  - 0.6100746268656716
  - 0.5913482652613087
  - 0.6996413628212791
  - 0.7112084702446149
  - 0.5735849056603773
  - 0.6555409164104816
  - 0.5904499540863177
  - 0.6641249092229484
  LT_f1_macro:
  - 0.5760956175298805
  - 0.5601228443184503
  - 0.6658549783549784
  - 0.6730300285654567
  - 0.5099206349206349
  - 0.6114209827357238
  - 0.5576119402985075
  - 0.5772676935467633
  - 0.6146061047688447
  - 0.6095542260806981
  - 0.7235745061832017
  - 0.6942204301075269
  - 0.569128787878788
  - 0.6608116293155663
  - 0.6004098360655737
  - 0.6895849427628346
  LT_f1_micro:
  - 0.9097744360902256
  - 0.8947368421052632
  - 0.9190283400809717
  - 0.9230769230769231
  - 0.9022556390977443
  - 0.9172932330827067
  - 0.9149797570850202
  - 0.9311740890688259
  - 0.9392857142857143
  - 0.8892857142857142
  - 0.926923076923077
  - 0.9461538461538461
  - 0.9071428571428571
  - 0.8857142857142857
  - 0.9076923076923076
  - 0.9346153846153846
  LT_f1_weighted:
  - 0.9097744360902256
  - 0.8716600146716899
  - 0.9213834411202833
  - 0.9265497966118046
  - 0.9088495047141664
  - 0.9043325445086821
  - 0.9165895220255
  - 0.935871961575756
  - 0.938022369501602
  - 0.87630239626776
  - 0.9223636919289093
  - 0.9482888751033912
  - 0.9098687770562771
  - 0.8837414553949987
  - 0.9023013871374526
  - 0.929311695397797
  LT_matthews_corrcoef:
  - 0.15219123505976095
  - 0.15349289593487736
  - 0.33263394158618015
  - 0.34832931305701254
  - 0.021193088062557014
  - 0.24345080136020672
  - 0.11540178894644995
  - 0.15705545208418817
  - 0.2295106035639537
  - 0.2323327793955955
  - 0.45272472631221383
  - 0.3901370448695176
  - 0.1387666054733509
  - 0.3220154410484914
  - 0.20344672846731274
  - 0.38673691505893226
  LT_precision_macro:
  - 0.5760956175298805
  - 0.6238651102464332
  - 0.6569053708439898
  - 0.6590792838874681
  - 0.50925
  - 0.66875
  - 0.5555555555555556
  - 0.5684397163120567
  - 0.6196350118283204
  - 0.6477272727272727
  - 0.7566598360655737
  - 0.680161943319838
  - 0.5654216059047193
  - 0.6666666666666667
  - 0.6144018583042974
  - 0.7278225806451613
  LT_precision_micro:
  - 0.9097744360902256
  - 0.8947368421052632
  - 0.9190283400809717
  - 0.9230769230769231
  - 0.9022556390977443
  - 0.9172932330827067
  - 0.9149797570850202
  - 0.9311740890688259
  - 0.9392857142857143
  - 0.8892857142857142
  - 0.926923076923077
  - 0.9461538461538461
  - 0.9071428571428571
  - 0.8857142857142857
  - 0.9076923076923077
  - 0.9346153846153846
  LT_precision_weighted:
  - 0.9097744360902256
  - 0.8597856508976722
  - 0.9239508371558446
  - 0.9305134762935274
  - 0.9156917293233082
  - 0.8970864661654135
  - 0.9182324647911692
  - 0.9409337582909811
  - 0.9368078018635639
  - 0.8678571428571429
  - 0.9194553909205548
  - 0.9507007162877608
  - 0.9126993002524205
  - 0.881904761904762
  - 0.8975788439203073
  - 0.9258529776674937
  LT_recall_macro:
  - 0.5760956175298805
  - 0.547551867219917
  - 0.6762931034482759
  - 0.690680564071122
  - 0.5121391076115486
  - 0.5878048780487805
  - 0.5599290780141845
  - 0.5901027077497666
  - 0.6100746268656716
  - 0.5913482652613087
  - 0.6996413628212791
  - 0.7112084702446149
  - 0.5735849056603773
  - 0.6555409164104816
  - 0.5904499540863177
  - 0.6641249092229484
  LT_recall_micro:
  - 0.9097744360902256
  - 0.8947368421052632
  - 0.9190283400809717
  - 0.9230769230769231
  - 0.9022556390977443
  - 0.9172932330827067
  - 0.9149797570850202
  - 0.9311740890688259
  - 0.9392857142857143
  - 0.8892857142857142
  - 0.926923076923077
  - 0.9461538461538461
  - 0.9071428571428571
  - 0.8857142857142857
  - 0.9076923076923077
  - 0.9346153846153846
  LT_recall_weighted:
  - 0.9097744360902256
  - 0.8947368421052632
  - 0.9190283400809717
  - 0.9230769230769231
  - 0.9022556390977443
  - 0.9172932330827067
  - 0.9149797570850202
  - 0.9311740890688259
  - 0.9392857142857143
  - 0.8892857142857142
  - 0.926923076923077
  - 0.9461538461538461
  - 0.9071428571428571
  - 0.8857142857142857
  - 0.9076923076923077
  - 0.9346153846153846
  LT_roc_auc:
  - 0.5359893758300133
  - 0.5609128630705393
  - 0.661206896551724
  - 0.6845493562231759
  - 0.562992125984252
  - 0.6095528455284553
  - 0.5524822695035462
  - 0.5819327731092437
  - 0.5925062189054727
  - 0.6419997072170984
  - 0.7139868499701135
  - 0.7009857612267252
  - 0.5802515723270439
  - 0.659273898404333
  - 0.6685032139577594
  - 0.7407407407407407
  TL_average_precision:
  - 0.3024882343509794
  - 0.24093406593406594
  - 0.28453348819202473
  - 0.2242283461795657
  - 0.26085660070479805
  - 0.27994505494505495
  - 0.1891928707646865
  - 0.2097531420244526
  - 0.12418414918414919
  - 0.12692307692307692
  - 0.10264227642276422
  - 0.05143300769877726
  - 0.12333333333333335
  - 0.1875
  - 0.26744579945799457
  - 0.18167604752970606
  TL_balanced_accuracy:
  - 0.6456743002544529
  - 0.644482857966004
  - 0.6657509157509157
  - 0.6203015282940934
  - 0.6290970332944682
  - 0.5963541666666666
  - 0.5606125356125355
  - 0.5629510825982358
  - 0.5933581836665537
  - 0.5142324635716706
  - 0.5548245614035088
  - 0.4613733905579399
  - 0.5869565217391305
  - 0.6321275291232373
  - 0.6047819971870605
  - 0.6068009243974909
  TL_f1_macro:
  - 0.6495238095238096
  - 0.668807029401825
  - 0.6777091521617069
  - 0.6302582199070184
  - 0.658203125
  - 0.6296935196365937
  - 0.5772780832678712
  - 0.574604743083004
  - 0.5933581836665537
  - 0.5147252747252747
  - 0.5576676085281274
  - 0.46637744034707157
  - 0.595959595959596
  - 0.6321275291232373
  - 0.6323968918111178
  - 0.6351694915254237
  TL_f1_micro:
  - 0.9178571428571429
  - 0.9500000000000001
  - 0.9442508710801394
  - 0.9198606271777003
  - 0.8928571428571429
  - 0.9178571428571429
  - 0.8954703832752613
  - 0.8745644599303136
  - 0.9166666666666666
  - 0.9041666666666667
  - 0.8861788617886179
  - 0.8739837398373984
  - 0.9416666666666667
  - 0.9583333333333334
  - 0.959349593495935
  - 0.943089430894309
  TL_f1_weighted:
  - 0.9167619047619048
  - 0.9456404190604935
  - 0.9422084058010708
  - 0.9164401263044245
  - 0.8786969866071429
  - 0.900357327681806
  - 0.8750242917085214
  - 0.8596287063943481
  - 0.9166666666666666
  - 0.9023553113553113
  - 0.8830796990220096
  - 0.8834629561046152
  - 0.9385521885521886
  - 0.9583333333333334
  - 0.9537124779496451
  - 0.9349145652473474
  TL_matthews_corrcoef:
  - 0.2992247408890291
  - 0.34472098817495367
  - 0.35675847891341317
  - 0.26210991600836314
  - 0.33925358313943854
  - 0.3058582495634564
  - 0.18433598350047706
  - 0.16074434675651214
  - 0.18671636733310742
  - 0.029562192100202053
  - 0.11579369921559651
  - -0.06636858289902231
  - 0.19360077316559154
  - 0.26425505824647455
  - 0.2788165647002163
  - 0.2874131758190658
  TL_precision_macro:
  - 0.6536569000223664
  - 0.7056170561705617
  - 0.691969696969697
  - 0.6427696078431372
  - 0.7228807872959069
  - 0.7427224272242723
  - 0.6401515151515151
  - 0.6026143790849673
  - 0.5933581836665537
  - 0.5153508771929824
  - 0.5611413043478262
  - 0.47149122807017546
  - 0.6077586206896552
  - 0.6321275291232373
  - 0.6854771784232365
  - 0.6933652121936641
  TL_precision_micro:
  - 0.9178571428571428
  - 0.95
  - 0.9442508710801394
  - 0.9198606271777003
  - 0.8928571428571429
  - 0.9178571428571428
  - 0.8954703832752613
  - 0.8745644599303136
  - 0.9166666666666666
  - 0.9041666666666667
  - 0.8861788617886179
  - 0.8739837398373984
  - 0.9416666666666667
  - 0.9583333333333334
  - 0.959349593495935
  - 0.943089430894309
  TL_precision_weighted:
  - 0.9157091734032016
  - 0.9425379253792538
  - 0.9404138950480413
  - 0.9133915761426521
  - 0.8735102405981403
  - 0.897803549464066
  - 0.8646394256150353
  - 0.8487668238026917
  - 0.9166666666666666
  - 0.9005665204678363
  - 0.8801033934252387
  - 0.8931500499215519
  - 0.9357040229885059
  - 0.9583333333333334
  - 0.9500657828155045
  - 0.9301726609615171
  TL_recall_macro:
  - 0.6456743002544529
  - 0.644482857966004
  - 0.6657509157509157
  - 0.6203015282940934
  - 0.6290970332944682
  - 0.5963541666666666
  - 0.5606125356125355
  - 0.5629510825982358
  - 0.5933581836665537
  - 0.5142324635716706
  - 0.5548245614035088
  - 0.4613733905579399
  - 0.5869565217391305
  - 0.6321275291232373
  - 0.6047819971870605
  - 0.6068009243974909
  TL_recall_micro:
  - 0.9178571428571428
  - 0.95
  - 0.9442508710801394
  - 0.9198606271777003
  - 0.8928571428571429
  - 0.9178571428571428
  - 0.8954703832752613
  - 0.8745644599303136
  - 0.9166666666666666
  - 0.9041666666666667
  - 0.8861788617886179
  - 0.8739837398373984
  - 0.9416666666666667
  - 0.9583333333333334
  - 0.959349593495935
  - 0.943089430894309
  TL_recall_weighted:
  - 0.9178571428571428
  - 0.95
  - 0.9442508710801394
  - 0.9198606271777003
  - 0.8928571428571429
  - 0.9178571428571428
  - 0.8954703832752613
  - 0.8745644599303136
  - 0.9166666666666666
  - 0.9041666666666667
  - 0.8861788617886179
  - 0.8739837398373984
  - 0.9416666666666667
  - 0.9583333333333334
  - 0.959349593495935
  - 0.943089430894309
  TL_roc_auc:
  - 0.6960347752332485
  - 0.641313742437338
  - 0.6652276295133439
  - 0.6136926889714994
  - 0.6297447855939888
  - 0.6136067708333334
  - 0.5550569800569801
  - 0.5535952953755681
  - 0.5830227041680787
  - 0.5160962385631989
  - 0.5489766081871346
  - 0.4630241003631561
  - 0.5654347826086956
  - 0.6324340895156346
  - 0.6427566807313642
  - 0.5825354902608121
  TT_average_precision:
  - 0.030612244897959183
  - 0.08163265306122448
  - 0.1054945054945055
  - 0.11921411921411922
  - 0.1298185941043084
  - 0.1480900052328624
  - 0.2269230769230769
  - 0.13942307692307693
  - 0.07142857142857142
  - 0.07142857142857142
  - 0.01282051282051282
  - 0.14017094017094017
  - 0.1738095238095238
  - 0.22619047619047616
  - 0.05128205128205128
  - -0.0
  TT_balanced_accuracy:
  - 0.48947368421052634
  - 0.4888888888888889
  - 0.5416666666666666
  - 0.4715909090909091
  - 0.5561594202898551
  - 0.5266968325791855
  - 0.5876543209876544
  - 0.5
  - 0.4807692307692308
  - 0.4358974358974359
  - 0.44155844155844154
  - 0.5694444444444444
  - 0.49382716049382713
  - 0.5576923076923077
  - 0.49324324324324326
  - 1.0
  TT_f1_macro:
  - 0.4869109947643979
  - 0.4731182795698925
  - 0.5443786982248521
  - 0.4770114942528736
  - 0.5561594202898551
  - 0.5236111111111111
  - 0.6130952380952381
  - 0.4770114942528736
  - 0.4716981132075472
  - 0.4473684210526316
  - 0.4657534246575342
  - 0.5873015873015873
  - 0.4878048780487805
  - 0.5622466705269253
  - 0.48344370860927155
  - 1.0
  TT_f1_micro:
  - 0.9489795918367347
  - 0.8979591836734694
  - 0.8791208791208791
  - 0.9120879120879121
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.8901098901098901
  - 0.9120879120879121
  - 0.8928571428571429
  - 0.8095238095238095
  - 0.8717948717948718
  - 0.9102564102564102
  - 0.9523809523809523
  - 0.8928571428571429
  - 0.9358974358974359
  - 1.0
  TT_f1_weighted:
  - 0.9440111122983225
  - 0.8689927583936802
  - 0.8748293126991351
  - 0.922571681192371
  - 0.8979591836734694
  - 0.8164682539682541
  - 0.8685243328100472
  - 0.8701528356700772
  - 0.8760107816711591
  - 0.8308270676691729
  - 0.919564453811029
  - 0.8962148962148961
  - 0.940766550522648
  - 0.8883282322772769
  - 0.9173034471047716
  - 1.0
  TT_matthews_corrcoef:
  - -0.025649458802128853
  - -0.04303314829119352
  - 0.08947924869885988
  - -0.04451999099627793
  - 0.11231884057971014
  - 0.1051352720011248
  - 0.2674583819837641
  - 0.0
  - -0.05337605126836238
  - -0.10195592378577321
  - -0.041157723645718625
  - 0.19245008972987526
  - -0.021124141684149264
  - 0.12559498126280014
  - -0.026495295846634775
  - 0.0
  TT_precision_macro:
  - 0.484375
  - 0.4583333333333333
  - 0.5480392156862746
  - 0.48255813953488375
  - 0.5561594202898551
  - 0.6035087719298246
  - 0.7040229885057472
  - 0.45604395604395603
  - 0.46296296296296297
  - 0.4594594594594595
  - 0.4927536231884058
  - 0.6333333333333333
  - 0.4819277108433735
  - 0.5683544303797469
  - 0.474025974025974
  - 1.0
  TT_precision_micro:
  - 0.9489795918367347
  - 0.8979591836734694
  - 0.8791208791208791
  - 0.9120879120879121
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.8901098901098901
  - 0.9120879120879121
  - 0.8928571428571429
  - 0.8095238095238095
  - 0.8717948717948718
  - 0.9102564102564102
  - 0.9523809523809523
  - 0.8928571428571429
  - 0.9358974358974359
  - 1.0
  TT_precision_weighted:
  - 0.939094387755102
  - 0.8418367346938775
  - 0.870739064856712
  - 0.9332992588806542
  - 0.8979591836734694
  - 0.8020050125313284
  - 0.8632057597574838
  - 0.8319043593768868
  - 0.8597883597883599
  - 0.8532818532818534
  - 0.9728725380899295
  - 0.8871794871794872
  - 0.9294320137693632
  - 0.8840867992766727
  - 0.8994338994338994
  - 1.0
  TT_recall_macro:
  - 0.48947368421052634
  - 0.4888888888888889
  - 0.5416666666666666
  - 0.4715909090909091
  - 0.5561594202898551
  - 0.5266968325791855
  - 0.5876543209876544
  - 0.5
  - 0.4807692307692308
  - 0.4358974358974359
  - 0.44155844155844154
  - 0.5694444444444444
  - 0.49382716049382713
  - 0.5576923076923077
  - 0.49324324324324326
  - 1.0
  TT_recall_micro:
  - 0.9489795918367347
  - 0.8979591836734694
  - 0.8791208791208791
  - 0.9120879120879121
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.8901098901098901
  - 0.9120879120879121
  - 0.8928571428571429
  - 0.8095238095238095
  - 0.8717948717948718
  - 0.9102564102564102
  - 0.9523809523809523
  - 0.8928571428571429
  - 0.9358974358974359
  - 1.0
  TT_recall_weighted:
  - 0.9489795918367347
  - 0.8979591836734694
  - 0.8791208791208791
  - 0.9120879120879121
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.8901098901098901
  - 0.9120879120879121
  - 0.8928571428571429
  - 0.8095238095238095
  - 0.8717948717948718
  - 0.9102564102564102
  - 0.9523809523809523
  - 0.8928571428571429
  - 0.9358974358974359
  - 1.0
  TT_roc_auc:
  - 0.45263157894736844
  - 0.48333333333333334
  - 0.5739795918367346
  - 0.7670454545454545
  - 0.671195652173913
  - 0.49954751131221714
  - 0.6166666666666667
  - 0.5564759036144579
  - 0.47435897435897434
  - 0.4166666666666667
  - 0.4285714285714286
  - 0.6122685185185185
  - 0.7942386831275718
  - 0.5352564102564104
  - 0.46621621621621623
  - .nan
  fit_time:
  - 0.1709299087524414
  - 0.17077374458312988
  - 0.18372750282287598
  - 0.19278168678283691
  - 0.16754841804504395
  - 0.15372204780578613
  - 0.16504740715026855
  - 0.17541122436523438
  - 0.1635117530822754
  - 0.16302061080932617
  - 0.16975641250610352
  - 0.17102909088134766
  - 0.21108078956604004
  - 0.16656994819641113
  - 0.19824838638305664
  - 0.17094850540161133
  score_time:
  - 0.30877232551574707
  - 0.3101043701171875
  - 0.3264119625091553
  - 0.32459211349487305
  - 0.3105905055999756
  - 0.3209700584411621
  - 0.3286900520324707
  - 0.3047935962677002
  - 0.3067166805267334
  - 0.314791202545166
  - 0.3150184154510498
  - 0.31053876876831055
  - 0.32430243492126465
  - 0.30256080627441406
  - 0.32807040214538574
  - 0.3150944709777832
start: 2023-08-08 09:14:45.787011
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
