active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: runs
end: 2023-08-03 06:12:08.037628
estimator:
  call: y_reconstruction.estimators.bxt_gmosa_nrlmf
  final_params:
    memory: /tmp
    steps:
    - - symmetryenforcer
      - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
        params:
          ndim: 2
          samplers:
            call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
            params:
              sampling_strategy: auto
          samplers__sampling_strategy: auto
    - - regressorassampler
      - call: y_reconstruction.estimators.RegressorAsSampler
        params:
          estimator:
            call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
            params:
              cv:
                call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                params: {}
              diagonal: false
              error_score: .nan
              estimator:
                call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
                params:
                  alpha_cols: same
                  alpha_rows: 0.1
                  keep_positives: true
                  lambda_cols: same
                  lambda_rows: 0.625
                  learning_rate: 1.0
                  max_iter: 100
                  n_components_cols: same
                  n_components_rows: 10
                  n_neighbors: 5
                  positive_importance: 5
                  random_state: null
                  resample_X: false
                  tol: 1.0e-05
                  verbose: false
              estimator__alpha_cols: same
              estimator__alpha_rows: 0.1
              estimator__keep_positives: true
              estimator__lambda_cols: same
              estimator__lambda_rows: 0.625
              estimator__learning_rate: 1.0
              estimator__max_iter: 100
              estimator__n_components_cols: same
              estimator__n_components_rows: 10
              estimator__n_neighbors: 5
              estimator__positive_importance: 5
              estimator__random_state: null
              estimator__resample_X: false
              estimator__tol: 1.0e-05
              estimator__verbose: false
              n_iter: 100
              n_jobs: 3
              pairwise: true
              param_distributions:
                alpha_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                alpha_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                learning_rate:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                n_components_rows:
                - 50
                - 100
                n_neighbors:
                - 3
                - 5
                - 10
              pre_dispatch: 2*n_jobs
              random_state: 0
              refit: true
              return_train_score: false
              scoring: null
              train_test_combinations: null
              verbose: 1
          estimator__cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          estimator__diagonal: false
          estimator__error_score: .nan
          estimator__estimator:
            call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
            params:
              alpha_cols: same
              alpha_rows: 0.1
              keep_positives: true
              lambda_cols: same
              lambda_rows: 0.625
              learning_rate: 1.0
              max_iter: 100
              n_components_cols: same
              n_components_rows: 10
              n_neighbors: 5
              positive_importance: 5
              random_state: null
              resample_X: false
              tol: 1.0e-05
              verbose: false
          estimator__estimator__alpha_cols: same
          estimator__estimator__alpha_rows: 0.1
          estimator__estimator__keep_positives: true
          estimator__estimator__lambda_cols: same
          estimator__estimator__lambda_rows: 0.625
          estimator__estimator__learning_rate: 1.0
          estimator__estimator__max_iter: 100
          estimator__estimator__n_components_cols: same
          estimator__estimator__n_components_rows: 10
          estimator__estimator__n_neighbors: 5
          estimator__estimator__positive_importance: 5
          estimator__estimator__random_state: null
          estimator__estimator__resample_X: false
          estimator__estimator__tol: 1.0e-05
          estimator__estimator__verbose: false
          estimator__n_iter: 100
          estimator__n_jobs: 3
          estimator__pairwise: true
          estimator__param_distributions:
            alpha_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            alpha_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            learning_rate:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            n_components_rows:
            - 50
            - 100
            n_neighbors:
            - 3
            - 5
            - 10
          estimator__pre_dispatch: 2*n_jobs
          estimator__random_state: 0
          estimator__refit: true
          estimator__return_train_score: false
          estimator__scoring: null
          estimator__train_test_combinations: null
          estimator__verbose: 1
    - - regressortobinaryclassifier
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error
          estimator__max_col_features: null
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: null
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: bxt_gmosa_nrlmf
  params:
    regressortobinaryclassifier__estimator__min_cols_leaf: 1
    regressortobinaryclassifier__estimator__min_rows_leaf: 1
    regressortobinaryclassifier__estimator__min_samples_leaf: 1
hash: de7f131d218fac8b52941d807e4f298a796c23897e355a84f9c0fe16b990ada3
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/de7f131_20230803T061121594313_bxt_gmosa_nrlmf_ion_channels.yml
results:
  LL_average_precision:
  - 0.9759289987751666
  - 0.9917450558185992
  - 0.9926488385753346
  - 0.9803859617170153
  - 0.9786015857416039
  - 0.9729845026760364
  - 0.9914838577748702
  - 0.9834373070469937
  - 0.9956531836468754
  - 0.9940213822818071
  - 0.9940923839852569
  - 0.9933538027340699
  - 0.9740524442149952
  - 0.9858923027164981
  - 0.9907921895789171
  - 0.9901028400463592
  LL_balanced_accuracy:
  - 0.9315777093632909
  - 0.9556505592261519
  - 0.9562117254079054
  - 0.9534993155373033
  - 0.9301380329606816
  - 0.9354751420818976
  - 0.9519568382289971
  - 0.9497219846022241
  - 0.9640483383685801
  - 0.9597954162890069
  - 0.9546564427690198
  - 0.9510843991957907
  - 0.9307270529315258
  - 0.9541927139469712
  - 0.9522881972687187
  - 0.9487480772517518
  LL_f1_macro:
  - 0.6435380658195372
  - 0.7052467595093939
  - 0.7000780572654979
  - 0.6872868621304915
  - 0.6373438682575723
  - 0.646406334385874
  - 0.6858886569826887
  - 0.6751041438410804
  - 0.7340260166099577
  - 0.7179118309064116
  - 0.6960024994435969
  - 0.6796437441597978
  - 0.6371310169410421
  - 0.6946889208946012
  - 0.6861434737666678
  - 0.6684707958633569
  LL_f1_micro:
  - 0.8692394155114275
  - 0.9144914866158778
  - 0.9154049805576239
  - 0.9100686688177381
  - 0.8663669289371799
  - 0.876566337787769
  - 0.9071729957805907
  - 0.9027467527095226
  - 0.9306440198159944
  - 0.9224428624953166
  - 0.9124265740051295
  - 0.9053942252006287
  - 0.8664085591773864
  - 0.9115357395612174
  - 0.9077934971456937
  - 0.900761148341193
  LL_f1_weighted:
  - 0.9063052592219456
  - 0.9357271538660739
  - 0.9369029817357909
  - 0.9338055658839052
  - 0.9048553766641526
  - 0.9117554033233632
  - 0.9316462366018078
  - 0.9291953701273485
  - 0.946504456234009
  - 0.9410720456306512
  - 0.9348891795768688
  - 0.930836069685938
  - 0.9049416917340237
  - 0.9342980142928197
  - 0.9321133544979876
  - 0.9283007853856373
  LL_matthews_corrcoef:
  - 0.43521149616934357
  - 0.5194517086003114
  - 0.5116919251149353
  - 0.4934922752240057
  - 0.42655185576243754
  - 0.43809056895741144
  - 0.4918424672891694
  - 0.4765264191577131
  - 0.560169915728093
  - 0.5371952909418669
  - 0.5060642412644737
  - 0.48285404888906513
  - 0.42650309045681445
  - 0.5042437202321516
  - 0.49212916745497304
  - 0.466982430501272
  LL_precision_macro:
  - 0.6097189696598295
  - 0.6480466072652502
  - 0.6434797768479776
  - 0.6342530282637955
  - 0.6057488943735247
  - 0.6101804259663887
  - 0.6338120104438643
  - 0.6262321144674086
  - 0.6690504568931267
  - 0.6569060773480663
  - 0.6408211740753309
  - 0.6292153047989624
  - 0.6055801376597837
  - 0.6399525584547611
  - 0.6338699080157687
  - 0.6214894288419059
  LL_precision_micro:
  - 0.8692394155114275
  - 0.9144914866158778
  - 0.9154049805576239
  - 0.9100686688177381
  - 0.8663669289371799
  - 0.876566337787769
  - 0.9071729957805907
  - 0.9027467527095226
  - 0.9306440198159943
  - 0.9224428624953166
  - 0.9124265740051295
  - 0.9053942252006287
  - 0.8664085591773865
  - 0.9115357395612173
  - 0.9077934971456937
  - 0.900761148341193
  LL_precision_weighted:
  - 0.9712281077841243
  - 0.974681509402371
  - 0.9757246509759151
  - 0.9758528929059741
  - 0.9716578621126986
  - 0.9727229384732474
  - 0.9751572638838395
  - 0.9754470339114025
  - 0.9765506797232465
  - 0.9756616275675911
  - 0.9753356146672064
  - 0.9755509719471145
  - 0.9717907945755592
  - 0.975238400839568
  - 0.9753126478888765
  - 0.9758870571860898
  LL_recall_macro:
  - 0.9315777093632909
  - 0.9556505592261519
  - 0.9562117254079054
  - 0.9534993155373033
  - 0.9301380329606816
  - 0.9354751420818976
  - 0.9519568382289971
  - 0.9497219846022241
  - 0.9640483383685801
  - 0.9597954162890069
  - 0.9546564427690198
  - 0.9510843991957907
  - 0.9307270529315258
  - 0.9541927139469712
  - 0.9522881972687187
  - 0.9487480772517518
  LL_recall_micro:
  - 0.8692394155114275
  - 0.9144914866158778
  - 0.9154049805576239
  - 0.9100686688177381
  - 0.8663669289371799
  - 0.876566337787769
  - 0.9071729957805907
  - 0.9027467527095226
  - 0.9306440198159943
  - 0.9224428624953166
  - 0.9124265740051295
  - 0.9053942252006287
  - 0.8664085591773865
  - 0.9115357395612173
  - 0.9077934971456937
  - 0.900761148341193
  LL_recall_weighted:
  - 0.8692394155114275
  - 0.9144914866158778
  - 0.9154049805576239
  - 0.9100686688177381
  - 0.8663669289371799
  - 0.876566337787769
  - 0.9071729957805907
  - 0.9027467527095226
  - 0.9306440198159943
  - 0.9224428624953166
  - 0.9124265740051295
  - 0.9053942252006287
  - 0.8664085591773865
  - 0.9115357395612173
  - 0.9077934971456937
  - 0.900761148341193
  LL_roc_auc:
  - 0.9989417256291807
  - 0.9996882941962993
  - 0.9997186213063225
  - 0.99920432819729
  - 0.9989564975466183
  - 0.9988296733450566
  - 0.9996777853900831
  - 0.9992375719952682
  - 0.999825689343619
  - 0.9997726189093936
  - 0.9997706384138335
  - 0.9997061691700209
  - 0.9990014152481097
  - 0.9994813683545183
  - 0.9996670008301999
  - 0.9996036031136868
  LT_average_precision:
  - 0.4973159486011993
  - 0.17400127892292586
  - 0.2869271190096833
  - 0.332150742520612
  - 0.48316992993993335
  - 0.15854792923942668
  - 0.2432626488886928
  - 0.313731471026895
  - 0.48634933891171894
  - 0.13987897506123634
  - 0.22001203910510914
  - 0.3187397248601721
  - 0.4626213216604628
  - 0.1602243234793026
  - 0.2885443127813416
  - 0.34461535010749117
  LT_balanced_accuracy:
  - 0.7952611208285263
  - 0.6798814647222291
  - 0.6886311389759665
  - 0.7110916000524178
  - 0.7818741701274119
  - 0.6760197062847096
  - 0.6726179939485005
  - 0.6927599107501488
  - 0.8090733590733591
  - 0.6703175125076646
  - 0.6672829970967021
  - 0.7104136717638014
  - 0.7725203839065224
  - 0.6831138826119706
  - 0.6727360310565622
  - 0.7168519185437401
  LT_f1_macro:
  - 0.5683254590833293
  - 0.5779859484777518
  - 0.5930664969345631
  - 0.6139303898929618
  - 0.5643584411278144
  - 0.5476067057682539
  - 0.575944669016924
  - 0.5942725769900019
  - 0.622596613876467
  - 0.5786201211867115
  - 0.5744627510117045
  - 0.6059641783020073
  - 0.5552148429984385
  - 0.5745516456905162
  - 0.5752719363862471
  - 0.6100135923487107
  LT_f1_micro:
  - 0.846713528178567
  - 0.8934517203107658
  - 0.8907742584213172
  - 0.8950477626948216
  - 0.8437538537427549
  - 0.8510297200641262
  - 0.8833584715937656
  - 0.8867521367521367
  - 0.8941916389197189
  - 0.8987544703415958
  - 0.8858722976370035
  - 0.8910256410256411
  - 0.8396843013935134
  - 0.8861758539893945
  - 0.8859979889391654
  - 0.8903971845148315
  LT_f1_weighted:
  - 0.8945507900516583
  - 0.9195493023480142
  - 0.9148796186827723
  - 0.9164555814808816
  - 0.8923275249534522
  - 0.8937949574351453
  - 0.9111319063704159
  - 0.911821813303177
  - 0.9223026518330486
  - 0.9225335497567504
  - 0.9128678357664373
  - 0.9147421481208686
  - 0.890656315372708
  - 0.9149584357645502
  - 0.9134405102594159
  - 0.9140880602240947
  LT_matthews_corrcoef:
  - 0.2674783511613122
  - 0.20770786202208924
  - 0.23251884195027436
  - 0.27165667363679896
  - 0.2563628285902807
  - 0.17647218038977935
  - 0.20286011614208507
  - 0.23704665522964957
  - 0.33479455912143485
  - 0.20241714951257953
  - 0.19754593385454544
  - 0.2613601479206548
  - 0.24038760134571852
  - 0.2064137208451946
  - 0.20161344002546894
  - 0.2703456547810954
  LT_precision_macro:
  - 0.560577454406471
  - 0.5599597018130905
  - 0.571654409970966
  - 0.5873996742564426
  - 0.5582901049900229
  - 0.5442314544048129
  - 0.5596001404312718
  - 0.5728770787152911
  - 0.5906640717541687
  - 0.5601416463485429
  - 0.5583209242118992
  - 0.5811605138921137
  - 0.5530108959671154
  - 0.5581695712326792
  - 0.5588296184505843
  - 0.584258849944504
  LT_precision_micro:
  - 0.846713528178567
  - 0.8934517203107658
  - 0.8907742584213173
  - 0.8950477626948216
  - 0.8437538537427549
  - 0.8510297200641262
  - 0.8833584715937657
  - 0.8867521367521367
  - 0.8941916389197189
  - 0.8987544703415957
  - 0.8858722976370035
  - 0.8910256410256411
  - 0.8396843013935134
  - 0.8861758539893945
  - 0.8859979889391654
  - 0.8903971845148315
  LT_precision_weighted:
  - 0.965454958384751
  - 0.9536057774492052
  - 0.9470054821169179
  - 0.9457665323767864
  - 0.9638987082970268
  - 0.9517004217844127
  - 0.9476687924868025
  - 0.9456037101340453
  - 0.9642781081338818
  - 0.953093988176336
  - 0.948052255912683
  - 0.9472648630037764
  - 0.9648447361504078
  - 0.9529331256982545
  - 0.9493855423445934
  - 0.9469058796913494
  LT_recall_macro:
  - 0.7952611208285263
  - 0.6798814647222291
  - 0.6886311389759665
  - 0.7110916000524178
  - 0.7818741701274119
  - 0.6760197062847096
  - 0.6726179939485005
  - 0.6927599107501488
  - 0.8090733590733591
  - 0.6703175125076646
  - 0.6672829970967021
  - 0.7104136717638014
  - 0.7725203839065224
  - 0.6831138826119706
  - 0.6727360310565622
  - 0.7168519185437401
  LT_recall_micro:
  - 0.846713528178567
  - 0.8934517203107658
  - 0.8907742584213173
  - 0.8950477626948216
  - 0.8437538537427549
  - 0.8510297200641262
  - 0.8833584715937657
  - 0.8867521367521367
  - 0.8941916389197189
  - 0.8987544703415957
  - 0.8858722976370035
  - 0.8910256410256411
  - 0.8396843013935134
  - 0.8861758539893945
  - 0.8859979889391654
  - 0.8903971845148315
  LT_recall_weighted:
  - 0.846713528178567
  - 0.8934517203107658
  - 0.8907742584213173
  - 0.8950477626948216
  - 0.8437538537427549
  - 0.8510297200641262
  - 0.8833584715937657
  - 0.8867521367521367
  - 0.8941916389197189
  - 0.8987544703415957
  - 0.8858722976370035
  - 0.8910256410256411
  - 0.8396843013935134
  - 0.8861758539893945
  - 0.8859979889391654
  - 0.8903971845148315
  LT_roc_auc:
  - 0.8874886359407316
  - 0.7593542040675798
  - 0.7038958551027517
  - 0.7631636140036088
  - 0.8826783814070871
  - 0.7342340615020913
  - 0.6889771685111619
  - 0.7833432523200967
  - 0.8890736049971718
  - 0.7479790753955207
  - 0.6702304957939402
  - 0.7770354296921864
  - 0.8826596945408828
  - 0.721900650868146
  - 0.6970067817874094
  - 0.7542434684389733
  TL_average_precision:
  - 0.7682183934094536
  - 0.7874672172719287
  - 0.7595119854524868
  - 0.7429917498797575
  - 0.8092065697625385
  - 0.8248837486960153
  - 0.823707236910524
  - 0.818369501434107
  - 0.7452199339432223
  - 0.7608668699459388
  - 0.738999526550063
  - 0.7207727187222549
  - 0.7700980551906109
  - 0.8188383814126226
  - 0.8309535779935732
  - 0.8180143037063496
  TL_balanced_accuracy:
  - 0.872170032381059
  - 0.8922239319831569
  - 0.8819143605270773
  - 0.8706907599641164
  - 0.8970825718409423
  - 0.8973926620460335
  - 0.911931659459399
  - 0.909196605247381
  - 0.8874083533304074
  - 0.8902835912147862
  - 0.886503508514613
  - 0.8756413619905152
  - 0.8701653657504949
  - 0.9067062124435117
  - 0.9241867501442569
  - 0.9116435072091623
  TL_f1_macro:
  - 0.6012444894804614
  - 0.663535163636563
  - 0.6506135598579544
  - 0.6420179100457851
  - 0.6362250512862098
  - 0.6472519251760029
  - 0.6821156466965574
  - 0.6586605667810395
  - 0.7142762671619483
  - 0.6966974870181668
  - 0.6863346618877573
  - 0.6714046191992418
  - 0.6455020247621632
  - 0.7095622302993668
  - 0.7076053929458005
  - 0.6675472297266899
  TL_f1_micro:
  - 0.8503809166978894
  - 0.9052079430498314
  - 0.8947629684785308
  - 0.896500372300819
  - 0.8719870113650556
  - 0.8827276133383289
  - 0.9108960039712087
  - 0.9000992802184163
  - 0.9276882727613338
  - 0.9235668789808917
  - 0.9209481260858774
  - 0.9164805162571358
  - 0.8858498813538154
  - 0.9218184088922193
  - 0.9231819310002483
  - 0.8984859766691486
  TL_f1_weighted:
  - 0.8953349062511051
  - 0.9299592813481251
  - 0.9228894442934902
  - 0.9247429063809333
  - 0.9078670118052274
  - 0.9147266788804123
  - 0.9333188886075482
  - 0.9272820658688102
  - 0.9426456170844121
  - 0.9409956900313132
  - 0.9396996972665852
  - 0.9371529622368718
  - 0.9160346265772173
  - 0.9391834140071934
  - 0.941159624663699
  - 0.9251697866196174
  TL_matthews_corrcoef:
  - 0.3514782196402767
  - 0.43080240719560114
  - 0.4106679803026509
  - 0.39213292749721806
  - 0.4060319943470529
  - 0.4179535517899479
  - 0.46549377669902764
  - 0.43375350448622585
  - 0.49532104563499463
  - 0.47219299737457704
  - 0.45606793714503063
  - 0.4305210618997932
  - 0.4006019781633346
  - 0.499430970862325
  - 0.5045874118189358
  - 0.4485684302998553
  TL_precision_macro:
  - 0.5829842062317172
  - 0.618293848814339
  - 0.6103966016184285
  - 0.6037038479475612
  - 0.6037957795963678
  - 0.6098945628200838
  - 0.6315050999174786
  - 0.6149460309796195
  - 0.6583232112445571
  - 0.6428232135481207
  - 0.6345382116265186
  - 0.6233546165930508
  - 0.6083853054316727
  - 0.6533240008542582
  - 0.6500568181818182
  - 0.6222013909716766
  TL_precision_micro:
  - 0.8503809166978894
  - 0.9052079430498314
  - 0.8947629684785307
  - 0.896500372300819
  - 0.8719870113650556
  - 0.8827276133383289
  - 0.9108960039712087
  - 0.9000992802184165
  - 0.9276882727613338
  - 0.9235668789808917
  - 0.9209481260858774
  - 0.9164805162571358
  - 0.8858498813538154
  - 0.9218184088922193
  - 0.9231819310002481
  - 0.8984859766691486
  TL_precision_weighted:
  - 0.9681241375779235
  - 0.9706833314897155
  - 0.9688127338085437
  - 0.9696025508976258
  - 0.9682708534016824
  - 0.9685399543645875
  - 0.9716134563604397
  - 0.9724544279301565
  - 0.968291864007841
  - 0.9702916185429861
  - 0.9707080519604447
  - 0.9704870771808074
  - 0.9655517612717804
  - 0.969664667762946
  - 0.9728801934083952
  - 0.9706734643800032
  TL_recall_macro:
  - 0.872170032381059
  - 0.8922239319831569
  - 0.8819143605270773
  - 0.8706907599641164
  - 0.8970825718409423
  - 0.8973926620460335
  - 0.911931659459399
  - 0.909196605247381
  - 0.8874083533304074
  - 0.8902835912147862
  - 0.886503508514613
  - 0.8756413619905152
  - 0.8701653657504949
  - 0.9067062124435117
  - 0.9241867501442569
  - 0.9116435072091623
  TL_recall_micro:
  - 0.8503809166978894
  - 0.9052079430498314
  - 0.8947629684785307
  - 0.896500372300819
  - 0.8719870113650556
  - 0.8827276133383289
  - 0.9108960039712087
  - 0.9000992802184165
  - 0.9276882727613338
  - 0.9235668789808917
  - 0.9209481260858774
  - 0.9164805162571358
  - 0.8858498813538154
  - 0.9218184088922193
  - 0.9231819310002481
  - 0.8984859766691486
  TL_recall_weighted:
  - 0.8503809166978894
  - 0.9052079430498314
  - 0.8947629684785307
  - 0.896500372300819
  - 0.8719870113650556
  - 0.8827276133383289
  - 0.9108960039712087
  - 0.9000992802184165
  - 0.9276882727613338
  - 0.9235668789808917
  - 0.9209481260858774
  - 0.9164805162571358
  - 0.8858498813538154
  - 0.9218184088922193
  - 0.9231819310002481
  - 0.8984859766691486
  TL_roc_auc:
  - 0.9431337787095021
  - 0.9256441390660842
  - 0.9266780532676487
  - 0.9256371983626207
  - 0.952138583423074
  - 0.9565967723942363
  - 0.9501941958216471
  - 0.960678802004613
  - 0.9147361550261134
  - 0.9159608239665146
  - 0.9120861863333899
  - 0.9002612010542168
  - 0.9332429136864757
  - 0.9619559078527928
  - 0.964926233345246
  - 0.9530680694897345
  TT_average_precision:
  - 0.3188675780496814
  - 0.11754782767400156
  - 0.14968167570375934
  - 0.24138615609833738
  - 0.4521135525055423
  - 0.1456945176234667
  - 0.2728961118036412
  - 0.3767645926268599
  - 0.3182868718487319
  - 0.13238534786135983
  - 0.15426222266812983
  - 0.31285249426522693
  - 0.5045738473624558
  - 0.10001511903858604
  - 0.18026211544357562
  - 0.23425658044934608
  TT_balanced_accuracy:
  - 0.7209320091673033
  - 0.6402793723689246
  - 0.6269828926905132
  - 0.6975212951272913
  - 0.7667810831426392
  - 0.6814218706888624
  - 0.6680773109935574
  - 0.7476588863892013
  - 0.7450020411733831
  - 0.640658919946822
  - 0.5959090909090909
  - 0.6722873900293255
  - 0.7977382276603634
  - 0.6048892284186402
  - 0.6561725279039766
  - 0.6412147158413541
  TT_f1_macro:
  - 0.5465987719035496
  - 0.5669509551274184
  - 0.5486651165835181
  - 0.5940123979767308
  - 0.5733743925905279
  - 0.5562469218016218
  - 0.5776347855829664
  - 0.6386177781301052
  - 0.5957129649205293
  - 0.590954106084676
  - 0.5618864908073542
  - 0.6180969240008427
  - 0.6219374594008028
  - 0.5556934445671984
  - 0.5923231366772754
  - 0.5923004379448887
  TT_f1_micro:
  - 0.8342582315945245
  - 0.8956714761376249
  - 0.8872549019607843
  - 0.889894419306184
  - 0.860895301516833
  - 0.8686644469108398
  - 0.8876319758672699
  - 0.9008295625942685
  - 0.9123196448390677
  - 0.9204587495375509
  - 0.9064856711915534
  - 0.9136500754147813
  - 0.8897521272660007
  - 0.9071402145763966
  - 0.9008295625942685
  - 0.9102564102564102
  TT_f1_weighted:
  - 0.8850295249909811
  - 0.9191216024772063
  - 0.9159989194394814
  - 0.9149868875461378
  - 0.902617578521912
  - 0.9057192591923124
  - 0.9135560366744961
  - 0.9204461148627251
  - 0.9362769228763818
  - 0.9333618579992258
  - 0.9211369968881609
  - 0.9261917650804391
  - 0.9182405446828701
  - 0.9259990470768903
  - 0.9188826044229613
  - 0.9243757190183224
  TT_matthews_corrcoef:
  - 0.2043273037293591
  - 0.17130320348917938
  - 0.14248683824119132
  - 0.2387967759261503
  - 0.25540384974769237
  - 0.1859994594025386
  - 0.20171801910768294
  - 0.3236613521480111
  - 0.26098986359025433
  - 0.20045019200855702
  - 0.13837412077734998
  - 0.25499562354498617
  - 0.3293920172280841
  - 0.13559255219625138
  - 0.2122997511986785
  - 0.20341776474105988
  TT_precision_macro:
  - 0.5472426417596357
  - 0.5522970466543016
  - 0.5399709335679046
  - 0.5721743700546001
  - 0.5611279533930306
  - 0.5476731371563358
  - 0.5605229804549396
  - 0.6057469332128582
  - 0.5695052463345146
  - 0.571414382201033
  - 0.5499102773246329
  - 0.5943521867967654
  - 0.5911027632109722
  - 0.5438208491193025
  - 0.5721496683250414
  - 0.5732550902462878
  TT_precision_micro:
  - 0.8342582315945246
  - 0.8956714761376249
  - 0.8872549019607843
  - 0.889894419306184
  - 0.8608953015168331
  - 0.8686644469108398
  - 0.8876319758672699
  - 0.9008295625942685
  - 0.9123196448390677
  - 0.9204587495375509
  - 0.9064856711915535
  - 0.9136500754147813
  - 0.8897521272660007
  - 0.9071402145763966
  - 0.9008295625942685
  - 0.9102564102564102
  TT_precision_weighted:
  - 0.9572880388559547
  - 0.9484258466480942
  - 0.9516891301592728
  - 0.9487768994763618
  - 0.9626613385182717
  - 0.9550543041634276
  - 0.9473348664804714
  - 0.9485510595947071
  - 0.9684475563083795
  - 0.9489093843697852
  - 0.9381531129204096
  - 0.9419495301803888
  - 0.9608521234306018
  - 0.9483430261315308
  - 0.941687560500664
  - 0.9415773551009614
  TT_recall_macro:
  - 0.7209320091673033
  - 0.6402793723689246
  - 0.6269828926905132
  - 0.6975212951272913
  - 0.7667810831426392
  - 0.6814218706888624
  - 0.6680773109935574
  - 0.7476588863892013
  - 0.7450020411733831
  - 0.640658919946822
  - 0.5959090909090909
  - 0.6722873900293255
  - 0.7977382276603634
  - 0.6048892284186402
  - 0.6561725279039766
  - 0.6412147158413541
  TT_recall_micro:
  - 0.8342582315945246
  - 0.8956714761376249
  - 0.8872549019607843
  - 0.889894419306184
  - 0.8608953015168331
  - 0.8686644469108398
  - 0.8876319758672699
  - 0.9008295625942685
  - 0.9123196448390677
  - 0.9204587495375509
  - 0.9064856711915535
  - 0.9136500754147813
  - 0.8897521272660007
  - 0.9071402145763966
  - 0.9008295625942685
  - 0.9102564102564102
  TT_recall_weighted:
  - 0.8342582315945246
  - 0.8956714761376249
  - 0.8872549019607843
  - 0.889894419306184
  - 0.8608953015168331
  - 0.8686644469108398
  - 0.8876319758672699
  - 0.9008295625942685
  - 0.9123196448390677
  - 0.9204587495375509
  - 0.9064856711915535
  - 0.9136500754147813
  - 0.8897521272660007
  - 0.9071402145763966
  - 0.9008295625942685
  - 0.9102564102564102
  TT_roc_auc:
  - 0.7937985889542982
  - 0.7234808861674533
  - 0.6268273716951789
  - 0.6849319994246719
  - 0.8632699569643378
  - 0.7470017474478063
  - 0.6716341106971575
  - 0.8034730033745782
  - 0.7852685600979764
  - 0.7141258435286
  - 0.5866967084639498
  - 0.7241077176167656
  - 0.8689819964569687
  - 0.6781377791758415
  - 0.6313234991680221
  - 0.6788689263255722
  fit_time:
  - 42.943804025650024
  - 38.85829710960388
  - 37.2085645198822
  - 40.0687198638916
  - 41.58360576629639
  - 39.564703702926636
  - 43.2444269657135
  - 44.926859855651855
  - 42.08544731140137
  - 44.3957245349884
  - 41.013097047805786
  - 38.49920034408569
  - 41.50801610946655
  - 43.276933908462524
  - 42.786327600479126
  - 40.05144739151001
  score_time:
  - 1.4859437942504883
  - 1.655351161956787
  - 1.6883203983306885
  - 1.6686086654663086
  - 1.5118787288665771
  - 1.724714756011963
  - 1.5083067417144775
  - 1.4376614093780518
  - 1.7301154136657715
  - 1.5032329559326172
  - 1.8721752166748047
  - 2.007040500640869
  - 1.6842236518859863
  - 1.5305206775665283
  - 1.7063491344451904
  - 1.7246615886688232
start: 2023-08-03 06:11:21.594313
