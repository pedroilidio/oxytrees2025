active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
directory: runs
end: 2023-08-12 13:17:39.185575
estimator:
  call: missing_data_simulation.estimators.md_ss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.PositiveDropper
        params:
          drop: 0.3
          random_state: 0
    - - estimator
      - call: missing_data_simulation.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: imblearn.pipeline.Pipeline
            params:
              bipartiteextratreesregressorss:
                call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
                params:
                  axis_decision_only: false
                  bipartite_adapter: gmosa
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error_gso
                  max_col_features: null
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_row_features: null
                  max_samples: null
                  min_col_weight_fraction_leaf: 0.0
                  min_cols_leaf: 1
                  min_cols_split: 1
                  min_impurity_decrease: 0.0
                  min_row_weight_fraction_leaf: 0.0
                  min_rows_leaf: 1
                  min_rows_split: 1
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 100
                  n_jobs: 3
                  oob_score: false
                  prediction_weights: null
                  preprocess_X_targets: null
                  random_state: null
                  ss_adapter: null
                  supervision: 0.5
                  unsupervised_criterion_cols: mean_distance
                  unsupervised_criterion_rows: mean_distance
                  update_supervision: null
                  verbose: 0
                  warm_start: false
              bipartiteextratreesregressorss__axis_decision_only: false
              bipartiteextratreesregressorss__bipartite_adapter: gmosa
              bipartiteextratreesregressorss__bootstrap: false
              bipartiteextratreesregressorss__ccp_alpha: 0.0
              bipartiteextratreesregressorss__criterion: squared_error_gso
              bipartiteextratreesregressorss__max_col_features: null
              bipartiteextratreesregressorss__max_depth: null
              bipartiteextratreesregressorss__max_features: 1.0
              bipartiteextratreesregressorss__max_leaf_nodes: null
              bipartiteextratreesregressorss__max_row_features: null
              bipartiteextratreesregressorss__max_samples: null
              bipartiteextratreesregressorss__min_col_weight_fraction_leaf: 0.0
              bipartiteextratreesregressorss__min_cols_leaf: 1
              bipartiteextratreesregressorss__min_cols_split: 1
              bipartiteextratreesregressorss__min_impurity_decrease: 0.0
              bipartiteextratreesregressorss__min_row_weight_fraction_leaf: 0.0
              bipartiteextratreesregressorss__min_rows_leaf: 1
              bipartiteextratreesregressorss__min_rows_split: 1
              bipartiteextratreesregressorss__min_samples_leaf: 1
              bipartiteextratreesregressorss__min_samples_split: 2
              bipartiteextratreesregressorss__min_weight_fraction_leaf: 0.0
              bipartiteextratreesregressorss__n_estimators: 100
              bipartiteextratreesregressorss__n_jobs: 3
              bipartiteextratreesregressorss__oob_score: false
              bipartiteextratreesregressorss__prediction_weights: null
              bipartiteextratreesregressorss__preprocess_X_targets: null
              bipartiteextratreesregressorss__random_state: null
              bipartiteextratreesregressorss__ss_adapter: null
              bipartiteextratreesregressorss__supervision: 0.5
              bipartiteextratreesregressorss__unsupervised_criterion_cols: mean_distance
              bipartiteextratreesregressorss__unsupervised_criterion_rows: mean_distance
              bipartiteextratreesregressorss__update_supervision: null
              bipartiteextratreesregressorss__verbose: 0
              bipartiteextratreesregressorss__warm_start: false
              memory: null
              minmaxscaler:
                call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
                params:
                  ndim: 2
                  transformers:
                    call: sklearn.preprocessing._data.MinMaxScaler
                    params:
                      clip: true
                      copy: true
                      feature_range:
                      - 0
                      - 1
                  transformers__clip: true
                  transformers__copy: true
                  transformers__feature_range:
                  - 0
                  - 1
              minmaxscaler__ndim: 2
              minmaxscaler__transformers:
                call: sklearn.preprocessing._data.MinMaxScaler
                params:
                  clip: true
                  copy: true
                  feature_range:
                  - 0
                  - 1
              minmaxscaler__transformers__clip: true
              minmaxscaler__transformers__copy: true
              minmaxscaler__transformers__feature_range:
              - 0
              - 1
              positivedropper:
                call: missing_data_simulation.positive_dropper.PositiveDropper
                params:
                  drop: 0.0
                  random_state:
                    call: numpy.random.mtrand.RandomState
                    params: {}
              positivedropper__drop: 0.0
              positivedropper__random_state:
                call: numpy.random.mtrand.RandomState
                params: {}
              similaritydistanceswitcher:
                call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
                params:
                  ndim: 2
                  transformers:
                    call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                    params: {}
              similaritydistanceswitcher__ndim: 2
              similaritydistanceswitcher__transformers:
                call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                params: {}
              steps:
              - - symmetryenforcer
                - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
                  params:
                    ndim: 2
                    samplers:
                      call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                      params:
                        sampling_strategy: auto
                    samplers__sampling_strategy: auto
              - - minmaxscaler
                - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
                  params:
                    ndim: 2
                    transformers:
                      call: sklearn.preprocessing._data.MinMaxScaler
                      params:
                        clip: true
                        copy: true
                        feature_range:
                        - 0
                        - 1
                    transformers__clip: true
                    transformers__copy: true
                    transformers__feature_range:
                    - 0
                    - 1
              - - similaritydistanceswitcher
                - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
                  params:
                    ndim: 2
                    transformers:
                      call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                      params: {}
              - - positivedropper
                - call: missing_data_simulation.positive_dropper.PositiveDropper
                  params:
                    drop: 0.0
                    random_state:
                      call: numpy.random.mtrand.RandomState
                      params: {}
              - - bipartiteextratreesregressorss
                - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
                  params:
                    axis_decision_only: false
                    bipartite_adapter: gmosa
                    bootstrap: false
                    ccp_alpha: 0.0
                    criterion: squared_error_gso
                    max_col_features: null
                    max_depth: null
                    max_features: 1.0
                    max_leaf_nodes: null
                    max_row_features: null
                    max_samples: null
                    min_col_weight_fraction_leaf: 0.0
                    min_cols_leaf: 1
                    min_cols_split: 1
                    min_impurity_decrease: 0.0
                    min_row_weight_fraction_leaf: 0.0
                    min_rows_leaf: 1
                    min_rows_split: 1
                    min_samples_leaf: 1
                    min_samples_split: 2
                    min_weight_fraction_leaf: 0.0
                    n_estimators: 100
                    n_jobs: 3
                    oob_score: false
                    prediction_weights: null
                    preprocess_X_targets: null
                    random_state: null
                    ss_adapter: null
                    supervision: 0.5
                    unsupervised_criterion_cols: mean_distance
                    unsupervised_criterion_rows: mean_distance
                    update_supervision: null
                    verbose: 0
                    warm_start: false
              symmetryenforcer:
                call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
                params:
                  ndim: 2
                  samplers:
                    call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                    params:
                      sampling_strategy: auto
                  samplers__sampling_strategy: auto
              symmetryenforcer__ndim: 2
              symmetryenforcer__samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
              symmetryenforcer__samplers__sampling_strategy: auto
              verbose: false
          estimator__bipartiteextratreesregressorss:
            call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
            params:
              axis_decision_only: false
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              preprocess_X_targets: null
              random_state: null
              ss_adapter: null
              supervision: 0.5
              unsupervised_criterion_cols: mean_distance
              unsupervised_criterion_rows: mean_distance
              update_supervision: null
              verbose: 0
              warm_start: false
          estimator__bipartiteextratreesregressorss__axis_decision_only: false
          estimator__bipartiteextratreesregressorss__bipartite_adapter: gmosa
          estimator__bipartiteextratreesregressorss__bootstrap: false
          estimator__bipartiteextratreesregressorss__ccp_alpha: 0.0
          estimator__bipartiteextratreesregressorss__criterion: squared_error_gso
          estimator__bipartiteextratreesregressorss__max_col_features: null
          estimator__bipartiteextratreesregressorss__max_depth: null
          estimator__bipartiteextratreesregressorss__max_features: 1.0
          estimator__bipartiteextratreesregressorss__max_leaf_nodes: null
          estimator__bipartiteextratreesregressorss__max_row_features: null
          estimator__bipartiteextratreesregressorss__max_samples: null
          estimator__bipartiteextratreesregressorss__min_col_weight_fraction_leaf: 0.0
          estimator__bipartiteextratreesregressorss__min_cols_leaf: 1
          estimator__bipartiteextratreesregressorss__min_cols_split: 1
          estimator__bipartiteextratreesregressorss__min_impurity_decrease: 0.0
          estimator__bipartiteextratreesregressorss__min_row_weight_fraction_leaf: 0.0
          estimator__bipartiteextratreesregressorss__min_rows_leaf: 1
          estimator__bipartiteextratreesregressorss__min_rows_split: 1
          estimator__bipartiteextratreesregressorss__min_samples_leaf: 1
          estimator__bipartiteextratreesregressorss__min_samples_split: 2
          estimator__bipartiteextratreesregressorss__min_weight_fraction_leaf: 0.0
          estimator__bipartiteextratreesregressorss__n_estimators: 100
          estimator__bipartiteextratreesregressorss__n_jobs: 3
          estimator__bipartiteextratreesregressorss__oob_score: false
          estimator__bipartiteextratreesregressorss__prediction_weights: null
          estimator__bipartiteextratreesregressorss__preprocess_X_targets: null
          estimator__bipartiteextratreesregressorss__random_state: null
          estimator__bipartiteextratreesregressorss__ss_adapter: null
          estimator__bipartiteextratreesregressorss__supervision: 0.5
          estimator__bipartiteextratreesregressorss__unsupervised_criterion_cols: mean_distance
          estimator__bipartiteextratreesregressorss__unsupervised_criterion_rows: mean_distance
          estimator__bipartiteextratreesregressorss__update_supervision: null
          estimator__bipartiteextratreesregressorss__verbose: 0
          estimator__bipartiteextratreesregressorss__warm_start: false
          estimator__memory: null
          estimator__minmaxscaler:
            call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: sklearn.preprocessing._data.MinMaxScaler
                params:
                  clip: true
                  copy: true
                  feature_range:
                  - 0
                  - 1
              transformers__clip: true
              transformers__copy: true
              transformers__feature_range:
              - 0
              - 1
          estimator__minmaxscaler__ndim: 2
          estimator__minmaxscaler__transformers:
            call: sklearn.preprocessing._data.MinMaxScaler
            params:
              clip: true
              copy: true
              feature_range:
              - 0
              - 1
          estimator__minmaxscaler__transformers__clip: true
          estimator__minmaxscaler__transformers__copy: true
          estimator__minmaxscaler__transformers__feature_range:
          - 0
          - 1
          estimator__positivedropper:
            call: missing_data_simulation.positive_dropper.PositiveDropper
            params:
              drop: 0.0
              random_state:
                call: numpy.random.mtrand.RandomState
                params: {}
          estimator__positivedropper__drop: 0.0
          estimator__positivedropper__random_state:
            call: numpy.random.mtrand.RandomState
            params: {}
          estimator__similaritydistanceswitcher:
            call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
            params:
              ndim: 2
              transformers:
                call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                params: {}
          estimator__similaritydistanceswitcher__ndim: 2
          estimator__similaritydistanceswitcher__transformers:
            call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
            params: {}
          estimator__steps:
          - - symmetryenforcer
            - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
              params:
                ndim: 2
                samplers:
                  call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                  params:
                    sampling_strategy: auto
                samplers__sampling_strategy: auto
          - - minmaxscaler
            - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
              params:
                ndim: 2
                transformers:
                  call: sklearn.preprocessing._data.MinMaxScaler
                  params:
                    clip: true
                    copy: true
                    feature_range:
                    - 0
                    - 1
                transformers__clip: true
                transformers__copy: true
                transformers__feature_range:
                - 0
                - 1
          - - similaritydistanceswitcher
            - call: bipartite_learn.wrappers.MultipartiteTransformerWrapper
              params:
                ndim: 2
                transformers:
                  call: bipartite_learn.preprocessing.monopartite.SimilarityDistanceSwitcher
                  params: {}
          - - positivedropper
            - call: missing_data_simulation.positive_dropper.PositiveDropper
              params:
                drop: 0.0
                random_state:
                  call: numpy.random.mtrand.RandomState
                  params: {}
          - - bipartiteextratreesregressorss
            - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
              params:
                axis_decision_only: false
                bipartite_adapter: gmosa
                bootstrap: false
                ccp_alpha: 0.0
                criterion: squared_error_gso
                max_col_features: null
                max_depth: null
                max_features: 1.0
                max_leaf_nodes: null
                max_row_features: null
                max_samples: null
                min_col_weight_fraction_leaf: 0.0
                min_cols_leaf: 1
                min_cols_split: 1
                min_impurity_decrease: 0.0
                min_row_weight_fraction_leaf: 0.0
                min_rows_leaf: 1
                min_rows_split: 1
                min_samples_leaf: 1
                min_samples_split: 2
                min_weight_fraction_leaf: 0.0
                n_estimators: 100
                n_jobs: 3
                oob_score: false
                prediction_weights: null
                preprocess_X_targets: null
                random_state: null
                ss_adapter: null
                supervision: 0.5
                unsupervised_criterion_cols: mean_distance
                unsupervised_criterion_rows: mean_distance
                update_supervision: null
                verbose: 0
                warm_start: false
          estimator__symmetryenforcer:
            call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
              samplers__sampling_strategy: auto
          estimator__symmetryenforcer__ndim: 2
          estimator__symmetryenforcer__samplers:
            call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
            params:
              sampling_strategy: auto
          estimator__symmetryenforcer__samplers__sampling_strategy: auto
          estimator__verbose: false
    verbose: false
  name: md_ss_bxt_gso__drop30
  params: {}
hash: e46f0ebf1486199340357aeb6948fa4b4d6f99c06008f1f84ff7439275210c09
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/e46f0eb_20230812T104428132638_md_ss_bxt_gso__drop30_kiba.yml
results:
  LL_average_precision:
  - 0.7602252228233629
  - 0.7586729037161428
  - 0.7614692886023671
  - 0.7596369835530841
  - 0.7609666430551748
  - 0.7597392169901903
  - 0.762281086081217
  - 0.7605317530535548
  - 0.760384828955963
  - 0.7584595730256132
  - 0.7615710270474885
  - 0.7595897575256575
  - 0.7618940648926158
  - 0.759887133418502
  - 0.7629025347773349
  - 0.7610406135136428
  LL_balanced_accuracy:
  - 0.8503823689071865
  - 0.8504764186374377
  - 0.8503098682860244
  - 0.8503026560834317
  - 0.8503951966377622
  - 0.8506931876096924
  - 0.8504293287989617
  - 0.8504229868630184
  - 0.850140726464942
  - 0.8499948826660196
  - 0.8500412713349713
  - 0.8499928826533468
  - 0.8503386096410112
  - 0.8501268794040794
  - 0.8501549478179751
  - 0.8500693819619847
  LL_f1_macro:
  - 0.8936958916246855
  - 0.8944058286106404
  - 0.8931878265028005
  - 0.8938176446911894
  - 0.893348478313811
  - 0.8942096513001181
  - 0.892930190277879
  - 0.8935348367452731
  - 0.8927578147433184
  - 0.8932402948053222
  - 0.8922064156855526
  - 0.8928053400392839
  - 0.8927509826729997
  - 0.8931399411926508
  - 0.8921296165148855
  - 0.8926613205734996
  LL_f1_micro:
  - 0.9406707968067146
  - 0.9423930129721312
  - 0.9392821989451879
  - 0.9410928616550853
  - 0.9399873657612129
  - 0.9417870102396098
  - 0.9387459783455023
  - 0.94047216794723
  - 0.9401351346359159
  - 0.9417502828012752
  - 0.9387680148085031
  - 0.9406337686759024
  - 0.938991523421348
  - 0.9405684754521964
  - 0.937635805731736
  - 0.9393168604651163
  LL_f1_weighted:
  - 0.9365691106604347
  - 0.938374407527152
  - 0.9351073575373771
  - 0.9370051324252662
  - 0.9358673880665782
  - 0.9377623441159726
  - 0.9345694947789811
  - 0.9363767763661359
  - 0.9360680898063186
  - 0.9377513064784897
  - 0.9346345371296959
  - 0.9365870552738379
  - 0.9348480610620866
  - 0.9364926756120769
  - 0.9334248174779459
  - 0.9351799122026426
  LL_matthews_corrcoef:
  - 0.8060844677149483
  - 0.8073124528713813
  - 0.8053176457778614
  - 0.8063243262367426
  - 0.8053195829260836
  - 0.8067821011150286
  - 0.8046410100481666
  - 0.8056177927453408
  - 0.8035297449949934
  - 0.8043541207679757
  - 0.8026086411401816
  - 0.8035589390332686
  - 0.8039779688881381
  - 0.804564455866097
  - 0.8029263879065492
  - 0.8037786348917858
  LL_precision_macro:
  - 0.9636164849831605
  - 0.9649053130985645
  - 0.9628306032130343
  - 0.9639979941561506
  - 0.9627201206433063
  - 0.9640077008025623
  - 0.9618956675732244
  - 0.9630261514790259
  - 0.9610003937633675
  - 0.9621392937720501
  - 0.9600747708806895
  - 0.961228642426293
  - 0.9612541671611904
  - 0.9622067039988924
  - 0.960289643495053
  - 0.9613800343574896
  LL_precision_micro:
  - 0.9406707968067146
  - 0.9423930129721312
  - 0.9392821989451879
  - 0.9410928616550853
  - 0.9399873657612129
  - 0.9417870102396098
  - 0.9387459783455023
  - 0.94047216794723
  - 0.9401351346359159
  - 0.9417502828012752
  - 0.9387680148085031
  - 0.9406337686759024
  - 0.938991523421348
  - 0.9405684754521964
  - 0.937635805731736
  - 0.9393168604651163
  LL_precision_weighted:
  - 0.9443560862460678
  - 0.9458721660511924
  - 0.9431935731520034
  - 0.9447386797623395
  - 0.9436776942502263
  - 0.9452531866326149
  - 0.9426139480723917
  - 0.9440920960733039
  - 0.9434342304537287
  - 0.9448558543232046
  - 0.9422425534102128
  - 0.9438469281331773
  - 0.9426531787351058
  - 0.9439931615487268
  - 0.9414733141977355
  - 0.942910864705342
  LL_recall_macro:
  - 0.8503823689071865
  - 0.8504764186374377
  - 0.8503098682860244
  - 0.8503026560834317
  - 0.8503951966377622
  - 0.8506931876096924
  - 0.8504293287989617
  - 0.8504229868630184
  - 0.850140726464942
  - 0.8499948826660196
  - 0.8500412713349713
  - 0.8499928826533468
  - 0.8503386096410112
  - 0.8501268794040794
  - 0.8501549478179751
  - 0.8500693819619847
  LL_recall_micro:
  - 0.9406707968067146
  - 0.9423930129721312
  - 0.9392821989451879
  - 0.9410928616550853
  - 0.9399873657612129
  - 0.9417870102396098
  - 0.9387459783455023
  - 0.94047216794723
  - 0.9401351346359159
  - 0.9417502828012752
  - 0.9387680148085031
  - 0.9406337686759024
  - 0.938991523421348
  - 0.9405684754521964
  - 0.937635805731736
  - 0.9393168604651163
  LL_recall_weighted:
  - 0.9406707968067146
  - 0.9423930129721312
  - 0.9392821989451879
  - 0.9410928616550853
  - 0.9399873657612129
  - 0.9417870102396098
  - 0.9387459783455023
  - 0.94047216794723
  - 0.9401351346359159
  - 0.9417502828012752
  - 0.9387680148085031
  - 0.9406337686759024
  - 0.938991523421348
  - 0.9405684754521964
  - 0.937635805731736
  - 0.9393168604651163
  LL_roc_auc:
  - 0.8506606388616567
  - 0.8507244936998024
  - 0.8505755120565633
  - 0.8505647572470121
  - 0.8507414630078054
  - 0.8510125330214157
  - 0.8507828084910452
  - 0.8507678042244181
  - 0.8507445478627091
  - 0.8505678799277226
  - 0.8506652936148479
  - 0.8506041895857086
  - 0.8508096652144308
  - 0.8505966969107561
  - 0.8506480327113403
  - 0.8505514906610251
  LT_average_precision:
  - 0.44182092668509476
  - 0.40062073235327855
  - 0.38736421270562393
  - 0.37227296577268704
  - 0.4489567853224239
  - 0.40482361486978513
  - 0.40297071056867395
  - 0.37791580280990766
  - 0.4417319398546064
  - 0.4032865201583467
  - 0.396589132796506
  - 0.37103119523779193
  - 0.43909883851617926
  - 0.4051775650535041
  - 0.3996572792049905
  - 0.3744854983680695
  LT_balanced_accuracy:
  - 0.7334407404398187
  - 0.6958057470100528
  - 0.707038545854684
  - 0.6894517702466625
  - 0.7386317196266909
  - 0.6992051181817146
  - 0.7109308784233346
  - 0.6901320296174416
  - 0.730524348590865
  - 0.6979427087167891
  - 0.7052700035688069
  - 0.6901547279339677
  - 0.7263111092612919
  - 0.6993379451549792
  - 0.7070758525766228
  - 0.6879156555675598
  LT_f1_macro:
  - 0.6694963938159476
  - 0.6561255494338563
  - 0.6456370617286487
  - 0.6515303498227119
  - 0.6753049333669079
  - 0.6598628936594426
  - 0.6492591241421332
  - 0.654141271197104
  - 0.6686742391089935
  - 0.657956512100695
  - 0.6446958010534192
  - 0.6555994744923216
  - 0.6699342869118112
  - 0.6572934352302109
  - 0.6480650980132171
  - 0.6512328728862754
  LT_f1_micro:
  - 0.7382752085738559
  - 0.7285522713923153
  - 0.7299930179206703
  - 0.7363212199798296
  - 0.7430783976299911
  - 0.7312121111369707
  - 0.7307133911848478
  - 0.7387815717436358
  - 0.7398109220815997
  - 0.7311012844809434
  - 0.7300151832518758
  - 0.7426161740421806
  - 0.7401928770463253
  - 0.724426280347333
  - 0.7290116073010809
  - 0.7334640262271841
  LT_f1_weighted:
  - 0.7616459489910689
  - 0.747369926585531
  - 0.7561655148683993
  - 0.7551238416619781
  - 0.7655930762603119
  - 0.7495147064638659
  - 0.7564142982939719
  - 0.7566550729411089
  - 0.7628710258560214
  - 0.7498178337476813
  - 0.7561246585668593
  - 0.7598257384774632
  - 0.7618454583313219
  - 0.743740769982516
  - 0.7542203479247811
  - 0.7519074680008926
  LT_matthews_corrcoef:
  - 0.38752132922796934
  - 0.33972316333686364
  - 0.338136012334417
  - 0.3274532574707003
  - 0.39764044527002584
  - 0.34653261661508844
  - 0.34559508035028746
  - 0.3306662616033687
  - 0.3833453545341007
  - 0.3432403314758275
  - 0.3354444653011618
  - 0.33183155334377357
  - 0.3808033059576865
  - 0.34519147176316695
  - 0.3411197549711139
  - 0.3262382378761593
  LT_precision_macro:
  - 0.6608253772709899
  - 0.6473550054964424
  - 0.6380612030062159
  - 0.6414946343448877
  - 0.6656505723148414
  - 0.6507050314196228
  - 0.6415581735295006
  - 0.6437687495141498
  - 0.6593689145432626
  - 0.6487980106913168
  - 0.6370426600877712
  - 0.6447665553611409
  - 0.660190056844357
  - 0.6494411313477977
  - 0.640483168104422
  - 0.6415946259654202
  LT_precision_micro:
  - 0.7382752085738559
  - 0.7285522713923153
  - 0.7299930179206703
  - 0.7363212199798296
  - 0.7430783976299911
  - 0.7312121111369707
  - 0.7307133911848478
  - 0.7387815717436358
  - 0.7398109220815997
  - 0.7311012844809434
  - 0.7300151832518758
  - 0.7426161740421806
  - 0.7401928770463253
  - 0.724426280347333
  - 0.7290116073010809
  - 0.7334640262271841
  LT_precision_weighted:
  - 0.8179993514280717
  - 0.7855553958433085
  - 0.8126998619790622
  - 0.7903607938830528
  - 0.8201137214745299
  - 0.7867665815736578
  - 0.8129100505425307
  - 0.7896515193358731
  - 0.8169795173766198
  - 0.7877054942301683
  - 0.8120103737966694
  - 0.7908619390315405
  - 0.8114707954952621
  - 0.7850013406373595
  - 0.8090898205132454
  - 0.7865898679570079
  LT_recall_macro:
  - 0.7334407404398187
  - 0.6958057470100528
  - 0.707038545854684
  - 0.6894517702466625
  - 0.7386317196266909
  - 0.6992051181817146
  - 0.7109308784233346
  - 0.6901320296174416
  - 0.730524348590865
  - 0.6979427087167891
  - 0.7052700035688069
  - 0.6901547279339677
  - 0.7263111092612919
  - 0.6993379451549792
  - 0.7070758525766228
  - 0.6879156555675598
  LT_recall_micro:
  - 0.7382752085738559
  - 0.7285522713923153
  - 0.7299930179206703
  - 0.7363212199798296
  - 0.7430783976299911
  - 0.7312121111369707
  - 0.7307133911848478
  - 0.7387815717436358
  - 0.7398109220815997
  - 0.7311012844809434
  - 0.7300151832518758
  - 0.7426161740421806
  - 0.7401928770463253
  - 0.724426280347333
  - 0.7290116073010809
  - 0.7334640262271841
  LT_recall_weighted:
  - 0.7382752085738559
  - 0.7285522713923153
  - 0.7299930179206703
  - 0.7363212199798296
  - 0.7430783976299911
  - 0.7312121111369707
  - 0.7307133911848478
  - 0.7387815717436358
  - 0.7398109220815997
  - 0.7311012844809434
  - 0.7300151832518758
  - 0.7426161740421806
  - 0.7401928770463253
  - 0.724426280347333
  - 0.7290116073010809
  - 0.7334640262271841
  LT_roc_auc:
  - 0.8017309091620829
  - 0.7626125518004627
  - 0.7681000826322409
  - 0.7566573478132672
  - 0.804684264752402
  - 0.7635850018117322
  - 0.7714428538624867
  - 0.7581389341105589
  - 0.8010503356754766
  - 0.7637114187164199
  - 0.7682057276195082
  - 0.7574984760369661
  - 0.799568464413804
  - 0.7623844658292503
  - 0.7695053089433476
  - 0.755563395894925
  TL_average_precision:
  - 0.6709347578316709
  - 0.6632928665464802
  - 0.6704004339596645
  - 0.6557609417988502
  - 0.6364076744783388
  - 0.624217858491839
  - 0.6270155370922155
  - 0.6195608493271731
  - 0.6597424704751833
  - 0.6542986224451905
  - 0.656172230102122
  - 0.6499449528961141
  - 0.6367008428350498
  - 0.627447283206939
  - 0.63193778658833
  - 0.6155056501248092
  TL_balanced_accuracy:
  - 0.8065408201682778
  - 0.8058174310775181
  - 0.8044120951868429
  - 0.7974922705231955
  - 0.8098542894178131
  - 0.8111730802555842
  - 0.8037728095028364
  - 0.8039106654779379
  - 0.8152968931442468
  - 0.813235003183078
  - 0.8089849961571703
  - 0.8094220414415336
  - 0.8054889423346686
  - 0.8036741714841393
  - 0.799592865834015
  - 0.7968424992875032
  TL_f1_macro:
  - 0.7307825307454205
  - 0.7257353831250879
  - 0.7309044083507101
  - 0.7171253961883485
  - 0.7249552256373222
  - 0.7240601288592361
  - 0.7239540099437531
  - 0.7159911042620442
  - 0.7403208461988351
  - 0.7339496980576146
  - 0.7385723275571747
  - 0.7319070451231041
  - 0.7275168835609178
  - 0.7172265780494833
  - 0.7192154518750369
  - 0.7092318042216932
  TL_f1_micro:
  - 0.782916888180046
  - 0.7803801092318533
  - 0.7816464059196617
  - 0.7698533298097252
  - 0.7777445507708665
  - 0.7800167371388301
  - 0.7755351479915433
  - 0.7693688336856942
  - 0.790991050859472
  - 0.7873062015503876
  - 0.7884954193093728
  - 0.7827475334742776
  - 0.7886414328040214
  - 0.7797537619699042
  - 0.7764882397069856
  - 0.7692180398040687
  TL_f1_weighted:
  - 0.8012555013761179
  - 0.7999250652922919
  - 0.7996086304369193
  - 0.7903062651676155
  - 0.7980181606331767
  - 0.8007733330797888
  - 0.7951535083398011
  - 0.7910651026137547
  - 0.8082453208365576
  - 0.8058543757913719
  - 0.8052412792449989
  - 0.801200157369108
  - 0.8077441075229604
  - 0.8012885559815357
  - 0.7968298864673682
  - 0.7918321701986194
  TL_matthews_corrcoef:
  - 0.5141815245511779
  - 0.507847167822727
  - 0.5130739990411946
  - 0.4938978652391126
  - 0.5117769940551838
  - 0.5104995205571646
  - 0.5060348610755095
  - 0.49854769920205033
  - 0.5311888909352029
  - 0.5223083498669342
  - 0.5244299258851823
  - 0.5184007581809803
  - 0.5061609312415739
  - 0.49467624472368477
  - 0.4953211116742584
  - 0.48297862024643656
  TL_precision_macro:
  - 0.7156178091099245
  - 0.7108355506068185
  - 0.7161912524620191
  - 0.7049928060809338
  - 0.7113216603651628
  - 0.7093768524859552
  - 0.7107424303732156
  - 0.7044595966949548
  - 0.7237269411689725
  - 0.7177327003435752
  - 0.722524354405902
  - 0.7171300926322297
  - 0.7096629802353589
  - 0.701453243371002
  - 0.7047303454533459
  - 0.6964580107085866
  TL_precision_micro:
  - 0.7829168881800461
  - 0.7803801092318534
  - 0.7816464059196617
  - 0.7698533298097252
  - 0.7777445507708666
  - 0.7800167371388301
  - 0.7755351479915433
  - 0.7693688336856942
  - 0.790991050859472
  - 0.7873062015503876
  - 0.7884954193093728
  - 0.7827475334742776
  - 0.7886414328040214
  - 0.7797537619699042
  - 0.7764882397069856
  - 0.7692180398040687
  TL_precision_weighted:
  - 0.8559540002381312
  - 0.8578304937087243
  - 0.8533808965986294
  - 0.8520586385923239
  - 0.860574145923801
  - 0.8633260001555534
  - 0.8550730964219677
  - 0.8582718223507746
  - 0.8604545041106826
  - 0.861452904404444
  - 0.8550918260732313
  - 0.8575171409877139
  - 0.860446877292546
  - 0.8620219850612216
  - 0.855536635983061
  - 0.8572732765752948
  TL_recall_macro:
  - 0.8065408201682778
  - 0.8058174310775181
  - 0.8044120951868429
  - 0.7974922705231955
  - 0.8098542894178131
  - 0.8111730802555842
  - 0.8037728095028364
  - 0.8039106654779379
  - 0.8152968931442468
  - 0.813235003183078
  - 0.8089849961571703
  - 0.8094220414415336
  - 0.8054889423346686
  - 0.8036741714841393
  - 0.799592865834015
  - 0.7968424992875032
  TL_recall_micro:
  - 0.7829168881800461
  - 0.7803801092318534
  - 0.7816464059196617
  - 0.7698533298097252
  - 0.7777445507708666
  - 0.7800167371388301
  - 0.7755351479915433
  - 0.7693688336856942
  - 0.790991050859472
  - 0.7873062015503876
  - 0.7884954193093728
  - 0.7827475334742776
  - 0.7886414328040214
  - 0.7797537619699042
  - 0.7764882397069856
  - 0.7692180398040687
  TL_recall_weighted:
  - 0.7829168881800461
  - 0.7803801092318534
  - 0.7816464059196617
  - 0.7698533298097252
  - 0.7777445507708666
  - 0.7800167371388301
  - 0.7755351479915433
  - 0.7693688336856942
  - 0.790991050859472
  - 0.7873062015503876
  - 0.7884954193093728
  - 0.7827475334742776
  - 0.7886414328040214
  - 0.7797537619699042
  - 0.7764882397069856
  - 0.7692180398040687
  TL_roc_auc:
  - 0.8846954746525596
  - 0.8856005805528234
  - 0.8835391473296121
  - 0.8796689124178177
  - 0.8888805903857159
  - 0.8875141027902886
  - 0.8838958747684258
  - 0.8827857885805739
  - 0.8942879036326921
  - 0.89335900673882
  - 0.8901421338734018
  - 0.8912884299482817
  - 0.8827146984723316
  - 0.8815357084313529
  - 0.8781213859214512
  - 0.8758068072985011
  TT_average_precision:
  - 0.35137805470265443
  - 0.3314206697854808
  - 0.3158571249426652
  - 0.29447508572352427
  - 0.3205612715757695
  - 0.3218770911608757
  - 0.3117988864012743
  - 0.284963382984439
  - 0.3336069261871434
  - 0.32707475687524973
  - 0.3131968617067583
  - 0.2823889113023265
  - 0.31859778714754294
  - 0.3096511034757128
  - 0.29600000550016115
  - 0.2757203700883411
  TT_balanced_accuracy:
  - 0.6475446659079229
  - 0.6190266539418483
  - 0.6296354094178496
  - 0.5940053708305915
  - 0.6397447423476175
  - 0.6190470178970309
  - 0.6410927059829519
  - 0.5960288569877612
  - 0.6447734064897916
  - 0.6163967305283629
  - 0.6384312016437073
  - 0.5884744798163323
  - 0.637587483855319
  - 0.6200813267087952
  - 0.6309568281166884
  - 0.590036654953081
  TT_f1_macro:
  - 0.5814661621582989
  - 0.5789894337122063
  - 0.5737001073071176
  - 0.562576167011074
  - 0.5666606458110517
  - 0.5760827501745283
  - 0.5708472246512555
  - 0.5610996662377825
  - 0.5837368903175139
  - 0.5783484652779448
  - 0.5849778094285502
  - 0.5623758616728918
  - 0.5789484396918871
  - 0.5763308653778123
  - 0.5719643508698262
  - 0.5599401737298322
  TT_f1_micro:
  - 0.6428291536050157
  - 0.6469298245614035
  - 0.6523125996810207
  - 0.6482589048378522
  - 0.6249020376175548
  - 0.6445374800637959
  - 0.6457336523125997
  - 0.647627591706539
  - 0.6458333333333334
  - 0.6448032961190856
  - 0.6657363104731526
  - 0.6559675704412546
  - 0.656808218281751
  - 0.6517860115183595
  - 0.6642364925596724
  - 0.6597090449082859
  TT_f1_weighted:
  - 0.6781628495156614
  - 0.6753647606819111
  - 0.6879935715368947
  - 0.676871278550578
  - 0.6637313613613579
  - 0.6745253384194548
  - 0.685630987062495
  - 0.6781969500944759
  - 0.6796010304484629
  - 0.6724353349221311
  - 0.6988889039269853
  - 0.6822200514752886
  - 0.6923498092387795
  - 0.6826418510381668
  - 0.7022118344467962
  - 0.6887963827265166
  TT_matthews_corrcoef:
  - 0.2384862003472454
  - 0.20118672485396616
  - 0.2083412215574327
  - 0.15880559291749644
  - 0.2229176734614293
  - 0.1994649710227507
  - 0.2210076569995878
  - 0.16026920375367007
  - 0.23613936418808854
  - 0.19793840504309398
  - 0.22446378118642155
  - 0.1512030676228001
  - 0.2206285085412767
  - 0.19940020919341467
  - 0.20564694680638215
  - 0.1508383608369804
  TT_precision_macro:
  - 0.5963702540618452
  - 0.5850147780287105
  - 0.5837079637326055
  - 0.5670685518259524
  - 0.588898316148893
  - 0.5835515987043028
  - 0.5865466150644763
  - 0.5668710908303041
  - 0.5962915093855421
  - 0.5841510152672564
  - 0.5909910274314158
  - 0.5646015882376646
  - 0.5884472508275803
  - 0.582778156513042
  - 0.5807339856557615
  - 0.5631748567065367
  TT_precision_micro:
  - 0.6428291536050157
  - 0.6469298245614035
  - 0.6523125996810207
  - 0.6482589048378522
  - 0.6249020376175548
  - 0.6445374800637959
  - 0.6457336523125997
  - 0.647627591706539
  - 0.6458333333333334
  - 0.6448032961190856
  - 0.6657363104731526
  - 0.6559675704412546
  - 0.656808218281751
  - 0.6517860115183595
  - 0.6642364925596724
  - 0.6597090449082859
  TT_precision_weighted:
  - 0.7689612363213353
  - 0.7360593083325064
  - 0.7663490957063546
  - 0.7296688891022638
  - 0.7689361665287966
  - 0.7396237659503744
  - 0.7807131468607545
  - 0.7358598158761076
  - 0.7639404540272522
  - 0.7311415572285089
  - 0.7698410364065706
  - 0.7272063949914475
  - 0.7716362711163043
  - 0.7472715901511008
  - 0.7810402916649359
  - 0.7391618357503453
  TT_recall_macro:
  - 0.6475446659079229
  - 0.6190266539418483
  - 0.6296354094178496
  - 0.5940053708305915
  - 0.6397447423476175
  - 0.6190470178970309
  - 0.6410927059829519
  - 0.5960288569877612
  - 0.6447734064897916
  - 0.6163967305283629
  - 0.6384312016437073
  - 0.5884744798163323
  - 0.637587483855319
  - 0.6200813267087952
  - 0.6309568281166884
  - 0.590036654953081
  TT_recall_micro:
  - 0.6428291536050157
  - 0.6469298245614035
  - 0.6523125996810207
  - 0.6482589048378522
  - 0.6249020376175548
  - 0.6445374800637959
  - 0.6457336523125997
  - 0.647627591706539
  - 0.6458333333333334
  - 0.6448032961190856
  - 0.6657363104731526
  - 0.6559675704412546
  - 0.656808218281751
  - 0.6517860115183595
  - 0.6642364925596724
  - 0.6597090449082859
  TT_recall_weighted:
  - 0.6428291536050157
  - 0.6469298245614035
  - 0.6523125996810207
  - 0.6482589048378522
  - 0.6249020376175548
  - 0.6445374800637957
  - 0.6457336523125997
  - 0.647627591706539
  - 0.6458333333333335
  - 0.6448032961190856
  - 0.6657363104731526
  - 0.6559675704412546
  - 0.656808218281751
  - 0.6517860115183595
  - 0.6642364925596724
  - 0.6597090449082859
  TT_roc_auc:
  - 0.7088670433047347
  - 0.6745396046563586
  - 0.6849375716652494
  - 0.6497505728972734
  - 0.7001654469678351
  - 0.6748171226977346
  - 0.6988327155522119
  - 0.6571637854327768
  - 0.7059796329916807
  - 0.6774556446182921
  - 0.6959352710456419
  - 0.6556820055890521
  - 0.7008051848682436
  - 0.6749879707100418
  - 0.6893264851820743
  - 0.6543440091670747
  fit_time:
  - 8942.862331151962
  - 7749.8503630161285
  - 7546.607929468155
  - 6960.558673620224
  - 8898.546069383621
  - 7864.484493732452
  - 6371.85148358345
  - 6721.113134384155
  - 9154.004784345627
  - 7773.378564357758
  - 6733.397171497345
  - 4646.573061704636
  - 8468.40831398964
  - 8478.673529624939
  - 5291.908655881882
  - 6232.9314777851105
  score_time:
  - 33.00161266326904
  - 38.23932242393494
  - 43.956658363342285
  - 41.61781430244446
  - 33.29730749130249
  - 35.45924139022827
  - 46.350931882858276
  - 47.23709797859192
  - 36.100396394729614
  - 39.141313552856445
  - 47.95395374298096
  - 63.04981994628906
  - 37.458720445632935
  - 36.71839094161987
  - 64.54510545730591
  - 62.507301807403564
start: 2023-08-12 10:44:28.132638
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop30
  params:
    drop: 0.3
    random_state: 0
