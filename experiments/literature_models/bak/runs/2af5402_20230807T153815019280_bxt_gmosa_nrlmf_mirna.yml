active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
    url: null
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
    url: null
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: utils.read_table_to_array
      params: {}
    url: null
directory: runs
end: 2023-08-07 18:39:43.275141
estimator:
  call: y_reconstruction.estimators.bxt_gmosa_nrlmf
  final_params:
    memory: /tmp
    steps:
    - - symmetryenforcer
      - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
        params:
          ndim: 2
          samplers:
            call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
            params:
              sampling_strategy: auto
          samplers__sampling_strategy: auto
    - - regressorassampler
      - call: y_reconstruction.estimators.RegressorAsSampler
        params:
          estimator:
            call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
            params:
              cv:
                call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                params: {}
              diagonal: false
              error_score: .nan
              estimator:
                call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
                params:
                  alpha_cols: same
                  alpha_rows: 0.1
                  keep_positives: true
                  lambda_cols: same
                  lambda_rows: 0.625
                  learning_rate: 1.0
                  max_iter: 100
                  n_components_cols: same
                  n_components_rows: 10
                  n_neighbors: 5
                  positive_importance: 5
                  random_state: null
                  resample_X: false
                  tol: 1.0e-05
                  verbose: false
              estimator__alpha_cols: same
              estimator__alpha_rows: 0.1
              estimator__keep_positives: true
              estimator__lambda_cols: same
              estimator__lambda_rows: 0.625
              estimator__learning_rate: 1.0
              estimator__max_iter: 100
              estimator__n_components_cols: same
              estimator__n_components_rows: 10
              estimator__n_neighbors: 5
              estimator__positive_importance: 5
              estimator__random_state: null
              estimator__resample_X: false
              estimator__tol: 1.0e-05
              estimator__verbose: false
              n_iter: 100
              n_jobs: 3
              pairwise: true
              param_distributions:
                alpha_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                alpha_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                learning_rate:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                n_components_rows:
                - 50
                - 100
                n_neighbors:
                - 3
                - 5
                - 10
              pre_dispatch: 2*n_jobs
              random_state: 0
              refit: true
              return_train_score: false
              scoring: null
              train_test_combinations: null
              verbose: 1
          estimator__cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          estimator__diagonal: false
          estimator__error_score: .nan
          estimator__estimator:
            call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
            params:
              alpha_cols: same
              alpha_rows: 0.1
              keep_positives: true
              lambda_cols: same
              lambda_rows: 0.625
              learning_rate: 1.0
              max_iter: 100
              n_components_cols: same
              n_components_rows: 10
              n_neighbors: 5
              positive_importance: 5
              random_state: null
              resample_X: false
              tol: 1.0e-05
              verbose: false
          estimator__estimator__alpha_cols: same
          estimator__estimator__alpha_rows: 0.1
          estimator__estimator__keep_positives: true
          estimator__estimator__lambda_cols: same
          estimator__estimator__lambda_rows: 0.625
          estimator__estimator__learning_rate: 1.0
          estimator__estimator__max_iter: 100
          estimator__estimator__n_components_cols: same
          estimator__estimator__n_components_rows: 10
          estimator__estimator__n_neighbors: 5
          estimator__estimator__positive_importance: 5
          estimator__estimator__random_state: null
          estimator__estimator__resample_X: false
          estimator__estimator__tol: 1.0e-05
          estimator__estimator__verbose: false
          estimator__n_iter: 100
          estimator__n_jobs: 3
          estimator__pairwise: true
          estimator__param_distributions:
            alpha_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            alpha_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            learning_rate:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            n_components_rows:
            - 50
            - 100
            n_neighbors:
            - 3
            - 5
            - 10
          estimator__pre_dispatch: 2*n_jobs
          estimator__random_state: 0
          estimator__refit: true
          estimator__return_train_score: false
          estimator__scoring: null
          estimator__train_test_combinations: null
          estimator__verbose: 1
    - - regressortobinaryclassifier
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error
          estimator__max_col_features: null
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: null
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: bxt_gmosa_nrlmf
  params:
    regressortobinaryclassifier__estimator__min_cols_leaf: 1
    regressortobinaryclassifier__estimator__min_rows_leaf: 1
    regressortobinaryclassifier__estimator__min_samples_leaf: 1
hash: 2af5402c4b1565b34a935e289f11fb09daf8714864e759b9c8acc56e0c571693
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/2af5402_20230807T153815019280_bxt_gmosa_nrlmf_mirna.yml
results:
  LL_average_precision:
  - 0.9960460630594462
  - 0.992221191572096
  - 0.9923845995475076
  - 0.9956068180501709
  - 0.9956211615012663
  - 0.9966326382574662
  - 0.9922836452275906
  - 0.9981614454899683
  - 0.9958394803932737
  - 0.9958251380088534
  - 0.9915831511364761
  - 0.991430449749021
  - 0.9928639239829101
  - 0.9964630155671081
  - 0.9959509849541952
  - 0.9926601004512224
  LL_balanced_accuracy:
  - 0.923629447193316
  - 0.9181072973866367
  - 0.9168287817971386
  - 0.9231258878408203
  - 0.922938507468569
  - 0.9235604417274699
  - 0.9172414980713217
  - 0.9315286311374363
  - 0.922295209511546
  - 0.9226376138877802
  - 0.9156118921523793
  - 0.9178060503112542
  - 0.9182058632306873
  - 0.9234313025054814
  - 0.9228183050130472
  - 0.9181208317275947
  LL_f1_macro:
  - 0.7088408298626983
  - 0.6979106712237142
  - 0.6921242201517245
  - 0.7078936223953141
  - 0.7070577314998279
  - 0.7096805752065216
  - 0.6924769922124077
  - 0.727069558462665
  - 0.704809193350611
  - 0.7067668562153772
  - 0.6880799492154891
  - 0.6954937670565787
  - 0.6964365330227986
  - 0.7084003602760012
  - 0.7040268787507403
  - 0.6961204599788089
  LL_f1_micro:
  - 0.8581109553778363
  - 0.8479424886177298
  - 0.8452973131429723
  - 0.8571891664840383
  - 0.856806764998684
  - 0.8580631872847319
  - 0.8460207572862194
  - 0.87278720686194
  - 0.8555434770170841
  - 0.8562781064411668
  - 0.8429014429403485
  - 0.8472283055023269
  - 0.8479797690837729
  - 0.8577427881589638
  - 0.8563604947877927
  - 0.8478100191623323
  LL_f1_weighted:
  - 0.8876911174997786
  - 0.880314318954941
  - 0.8788924844545214
  - 0.8870124252257358
  - 0.8867980818398743
  - 0.8875226350850123
  - 0.8794800748736145
  - 0.8981567621361196
  - 0.886015030233216
  - 0.8863711695072307
  - 0.87742451773389
  - 0.880066798081392
  - 0.8805855359118085
  - 0.8874293148125348
  - 0.8868603594579926
  - 0.8804849470029378
  LL_matthews_corrcoef:
  - 0.5316916803382133
  - 0.5174095613565288
  - 0.509547326079007
  - 0.5304522771858489
  - 0.529306900021505
  - 0.5328956421999307
  - 0.5099506824035415
  - 0.5561392819528117
  - 0.5262572900720055
  - 0.5289569339878302
  - 0.5041383853154122
  - 0.5140719325136152
  - 0.5153117704504308
  - 0.5311078307110103
  - 0.5250403450987787
  - 0.5148852126459056
  LL_precision_macro:
  - 0.666829787691712
  - 0.6600741339941225
  - 0.655722498572943
  - 0.6662505335040546
  - 0.6656066954551285
  - 0.667613484109545
  - 0.655814857633951
  - 0.6791833024588372
  - 0.6639532778943109
  - 0.6655055234199397
  - 0.6528803171585186
  - 0.6581295625095717
  - 0.6587413305933727
  - 0.6665414945550131
  - 0.6629939862542955
  - 0.658510867005866
  LL_precision_micro:
  - 0.8581109553778364
  - 0.8479424886177298
  - 0.8452973131429723
  - 0.8571891664840383
  - 0.856806764998684
  - 0.8580631872847319
  - 0.8460207572862194
  - 0.87278720686194
  - 0.8555434770170841
  - 0.8562781064411668
  - 0.8429014429403485
  - 0.8472283055023269
  - 0.8479797690837729
  - 0.8577427881589638
  - 0.8563604947877927
  - 0.8478100191623323
  LL_precision_weighted:
  - 0.9526573616198092
  - 0.9513190510963634
  - 0.9518186221333521
  - 0.9525152454756253
  - 0.9525724830798049
  - 0.9524189525947799
  - 0.9520154924359373
  - 0.954411183221019
  - 0.9526317590874721
  - 0.9524264655592809
  - 0.9519654455431498
  - 0.951684557570474
  - 0.9517362125344927
  - 0.9526165426575294
  - 0.9531752489237353
  - 0.9517524683756303
  LL_recall_macro:
  - 0.923629447193316
  - 0.9181072973866367
  - 0.9168287817971386
  - 0.9231258878408203
  - 0.922938507468569
  - 0.9235604417274699
  - 0.9172414980713217
  - 0.9315286311374363
  - 0.922295209511546
  - 0.9226376138877802
  - 0.9156118921523793
  - 0.9178060503112542
  - 0.9182058632306873
  - 0.9234313025054814
  - 0.9228183050130472
  - 0.9181208317275947
  LL_recall_micro:
  - 0.8581109553778364
  - 0.8479424886177298
  - 0.8452973131429723
  - 0.8571891664840383
  - 0.856806764998684
  - 0.8580631872847319
  - 0.8460207572862194
  - 0.87278720686194
  - 0.8555434770170841
  - 0.8562781064411668
  - 0.8429014429403485
  - 0.8472283055023269
  - 0.8479797690837729
  - 0.8577427881589638
  - 0.8563604947877927
  - 0.8478100191623323
  LL_recall_weighted:
  - 0.8581109553778364
  - 0.8479424886177298
  - 0.8452973131429723
  - 0.8571891664840383
  - 0.856806764998684
  - 0.8580631872847319
  - 0.8460207572862194
  - 0.87278720686194
  - 0.8555434770170841
  - 0.8562781064411668
  - 0.8429014429403485
  - 0.8472283055023269
  - 0.8479797690837729
  - 0.8577427881589638
  - 0.8563604947877927
  - 0.8478100191623323
  LL_roc_auc:
  - 0.9997420186125896
  - 0.9994912843660205
  - 0.999498205580655
  - 0.9997214768329916
  - 0.9997303809073932
  - 0.9997769014526102
  - 0.9995044145298417
  - 0.9998808488839565
  - 0.9997382955300866
  - 0.9997298492919369
  - 0.999457401575273
  - 0.9994387161551478
  - 0.9995267199758924
  - 0.9997691942188724
  - 0.9997542070803016
  - 0.9995064779808222
  LT_average_precision:
  - 0.1733391183816155
  - 0.15548466725985816
  - 0.16084092114825776
  - 0.17609304346428273
  - 0.17227887541727127
  - 0.14793691408933352
  - 0.15858258757724944
  - 0.17011143411334892
  - 0.17332306518859622
  - 0.14936584845334505
  - 0.15700402807105424
  - 0.1755115198826606
  - 0.16858205699762352
  - 0.1460972519407529
  - 0.14802142725576867
  - 0.1686488935960572
  LT_balanced_accuracy:
  - 0.6114363669808066
  - 0.6108095978319815
  - 0.6045532460685099
  - 0.6124079587420315
  - 0.6052005551847095
  - 0.6009321194226221
  - 0.5927510528151728
  - 0.6167879591144848
  - 0.6043869074427473
  - 0.5994167210135803
  - 0.600616801367244
  - 0.607320963961982
  - 0.6047537456320783
  - 0.6001380896043651
  - 0.5924090993191795
  - 0.6029028648259322
  LT_f1_macro:
  - 0.5587304290370593
  - 0.5663202644658036
  - 0.5717294485353671
  - 0.5643868163897868
  - 0.5667057888271694
  - 0.56011865226492
  - 0.5771876453486541
  - 0.5493251777352554
  - 0.564026085235506
  - 0.559255477681246
  - 0.567909323588652
  - 0.57252928194488
  - 0.5672221032584452
  - 0.5536610152779122
  - 0.5603814848474092
  - 0.5697775869015462
  LT_f1_micro:
  - 0.8151435459127767
  - 0.8334360618014465
  - 0.8402024435678281
  - 0.8255262357204105
  - 0.836647960580345
  - 0.8325417465097181
  - 0.86294826170271
  - 0.7928618318764468
  - 0.8334519572953737
  - 0.833301396112784
  - 0.8373117985217629
  - 0.8470234599039491
  - 0.8395565288803722
  - 0.8202162606077197
  - 0.8327128387626609
  - 0.8457243547662647
  LT_f1_weighted:
  - 0.8475931457933884
  - 0.8597362279634785
  - 0.8607427444186453
  - 0.8542110599842324
  - 0.8604817387267782
  - 0.8588409244385256
  - 0.873258157239717
  - 0.8341788859926914
  - 0.8587648730880234
  - 0.8594501621884334
  - 0.8586906494334408
  - 0.8674983845738578
  - 0.8626473454913556
  - 0.851168017398053
  - 0.8555590633298517
  - 0.8661336395239966
  LT_matthews_corrcoef:
  - 0.1530554065162272
  - 0.15892621842300214
  - 0.16031322029664238
  - 0.1586954207275224
  - 0.15513656082718022
  - 0.1450582996252655
  - 0.15934055731897856
  - 0.15056557878858415
  - 0.15179078051361994
  - 0.14295064541437072
  - 0.15329340833177066
  - 0.16266459415839005
  - 0.1551933032728218
  - 0.13875628228883963
  - 0.13917013054552543
  - 0.15650538479030954
  LT_precision_macro:
  - 0.5525545611781348
  - 0.5569841047084507
  - 0.5614527276012055
  - 0.5560107950578514
  - 0.5571939769306072
  - 0.5521189647322939
  - 0.5684342992238502
  - 0.5485281053111786
  - 0.5551803899870558
  - 0.5513869468235472
  - 0.558387040530641
  - 0.5616370027250385
  - 0.5574799527105277
  - 0.5480668893092726
  - 0.5523983173160273
  - 0.5595074187433853
  LT_precision_micro:
  - 0.8151435459127767
  - 0.8334360618014465
  - 0.8402024435678281
  - 0.8255262357204105
  - 0.836647960580345
  - 0.832541746509718
  - 0.8629482617027101
  - 0.7928618318764468
  - 0.8334519572953737
  - 0.833301396112784
  - 0.837311798521763
  - 0.8470234599039491
  - 0.8395565288803722
  - 0.8202162606077197
  - 0.8327128387626608
  - 0.8457243547662647
  LT_precision_weighted:
  - 0.8912354701870446
  - 0.8938202849677828
  - 0.886389196363242
  - 0.8920424777380855
  - 0.8907740645366983
  - 0.8924700033296465
  - 0.8849950959120403
  - 0.8927052674452595
  - 0.8911618376595568
  - 0.892775374879807
  - 0.8853966601166625
  - 0.8930299427739595
  - 0.8918216883878802
  - 0.8917220027619606
  - 0.8840515980959269
  - 0.8914435414683644
  LT_recall_macro:
  - 0.6114363669808066
  - 0.6108095978319815
  - 0.6045532460685099
  - 0.6124079587420315
  - 0.6052005551847095
  - 0.6009321194226221
  - 0.5927510528151728
  - 0.6167879591144848
  - 0.6043869074427473
  - 0.5994167210135803
  - 0.600616801367244
  - 0.607320963961982
  - 0.6047537456320783
  - 0.6001380896043651
  - 0.5924090993191795
  - 0.6029028648259322
  LT_recall_micro:
  - 0.8151435459127767
  - 0.8334360618014465
  - 0.8402024435678281
  - 0.8255262357204105
  - 0.836647960580345
  - 0.832541746509718
  - 0.8629482617027101
  - 0.7928618318764468
  - 0.8334519572953737
  - 0.833301396112784
  - 0.837311798521763
  - 0.8470234599039491
  - 0.8395565288803722
  - 0.8202162606077197
  - 0.8327128387626608
  - 0.8457243547662647
  LT_recall_weighted:
  - 0.8151435459127767
  - 0.8334360618014465
  - 0.8402024435678281
  - 0.8255262357204105
  - 0.836647960580345
  - 0.832541746509718
  - 0.8629482617027101
  - 0.7928618318764468
  - 0.8334519572953737
  - 0.833301396112784
  - 0.837311798521763
  - 0.8470234599039491
  - 0.8395565288803722
  - 0.8202162606077197
  - 0.8327128387626608
  - 0.8457243547662647
  LT_roc_auc:
  - 0.658949875623745
  - 0.6607094154777152
  - 0.6486371418845469
  - 0.670539629011705
  - 0.6584526512676232
  - 0.655926811056354
  - 0.650819356483767
  - 0.6687862463276646
  - 0.660674838203259
  - 0.6555136969145866
  - 0.6442163662950642
  - 0.6672960641414765
  - 0.6574158678047286
  - 0.6492331266604605
  - 0.6335109488862172
  - 0.658581885441089
  TL_average_precision:
  - 0.29599716365175105
  - 0.303504274219787
  - 0.2973924549819467
  - 0.30444894088896596
  - 0.2666397827070079
  - 0.2771129609085976
  - 0.2625557096054611
  - 0.28019259836850274
  - 0.3093923010259484
  - 0.31101786757207783
  - 0.3032629797766897
  - 0.300571638503479
  - 0.2999150051270217
  - 0.3197216295475782
  - 0.3089051475678314
  - 0.30951327886314317
  TL_balanced_accuracy:
  - 0.6511090555685927
  - 0.6583881014408501
  - 0.6601691043904572
  - 0.6562214735721182
  - 0.6459907811767068
  - 0.6559818742226257
  - 0.6507074686707005
  - 0.6547337721255755
  - 0.671152474861241
  - 0.6750928214953984
  - 0.6689773265781839
  - 0.6706741276902326
  - 0.6584283272987019
  - 0.6665416030350155
  - 0.661220208630907
  - 0.660490039739114
  TL_f1_macro:
  - 0.5317681973380386
  - 0.5276199856686608
  - 0.5208185693120864
  - 0.533550715060105
  - 0.5225380178682737
  - 0.5264791623194531
  - 0.5118602943861517
  - 0.5440396599431436
  - 0.5314386442250781
  - 0.5367836136118372
  - 0.5217761474580556
  - 0.5283149284570033
  - 0.5205892692336389
  - 0.5316930946012198
  - 0.5257373425342499
  - 0.5210058457436814
  TL_f1_micro:
  - 0.7321317162465121
  - 0.718159318245703
  - 0.708471880377625
  - 0.7322316986496091
  - 0.7159218951823454
  - 0.717158600599115
  - 0.6940528210624674
  - 0.7530202169625246
  - 0.7153104130596093
  - 0.7226275867754968
  - 0.6999065600351774
  - 0.7100317773394698
  - 0.7030464176766428
  - 0.717433424025064
  - 0.7141149311567317
  - 0.7014162831470524
  TL_f1_weighted:
  - 0.7951739658236316
  - 0.7853137578729308
  - 0.7796500844784507
  - 0.7953061495445473
  - 0.7836122022584677
  - 0.7845253544292343
  - 0.7687943751346517
  - 0.8092984422911735
  - 0.7828567084152267
  - 0.7879353413131749
  - 0.7723298177255448
  - 0.779213705551327
  - 0.7743398552497047
  - 0.7840371669511337
  - 0.7828328083014552
  - 0.77289434601329
  TL_matthews_corrcoef:
  - 0.1725457875831195
  - 0.17795693234931761
  - 0.17553369292324406
  - 0.1781785919588178
  - 0.16409612617033636
  - 0.17527855288050356
  - 0.16403374712897187
  - 0.1821197962383108
  - 0.1924023741450627
  - 0.19857250801540266
  - 0.18595962713553135
  - 0.19054807612364552
  - 0.175647815727742
  - 0.18847354736191727
  - 0.17947146257961488
  - 0.17816211798767778
  TL_precision_macro:
  - 0.5492558978359252
  - 0.5499858724915113
  - 0.5480930412087444
  - 0.5508054525195778
  - 0.5461117106283546
  - 0.5492406108930878
  - 0.5446345997887538
  - 0.5535882046405589
  - 0.5540726530636921
  - 0.5563001963797862
  - 0.5511621642155429
  - 0.5531840557877661
  - 0.5486847202390738
  - 0.5533234300136349
  - 0.5499472214959831
  - 0.5494450315070226
  TL_precision_micro:
  - 0.7321317162465121
  - 0.718159318245703
  - 0.708471880377625
  - 0.7322316986496091
  - 0.7159218951823454
  - 0.7171586005991151
  - 0.6940528210624674
  - 0.7530202169625246
  - 0.7153104130596092
  - 0.7226275867754968
  - 0.6999065600351774
  - 0.7100317773394696
  - 0.7030464176766428
  - 0.7174334240250639
  - 0.7141149311567317
  - 0.7014162831470524
  TL_precision_weighted:
  - 0.9000431117935654
  - 0.9012221428719923
  - 0.9044876307864145
  - 0.9010047013242828
  - 0.8988191351183664
  - 0.9006286130584278
  - 0.9019197168949117
  - 0.9000209811673937
  - 0.9025611163397744
  - 0.9028633451007411
  - 0.9037253785434263
  - 0.9028790775005352
  - 0.9010422555955954
  - 0.9009260046680432
  - 0.902670567206295
  - 0.9008539751049003
  TL_recall_macro:
  - 0.6511090555685927
  - 0.6583881014408501
  - 0.6601691043904572
  - 0.6562214735721182
  - 0.6459907811767068
  - 0.6559818742226257
  - 0.6507074686707005
  - 0.6547337721255755
  - 0.671152474861241
  - 0.6750928214953984
  - 0.6689773265781839
  - 0.6706741276902326
  - 0.6584283272987019
  - 0.6665416030350155
  - 0.661220208630907
  - 0.660490039739114
  TL_recall_micro:
  - 0.7321317162465121
  - 0.718159318245703
  - 0.708471880377625
  - 0.7322316986496091
  - 0.7159218951823454
  - 0.7171586005991151
  - 0.6940528210624674
  - 0.7530202169625246
  - 0.7153104130596092
  - 0.7226275867754968
  - 0.6999065600351774
  - 0.7100317773394696
  - 0.7030464176766428
  - 0.7174334240250639
  - 0.7141149311567317
  - 0.7014162831470524
  TL_recall_weighted:
  - 0.7321317162465121
  - 0.718159318245703
  - 0.708471880377625
  - 0.7322316986496091
  - 0.7159218951823454
  - 0.7171586005991151
  - 0.6940528210624674
  - 0.7530202169625246
  - 0.7153104130596092
  - 0.7226275867754968
  - 0.6999065600351774
  - 0.7100317773394696
  - 0.7030464176766428
  - 0.7174334240250639
  - 0.7141149311567317
  - 0.7014162831470524
  TL_roc_auc:
  - 0.7127523771256337
  - 0.7236519800757586
  - 0.7233544724698404
  - 0.7202287398986726
  - 0.7078921248960732
  - 0.7166911220908596
  - 0.7142628686012334
  - 0.7144917073077457
  - 0.7364357816375402
  - 0.7406782107576235
  - 0.7328505771339144
  - 0.7361417240077687
  - 0.7249193137271693
  - 0.7306773891354724
  - 0.7245328542357501
  - 0.7256680236332563
  TT_average_precision:
  - 0.11858256549344633
  - 0.10046929942886326
  - 0.11001787971267252
  - 0.10846752401642454
  - 0.10759854452859806
  - 0.09695284980768845
  - 0.10330675314104999
  - 0.09913807149295215
  - 0.1172293406779752
  - 0.10934455243367833
  - 0.1178054205797758
  - 0.11104499014223324
  - 0.12572209925386896
  - 0.10653476984187643
  - 0.11629561595806259
  - 0.12410218583017248
  TT_balanced_accuracy:
  - 0.5474027618962007
  - 0.5358811061189428
  - 0.5361761854061746
  - 0.537989048060369
  - 0.5343020674120812
  - 0.5289337265511912
  - 0.5267965972373924
  - 0.5311601020213378
  - 0.5472508488809301
  - 0.5469909596395307
  - 0.5470518398759967
  - 0.5424216532802172
  - 0.5479092014385217
  - 0.5389634619290086
  - 0.5385739766033638
  - 0.5521550424107619
  TT_f1_macro:
  - 0.5473440993403014
  - 0.5351516090940542
  - 0.5387409439037811
  - 0.5388880074367063
  - 0.5373470098310329
  - 0.5290696201160134
  - 0.5306888076999496
  - 0.5296333145130198
  - 0.5501393267818402
  - 0.5461069913432626
  - 0.5484327719097916
  - 0.5453543420559684
  - 0.550156238018557
  - 0.5351791776506833
  - 0.540910177617898
  - 0.5537467703645543
  TT_f1_micro:
  - 0.8835287846481876
  - 0.8806380186977202
  - 0.88307774315237
  - 0.8846543979133459
  - 0.8914160092044707
  - 0.8799720578566732
  - 0.894456771860618
  - 0.8723757364534064
  - 0.8887656147271532
  - 0.8795816896778436
  - 0.8803418803418802
  - 0.887664924072691
  - 0.8858892176199868
  - 0.87060322156476
  - 0.880567882971729
  - 0.8873330014106713
  TT_f1_weighted:
  - 0.883600764240617
  - 0.8818211350587886
  - 0.8784776525566138
  - 0.8832492130891477
  - 0.8859360432450284
  - 0.8796880886349095
  - 0.8836161452653652
  - 0.8752910627798166
  - 0.8851410271987058
  - 0.8806927657599286
  - 0.8785283432271728
  - 0.883450183600302
  - 0.8830786675624408
  - 0.8762333740940584
  - 0.8766329973370316
  - 0.8855640987290677
  TT_matthews_corrcoef:
  - 0.09468841585704775
  - 0.07035337579580525
  - 0.07829151035393578
  - 0.07785249098063528
  - 0.07592245316233977
  - 0.058141917009930495
  - 0.06605390130895225
  - 0.05953467229214861
  - 0.10087714652402748
  - 0.09226327233431983
  - 0.09700096525593292
  - 0.09147091262136053
  - 0.10066164819808103
  - 0.07141195082636062
  - 0.08241267045723749
  - 0.10763883880505226
  TT_precision_macro:
  - 0.5472857262892724
  - 0.5344860988221649
  - 0.5423590859890263
  - 0.5398865637687095
  - 0.542010725074821
  - 0.5292088413465226
  - 0.5407058948518698
  - 0.5284368228520755
  - 0.5538413538160639
  - 0.5452880271393511
  - 0.5499937265225985
  - 0.5493081198445795
  - 0.5528748503090625
  - 0.5327208265664262
  - 0.5440183308149058
  - 0.555536910161295
  TT_precision_micro:
  - 0.8835287846481876
  - 0.8806380186977202
  - 0.88307774315237
  - 0.8846543979133459
  - 0.8914160092044707
  - 0.8799720578566732
  - 0.894456771860618
  - 0.8723757364534064
  - 0.8887656147271532
  - 0.8795816896778436
  - 0.8803418803418803
  - 0.887664924072691
  - 0.8858892176199868
  - 0.87060322156476
  - 0.8805678829717292
  - 0.8873330014106713
  TT_precision_weighted:
  - 0.8836727996639032
  - 0.8830169561511674
  - 0.8740942465016436
  - 0.8818634866586335
  - 0.8807652815000699
  - 0.8794048037964876
  - 0.8739827023383114
  - 0.8782769384613707
  - 0.8816716238212575
  - 0.8818167459112659
  - 0.876751481873447
  - 0.8794341482861209
  - 0.8803599224646358
  - 0.8821396961356959
  - 0.8728594280581017
  - 0.8838327419154156
  TT_recall_macro:
  - 0.5474027618962007
  - 0.5358811061189428
  - 0.5361761854061746
  - 0.537989048060369
  - 0.5343020674120812
  - 0.5289337265511912
  - 0.5267965972373924
  - 0.5311601020213378
  - 0.5472508488809301
  - 0.5469909596395307
  - 0.5470518398759967
  - 0.5424216532802172
  - 0.5479092014385217
  - 0.5389634619290086
  - 0.5385739766033638
  - 0.5521550424107619
  TT_recall_micro:
  - 0.8835287846481876
  - 0.8806380186977202
  - 0.88307774315237
  - 0.8846543979133459
  - 0.8914160092044707
  - 0.8799720578566732
  - 0.894456771860618
  - 0.8723757364534064
  - 0.8887656147271532
  - 0.8795816896778436
  - 0.8803418803418803
  - 0.887664924072691
  - 0.8858892176199868
  - 0.87060322156476
  - 0.8805678829717292
  - 0.8873330014106713
  TT_recall_weighted:
  - 0.8835287846481876
  - 0.8806380186977202
  - 0.88307774315237
  - 0.8846543979133459
  - 0.8914160092044707
  - 0.8799720578566732
  - 0.894456771860618
  - 0.8723757364534064
  - 0.8887656147271532
  - 0.8795816896778436
  - 0.8803418803418803
  - 0.887664924072691
  - 0.8858892176199868
  - 0.87060322156476
  - 0.8805678829717292
  - 0.8873330014106713
  TT_roc_auc:
  - 0.596044646629514
  - 0.5787818764284205
  - 0.5787968748950326
  - 0.5911519334336228
  - 0.5766243849304669
  - 0.5740210476015174
  - 0.5732775203273789
  - 0.573303580534342
  - 0.5998630867826581
  - 0.5921709843519741
  - 0.5977839550065799
  - 0.5899910194806055
  - 0.5989704609450126
  - 0.5801253674057032
  - 0.5869437744740352
  - 0.6045406866035835
  fit_time:
  - 9051.32454609871
  - 7636.117128610611
  - 7442.9352951049805
  - 9173.293615579605
  - 7850.867165327072
  - 8359.913255214691
  - 5467.24539732933
  - 10791.111951589584
  - 8038.214360237122
  - 8042.007449150085
  - 7440.964638471603
  - 7528.418995380402
  - 7432.880261659622
  - 8973.754846334457
  - 8481.62532877922
  - 7565.42171049118
  score_time:
  - 88.59056949615479
  - 128.84313416481018
  - 139.29660320281982
  - 91.84161448478699
  - 131.1490340232849
  - 97.6072735786438
  - 124.52114582061768
  - 96.21923017501831
  - 107.07838416099548
  - 102.38866853713989
  - 152.45798015594482
  - 138.15006923675537
  - 133.1361768245697
  - 89.25005173683167
  - 105.37899374961853
  - 137.2612771987915
start: 2023-08-07 15:38:15.019280
wrapper: null
