active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
directory: runs
end: 2023-08-12 05:56:31.347767
estimator:
  call: y_reconstruction.estimators.bxt_gmosa_nrlmf
  final_params:
    memory: /tmp
    steps:
    - - symmetryenforcer
      - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
        params:
          ndim: 2
          samplers:
            call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
            params:
              sampling_strategy: auto
          samplers__sampling_strategy: auto
    - - regressorassampler
      - call: y_reconstruction.estimators.RegressorAsSampler
        params:
          estimator:
            call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
            params:
              cv:
                call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                params: {}
              diagonal: false
              error_score: .nan
              estimator:
                call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
                params:
                  alpha_cols: same
                  alpha_rows: 0.1
                  keep_positives: true
                  lambda_cols: same
                  lambda_rows: 0.625
                  learning_rate: 1.0
                  max_iter: 100
                  n_components_cols: same
                  n_components_rows: 10
                  n_neighbors: 5
                  positive_importance: 5
                  random_state: null
                  resample_X: false
                  tol: 1.0e-05
                  verbose: false
              estimator__alpha_cols: same
              estimator__alpha_rows: 0.1
              estimator__keep_positives: true
              estimator__lambda_cols: same
              estimator__lambda_rows: 0.625
              estimator__learning_rate: 1.0
              estimator__max_iter: 100
              estimator__n_components_cols: same
              estimator__n_components_rows: 10
              estimator__n_neighbors: 5
              estimator__positive_importance: 5
              estimator__random_state: null
              estimator__resample_X: false
              estimator__tol: 1.0e-05
              estimator__verbose: false
              n_iter: 100
              n_jobs: 3
              pairwise: true
              param_distributions:
                alpha_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                alpha_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                learning_rate:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                n_components_rows:
                - 50
                - 100
                n_neighbors:
                - 3
                - 5
                - 10
              pre_dispatch: 2*n_jobs
              random_state: 0
              refit: true
              return_train_score: false
              scoring: null
              train_test_combinations: null
              verbose: 1
          estimator__cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          estimator__diagonal: false
          estimator__error_score: .nan
          estimator__estimator:
            call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
            params:
              alpha_cols: same
              alpha_rows: 0.1
              keep_positives: true
              lambda_cols: same
              lambda_rows: 0.625
              learning_rate: 1.0
              max_iter: 100
              n_components_cols: same
              n_components_rows: 10
              n_neighbors: 5
              positive_importance: 5
              random_state: null
              resample_X: false
              tol: 1.0e-05
              verbose: false
          estimator__estimator__alpha_cols: same
          estimator__estimator__alpha_rows: 0.1
          estimator__estimator__keep_positives: true
          estimator__estimator__lambda_cols: same
          estimator__estimator__lambda_rows: 0.625
          estimator__estimator__learning_rate: 1.0
          estimator__estimator__max_iter: 100
          estimator__estimator__n_components_cols: same
          estimator__estimator__n_components_rows: 10
          estimator__estimator__n_neighbors: 5
          estimator__estimator__positive_importance: 5
          estimator__estimator__random_state: null
          estimator__estimator__resample_X: false
          estimator__estimator__tol: 1.0e-05
          estimator__estimator__verbose: false
          estimator__n_iter: 100
          estimator__n_jobs: 3
          estimator__pairwise: true
          estimator__param_distributions:
            alpha_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            alpha_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            learning_rate:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            n_components_rows:
            - 50
            - 100
            n_neighbors:
            - 3
            - 5
            - 10
          estimator__pre_dispatch: 2*n_jobs
          estimator__random_state: 0
          estimator__refit: true
          estimator__return_train_score: false
          estimator__scoring: null
          estimator__train_test_combinations: null
          estimator__verbose: 1
    - - regressortobinaryclassifier
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error
          estimator__max_col_features: null
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: null
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: bxt_gmosa_nrlmf
  params:
    regressortobinaryclassifier__estimator__min_cols_leaf: 1
    regressortobinaryclassifier__estimator__min_rows_leaf: 1
    regressortobinaryclassifier__estimator__min_samples_leaf: 1
hash: 5491df4b1d631fcd9a90689be0b00a2c06a0656a147f0bb1e7ff77f24d67d2ee
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/5491df4_20230812T045900654027_bxt_gmosa_nrlmf_kiba.yml
results:
  LL_average_precision:
  - 0.9951375333905621
  - 0.9946939958330598
  - 0.990061738952867
  - 0.9903277363567926
  - 0.9903627540214951
  - 0.9941739965820118
  - 0.9906126969256183
  - 0.9895732653398904
  - 0.9901001707143662
  - 0.9938480138787332
  - 0.9895347866865549
  - 0.988892833613226
  - 0.9944049412007228
  - 0.9938569277601559
  - 0.9944550939243126
  - 0.9936786390221524
  LL_balanced_accuracy:
  - 0.9674857756114561
  - 0.9690232031062902
  - 0.961369292577956
  - 0.9600232510190576
  - 0.9604466917631027
  - 0.9691322824779227
  - 0.9622719666250052
  - 0.9604295480990033
  - 0.9601141616534077
  - 0.9676194436498569
  - 0.9607726910071028
  - 0.9593566058228664
  - 0.9668677634992711
  - 0.968266996634791
  - 0.9682353078336923
  - 0.9665993541109805
  LL_f1_macro:
  - 0.9249386596296681
  - 0.9263946792966133
  - 0.9138398543220672
  - 0.9087241962363448
  - 0.9111747222973381
  - 0.9275140008981182
  - 0.916453079236562
  - 0.9105901351572996
  - 0.9097076561643138
  - 0.9238403527409995
  - 0.9127804507720927
  - 0.9075040143504001
  - 0.925183904567322
  - 0.9266737069064181
  - 0.9294432928390224
  - 0.9242172040032559
  LL_f1_micro:
  - 0.9480555463200009
  - 0.9501388297169049
  - 0.9386174323113311
  - 0.9358959291307349
  - 0.9371058727045029
  - 0.9506383228782559
  - 0.9403913675828939
  - 0.936990406793107
  - 0.9364741607651472
  - 0.9483538762138418
  - 0.9379600111651413
  - 0.9351870895708766
  - 0.9474459507354244
  - 0.9495830396993188
  - 0.9499977977448908
  - 0.9469843786704252
  LL_f1_weighted:
  - 0.9502113188809099
  - 0.9522168497615769
  - 0.9414433906723807
  - 0.939080682443675
  - 0.9401084027004368
  - 0.9526475252133099
  - 0.9430403734730137
  - 0.9400345605328798
  - 0.9395782711214127
  - 0.9505650953090214
  - 0.9408460548078788
  - 0.938444829328117
  - 0.9495802010313316
  - 0.9516325829926647
  - 0.951889134804015
  - 0.9491740109164936
  LL_matthews_corrcoef:
  - 0.8600555378704902
  - 0.8625956752833351
  - 0.8409374763063262
  - 0.8322604966478823
  - 0.8363423580837794
  - 0.8645016114952442
  - 0.8453432111149837
  - 0.8353352280513711
  - 0.8338212576925542
  - 0.8580202479033998
  - 0.8390253203127493
  - 0.8300629191967271
  - 0.860465220599405
  - 0.8629903287639281
  - 0.8678834545073524
  - 0.8587643259089
  LL_precision_macro:
  - 0.895571141846081
  - 0.8966068704541742
  - 0.8831940326506255
  - 0.8764252854318686
  - 0.8797771557695377
  - 0.898268816809172
  - 0.8864635951188227
  - 0.8788771518382199
  - 0.8777637963161158
  - 0.8935886091829519
  - 0.8819472713255156
  - 0.874983423059274
  - 0.8964722206946392
  - 0.8976109318467074
  - 0.9021598104660363
  - 0.8951335128071989
  LL_precision_micro:
  - 0.9480555463200009
  - 0.9501388297169049
  - 0.9386174323113311
  - 0.9358959291307349
  - 0.9371058727045029
  - 0.9506383228782559
  - 0.9403913675828939
  - 0.936990406793107
  - 0.9364741607651472
  - 0.9483538762138418
  - 0.9379600111651413
  - 0.9351870895708766
  - 0.9474459507354244
  - 0.9495830396993188
  - 0.9499977977448908
  - 0.9469843786704252
  LL_precision_weighted:
  - 0.9588511975761238
  - 0.9604074362885413
  - 0.9528873788867224
  - 0.9516877739438361
  - 0.9521203994521601
  - 0.9606047294767732
  - 0.9538117341163548
  - 0.9521389587218783
  - 0.9518777964600585
  - 0.9592135615773509
  - 0.952462452707856
  - 0.9512464700630454
  - 0.9582559469331027
  - 0.9597959025944736
  - 0.9596936606249115
  - 0.9580191587775253
  LL_recall_macro:
  - 0.9674857756114561
  - 0.9690232031062902
  - 0.961369292577956
  - 0.9600232510190576
  - 0.9604466917631027
  - 0.9691322824779227
  - 0.9622719666250052
  - 0.9604295480990033
  - 0.9601141616534077
  - 0.9676194436498569
  - 0.9607726910071028
  - 0.9593566058228664
  - 0.9668677634992711
  - 0.968266996634791
  - 0.9682353078336923
  - 0.9665993541109805
  LL_recall_micro:
  - 0.9480555463200009
  - 0.9501388297169049
  - 0.9386174323113311
  - 0.9358959291307349
  - 0.9371058727045029
  - 0.9506383228782559
  - 0.9403913675828939
  - 0.936990406793107
  - 0.9364741607651472
  - 0.9483538762138418
  - 0.9379600111651413
  - 0.9351870895708766
  - 0.9474459507354244
  - 0.9495830396993188
  - 0.9499977977448908
  - 0.9469843786704252
  LL_recall_weighted:
  - 0.9480555463200009
  - 0.9501388297169049
  - 0.9386174323113311
  - 0.9358959291307349
  - 0.9371058727045029
  - 0.9506383228782559
  - 0.9403913675828939
  - 0.936990406793107
  - 0.9364741607651472
  - 0.9483538762138418
  - 0.9379600111651413
  - 0.9351870895708766
  - 0.9474459507354244
  - 0.9495830396993188
  - 0.9499977977448908
  - 0.9469843786704252
  LL_roc_auc:
  - 0.9989292744816165
  - 0.9988822203556426
  - 0.9977626092475715
  - 0.9978997456605487
  - 0.997838130967635
  - 0.9987673947507498
  - 0.9978417121394019
  - 0.9976938239778183
  - 0.997778283735518
  - 0.9986335681212628
  - 0.9975790464715022
  - 0.9975586266526046
  - 0.9987482715691719
  - 0.9986447601406098
  - 0.9987282157418407
  - 0.9986058067298226
  LT_average_precision:
  - 0.45914489775297473
  - 0.41119681008316256
  - 0.41776535178872687
  - 0.39215965930459684
  - 0.46891283699104613
  - 0.4116570912021902
  - 0.43010975067157764
  - 0.39957119132828023
  - 0.4633306607272992
  - 0.4109341486364282
  - 0.42273531114012586
  - 0.3927619077903318
  - 0.4574584778743316
  - 0.41459702569090245
  - 0.4320355036679251
  - 0.39660497663258437
  LT_balanced_accuracy:
  - 0.7339047746041241
  - 0.7058453508586523
  - 0.7195939073465474
  - 0.6945824065393953
  - 0.7363326016946055
  - 0.7062074082225076
  - 0.7202055095603739
  - 0.7012931468468643
  - 0.7306705535848714
  - 0.7092053316518003
  - 0.7176133566275636
  - 0.6940382999679624
  - 0.731302549541164
  - 0.7054204446376551
  - 0.719382759496247
  - 0.6970086344509592
  LT_f1_macro:
  - 0.6715823664333104
  - 0.6594845111089658
  - 0.6434908205903772
  - 0.6512180915161239
  - 0.6715461267442353
  - 0.6567266276417645
  - 0.6445508717163251
  - 0.6540178781058696
  - 0.6664186219371764
  - 0.6605285555913608
  - 0.6416309949977215
  - 0.6511025365836118
  - 0.6684126530579171
  - 0.6586677068335073
  - 0.6441837320520746
  - 0.6514937570889313
  LT_f1_micro:
  - 0.7412486113228919
  - 0.7266238875774401
  - 0.7182453923817756
  - 0.731566756436258
  - 0.7386346308841788
  - 0.7206392481519656
  - 0.717037381831078
  - 0.7296272899557802
  - 0.7361731326377241
  - 0.7270117808735357
  - 0.7168046458534206
  - 0.7315335084394499
  - 0.734641675374434
  - 0.7222332978911926
  - 0.7145910863016126
  - 0.7265306574517101
  LT_f1_weighted:
  - 0.7640313696310722
  - 0.7469051203782674
  - 0.7478537608257042
  - 0.7521066121056678
  - 0.7618953203422189
  - 0.7419680784362682
  - 0.7463116354067615
  - 0.7509257663219318
  - 0.7600127771308087
  - 0.7477770706413674
  - 0.7466751032095992
  - 0.7519591842319373
  - 0.7578546581591339
  - 0.7426180747375797
  - 0.7437318738346671
  - 0.7476276773675274
  LT_matthews_corrcoef:
  - 0.3894422021707637
  - 0.35329840905176474
  - 0.3514289852706471
  - 0.33249611715989813
  - 0.3925322241003218
  - 0.3521433814256523
  - 0.35365451369502077
  - 0.3421908595268362
  - 0.3820108420876624
  - 0.35757586726430085
  - 0.3479367232901042
  - 0.33188073792679623
  - 0.38543977817993574
  - 0.3530975938255055
  - 0.35333944992003496
  - 0.33608188144740836
  LT_precision_macro:
  - 0.6621014674543328
  - 0.6515941036776415
  - 0.6406030945720343
  - 0.6420396503113784
  - 0.6629922679439008
  - 0.6503400898042485
  - 0.6419940801056236
  - 0.6454279320706281
  - 0.6581609368909235
  - 0.6527930715726534
  - 0.6390768991503629
  - 0.6419111899880343
  - 0.6605730491277602
  - 0.6517350317604502
  - 0.6422727646835994
  - 0.6433325896502096
  LT_precision_micro:
  - 0.7412486113228919
  - 0.7266238875774401
  - 0.7182453923817756
  - 0.731566756436258
  - 0.7386346308841789
  - 0.7206392481519656
  - 0.717037381831078
  - 0.7296272899557802
  - 0.7361731326377241
  - 0.7270117808735357
  - 0.7168046458534206
  - 0.7315335084394499
  - 0.734641675374434
  - 0.7222332978911926
  - 0.7145910863016126
  - 0.7265306574517101
  LT_precision_weighted:
  - 0.8181708020993557
  - 0.791572961320548
  - 0.8200861492972902
  - 0.7930584952400265
  - 0.8189258125000696
  - 0.7910603548488461
  - 0.8187139347267246
  - 0.7956662199793042
  - 0.8171831917469181
  - 0.794432716989243
  - 0.8193035278940479
  - 0.7925480035109189
  - 0.8145817983919744
  - 0.7887948692455545
  - 0.8167276589656938
  - 0.7916116802059852
  LT_recall_macro:
  - 0.7339047746041241
  - 0.7058453508586523
  - 0.7195939073465474
  - 0.6945824065393953
  - 0.7363326016946055
  - 0.7062074082225076
  - 0.7202055095603739
  - 0.7012931468468643
  - 0.7306705535848714
  - 0.7092053316518003
  - 0.7176133566275636
  - 0.6940382999679624
  - 0.731302549541164
  - 0.7054204446376551
  - 0.719382759496247
  - 0.6970086344509592
  LT_recall_micro:
  - 0.7412486113228919
  - 0.7266238875774401
  - 0.7182453923817756
  - 0.731566756436258
  - 0.7386346308841789
  - 0.7206392481519656
  - 0.717037381831078
  - 0.7296272899557802
  - 0.7361731326377241
  - 0.7270117808735357
  - 0.7168046458534206
  - 0.7315335084394499
  - 0.734641675374434
  - 0.7222332978911926
  - 0.7145910863016126
  - 0.7265306574517101
  LT_recall_weighted:
  - 0.7412486113228919
  - 0.7266238875774401
  - 0.7182453923817756
  - 0.731566756436258
  - 0.7386346308841789
  - 0.7206392481519656
  - 0.717037381831078
  - 0.7296272899557802
  - 0.7361731326377241
  - 0.7270117808735357
  - 0.7168046458534206
  - 0.7315335084394499
  - 0.734641675374434
  - 0.7222332978911926
  - 0.7145910863016125
  - 0.7265306574517101
  LT_roc_auc:
  - 0.8100747000863584
  - 0.7662500841323943
  - 0.7773943627390617
  - 0.763096411240263
  - 0.8131434994998256
  - 0.7661512066515516
  - 0.7799859831073592
  - 0.7620235078368762
  - 0.8115528070150393
  - 0.7681786641333319
  - 0.7763842189729416
  - 0.7612421501594719
  - 0.8064369108332948
  - 0.7660934237615289
  - 0.7810105375550412
  - 0.7615685383470492
  TL_average_precision:
  - 0.7130017759726548
  - 0.7071532941121017
  - 0.7174964602779652
  - 0.6960835897886317
  - 0.6754541359984463
  - 0.6664715234642239
  - 0.668602458246222
  - 0.657190122589472
  - 0.703829584269394
  - 0.6911365946596197
  - 0.7018728482850973
  - 0.690689229900237
  - 0.6833319511729026
  - 0.6711106418305802
  - 0.6684250015975093
  - 0.6651401618276417
  TL_balanced_accuracy:
  - 0.8218016056912826
  - 0.8171946478912666
  - 0.814836925825826
  - 0.809124422238314
  - 0.8195985753877861
  - 0.8179054484983248
  - 0.811900769864096
  - 0.8125029759618709
  - 0.8305156724219096
  - 0.8305528218423581
  - 0.8285371319377504
  - 0.8246288384000233
  - 0.8200753890537527
  - 0.8210809188636763
  - 0.8175614236406552
  - 0.8150397749548794
  TL_f1_macro:
  - 0.7343268201904144
  - 0.7225449772523014
  - 0.7205771521080988
  - 0.7132198549382436
  - 0.7230652400923896
  - 0.7209076160343861
  - 0.7176673347136812
  - 0.7135332198846562
  - 0.7416153199165039
  - 0.7384341540839247
  - 0.738846157734339
  - 0.7324262946166425
  - 0.7233354730162502
  - 0.720402976177521
  - 0.7217296865745395
  - 0.7187417585777733
  TL_f1_micro:
  - 0.7813995215311005
  - 0.7714169309372797
  - 0.7634447674418605
  - 0.759612843551797
  - 0.77128743576112
  - 0.7730686222692037
  - 0.7636539816772375
  - 0.7624867864693445
  - 0.7867269183058658
  - 0.7863482205778719
  - 0.7810958421423537
  - 0.7773630197322058
  - 0.7770342998546335
  - 0.7767640439521645
  - 0.7723511760293015
  - 0.7743700631040114
  TL_f1_weighted:
  - 0.8008491368225832
  - 0.7931134369927308
  - 0.7849261776727873
  - 0.7823362251403502
  - 0.7931356383321259
  - 0.795395249450786
  - 0.7856561054672878
  - 0.7857391438114721
  - 0.8055459379594673
  - 0.8059963284748339
  - 0.8001456752074
  - 0.7975089008766606
  - 0.7991065167498926
  - 0.7997629935684386
  - 0.7943708234300602
  - 0.7969735466359565
  TL_matthews_corrcoef:
  - 0.5338947036232352
  - 0.5189560302923137
  - 0.519349572984261
  - 0.5057267586144858
  - 0.522067124833118
  - 0.516211111653131
  - 0.5120606392224236
  - 0.507477446681059
  - 0.5492128177279856
  - 0.5447894216591589
  - 0.5470936656249747
  - 0.5364194023069982
  - 0.5192112145927817
  - 0.5161176264115063
  - 0.5175230635129823
  - 0.5097223706398266
  TL_precision_macro:
  - 0.7214435458957871
  - 0.7122634817194942
  - 0.7141775287725867
  - 0.7068419186413725
  - 0.7132003267699283
  - 0.7095543761933711
  - 0.710167883166117
  - 0.706024725122417
  - 0.7281546264859651
  - 0.7244690517974641
  - 0.7277607687764224
  - 0.7215959744901214
  - 0.710559991941179
  - 0.707406753751805
  - 0.7108490683450679
  - 0.7061778510093656
  TL_precision_micro:
  - 0.7813995215311005
  - 0.7714169309372798
  - 0.7634447674418605
  - 0.759612843551797
  - 0.77128743576112
  - 0.7730686222692037
  - 0.7636539816772375
  - 0.7624867864693446
  - 0.7867269183058657
  - 0.7863482205778718
  - 0.7810958421423537
  - 0.7773630197322058
  - 0.7770342998546335
  - 0.7767640439521645
  - 0.7723511760293015
  - 0.7743700631040114
  TL_precision_weighted:
  - 0.8658303963765246
  - 0.8658715420738421
  - 0.8624178914449941
  - 0.8609355112457664
  - 0.8675260993037426
  - 0.8681306907858019
  - 0.8617845763090652
  - 0.8646513199993713
  - 0.8705736282077754
  - 0.8723745678252262
  - 0.8686847002874222
  - 0.8679994068220341
  - 0.8698191632887232
  - 0.8723901558954915
  - 0.867048204497142
  - 0.8677169153612649
  TL_recall_macro:
  - 0.8218016056912826
  - 0.8171946478912666
  - 0.814836925825826
  - 0.809124422238314
  - 0.8195985753877861
  - 0.8179054484983248
  - 0.811900769864096
  - 0.8125029759618709
  - 0.8305156724219096
  - 0.8305528218423581
  - 0.8285371319377504
  - 0.8246288384000233
  - 0.8200753890537527
  - 0.8210809188636763
  - 0.8175614236406552
  - 0.8150397749548794
  TL_recall_micro:
  - 0.7813995215311005
  - 0.7714169309372798
  - 0.7634447674418605
  - 0.759612843551797
  - 0.77128743576112
  - 0.7730686222692037
  - 0.7636539816772375
  - 0.7624867864693446
  - 0.7867269183058657
  - 0.7863482205778718
  - 0.7810958421423537
  - 0.7773630197322058
  - 0.7770342998546335
  - 0.7767640439521645
  - 0.7723511760293015
  - 0.7743700631040114
  TL_recall_weighted:
  - 0.7813995215311005
  - 0.7714169309372798
  - 0.7634447674418605
  - 0.759612843551797
  - 0.7712874357611198
  - 0.7730686222692037
  - 0.7636539816772375
  - 0.7624867864693446
  - 0.7867269183058657
  - 0.7863482205778718
  - 0.7810958421423537
  - 0.7773630197322058
  - 0.7770342998546335
  - 0.7767640439521645
  - 0.7723511760293015
  - 0.7743700631040114
  TL_roc_auc:
  - 0.9044746637379256
  - 0.9046631119454352
  - 0.903561738854593
  - 0.8990961767853148
  - 0.9023031074766208
  - 0.9024474604437037
  - 0.8985312514619088
  - 0.8981920136823394
  - 0.9114969171476157
  - 0.9092090884526103
  - 0.9100276498208033
  - 0.9070838347725011
  - 0.9003475054521051
  - 0.8990488697621009
  - 0.8955529403413858
  - 0.8954205203100115
  TT_average_precision:
  - 0.35822096650950885
  - 0.3313162806718062
  - 0.32902505489906164
  - 0.30221325893263595
  - 0.33287728754549856
  - 0.3140654442444489
  - 0.31739288380829633
  - 0.2917988768500942
  - 0.3497862015677347
  - 0.31966031540993534
  - 0.3272570655842683
  - 0.29323574958366705
  - 0.3357633775135735
  - 0.3087874563401575
  - 0.31524278933475214
  - 0.28861857355034537
  TT_balanced_accuracy:
  - 0.6532891609311802
  - 0.6191743633918243
  - 0.6436394918407088
  - 0.6042141437295352
  - 0.6412224999436438
  - 0.6154064322547136
  - 0.6496230357219961
  - 0.6013351944858794
  - 0.6528223835000776
  - 0.614950129931634
  - 0.6516674702967616
  - 0.5973905111634853
  - 0.6464901823678368
  - 0.6193659499607596
  - 0.6563770427942031
  - 0.6076045846152196
  TT_f1_macro:
  - 0.5874501736308824
  - 0.5774568098189168
  - 0.5704743873646938
  - 0.5650868073336823
  - 0.5709727487321122
  - 0.5691969647518895
  - 0.5671034718734463
  - 0.5607991100585854
  - 0.5888454140884751
  - 0.5777884514422946
  - 0.5790825911631815
  - 0.5626617514353297
  - 0.5751449110662614
  - 0.5759596991024403
  - 0.5732157092383549
  - 0.5688415581948797
  TT_f1_micro:
  - 0.6495559038662487
  - 0.643640350877193
  - 0.6353003721424774
  - 0.6421783625730995
  - 0.6316940961337513
  - 0.6339712918660287
  - 0.6328748006379585
  - 0.6410154173312068
  - 0.6492293625914316
  - 0.6451023391812866
  - 0.6443048910154173
  - 0.6452684742158427
  - 0.6427730157691552
  - 0.6517194314058391
  - 0.6470588235294118
  - 0.6589433736143014
  TT_f1_weighted:
  - 0.6840323721908133
  - 0.6727508849720891
  - 0.6746550454193084
  - 0.6731889897576395
  - 0.6695942097666986
  - 0.6657312489994567
  - 0.6751431535111712
  - 0.6735834127112121
  - 0.6827965814081739
  - 0.6725443576578881
  - 0.6821764366120687
  - 0.6752165689731204
  - 0.681309112495716
  - 0.6825316908068592
  - 0.6895621991181496
  - 0.6900512025469752
  TT_matthews_corrcoef:
  - 0.24820687320751716
  - 0.20086192813534562
  - 0.2270708195106585
  - 0.1738225756125467
  - 0.22585589512168877
  - 0.1921609419506376
  - 0.23212501557309012
  - 0.16748936235156156
  - 0.24900074309854836
  - 0.19570063815376604
  - 0.24076910799913787
  - 0.1633509869930213
  - 0.23183838148326508
  - 0.19828272638047242
  - 0.23999190263470777
  - 0.1778575319907292
  TT_precision_macro:
  - 0.600474572913722
  - 0.584635472399378
  - 0.5897405657951325
  - 0.572481255209931
  - 0.5903023338731004
  - 0.5799908351942145
  - 0.5900296244405201
  - 0.5692076594002138
  - 0.6014271742195373
  - 0.5832942507254433
  - 0.5955540486916433
  - 0.568496264761363
  - 0.5917280500645021
  - 0.5823434982794468
  - 0.5920789143679249
  - 0.5734943167127821
  TT_precision_micro:
  - 0.6495559038662487
  - 0.643640350877193
  - 0.6353003721424774
  - 0.6421783625730995
  - 0.6316940961337513
  - 0.6339712918660287
  - 0.6328748006379585
  - 0.6410154173312068
  - 0.6492293625914316
  - 0.6451023391812866
  - 0.6443048910154173
  - 0.6452684742158427
  - 0.6427730157691552
  - 0.6517194314058391
  - 0.6470588235294118
  - 0.6589433736143014
  TT_precision_weighted:
  - 0.7720456726755058
  - 0.7363041873116273
  - 0.7760855290660538
  - 0.7359851109834689
  - 0.7691759263491513
  - 0.7378301261216174
  - 0.786982521703077
  - 0.7391777502934176
  - 0.7688999216621292
  - 0.7301818068253371
  - 0.7793117526680909
  - 0.7325924889035718
  - 0.7780042268563204
  - 0.74683620258988
  - 0.7961878096464825
  - 0.7490588176739394
  TT_recall_macro:
  - 0.6532891609311802
  - 0.6191743633918243
  - 0.6436394918407088
  - 0.6042141437295352
  - 0.6412224999436438
  - 0.6154064322547136
  - 0.6496230357219961
  - 0.6013351944858794
  - 0.6528223835000776
  - 0.614950129931634
  - 0.6516674702967616
  - 0.5973905111634853
  - 0.6464901823678368
  - 0.6193659499607596
  - 0.6563770427942031
  - 0.6076045846152196
  TT_recall_micro:
  - 0.6495559038662487
  - 0.643640350877193
  - 0.6353003721424774
  - 0.6421783625730995
  - 0.6316940961337513
  - 0.6339712918660287
  - 0.6328748006379585
  - 0.6410154173312068
  - 0.6492293625914316
  - 0.6451023391812866
  - 0.6443048910154173
  - 0.6452684742158427
  - 0.6427730157691552
  - 0.6517194314058391
  - 0.6470588235294118
  - 0.6589433736143014
  TT_recall_weighted:
  - 0.6495559038662487
  - 0.643640350877193
  - 0.6353003721424774
  - 0.6421783625730995
  - 0.6316940961337513
  - 0.6339712918660287
  - 0.6328748006379585
  - 0.6410154173312068
  - 0.6492293625914316
  - 0.6451023391812866
  - 0.6443048910154173
  - 0.6452684742158427
  - 0.6427730157691552
  - 0.6517194314058391
  - 0.6470588235294118
  - 0.6589433736143014
  TT_roc_auc:
  - 0.7172951048517862
  - 0.6773603211825304
  - 0.6958755525613771
  - 0.6620252352463496
  - 0.7066434391091124
  - 0.6726101220798932
  - 0.7056163713245864
  - 0.6630030202259343
  - 0.7175176301930655
  - 0.6760326069203653
  - 0.7085045717563132
  - 0.6638380175605925
  - 0.71161562487044
  - 0.6769394002875235
  - 0.7099874895571471
  - 0.6690482367570857
  fit_time:
  - 2812.0742921829224
  - 2412.888329744339
  - 2318.3370082378387
  - 2548.4535274505615
  - 3027.431567430496
  - 3305.009868621826
  - 2468.8452730178833
  - 3198.670820713043
  - 2848.005439758301
  - 2805.171977996826
  - 2734.5041959285736
  - 2635.9991550445557
  - 3401.0838465690613
  - 3268.8520855903625
  - 2552.8732974529266
  - 3305.8200299739838
  score_time:
  - 44.66205668449402
  - 59.240347146987915
  - 53.625877380371094
  - 45.71173405647278
  - 41.875343799591064
  - 48.905704975128174
  - 45.753373861312866
  - 46.95799994468689
  - 45.459712505340576
  - 50.60833716392517
  - 42.7940092086792
  - 50.59814143180847
  - 47.99712610244751
  - 44.402100801467896
  - 49.87839341163635
  - 49.561830282211304
start: 2023-08-12 04:59:00.654027
wrapper: null
