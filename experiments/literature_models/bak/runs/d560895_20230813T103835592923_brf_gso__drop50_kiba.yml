active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
directory: runs
end: 2023-08-13 11:06:50.851331
estimator:
  call: y_reconstruction.estimators.brf_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.PositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteRandomForestRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: 0.5
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: 0.5
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error_gso
          estimator__max_col_features: 0.5
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: 0.5
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: brf_gso__drop50
  params:
    estimator__min_cols_leaf: 1
    estimator__min_rows_leaf: 1
    estimator__min_samples_leaf: 1
hash: d560895076830e3132cdba9e7b2a2ed6fadda17e1696dc9e533fd8394b785573
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/d560895_20230813T103835592923_brf_gso__drop50_kiba.yml
results:
  LL_average_precision:
  - 0.5999946014448863
  - 0.5971511078099939
  - 0.6020808382461941
  - 0.5989825960581651
  - 0.6011556474331137
  - 0.5987435033299185
  - 0.6029822584525454
  - 0.6002500822269328
  - 0.6004644525152393
  - 0.5973462632771224
  - 0.6021924833494905
  - 0.598817977000407
  - 0.6025207826106754
  - 0.599453019355956
  - 0.604388682795616
  - 0.6014921155049622
  LL_balanced_accuracy:
  - 0.750773907041216
  - 0.7507258252307374
  - 0.7506525029210455
  - 0.750605280880403
  - 0.7508242419694638
  - 0.7510592151607983
  - 0.750647909831794
  - 0.7507619907868673
  - 0.7509073472779575
  - 0.7507015228734923
  - 0.7506020353011249
  - 0.7504970746905553
  - 0.7507513797741983
  - 0.7505779462011755
  - 0.7506296972129751
  - 0.7505943872872567
  LL_f1_macro:
  - 0.8048984041981286
  - 0.8058008568599113
  - 0.804022532102808
  - 0.8050004545168863
  - 0.8045173969758388
  - 0.8057065818966254
  - 0.803614991209506
  - 0.8047341194040223
  - 0.8046456216399462
  - 0.8054088592424036
  - 0.8035928549430245
  - 0.8045964235778142
  - 0.803823323486457
  - 0.8045837599902198
  - 0.8030222700137755
  - 0.80394032341345
  LL_f1_micro:
  - 0.9016376485538968
  - 0.9043764415519546
  - 0.8993080550617756
  - 0.9023086867737149
  - 0.9006032664309753
  - 0.9034656010812557
  - 0.8984339420294113
  - 0.9013794825838487
  - 0.9014898796791938
  - 0.9041854588726146
  - 0.8991758362837708
  - 0.9023233777490488
  - 0.8991264989072006
  - 0.9018381489311722
  - 0.8970188806671365
  - 0.8998377672069533
  LL_f1_weighted:
  - 0.888249222565338
  - 0.891261893647816
  - 0.885661709084054
  - 0.8889670587479643
  - 0.8871417971739203
  - 0.8903122160090685
  - 0.8847417471353364
  - 0.8879890301803626
  - 0.8882196589292475
  - 0.8911593800855758
  - 0.8856492305913002
  - 0.889092506413417
  - 0.8855607980364937
  - 0.8885343727267855
  - 0.8832229221321465
  - 0.8863250668274495
  LL_matthews_corrcoef:
  - 0.6668863913671512
  - 0.6681622029274175
  - 0.6658154966995274
  - 0.6670862890927645
  - 0.6660449819684983
  - 0.6677521504680565
  - 0.6647650260377302
  - 0.6663553463600368
  - 0.6651009571868621
  - 0.6662697389946731
  - 0.6635943087282264
  - 0.665083078046276
  - 0.6644925377340098
  - 0.6654457591614628
  - 0.6635183692542661
  - 0.6646736459403572
  LL_precision_macro:
  - 0.9433649659149009
  - 0.9451483298638761
  - 0.9421562426855952
  - 0.9439293094026275
  - 0.9421581368313519
  - 0.9440117186787274
  - 0.9407702224003234
  - 0.9426801747638094
  - 0.9407595951752168
  - 0.9426731836447959
  - 0.9392995113221614
  - 0.9414577508040121
  - 0.9402272213833889
  - 0.9417967194431995
  - 0.9391504989567618
  - 0.9407431670658504
  LL_precision_micro:
  - 0.9016376485538968
  - 0.9043764415519546
  - 0.8993080550617756
  - 0.9023086867737149
  - 0.9006032664309753
  - 0.9034656010812557
  - 0.8984339420294113
  - 0.9013794825838487
  - 0.9014898796791938
  - 0.9041854588726146
  - 0.8991758362837708
  - 0.9023233777490488
  - 0.8991264989072006
  - 0.9018381489311722
  - 0.8970188806671365
  - 0.8998377672069533
  LL_precision_weighted:
  - 0.9117833839252559
  - 0.9139512333438513
  - 0.910043594597461
  - 0.9123455158107691
  - 0.9108160131202443
  - 0.91308253620254
  - 0.9091181274762533
  - 0.9114313906818639
  - 0.9109548982516823
  - 0.9131538331962649
  - 0.9091243136987189
  - 0.9116563265938114
  - 0.9093692813382286
  - 0.9114548041793915
  - 0.9078034099405795
  - 0.909941810417481
  LL_recall_macro:
  - 0.750773907041216
  - 0.7507258252307374
  - 0.7506525029210455
  - 0.750605280880403
  - 0.7508242419694638
  - 0.7510592151607983
  - 0.750647909831794
  - 0.7507619907868673
  - 0.7509073472779575
  - 0.7507015228734923
  - 0.7506020353011249
  - 0.7504970746905553
  - 0.7507513797741983
  - 0.7505779462011755
  - 0.7506296972129751
  - 0.7505943872872567
  LL_recall_micro:
  - 0.9016376485538968
  - 0.9043764415519546
  - 0.8993080550617756
  - 0.9023086867737149
  - 0.9006032664309753
  - 0.9034656010812557
  - 0.8984339420294113
  - 0.9013794825838487
  - 0.9014898796791938
  - 0.9041854588726146
  - 0.8991758362837708
  - 0.9023233777490488
  - 0.8991264989072006
  - 0.9018381489311722
  - 0.8970188806671365
  - 0.8998377672069533
  LL_recall_weighted:
  - 0.9016376485538968
  - 0.9043764415519546
  - 0.8993080550617756
  - 0.9023086867737149
  - 0.9006032664309753
  - 0.9034656010812557
  - 0.8984339420294113
  - 0.9013794825838487
  - 0.9014898796791938
  - 0.9041854588726146
  - 0.8991758362837708
  - 0.9023233777490488
  - 0.8991264989072006
  - 0.9018381489311722
  - 0.8970188806671365
  - 0.8998377672069533
  LL_roc_auc:
  - 0.7509140970716395
  - 0.7508542550482614
  - 0.7507813961770246
  - 0.7507343470600543
  - 0.7510058179894858
  - 0.7512267763601174
  - 0.7508383751524647
  - 0.7509386576253914
  - 0.7512181114238413
  - 0.7509841948695705
  - 0.7509255049109415
  - 0.7507926014578317
  - 0.7510079697620748
  - 0.7508323913385673
  - 0.7508771155851641
  - 0.7508434550770903
  LT_average_precision:
  - 0.42591213331906885
  - 0.37603004663842304
  - 0.35563794250671954
  - 0.35808882199224007
  - 0.43676730862972135
  - 0.3866835817753675
  - 0.3714874224556517
  - 0.36789558214631607
  - 0.42230118456785126
  - 0.3770649798818092
  - 0.3703289396358622
  - 0.3580259358905009
  - 0.43506323767448024
  - 0.3868912120537408
  - 0.3858063986772138
  - 0.35845948067859346
  LT_balanced_accuracy:
  - 0.7134877008546465
  - 0.686600314743715
  - 0.6939591539852111
  - 0.6913681809679997
  - 0.7220117291628732
  - 0.6908579965350425
  - 0.7032303724463714
  - 0.6982166258303513
  - 0.7167608238070471
  - 0.6851776983420124
  - 0.6970642452601918
  - 0.6944325830798929
  - 0.713454423949611
  - 0.6895992148745977
  - 0.6994759268417972
  - 0.6882125431935087
  LT_f1_macro:
  - 0.6544471698917894
  - 0.6449114777549243
  - 0.640680805323917
  - 0.6443745043412883
  - 0.6610622159593778
  - 0.6474583247988801
  - 0.6475006258596945
  - 0.6517656506070124
  - 0.6578526996116464
  - 0.6439601980121895
  - 0.6431906650749436
  - 0.6471745210167824
  - 0.6619040542134977
  - 0.647155699689327
  - 0.6424896525379742
  - 0.6415968677174936
  LT_f1_micro:
  - 0.7269806347615834
  - 0.7162726779044895
  - 0.7311788631401626
  - 0.7222129866675533
  - 0.7309778465157819
  - 0.7162283472420786
  - 0.733218073611065
  - 0.7281200474338086
  - 0.7314026183370728
  - 0.7168489765158316
  - 0.733461892254325
  - 0.7244184371224967
  - 0.7358825322187391
  - 0.7143917242601453
  - 0.7250797448165869
  - 0.7161749069643807
  LT_f1_weighted:
  - 0.751209036399179
  - 0.736947137843989
  - 0.7559602582977589
  - 0.7446440554480293
  - 0.7547558674402646
  - 0.7370653948432435
  - 0.7576994159197381
  - 0.7494662436260437
  - 0.7551855268210751
  - 0.7375179959822665
  - 0.7580500361430881
  - 0.7465675843873721
  - 0.7573573783645307
  - 0.734939713907102
  - 0.7505632302901473
  - 0.7387877014604503
  LT_matthews_corrcoef:
  - 0.3548652164427488
  - 0.3212191868339941
  - 0.3203274910208884
  - 0.3239109004888535
  - 0.36928404136081366
  - 0.3281045240222324
  - 0.335874206772433
  - 0.3371593915737271
  - 0.3605285727124466
  - 0.3187046937579419
  - 0.32541851868676885
  - 0.32937158729976995
  - 0.3608483191909172
  - 0.3269672351799698
  - 0.32885768641389757
  - 0.31924422410780773
  LT_precision_macro:
  - 0.6474667174465218
  - 0.6382390031496018
  - 0.6322568429943258
  - 0.6370633703638593
  - 0.6535624983846352
  - 0.6410113548269514
  - 0.638772912504478
  - 0.6433740167482959
  - 0.6499127580565232
  - 0.6371286644298613
  - 0.6343435134116676
  - 0.6394900494581623
  - 0.6525050489157913
  - 0.6409652104202318
  - 0.6355393851600852
  - 0.6353747110805088
  LT_precision_micro:
  - 0.7269806347615833
  - 0.7162726779044896
  - 0.7311788631401624
  - 0.7222129866675533
  - 0.7309778465157819
  - 0.7162283472420786
  - 0.733218073611065
  - 0.7281200474338088
  - 0.7314026183370728
  - 0.7168489765158316
  - 0.733461892254325
  - 0.7244184371224967
  - 0.7358825322187391
  - 0.7143917242601453
  - 0.7250797448165869
  - 0.7161749069643807
  LT_precision_weighted:
  - 0.8067443280716373
  - 0.7799305133054524
  - 0.8057847719567772
  - 0.7911567173963255
  - 0.8107732144346658
  - 0.7816238315213503
  - 0.8087337943360473
  - 0.7938922550922259
  - 0.8092881847002005
  - 0.7799569154552332
  - 0.8076708617151814
  - 0.79270409853547
  - 0.8040880472485276
  - 0.779023583307336
  - 0.8049934564609618
  - 0.7864956851508599
  LT_recall_macro:
  - 0.7134877008546465
  - 0.686600314743715
  - 0.6939591539852111
  - 0.6913681809679997
  - 0.7220117291628732
  - 0.6908579965350425
  - 0.7032303724463714
  - 0.6982166258303513
  - 0.7167608238070471
  - 0.6851776983420124
  - 0.6970642452601918
  - 0.6944325830798929
  - 0.713454423949611
  - 0.6895992148745977
  - 0.6994759268417972
  - 0.6882125431935087
  LT_recall_micro:
  - 0.7269806347615833
  - 0.7162726779044896
  - 0.7311788631401624
  - 0.7222129866675533
  - 0.7309778465157819
  - 0.7162283472420786
  - 0.733218073611065
  - 0.7281200474338088
  - 0.7314026183370728
  - 0.7168489765158316
  - 0.733461892254325
  - 0.7244184371224967
  - 0.7358825322187391
  - 0.7143917242601453
  - 0.7250797448165869
  - 0.7161749069643807
  LT_recall_weighted:
  - 0.7269806347615833
  - 0.7162726779044896
  - 0.7311788631401624
  - 0.7222129866675533
  - 0.7309778465157819
  - 0.7162283472420786
  - 0.733218073611065
  - 0.7281200474338088
  - 0.7314026183370728
  - 0.7168489765158317
  - 0.733461892254325
  - 0.7244184371224968
  - 0.7358825322187391
  - 0.7143917242601452
  - 0.7250797448165869
  - 0.7161749069643807
  LT_roc_auc:
  - 0.7845276336024776
  - 0.7492777503322492
  - 0.7585239553977294
  - 0.7493977067729513
  - 0.7915203904001531
  - 0.7525715533840157
  - 0.7617113460903954
  - 0.7544476241791076
  - 0.7824834821170785
  - 0.7483342949118056
  - 0.7598922270798385
  - 0.7498988711476784
  - 0.7877254454029365
  - 0.7537499421465911
  - 0.7634043311617114
  - 0.7457659107278531
  TL_average_precision:
  - 0.6266960494603766
  - 0.6179987494775326
  - 0.6265948284845269
  - 0.6072509257477308
  - 0.5982509491286812
  - 0.5842106989331972
  - 0.5863378490756705
  - 0.5816472630979772
  - 0.6125590676342394
  - 0.6064062436435902
  - 0.6100903766686808
  - 0.5955967859433939
  - 0.5894291490974508
  - 0.5841299782096943
  - 0.5886852878400041
  - 0.5709779614074442
  TL_balanced_accuracy:
  - 0.7876805163365588
  - 0.7900376166367993
  - 0.7888553638214468
  - 0.7807765661477446
  - 0.7954986060611098
  - 0.7911724807433638
  - 0.7888766928067059
  - 0.7878909401211632
  - 0.7911142925718728
  - 0.7915514675680548
  - 0.7844752861043537
  - 0.784450289457842
  - 0.7857157864432877
  - 0.7868370725238519
  - 0.7871325982670099
  - 0.7812745964304688
  TL_f1_macro:
  - 0.7128198602799859
  - 0.7097223413637457
  - 0.7185139237680788
  - 0.6981356221669421
  - 0.7106621918565257
  - 0.7043938427121469
  - 0.7116295432484876
  - 0.7004413540845541
  - 0.7173005322764909
  - 0.7155885633097487
  - 0.7200986732564275
  - 0.7075479918863677
  - 0.7107003097802898
  - 0.6996271695854239
  - 0.7095713071813151
  - 0.6933052424248539
  TL_f1_micro:
  - 0.7667574871522241
  - 0.7654708421423537
  - 0.7716812015503876
  - 0.7508588794926004
  - 0.7644426723374091
  - 0.7618811663143057
  - 0.765206571529246
  - 0.7548669837914023
  - 0.7704346092503987
  - 0.7719785059901338
  - 0.7744340204369276
  - 0.7603836328400282
  - 0.7748815428831408
  - 0.7631944750893606
  - 0.7688981068796611
  - 0.7540819028286483
  TL_f1_weighted:
  - 0.7868540053911354
  - 0.7868140896200204
  - 0.7904417649716604
  - 0.7737296100772458
  - 0.7862997139344798
  - 0.784872363650963
  - 0.7857956438610237
  - 0.7782962964608656
  - 0.7898744354349868
  - 0.792017169532276
  - 0.7920669018289449
  - 0.7813270835856554
  - 0.7954078643120436
  - 0.7869832422633679
  - 0.7899104058355048
  - 0.7786947106316372
  TL_matthews_corrcoef:
  - 0.4806029765214033
  - 0.47928422049881103
  - 0.486961679012878
  - 0.46271567581220774
  - 0.4861494221976196
  - 0.47505520779566635
  - 0.48087984318554994
  - 0.4704381723470098
  - 0.4879794380181425
  - 0.48536727749007047
  - 0.4839507527418903
  - 0.47371439624980444
  - 0.4725057315919164
  - 0.46413933595283957
  - 0.47482051445980017
  - 0.45520295944281447
  TL_precision_macro:
  - 0.7007254644688979
  - 0.6980030786030871
  - 0.7052339219963576
  - 0.6906371671075335
  - 0.6999512483776349
  - 0.693766122641148
  - 0.7001246806512795
  - 0.6921839515929648
  - 0.7044935082238464
  - 0.70200669544146
  - 0.7058248488706396
  - 0.6972271935827785
  - 0.6953529319874734
  - 0.6877593099134955
  - 0.6962982628170757
  - 0.6841703240490818
  TL_precision_micro:
  - 0.766757487152224
  - 0.7654708421423537
  - 0.7716812015503876
  - 0.7508588794926004
  - 0.7644426723374091
  - 0.7618811663143058
  - 0.765206571529246
  - 0.7548669837914024
  - 0.7704346092503987
  - 0.7719785059901338
  - 0.7744340204369274
  - 0.7603836328400282
  - 0.7748815428831408
  - 0.7631944750893606
  - 0.7688981068796611
  - 0.7540819028286483
  TL_precision_weighted:
  - 0.8451836263538705
  - 0.8491778947478261
  - 0.8441431279734537
  - 0.8431334511731718
  - 0.852753442444189
  - 0.852676660198541
  - 0.8464468739503936
  - 0.8496279425644012
  - 0.8465237646610229
  - 0.8491225076461447
  - 0.8403575140574874
  - 0.8433327038336057
  - 0.8496694541372496
  - 0.8534194886993379
  - 0.8485279910242006
  - 0.8492443442144789
  TL_recall_macro:
  - 0.7876805163365588
  - 0.7900376166367993
  - 0.7888553638214468
  - 0.7807765661477446
  - 0.7954986060611098
  - 0.7911724807433638
  - 0.7888766928067059
  - 0.7878909401211632
  - 0.7911142925718728
  - 0.7915514675680548
  - 0.7844752861043537
  - 0.784450289457842
  - 0.7857157864432877
  - 0.7868370725238519
  - 0.7871325982670099
  - 0.7812745964304688
  TL_recall_micro:
  - 0.766757487152224
  - 0.7654708421423537
  - 0.7716812015503876
  - 0.7508588794926004
  - 0.7644426723374091
  - 0.7618811663143058
  - 0.765206571529246
  - 0.7548669837914024
  - 0.7704346092503987
  - 0.7719785059901338
  - 0.7744340204369274
  - 0.7603836328400282
  - 0.7748815428831408
  - 0.7631944750893606
  - 0.7688981068796611
  - 0.7540819028286483
  TL_recall_weighted:
  - 0.766757487152224
  - 0.7654708421423537
  - 0.7716812015503876
  - 0.7508588794926004
  - 0.7644426723374091
  - 0.7618811663143058
  - 0.765206571529246
  - 0.7548669837914024
  - 0.7704346092503987
  - 0.7719785059901338
  - 0.7744340204369274
  - 0.7603836328400282
  - 0.7748815428831408
  - 0.7631944750893606
  - 0.7688981068796611
  - 0.7540819028286483
  TL_roc_auc:
  - 0.8653338120488159
  - 0.8677343091667753
  - 0.8668325258512829
  - 0.8596975957558987
  - 0.8712735286804507
  - 0.8683377749809248
  - 0.8667145387021622
  - 0.8651703528256236
  - 0.8702524953752695
  - 0.8720449511161754
  - 0.8677175922190699
  - 0.8647324178579723
  - 0.863654200950396
  - 0.8638910481347643
  - 0.8615604048489349
  - 0.8568320417424645
  TT_average_precision:
  - 0.34087803415441265
  - 0.30413594103253566
  - 0.2928466853878004
  - 0.2806141053504685
  - 0.3146542911404472
  - 0.30292314891812433
  - 0.28258163339835507
  - 0.2718125609427522
  - 0.3247206748240907
  - 0.30154998945000766
  - 0.30214262755287413
  - 0.2714586446033887
  - 0.32424434655215684
  - 0.29611448958263953
  - 0.2858609279495653
  - 0.25842852635444724
  TT_balanced_accuracy:
  - 0.6412507478375513
  - 0.6091827099746907
  - 0.6170556995531773
  - 0.5969584301313162
  - 0.6430628429901
  - 0.6093875180769518
  - 0.629372899876063
  - 0.6017126708907531
  - 0.6380107195449406
  - 0.6060130193730926
  - 0.624857278645846
  - 0.5980192943130274
  - 0.637349250411624
  - 0.6222566138808783
  - 0.6345142555858345
  - 0.5943954617516906
  TT_f1_macro:
  - 0.5617353374633023
  - 0.5554616259223851
  - 0.5580995978886583
  - 0.5402236421670807
  - 0.5557457578872123
  - 0.5486861159105071
  - 0.556062268157639
  - 0.5427391737175548
  - 0.5664395520817178
  - 0.5587878055625601
  - 0.5677471456528602
  - 0.545034327765947
  - 0.5689547469011437
  - 0.5621346539013249
  - 0.5598557039520417
  - 0.538382485249265
  TT_f1_micro:
  - 0.611873040752351
  - 0.6088516746411483
  - 0.6322102604997342
  - 0.5977870813397129
  - 0.603676854754441
  - 0.5991826156299841
  - 0.6266281233386497
  - 0.6035021265284424
  - 0.6192202194357367
  - 0.6147660818713451
  - 0.6436071238702817
  - 0.6071903242955875
  - 0.6379964666623045
  - 0.6218582509404441
  - 0.6378374779453377
  - 0.6074103665235194
  TT_f1_weighted:
  - 0.6511777473276629
  - 0.6432506322049152
  - 0.6710845350458279
  - 0.6362690161195015
  - 0.6449083669516902
  - 0.6359251268493314
  - 0.6693887144730047
  - 0.6428975219658539
  - 0.6566384276909257
  - 0.6471206900811614
  - 0.6804179857622698
  - 0.6446157885850097
  - 0.6770013980176045
  - 0.6582878147734816
  - 0.6812751269673863
  - 0.6481579717144254
  TT_matthews_corrcoef:
  - 0.22588525675443138
  - 0.1808216869975334
  - 0.18644603195688533
  - 0.1576034391067829
  - 0.22673963609040895
  - 0.17929210903131448
  - 0.20125137108354132
  - 0.16395900643994896
  - 0.2227382970662858
  - 0.17738030151115164
  - 0.200199601981878
  - 0.1597066719726635
  - 0.21746808736512696
  - 0.19866697437596637
  - 0.2068238055060854
  - 0.1507757918513925
  TT_precision_macro:
  - 0.5903077505785967
  - 0.574866438322087
  - 0.5742426959241651
  - 0.564045086086493
  - 0.5898396493105634
  - 0.5734673866955345
  - 0.5782662257741102
  - 0.5660747465319466
  - 0.5898704628589261
  - 0.5741978946318289
  - 0.5802513899637918
  - 0.5650540825950274
  - 0.5860805007681427
  - 0.5807084489231752
  - 0.579501028232512
  - 0.5602077128141367
  TT_precision_micro:
  - 0.611873040752351
  - 0.6088516746411483
  - 0.6322102604997342
  - 0.5977870813397129
  - 0.603676854754441
  - 0.5991826156299841
  - 0.6266281233386497
  - 0.6035021265284424
  - 0.6192202194357367
  - 0.6147660818713451
  - 0.6436071238702817
  - 0.6071903242955875
  - 0.6379964666623045
  - 0.6218582509404441
  - 0.6378374779453377
  - 0.6074103665235194
  TT_precision_weighted:
  - 0.7683611160078343
  - 0.7319680024385028
  - 0.7601148014488994
  - 0.733882981740661
  - 0.7739945485039041
  - 0.7365743384198039
  - 0.7753757363639314
  - 0.741511952300902
  - 0.7621941140140907
  - 0.7258891977581893
  - 0.7630556231121634
  - 0.7347224286382673
  - 0.7728297023987015
  - 0.7505666910841272
  - 0.784548285061007
  - 0.7434341515561891
  TT_recall_macro:
  - 0.6412507478375513
  - 0.6091827099746907
  - 0.6170556995531773
  - 0.5969584301313162
  - 0.6430628429901
  - 0.6093875180769518
  - 0.629372899876063
  - 0.6017126708907531
  - 0.6380107195449406
  - 0.6060130193730926
  - 0.624857278645846
  - 0.5980192943130274
  - 0.637349250411624
  - 0.6222566138808783
  - 0.6345142555858345
  - 0.5943954617516906
  TT_recall_micro:
  - 0.611873040752351
  - 0.6088516746411483
  - 0.6322102604997342
  - 0.5977870813397129
  - 0.603676854754441
  - 0.5991826156299841
  - 0.6266281233386497
  - 0.6035021265284424
  - 0.6192202194357367
  - 0.6147660818713451
  - 0.6436071238702817
  - 0.6071903242955875
  - 0.6379964666623045
  - 0.6218582509404441
  - 0.6378374779453377
  - 0.6074103665235194
  TT_recall_weighted:
  - 0.611873040752351
  - 0.6088516746411483
  - 0.6322102604997342
  - 0.5977870813397129
  - 0.603676854754441
  - 0.5991826156299841
  - 0.6266281233386497
  - 0.6035021265284424
  - 0.6192202194357367
  - 0.6147660818713451
  - 0.6436071238702817
  - 0.6071903242955875
  - 0.6379964666623045
  - 0.6218582509404441
  - 0.6378374779453377
  - 0.6074103665235194
  TT_roc_auc:
  - 0.7002171648953857
  - 0.6558315666653559
  - 0.6667671952578779
  - 0.6399926976476612
  - 0.6943720533466164
  - 0.66001326014431
  - 0.67924532284217
  - 0.6473676282206793
  - 0.688281488438247
  - 0.6542861074310669
  - 0.6807084641506578
  - 0.6430911524802675
  - 0.6990445124534417
  - 0.6690188234301836
  - 0.6835849831108478
  - 0.6404995976116421
  fit_time:
  - 1564.6495280265808
  - 897.6766626834869
  - 725.8218913078308
  - 735.6079843044281
  - 1591.968757867813
  - 1084.3888800144196
  - 773.2404808998108
  - 666.5159392356873
  - 1657.9740273952484
  - 1222.3768532276154
  - 900.9177749156952
  - 823.1081759929657
  - 1529.2346410751343
  - 1146.1566927433014
  - 1010.1046595573425
  - 879.1002600193024
  score_time:
  - 34.63919711112976
  - 33.97833752632141
  - 36.7149293422699
  - 34.661399126052856
  - 31.696280479431152
  - 31.798829793930054
  - 32.147814989089966
  - 39.20306038856506
  - 35.77270865440369
  - 31.100712060928345
  - 33.198049783706665
  - 32.14681029319763
  - 32.142749547958374
  - 32.165412187576294
  - 31.23673152923584
  - 34.86183428764343
start: 2023-08-13 10:38:35.592923
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
