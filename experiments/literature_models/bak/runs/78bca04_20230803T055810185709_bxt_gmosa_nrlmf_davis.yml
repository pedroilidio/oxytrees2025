active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: ../missing_data_simulation/datasets/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: null
  - force_download: false
    path: ../missing_data_simulation/datasets/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: null
  name: davis
  pairwise: true
  y:
    force_download: false
    path: ../missing_data_simulation/datasets/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: null
directory: runs
end: 2023-08-03 05:59:10.580667
estimator:
  call: y_reconstruction.estimators.bxt_gmosa_nrlmf
  final_params:
    memory: /tmp
    steps:
    - - symmetryenforcer
      - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
        params:
          ndim: 2
          samplers:
            call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
            params:
              sampling_strategy: auto
          samplers__sampling_strategy: auto
    - - regressorassampler
      - call: y_reconstruction.estimators.RegressorAsSampler
        params:
          estimator:
            call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
            params:
              cv:
                call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                params: {}
              diagonal: false
              error_score: .nan
              estimator:
                call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
                params:
                  alpha_cols: same
                  alpha_rows: 0.1
                  keep_positives: true
                  lambda_cols: same
                  lambda_rows: 0.625
                  learning_rate: 1.0
                  max_iter: 100
                  n_components_cols: same
                  n_components_rows: 10
                  n_neighbors: 5
                  positive_importance: 5
                  random_state: null
                  resample_X: false
                  tol: 1.0e-05
                  verbose: false
              estimator__alpha_cols: same
              estimator__alpha_rows: 0.1
              estimator__keep_positives: true
              estimator__lambda_cols: same
              estimator__lambda_rows: 0.625
              estimator__learning_rate: 1.0
              estimator__max_iter: 100
              estimator__n_components_cols: same
              estimator__n_components_rows: 10
              estimator__n_neighbors: 5
              estimator__positive_importance: 5
              estimator__random_state: null
              estimator__resample_X: false
              estimator__tol: 1.0e-05
              estimator__verbose: false
              n_iter: 100
              n_jobs: 3
              pairwise: true
              param_distributions:
                alpha_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                alpha_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                learning_rate:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                n_components_rows:
                - 50
                - 100
                n_neighbors:
                - 3
                - 5
                - 10
              pre_dispatch: 2*n_jobs
              random_state: 0
              refit: true
              return_train_score: false
              scoring: null
              train_test_combinations: null
              verbose: 1
          estimator__cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          estimator__diagonal: false
          estimator__error_score: .nan
          estimator__estimator:
            call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
            params:
              alpha_cols: same
              alpha_rows: 0.1
              keep_positives: true
              lambda_cols: same
              lambda_rows: 0.625
              learning_rate: 1.0
              max_iter: 100
              n_components_cols: same
              n_components_rows: 10
              n_neighbors: 5
              positive_importance: 5
              random_state: null
              resample_X: false
              tol: 1.0e-05
              verbose: false
          estimator__estimator__alpha_cols: same
          estimator__estimator__alpha_rows: 0.1
          estimator__estimator__keep_positives: true
          estimator__estimator__lambda_cols: same
          estimator__estimator__lambda_rows: 0.625
          estimator__estimator__learning_rate: 1.0
          estimator__estimator__max_iter: 100
          estimator__estimator__n_components_cols: same
          estimator__estimator__n_components_rows: 10
          estimator__estimator__n_neighbors: 5
          estimator__estimator__positive_importance: 5
          estimator__estimator__random_state: null
          estimator__estimator__resample_X: false
          estimator__estimator__tol: 1.0e-05
          estimator__estimator__verbose: false
          estimator__n_iter: 100
          estimator__n_jobs: 3
          estimator__pairwise: true
          estimator__param_distributions:
            alpha_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            alpha_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            learning_rate:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            n_components_rows:
            - 50
            - 100
            n_neighbors:
            - 3
            - 5
            - 10
          estimator__pre_dispatch: 2*n_jobs
          estimator__random_state: 0
          estimator__refit: true
          estimator__return_train_score: false
          estimator__scoring: null
          estimator__train_test_combinations: null
          estimator__verbose: 1
    - - regressortobinaryclassifier
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error
          estimator__max_col_features: null
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: null
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: bxt_gmosa_nrlmf
  params:
    regressortobinaryclassifier__estimator__min_cols_leaf: 1
    regressortobinaryclassifier__estimator__min_rows_leaf: 1
    regressortobinaryclassifier__estimator__min_samples_leaf: 1
hash: 310776b6c15bfd39ec0b4a5bd861efd961e80366da001fbc11d8355f4e3930aa
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/310776b_20230803T055810185709_bxt_gmosa_nrlmf_davis.yml
results:
  LL_average_precision:
  - 0.96893934149048
  - 0.9477457839607072
  - 0.9502281652011961
  - 0.9555423415739265
  - 0.9437999197548805
  - 0.9104470917048295
  - 0.94875137645718
  - 0.9593799933037224
  - 0.972679600697154
  - 0.9531169899333948
  - 0.9578694634356361
  - 0.9676684977724872
  - 0.9714818273107343
  - 0.9248553745456088
  - 0.9466228143903644
  - 0.9523082525096797
  LL_balanced_accuracy:
  - 0.9660095173351462
  - 0.9655763345669531
  - 0.9646342809667596
  - 0.9656183770922372
  - 0.9440929345331437
  - 0.9416365927122317
  - 0.9564847579378308
  - 0.9629164812342382
  - 0.9617413528064636
  - 0.9636067857641828
  - 0.9630877203546002
  - 0.9639249387025924
  - 0.9653303032544454
  - 0.9579103425838393
  - 0.9475174474158472
  - 0.9492560794421262
  LL_f1_macro:
  - 0.7624067558057706
  - 0.7901819081475816
  - 0.7864906289740067
  - 0.786864349345894
  - 0.7208787212915083
  - 0.7267381006546876
  - 0.766254687495777
  - 0.7930500840262413
  - 0.7644536425209822
  - 0.7925070151258712
  - 0.7920249725221782
  - 0.7831147733677323
  - 0.7919563497462487
  - 0.7747497335440783
  - 0.746221009333446
  - 0.7461031993323639
  LL_f1_micro:
  - 0.9348379835317814
  - 0.9400509448492388
  - 0.9407039924403496
  - 0.9414717694306638
  - 0.9001836384100468
  - 0.8954445826669036
  - 0.9215686274509803
  - 0.936806047720293
  - 0.9305135951661632
  - 0.9382737989455601
  - 0.9383416017009213
  - 0.9357429718875502
  - 0.9373259877969314
  - 0.9233457733546591
  - 0.9084573588471533
  - 0.9088707772265533
  LL_f1_weighted:
  - 0.9480272158868757
  - 0.9505765476231269
  - 0.9513135289123217
  - 0.9519676202220784
  - 0.9223548968238913
  - 0.9177412098508161
  - 0.936422590698399
  - 0.9475632967042016
  - 0.9441859505165884
  - 0.9488645300054681
  - 0.9489326096431653
  - 0.9473480447122055
  - 0.9481635513451789
  - 0.9373047624346699
  - 0.9268404701009595
  - 0.9272762280572527
  LL_matthews_corrcoef:
  - 0.6020397385689958
  - 0.6420440735931053
  - 0.6357818887951606
  - 0.6365639916654997
  - 0.5423641882802688
  - 0.5515877227627465
  - 0.6078265004674904
  - 0.6462027624506216
  - 0.604556838752079
  - 0.6452288258110551
  - 0.6442280730371016
  - 0.6319432302637893
  - 0.6455130597771449
  - 0.6206488135175031
  - 0.5782877239231901
  - 0.5788571965814171
  LL_precision_macro:
  - 0.6944444444444444
  - 0.7213496272418184
  - 0.7174928899342558
  - 0.7175675056124573
  - 0.6655953573310909
  - 0.6722281514503259
  - 0.7023359204475741
  - 0.725514767310433
  - 0.697886202448874
  - 0.7245007247743768
  - 0.7240557198165913
  - 0.7152030495456101
  - 0.7238663092799937
  - 0.7103058797204154
  - 0.6868176836296134
  - 0.6864613910457178
  LL_precision_micro:
  - 0.9348379835317813
  - 0.9400509448492388
  - 0.9407039924403496
  - 0.9414717694306638
  - 0.9001836384100468
  - 0.8954445826669036
  - 0.9215686274509803
  - 0.936806047720293
  - 0.9305135951661632
  - 0.9382737989455601
  - 0.9383416017009213
  - 0.9357429718875502
  - 0.9373259877969314
  - 0.9233457733546591
  - 0.9084573588471533
  - 0.9088707772265533
  LL_precision_weighted:
  - 0.9746592158179149
  - 0.9730910835967148
  - 0.9736859314673696
  - 0.9740863021308609
  - 0.9663835531009624
  - 0.9634314480865301
  - 0.9679373461249904
  - 0.9709855195512997
  - 0.9722566823194
  - 0.9717710507172204
  - 0.9717841228147958
  - 0.972040307475678
  - 0.9717175310697422
  - 0.967521154985651
  - 0.9651043534795603
  - 0.9655829510481136
  LL_recall_macro:
  - 0.9660095173351462
  - 0.9655763345669531
  - 0.9646342809667596
  - 0.9656183770922372
  - 0.9440929345331437
  - 0.9416365927122317
  - 0.9564847579378308
  - 0.9629164812342382
  - 0.9617413528064636
  - 0.9636067857641828
  - 0.9630877203546002
  - 0.9639249387025924
  - 0.9653303032544454
  - 0.9579103425838393
  - 0.9475174474158472
  - 0.9492560794421262
  LL_recall_micro:
  - 0.9348379835317813
  - 0.9400509448492388
  - 0.9407039924403496
  - 0.9414717694306638
  - 0.9001836384100468
  - 0.8954445826669036
  - 0.9215686274509803
  - 0.936806047720293
  - 0.9305135951661632
  - 0.9382737989455601
  - 0.9383416017009213
  - 0.9357429718875502
  - 0.9373259877969314
  - 0.9233457733546591
  - 0.9084573588471533
  - 0.9088707772265533
  LL_recall_weighted:
  - 0.9348379835317813
  - 0.9400509448492388
  - 0.9407039924403496
  - 0.9414717694306638
  - 0.9001836384100468
  - 0.8954445826669036
  - 0.9215686274509803
  - 0.936806047720293
  - 0.9305135951661632
  - 0.9382737989455601
  - 0.9383416017009213
  - 0.9357429718875502
  - 0.9373259877969314
  - 0.9233457733546591
  - 0.9084573588471533
  - 0.9088707772265533
  LL_roc_auc:
  - 0.9984899397000009
  - 0.997240910897661
  - 0.9971622524458692
  - 0.997636910978106
  - 0.9957914407933048
  - 0.9942394507492633
  - 0.996760128884717
  - 0.996930404560578
  - 0.9983179194339271
  - 0.9971221834720344
  - 0.9970086440333531
  - 0.9979645132009421
  - 0.9983520912528743
  - 0.9963966894984779
  - 0.9960761961206462
  - 0.9966810616289792
  LT_average_precision:
  - 0.698175198811127
  - 0.6127437757800235
  - 0.5555348684710187
  - 0.5235990834172636
  - 0.6599925596660701
  - 0.593771235586032
  - 0.5795143265057618
  - 0.5064493143327637
  - 0.6862967641204003
  - 0.6090823173750655
  - 0.5560022310370961
  - 0.47432293925253605
  - 0.6654561529631866
  - 0.5893600004701512
  - 0.6038427893700383
  - 0.5339039009674946
  LT_balanced_accuracy:
  - 0.8893189541864512
  - 0.8607411484131352
  - 0.8374534450651769
  - 0.8552126865671642
  - 0.8816044074756584
  - 0.8449549213690624
  - 0.8645746866838202
  - 0.859004577737219
  - 0.8777105940618893
  - 0.8418558722400614
  - 0.8422666674688067
  - 0.8573758200562325
  - 0.8830542319778938
  - 0.8611400427919744
  - 0.8731266785843566
  - 0.8756599090622426
  LT_f1_macro:
  - 0.6986284412755001
  - 0.6860898246037941
  - 0.6847509578544061
  - 0.6793122348612831
  - 0.6905283929688872
  - 0.662458373393447
  - 0.6857462719156289
  - 0.678068862275449
  - 0.7051317018272109
  - 0.6861638840913452
  - 0.6726440340809282
  - 0.672349525841688
  - 0.7087018541015055
  - 0.6849035199985474
  - 0.6696156102096695
  - 0.662697449447531
  LT_f1_micro:
  - 0.8837661190602366
  - 0.9169757993287406
  - 0.9098039215686274
  - 0.8982174688057041
  - 0.8687511040452217
  - 0.8865924748277689
  - 0.890017825311943
  - 0.8770053475935828
  - 0.8878290054760642
  - 0.9081434375552022
  - 0.896969696969697
  - 0.8828877005347594
  - 0.8809397632927045
  - 0.8927751280692457
  - 0.8718360071301248
  - 0.8611408199643493
  LT_f1_weighted:
  - 0.9084678331122006
  - 0.9353325421184067
  - 0.9283209375704304
  - 0.9206511227698032
  - 0.8965880312175264
  - 0.9128297206059034
  - 0.9137283195708561
  - 0.9037106535591917
  - 0.9102561655065676
  - 0.9270730109024666
  - 0.9196727679338919
  - 0.9092459376599983
  - 0.9043638024016383
  - 0.9158769966477855
  - 0.9016461226023357
  - 0.8941147939172952
  LT_matthews_corrcoef:
  - 0.48710894906420366
  - 0.4442838870260384
  - 0.43256530168544177
  - 0.43698806522501443
  - 0.47670055698296115
  - 0.4112883989450864
  - 0.4534438402983529
  - 0.4437124378643169
  - 0.4886964193614457
  - 0.437211817093991
  - 0.42119033884650514
  - 0.43292881489942014
  - 0.49896976747401056
  - 0.44959648486654447
  - 0.4413618486432544
  - 0.43699271064588324
  LT_precision_macro:
  - 0.652365512715827
  - 0.6367934966244194
  - 0.6386211512717537
  - 0.6343973458511276
  - 0.6488736873684829
  - 0.6225943859819822
  - 0.6409939607812348
  - 0.6371018224589369
  - 0.658073531727287
  - 0.6397914944052763
  - 0.6295782779912403
  - 0.6311136262245758
  - 0.6624905875386833
  - 0.6399297884842895
  - 0.6305188643819732
  - 0.6270847810419373
  LT_precision_micro:
  - 0.8837661190602367
  - 0.9169757993287405
  - 0.9098039215686274
  - 0.8982174688057041
  - 0.8687511040452217
  - 0.8865924748277689
  - 0.890017825311943
  - 0.8770053475935828
  - 0.8878290054760642
  - 0.9081434375552022
  - 0.896969696969697
  - 0.8828877005347594
  - 0.8809397632927045
  - 0.8927751280692457
  - 0.8718360071301248
  - 0.8611408199643493
  LT_precision_weighted:
  - 0.9550218584391134
  - 0.9653760539019639
  - 0.95842979762186
  - 0.9584648526535041
  - 0.9501512400949274
  - 0.9565944232572927
  - 0.9554192904838397
  - 0.9514018310297854
  - 0.9521299745937829
  - 0.958178288953076
  - 0.9571872182537767
  - 0.9549511493586706
  - 0.9497097244979056
  - 0.9560019294041674
  - 0.9552845327089884
  - 0.9544240238827019
  LT_recall_macro:
  - 0.8893189541864512
  - 0.8607411484131352
  - 0.8374534450651769
  - 0.8552126865671642
  - 0.8816044074756584
  - 0.8449549213690624
  - 0.8645746866838202
  - 0.859004577737219
  - 0.8777105940618893
  - 0.8418558722400614
  - 0.8422666674688067
  - 0.8573758200562325
  - 0.8830542319778938
  - 0.8611400427919744
  - 0.8731266785843566
  - 0.8756599090622426
  LT_recall_micro:
  - 0.8837661190602367
  - 0.9169757993287405
  - 0.9098039215686274
  - 0.8982174688057041
  - 0.8687511040452217
  - 0.8865924748277689
  - 0.890017825311943
  - 0.8770053475935828
  - 0.8878290054760642
  - 0.9081434375552022
  - 0.896969696969697
  - 0.8828877005347594
  - 0.8809397632927045
  - 0.8927751280692457
  - 0.8718360071301248
  - 0.8611408199643493
  LT_recall_weighted:
  - 0.8837661190602367
  - 0.9169757993287405
  - 0.9098039215686274
  - 0.8982174688057041
  - 0.8687511040452217
  - 0.8865924748277689
  - 0.890017825311943
  - 0.8770053475935828
  - 0.8878290054760642
  - 0.9081434375552022
  - 0.896969696969697
  - 0.8828877005347594
  - 0.8809397632927045
  - 0.8927751280692457
  - 0.8718360071301248
  - 0.8611408199643493
  LT_roc_auc:
  - 0.9537080674000309
  - 0.9050362100444653
  - 0.92514121663563
  - 0.9215130597014926
  - 0.9413272970425575
  - 0.9136927342654391
  - 0.9259433877213847
  - 0.9302660716765528
  - 0.9380778895331736
  - 0.896679997427572
  - 0.9256423638266895
  - 0.9221579620005111
  - 0.950941914400724
  - 0.915792324357784
  - 0.9474916884913999
  - 0.9386192388285916
  TL_average_precision:
  - 0.38069965048333354
  - 0.3662238207492896
  - 0.36401015709852247
  - 0.3427604596846854
  - 0.2549704824578243
  - 0.2205076264905352
  - 0.31044157825172813
  - 0.2512652081203452
  - 0.40602383016551213
  - 0.37645413216677803
  - 0.3417707977715774
  - 0.32191075363890176
  - 0.16946180170901867
  - 0.19130407407035002
  - 0.22824586618427195
  - 0.21548502079064058
  TL_balanced_accuracy:
  - 0.7211136726502231
  - 0.7648183875083591
  - 0.7525872272359169
  - 0.750376394449966
  - 0.7003011150199749
  - 0.7379352186805603
  - 0.7313561940067964
  - 0.68779734321903
  - 0.7496674361025606
  - 0.7564184777877724
  - 0.73697154399956
  - 0.7181757370797804
  - 0.6985636293948827
  - 0.7265750513253413
  - 0.7627586320506062
  - 0.7655414760677919
  TL_f1_macro:
  - 0.6505309947050635
  - 0.6781330699855519
  - 0.6679622311712317
  - 0.6699999554433942
  - 0.5819635260833282
  - 0.5949089105114111
  - 0.6094742146291388
  - 0.5964581655931294
  - 0.7030713441570478
  - 0.707662539844651
  - 0.6922648184946445
  - 0.6703242043630069
  - 0.6092270300367113
  - 0.6231864664227191
  - 0.6294959069932319
  - 0.6322766409090591
  TL_f1_micro:
  - 0.8823529411764706
  - 0.885907232983828
  - 0.8796952515946137
  - 0.8860737065910702
  - 0.8702683490314556
  - 0.8564066109827617
  - 0.8745570517363572
  - 0.8791637136782424
  - 0.9299804513950596
  - 0.9219832948285054
  - 0.923458540042523
  - 0.9140680368532955
  - 0.9091878443220187
  - 0.8953261062733251
  - 0.8936924167257264
  - 0.9011339475549256
  TL_f1_weighted:
  - 0.8991465013397932
  - 0.9026357875804596
  - 0.8975941379450261
  - 0.9024909589773727
  - 0.9023502039283152
  - 0.8920364679812912
  - 0.9028325543611271
  - 0.9044181042988856
  - 0.9362540107738702
  - 0.9290561466430411
  - 0.9303584344305014
  - 0.9229579314238253
  - 0.9276235698247468
  - 0.9165532258183431
  - 0.9175288622114529
  - 0.9233065973777717
  TL_matthews_corrcoef:
  - 0.3286270957442675
  - 0.39003705788166715
  - 0.37014725795078485
  - 0.3709318360231298
  - 0.2286407776392942
  - 0.2697522153302722
  - 0.28072084908541245
  - 0.2383111420963824
  - 0.41640852319289584
  - 0.42668749250303933
  - 0.39476882652052625
  - 0.35343268092863234
  - 0.25653466871492747
  - 0.2923874820603853
  - 0.32053207377492204
  - 0.3242180390667607
  TL_precision_macro:
  - 0.622104353343347
  - 0.6436162608952003
  - 0.6356056223307347
  - 0.6373835852993976
  - 0.5652475214557442
  - 0.5764559551956049
  - 0.5851546199676416
  - 0.5756030403223608
  - 0.6736270265102366
  - 0.6775049694441454
  - 0.6644104854976625
  - 0.6431353706195144
  - 0.5828576165398869
  - 0.594329052520941
  - 0.5977520790817108
  - 0.5989650829814808
  TL_precision_micro:
  - 0.8823529411764706
  - 0.885907232983828
  - 0.8796952515946137
  - 0.8860737065910702
  - 0.8702683490314554
  - 0.8564066109827617
  - 0.8745570517363572
  - 0.8791637136782424
  - 0.9299804513950596
  - 0.9219832948285054
  - 0.923458540042523
  - 0.9140680368532955
  - 0.9091878443220188
  - 0.8953261062733251
  - 0.8936924167257264
  - 0.9011339475549256
  TL_precision_weighted:
  - 0.923003391028551
  - 0.9283387527530176
  - 0.9247743348469347
  - 0.9269720345949612
  - 0.946652086252438
  - 0.9447290714001181
  - 0.9436680802184386
  - 0.9387186203059421
  - 0.9445587770418654
  - 0.9386701605662662
  - 0.9393965998670276
  - 0.9345791925091463
  - 0.9519274419092183
  - 0.9462546166156426
  - 0.9523890704097333
  - 0.9554533730744519
  TL_recall_macro:
  - 0.7211136726502231
  - 0.7648183875083591
  - 0.7525872272359169
  - 0.750376394449966
  - 0.7003011150199749
  - 0.7379352186805603
  - 0.7313561940067964
  - 0.68779734321903
  - 0.7496674361025606
  - 0.7564184777877724
  - 0.73697154399956
  - 0.7181757370797804
  - 0.6985636293948827
  - 0.7265750513253413
  - 0.7627586320506062
  - 0.7655414760677919
  TL_recall_micro:
  - 0.8823529411764706
  - 0.885907232983828
  - 0.8796952515946137
  - 0.8860737065910702
  - 0.8702683490314554
  - 0.8564066109827617
  - 0.8745570517363572
  - 0.8791637136782424
  - 0.9299804513950596
  - 0.9219832948285054
  - 0.923458540042523
  - 0.9140680368532955
  - 0.9091878443220188
  - 0.8953261062733251
  - 0.8936924167257264
  - 0.9011339475549256
  TL_recall_weighted:
  - 0.8823529411764706
  - 0.885907232983828
  - 0.8796952515946137
  - 0.8860737065910702
  - 0.8702683490314554
  - 0.8564066109827617
  - 0.8745570517363572
  - 0.8791637136782424
  - 0.9299804513950596
  - 0.9219832948285054
  - 0.923458540042523
  - 0.9140680368532955
  - 0.9091878443220188
  - 0.8953261062733251
  - 0.8936924167257264
  - 0.9011339475549256
  TL_roc_auc:
  - 0.8329256542583011
  - 0.8612998313825401
  - 0.8398493781611897
  - 0.8337919437834586
  - 0.791274904810174
  - 0.8135989958971325
  - 0.8111791000889563
  - 0.7871627380699816
  - 0.8456906789147942
  - 0.8536470997881787
  - 0.8433498751485333
  - 0.8225503354066228
  - 0.76761972871152
  - 0.7638774919907316
  - 0.7811923431734317
  - 0.8066648264016686
  TT_average_precision:
  - 0.32488115941553386
  - 0.30368831523634654
  - 0.2516517513123607
  - 0.2938618420243065
  - 0.3180625070093943
  - 0.28225263123041655
  - 0.157654315967107
  - 0.2172173671475691
  - 0.2835501780664267
  - 0.33382836945204153
  - 0.27790776560157865
  - 0.2711024825151603
  - 0.3047267371263475
  - 0.17150421592341272
  - 0.11656514327060209
  - 0.24370546759364609
  TT_balanced_accuracy:
  - 0.7128696222254387
  - 0.6551793794440853
  - 0.6656255078823339
  - 0.7132607449856734
  - 0.666956005921024
  - 0.6780132450331126
  - 0.6318651206852006
  - 0.6991403674968096
  - 0.7652981477495016
  - 0.7367069792581582
  - 0.6388404913319976
  - 0.7209322033898304
  - 0.7688415889548261
  - 0.6820847307668567
  - 0.6180481568293202
  - 0.6667090727901108
  TT_f1_macro:
  - 0.614982958453531
  - 0.6385088249567905
  - 0.6325332131661281
  - 0.6316561863777295
  - 0.5754251728724866
  - 0.6120108457131176
  - 0.5686274509803921
  - 0.5750829383569517
  - 0.6912864828374813
  - 0.7011317168692046
  - 0.651711493446216
  - 0.6419378237071287
  - 0.6432150044592404
  - 0.5906162464985995
  - 0.5576808340129281
  - 0.5693228926761861
  TT_f1_micro:
  - 0.8314785373608903
  - 0.904610492845787
  - 0.8978609625668449
  - 0.8598930481283422
  - 0.8373078961314255
  - 0.9093799682034976
  - 0.8903743315508021
  - 0.8636363636363636
  - 0.899311075781664
  - 0.9417064122946476
  - 0.9331550802139037
  - 0.8914438502673797
  - 0.8839427662957074
  - 0.9162692103868575
  - 0.8925133689839572
  - 0.8598930481283422
  TT_f1_weighted:
  - 0.8626906208217393
  - 0.9095413452464478
  - 0.9073786980708354
  - 0.8828407760760941
  - 0.8724729851520252
  - 0.9246804375810291
  - 0.912886651986998
  - 0.8986522562562532
  - 0.9122034972940214
  - 0.9459694015815723
  - 0.9299739807798848
  - 0.9088661160553793
  - 0.9077049260124683
  - 0.9352317715639517
  - 0.9157684866555774
  - 0.8931875451072351
  TT_matthews_corrcoef:
  - 0.2851694403401436
  - 0.2797438819769968
  - 0.27414489071836173
  - 0.30168926587676514
  - 0.20688546263308952
  - 0.24968122188671107
  - 0.16922596200700343
  - 0.22071999835129452
  - 0.4074404527829956
  - 0.4084871489672839
  - 0.305512921876106
  - 0.3155133162833159
  - 0.34449503796399383
  - 0.22175723115062637
  - 0.14735819972715908
  - 0.19543134309835422
  TT_precision_macro:
  - 0.5955063583682544
  - 0.6260744819703277
  - 0.613441797202481
  - 0.6066961633649173
  - 0.5640911274991122
  - 0.5875506658946149
  - 0.5542930269740575
  - 0.5611595206493931
  - 0.6564350561549712
  - 0.6762323943661972
  - 0.6680672268907564
  - 0.6126461548211286
  - 0.6103594421934426
  - 0.5675183874019594
  - 0.54598639997875
  - 0.5572755417956656
  TT_precision_micro:
  - 0.8314785373608903
  - 0.904610492845787
  - 0.8978609625668449
  - 0.8598930481283422
  - 0.8373078961314255
  - 0.9093799682034976
  - 0.8903743315508021
  - 0.8636363636363636
  - 0.899311075781664
  - 0.9417064122946476
  - 0.9331550802139037
  - 0.8914438502673797
  - 0.8839427662957074
  - 0.9162692103868575
  - 0.8925133689839572
  - 0.8598930481283422
  TT_precision_weighted:
  - 0.9109803119513077
  - 0.9151279004307635
  - 0.9190253129921305
  - 0.9164989981962983
  - 0.9220625913112079
  - 0.9442944426084179
  - 0.9409431563406451
  - 0.9471860972236067
  - 0.9314048099649572
  - 0.9512845488404726
  - 0.9272295870219747
  - 0.9333019064707424
  - 0.943868676943734
  - 0.9593954951218985
  - 0.9442406444100977
  - 0.9382175791791528
  TT_recall_macro:
  - 0.7128696222254387
  - 0.6551793794440853
  - 0.6656255078823339
  - 0.7132607449856734
  - 0.666956005921024
  - 0.6780132450331126
  - 0.6318651206852006
  - 0.6991403674968096
  - 0.7652981477495016
  - 0.7367069792581582
  - 0.6388404913319976
  - 0.7209322033898304
  - 0.7688415889548261
  - 0.6820847307668567
  - 0.6180481568293202
  - 0.6667090727901108
  TT_recall_micro:
  - 0.8314785373608903
  - 0.904610492845787
  - 0.8978609625668449
  - 0.8598930481283422
  - 0.8373078961314255
  - 0.9093799682034976
  - 0.8903743315508021
  - 0.8636363636363636
  - 0.899311075781664
  - 0.9417064122946476
  - 0.9331550802139037
  - 0.8914438502673797
  - 0.8839427662957074
  - 0.9162692103868575
  - 0.8925133689839572
  - 0.8598930481283422
  TT_recall_weighted:
  - 0.8314785373608903
  - 0.904610492845787
  - 0.8978609625668449
  - 0.8598930481283422
  - 0.8373078961314255
  - 0.9093799682034976
  - 0.8903743315508021
  - 0.8636363636363636
  - 0.899311075781664
  - 0.9417064122946476
  - 0.9331550802139037
  - 0.8914438502673797
  - 0.8839427662957074
  - 0.9162692103868575
  - 0.8925133689839572
  - 0.8598930481283422
  TT_roc_auc:
  - 0.8328324152199641
  - 0.7854504924141603
  - 0.791844425483504
  - 0.8193879656160459
  - 0.7736514432495973
  - 0.7348270787343636
  - 0.7211987880590939
  - 0.7748749305169539
  - 0.8205614780565877
  - 0.8557462333626106
  - 0.8054055231291924
  - 0.8670141242937853
  - 0.8161953494005086
  - 0.7158083167013024
  - 0.6541316854890262
  - 0.7038356338655302
  fit_time:
  - 59.229243993759155
  - 58.41092491149902
  - 51.894999504089355
  - 54.140849351882935
  - 53.27206325531006
  - 48.12370300292969
  - 49.25600981712341
  - 56.63781476020813
  - 58.92098140716553
  - 54.55149745941162
  - 50.086345195770264
  - 58.18428945541382
  - 46.132453203201294
  - 50.88183879852295
  - 43.5942862033844
  - 48.88752198219299
  score_time:
  - 0.9977853298187256
  - 1.149080514907837
  - 1.191671371459961
  - 1.1196396350860596
  - 1.081230640411377
  - 1.1371006965637207
  - 1.218782901763916
  - 1.027627944946289
  - 1.1076714992523193
  - 1.064594030380249
  - 1.214376449584961
  - 1.1489284038543701
  - 1.3732507228851318
  - 1.1788780689239502
  - 1.440777063369751
  - 1.1739492416381836
start: 2023-08-03 05:58:10.185709
