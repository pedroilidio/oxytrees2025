active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: utils.read_table_to_array
      params: {}
directory: runs
end: 2023-08-12 04:59:00.613822
estimator:
  call: y_reconstruction.estimators.bxt_gso_nrlmf
  final_params:
    memory: /tmp
    steps:
    - - symmetryenforcer
      - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
        params:
          ndim: 2
          samplers:
            call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
            params:
              sampling_strategy: auto
          samplers__sampling_strategy: auto
    - - regressorassampler
      - call: y_reconstruction.estimators.RegressorAsSampler
        params:
          estimator:
            call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
            params:
              cv:
                call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                params: {}
              diagonal: false
              error_score: .nan
              estimator:
                call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
                params:
                  alpha_cols: same
                  alpha_rows: 0.1
                  keep_positives: true
                  lambda_cols: same
                  lambda_rows: 0.625
                  learning_rate: 1.0
                  max_iter: 100
                  n_components_cols: same
                  n_components_rows: 10
                  n_neighbors: 5
                  positive_importance: 5
                  random_state: null
                  resample_X: false
                  tol: 1.0e-05
                  verbose: false
              estimator__alpha_cols: same
              estimator__alpha_rows: 0.1
              estimator__keep_positives: true
              estimator__lambda_cols: same
              estimator__lambda_rows: 0.625
              estimator__learning_rate: 1.0
              estimator__max_iter: 100
              estimator__n_components_cols: same
              estimator__n_components_rows: 10
              estimator__n_neighbors: 5
              estimator__positive_importance: 5
              estimator__random_state: null
              estimator__resample_X: false
              estimator__tol: 1.0e-05
              estimator__verbose: false
              n_iter: 100
              n_jobs: 3
              pairwise: true
              param_distributions:
                alpha_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                alpha_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                learning_rate:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                n_components_rows:
                - 50
                - 100
                n_neighbors:
                - 3
                - 5
                - 10
              pre_dispatch: 2*n_jobs
              random_state: 0
              refit: true
              return_train_score: false
              scoring: null
              train_test_combinations: null
              verbose: 1
          estimator__cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          estimator__diagonal: false
          estimator__error_score: .nan
          estimator__estimator:
            call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
            params:
              alpha_cols: same
              alpha_rows: 0.1
              keep_positives: true
              lambda_cols: same
              lambda_rows: 0.625
              learning_rate: 1.0
              max_iter: 100
              n_components_cols: same
              n_components_rows: 10
              n_neighbors: 5
              positive_importance: 5
              random_state: null
              resample_X: false
              tol: 1.0e-05
              verbose: false
          estimator__estimator__alpha_cols: same
          estimator__estimator__alpha_rows: 0.1
          estimator__estimator__keep_positives: true
          estimator__estimator__lambda_cols: same
          estimator__estimator__lambda_rows: 0.625
          estimator__estimator__learning_rate: 1.0
          estimator__estimator__max_iter: 100
          estimator__estimator__n_components_cols: same
          estimator__estimator__n_components_rows: 10
          estimator__estimator__n_neighbors: 5
          estimator__estimator__positive_importance: 5
          estimator__estimator__random_state: null
          estimator__estimator__resample_X: false
          estimator__estimator__tol: 1.0e-05
          estimator__estimator__verbose: false
          estimator__n_iter: 100
          estimator__n_jobs: 3
          estimator__pairwise: true
          estimator__param_distributions:
            alpha_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            alpha_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            learning_rate:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            n_components_rows:
            - 50
            - 100
            n_neighbors:
            - 3
            - 5
            - 10
          estimator__pre_dispatch: 2*n_jobs
          estimator__random_state: 0
          estimator__refit: true
          estimator__return_train_score: false
          estimator__scoring: null
          estimator__train_test_combinations: null
          estimator__verbose: 1
    - - regressortobinaryclassifier
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error_gso
          estimator__max_col_features: null
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: null
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: bxt_gso_nrlmf
  params:
    regressortobinaryclassifier__estimator__min_cols_leaf: 1
    regressortobinaryclassifier__estimator__min_rows_leaf: 1
    regressortobinaryclassifier__estimator__min_samples_leaf: 1
hash: 5d9f504e30802af03404ca36bcde6dafd0250b08092756d976606edf163fe231
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/5d9f504_20230812T040135846874_bxt_gso_nrlmf_kiba.yml
results:
  LL_average_precision:
  - 0.9951375333905621
  - 0.9946939958330598
  - 0.990061738952867
  - 0.9903277363567926
  - 0.9903627540214951
  - 0.9941739965820116
  - 0.9906126969256183
  - 0.9895732653398904
  - 0.9901001707143662
  - 0.9938480138787332
  - 0.9895347866865549
  - 0.988892833613226
  - 0.9944049412007228
  - 0.9938569277601558
  - 0.9944550939243126
  - 0.9936786390221524
  LL_balanced_accuracy:
  - 0.9674857756114561
  - 0.9690232031062902
  - 0.961369292577956
  - 0.9600232510190576
  - 0.9604466917631027
  - 0.9691322824779227
  - 0.9622719666250052
  - 0.9604295480990033
  - 0.9601141616534077
  - 0.9676194436498569
  - 0.9607726910071028
  - 0.9593566058228664
  - 0.9668677634992711
  - 0.968266996634791
  - 0.9682353078336923
  - 0.9665993541109805
  LL_f1_macro:
  - 0.9249386596296681
  - 0.9263946792966133
  - 0.9138398543220672
  - 0.9087241962363448
  - 0.9111747222973381
  - 0.9275140008981182
  - 0.916453079236562
  - 0.9105901351572996
  - 0.9097076561643138
  - 0.9238403527409995
  - 0.9127804507720927
  - 0.9075040143504001
  - 0.925183904567322
  - 0.9266737069064181
  - 0.9294432928390224
  - 0.9242172040032559
  LL_f1_micro:
  - 0.9480555463200009
  - 0.9501388297169049
  - 0.9386174323113311
  - 0.9358959291307349
  - 0.9371058727045029
  - 0.9506383228782559
  - 0.9403913675828939
  - 0.936990406793107
  - 0.9364741607651472
  - 0.9483538762138418
  - 0.9379600111651413
  - 0.9351870895708766
  - 0.9474459507354244
  - 0.9495830396993188
  - 0.9499977977448908
  - 0.9469843786704252
  LL_f1_weighted:
  - 0.9502113188809099
  - 0.9522168497615769
  - 0.9414433906723807
  - 0.939080682443675
  - 0.9401084027004368
  - 0.9526475252133099
  - 0.9430403734730137
  - 0.9400345605328798
  - 0.9395782711214127
  - 0.9505650953090214
  - 0.9408460548078788
  - 0.938444829328117
  - 0.9495802010313316
  - 0.9516325829926647
  - 0.951889134804015
  - 0.9491740109164936
  LL_matthews_corrcoef:
  - 0.8600555378704902
  - 0.8625956752833351
  - 0.8409374763063262
  - 0.8322604966478823
  - 0.8363423580837794
  - 0.8645016114952442
  - 0.8453432111149837
  - 0.8353352280513711
  - 0.8338212576925542
  - 0.8580202479033998
  - 0.8390253203127493
  - 0.8300629191967271
  - 0.860465220599405
  - 0.8629903287639281
  - 0.8678834545073524
  - 0.8587643259089
  LL_precision_macro:
  - 0.895571141846081
  - 0.8966068704541742
  - 0.8831940326506255
  - 0.8764252854318686
  - 0.8797771557695377
  - 0.898268816809172
  - 0.8864635951188227
  - 0.8788771518382199
  - 0.8777637963161158
  - 0.8935886091829519
  - 0.8819472713255156
  - 0.874983423059274
  - 0.8964722206946392
  - 0.8976109318467074
  - 0.9021598104660363
  - 0.8951335128071989
  LL_precision_micro:
  - 0.9480555463200009
  - 0.9501388297169049
  - 0.9386174323113311
  - 0.9358959291307349
  - 0.9371058727045029
  - 0.9506383228782559
  - 0.9403913675828939
  - 0.936990406793107
  - 0.9364741607651472
  - 0.9483538762138418
  - 0.9379600111651413
  - 0.9351870895708766
  - 0.9474459507354244
  - 0.9495830396993188
  - 0.9499977977448908
  - 0.9469843786704252
  LL_precision_weighted:
  - 0.9588511975761238
  - 0.9604074362885413
  - 0.9528873788867224
  - 0.9516877739438361
  - 0.9521203994521601
  - 0.9606047294767732
  - 0.9538117341163548
  - 0.9521389587218783
  - 0.9518777964600585
  - 0.9592135615773509
  - 0.952462452707856
  - 0.9512464700630454
  - 0.9582559469331027
  - 0.9597959025944736
  - 0.9596936606249115
  - 0.9580191587775253
  LL_recall_macro:
  - 0.9674857756114561
  - 0.9690232031062902
  - 0.961369292577956
  - 0.9600232510190576
  - 0.9604466917631027
  - 0.9691322824779227
  - 0.9622719666250052
  - 0.9604295480990033
  - 0.9601141616534077
  - 0.9676194436498569
  - 0.9607726910071028
  - 0.9593566058228664
  - 0.9668677634992711
  - 0.968266996634791
  - 0.9682353078336923
  - 0.9665993541109805
  LL_recall_micro:
  - 0.9480555463200009
  - 0.9501388297169049
  - 0.9386174323113311
  - 0.9358959291307349
  - 0.9371058727045029
  - 0.9506383228782559
  - 0.9403913675828939
  - 0.936990406793107
  - 0.9364741607651472
  - 0.9483538762138418
  - 0.9379600111651413
  - 0.9351870895708766
  - 0.9474459507354244
  - 0.9495830396993188
  - 0.9499977977448908
  - 0.9469843786704252
  LL_recall_weighted:
  - 0.9480555463200009
  - 0.9501388297169049
  - 0.9386174323113311
  - 0.9358959291307349
  - 0.9371058727045029
  - 0.9506383228782559
  - 0.9403913675828939
  - 0.936990406793107
  - 0.9364741607651472
  - 0.9483538762138418
  - 0.9379600111651413
  - 0.9351870895708766
  - 0.9474459507354244
  - 0.9495830396993188
  - 0.9499977977448908
  - 0.9469843786704252
  LL_roc_auc:
  - 0.9989292744816165
  - 0.9988822203556426
  - 0.9977626092475715
  - 0.9978997456605487
  - 0.997838130967635
  - 0.9987673947507498
  - 0.9978417121394019
  - 0.9976938239778183
  - 0.997778283735518
  - 0.9986335681212628
  - 0.9975790464715022
  - 0.9975586266526046
  - 0.9987482715691719
  - 0.9986447601406098
  - 0.9987282157418407
  - 0.9986058067298226
  LT_average_precision:
  - 0.45856516422737914
  - 0.4139850629298556
  - 0.4157101275086431
  - 0.3923006146131648
  - 0.4741434143603988
  - 0.41877046889211655
  - 0.4229634793860464
  - 0.3974868901617683
  - 0.477397728709667
  - 0.41221243468750157
  - 0.42246486565719676
  - 0.397378279760033
  - 0.4658465790139958
  - 0.413977196696757
  - 0.4273628165446837
  - 0.39992262558282965
  LT_balanced_accuracy:
  - 0.7324680595959274
  - 0.7042698219610937
  - 0.720392996332867
  - 0.6945590394545746
  - 0.73902359206577
  - 0.7042716429204527
  - 0.7203885708860215
  - 0.6994105921986362
  - 0.7362760164056669
  - 0.7033655819094089
  - 0.7175727838476055
  - 0.6941312830561678
  - 0.7340778489901398
  - 0.7046289998280849
  - 0.7182798435756621
  - 0.6932514837549608
  LT_f1_macro:
  - 0.6629404037774264
  - 0.652983848894536
  - 0.6403938712430947
  - 0.6490882608498189
  - 0.6647751288778255
  - 0.6547004887290925
  - 0.6441392647137016
  - 0.6539395382574411
  - 0.6624414907132281
  - 0.651832368461031
  - 0.6409187543412305
  - 0.6509025702625099
  - 0.6657839382862094
  - 0.6548903571268346
  - 0.6435591929445826
  - 0.6529521345006706
  LT_f1_micro:
  - 0.7285925893654563
  - 0.7168157285190235
  - 0.7127594729084239
  - 0.7278983941217542
  - 0.7265667545254536
  - 0.7186111203466657
  - 0.7162615952388869
  - 0.7309239618312997
  - 0.7266103208660989
  - 0.7165829925413659
  - 0.7156742139619422
  - 0.731112367146546
  - 0.7288510101010099
  - 0.7164407230196704
  - 0.7142588162325004
  - 0.7320352649300018
  LT_f1_weighted:
  - 0.7538596319913868
  - 0.7390337553037426
  - 0.7435207087276214
  - 0.7493108056264743
  - 0.7523734856205324
  - 0.740191804012993
  - 0.7457028321549802
  - 0.7517356962459161
  - 0.752743678463517
  - 0.739032382690107
  - 0.7457743172928272
  - 0.7516493094298186
  - 0.7534100159160847
  - 0.7379551021599723
  - 0.7434012463137529
  - 0.7514372375787197
  LT_matthews_corrcoef:
  - 0.3823485150020869
  - 0.3471809337729107
  - 0.35082061046587354
  - 0.3308451621928539
  - 0.3917458764187813
  - 0.34856054108445716
  - 0.3536634352856255
  - 0.34008126284636225
  - 0.38626956199968826
  - 0.3450865923021939
  - 0.3475152649078285
  - 0.3318227205235418
  - 0.38713590952580273
  - 0.3497383458590558
  - 0.35166791244103635
  - 0.33316188281036163
  LT_precision_macro:
  - 0.6572155624071615
  - 0.6475188547410443
  - 0.6396086794674769
  - 0.6406494934047667
  - 0.6605122222086883
  - 0.6486922622544357
  - 0.6418832938513817
  - 0.6449963916961472
  - 0.6578706302878192
  - 0.6463924660562622
  - 0.6387660455598929
  - 0.6417936307356856
  - 0.6600687688849659
  - 0.6494374094910675
  - 0.6416419384112403
  - 0.6435911875047838
  LT_precision_micro:
  - 0.7285925893654562
  - 0.7168157285190234
  - 0.7127594729084239
  - 0.7278983941217542
  - 0.7265667545254536
  - 0.7186111203466657
  - 0.7162615952388869
  - 0.7309239618312997
  - 0.7266103208660989
  - 0.716582992541366
  - 0.7156742139619421
  - 0.731112367146546
  - 0.72885101010101
  - 0.7164407230196704
  - 0.7142588162325004
  - 0.7320352649300018
  LT_precision_weighted:
  - 0.8179069386725738
  - 0.7908122317327362
  - 0.8209312362142497
  - 0.7929953808301612
  - 0.8213093721880174
  - 0.7899032826019614
  - 0.8188732674055835
  - 0.7945955358759929
  - 0.8210694556855267
  - 0.7910836331778898
  - 0.8193546683677299
  - 0.7925920381546493
  - 0.8165844975220987
  - 0.788452670661733
  - 0.8161055542497103
  - 0.7895405022597843
  LT_recall_macro:
  - 0.7324680595959274
  - 0.7042698219610937
  - 0.720392996332867
  - 0.6945590394545746
  - 0.73902359206577
  - 0.7042716429204527
  - 0.7203885708860215
  - 0.6994105921986362
  - 0.7362760164056669
  - 0.7033655819094089
  - 0.7175727838476055
  - 0.6941312830561678
  - 0.7340778489901398
  - 0.7046289998280849
  - 0.7182798435756621
  - 0.6932514837549608
  LT_recall_micro:
  - 0.7285925893654562
  - 0.7168157285190234
  - 0.7127594729084239
  - 0.7278983941217542
  - 0.7265667545254536
  - 0.7186111203466657
  - 0.7162615952388869
  - 0.7309239618312997
  - 0.7266103208660989
  - 0.716582992541366
  - 0.7156742139619421
  - 0.731112367146546
  - 0.72885101010101
  - 0.7164407230196704
  - 0.7142588162325004
  - 0.7320352649300018
  LT_recall_weighted:
  - 0.7285925893654562
  - 0.7168157285190234
  - 0.7127594729084239
  - 0.7278983941217542
  - 0.7265667545254536
  - 0.7186111203466657
  - 0.7162615952388869
  - 0.7309239618312997
  - 0.7266103208660989
  - 0.716582992541366
  - 0.7156742139619421
  - 0.731112367146546
  - 0.72885101010101
  - 0.7164407230196704
  - 0.7142588162325004
  - 0.7320352649300018
  LT_roc_auc:
  - 0.8070498371011661
  - 0.7648064305488562
  - 0.7771725728798008
  - 0.761136180001869
  - 0.8126902313151287
  - 0.7662318843831066
  - 0.7761775777595021
  - 0.7636637642848351
  - 0.8153549846052663
  - 0.7646498086117103
  - 0.7749972427651591
  - 0.7619890388933449
  - 0.8084836919311942
  - 0.764057350770663
  - 0.7785473763631503
  - 0.7630969265651709
  TL_average_precision:
  - 0.7017445039674901
  - 0.6926514236334224
  - 0.7043978867282503
  - 0.68769071462023
  - 0.6709132242061544
  - 0.6560775983813091
  - 0.6587781055815453
  - 0.6464334338149554
  - 0.6926551367153153
  - 0.6777984324093619
  - 0.6829683365468041
  - 0.669777374301777
  - 0.6722538622984808
  - 0.6577704856039802
  - 0.6638807489190801
  - 0.6472148622236493
  TL_balanced_accuracy:
  - 0.8146695603339082
  - 0.8133982698174388
  - 0.8105870324559145
  - 0.808395423672083
  - 0.8184810329502956
  - 0.816742960213058
  - 0.8115230229255299
  - 0.8106334923188019
  - 0.8234735004247968
  - 0.8237651181252756
  - 0.8188486675063686
  - 0.813725761110029
  - 0.8168459103815394
  - 0.8132103606044951
  - 0.8103365890909532
  - 0.8031289535003747
  TL_f1_macro:
  - 0.7225381271604938
  - 0.7161383580204945
  - 0.7151822985464255
  - 0.7100058587157316
  - 0.7182656608126273
  - 0.7126025131115061
  - 0.7102561298852301
  - 0.7053738548478846
  - 0.7312137875129634
  - 0.7272840832873794
  - 0.7256507512430317
  - 0.718127709950544
  - 0.7146346535217127
  - 0.7062567816417995
  - 0.7112367037140752
  - 0.6989966494893193
  TL_f1_micro:
  - 0.7684963671805776
  - 0.7643036469344608
  - 0.7577959830866807
  - 0.7555166490486258
  - 0.7652954988481303
  - 0.7623766737138831
  - 0.7537328224101479
  - 0.7521141649048626
  - 0.7757398546872231
  - 0.7742908738548273
  - 0.7672656800563779
  - 0.7624647639182521
  - 0.7666921890431329
  - 0.7609218481090863
  - 0.7610873306561935
  - 0.7523939808481532
  TL_f1_weighted:
  - 0.7897107488063508
  - 0.7869989755368424
  - 0.7799568459078315
  - 0.7788444552728496
  - 0.7880614132887489
  - 0.7864406379020248
  - 0.7772254870170491
  - 0.7769263797039914
  - 0.7959939566488242
  - 0.7956149812669224
  - 0.7880060805404506
  - 0.7844794197336361
  - 0.7904027802415223
  - 0.7863664143769196
  - 0.7846691576861116
  - 0.7782884277227262
  TL_matthews_corrcoef:
  - 0.5184853458561057
  - 0.510853273309531
  - 0.5113517453569824
  - 0.5032683672810124
  - 0.518154031287639
  - 0.510281255450501
  - 0.5081009334343666
  - 0.5012467306694832
  - 0.53465335474445
  - 0.5301322276396794
  - 0.5280221078598281
  - 0.515359107316104
  - 0.5103640427371572
  - 0.4988032366379692
  - 0.503048995957384
  - 0.48458841999900415
  TL_precision_macro:
  - 0.7135788520362938
  - 0.7081784521362255
  - 0.710472894998238
  - 0.705320045357586
  - 0.7107532100518629
  - 0.7055191372595854
  - 0.7071809622065955
  - 0.7022063711895161
  - 0.720925523546829
  - 0.7170093094104295
  - 0.7186047605037952
  - 0.7116458404259819
  - 0.7055190295855172
  - 0.6985923042267196
  - 0.7038579249348245
  - 0.6936683497942742
  TL_precision_micro:
  - 0.7684963671805777
  - 0.7643036469344608
  - 0.7577959830866807
  - 0.7555166490486258
  - 0.7652954988481304
  - 0.7623766737138831
  - 0.7537328224101479
  - 0.7521141649048626
  - 0.7757398546872231
  - 0.7742908738548273
  - 0.7672656800563777
  - 0.7624647639182522
  - 0.7666921890431329
  - 0.7609218481090861
  - 0.7610873306561935
  - 0.7523939808481532
  TL_precision_weighted:
  - 0.8626644718992739
  - 0.8643257689351174
  - 0.860346181568255
  - 0.8610909611684325
  - 0.8676453991250271
  - 0.8688105335738283
  - 0.8631829535925013
  - 0.8650581195214899
  - 0.8672211205960518
  - 0.8694116387341457
  - 0.8639621843820372
  - 0.8627014053361153
  - 0.8690278594903355
  - 0.8694722287619375
  - 0.863838423302763
  - 0.8629763988029454
  TL_recall_macro:
  - 0.8146695603339082
  - 0.8133982698174388
  - 0.8105870324559145
  - 0.808395423672083
  - 0.8184810329502956
  - 0.816742960213058
  - 0.8115230229255299
  - 0.8106334923188019
  - 0.8234735004247968
  - 0.8237651181252756
  - 0.8188486675063686
  - 0.813725761110029
  - 0.8168459103815394
  - 0.8132103606044951
  - 0.8103365890909532
  - 0.8031289535003747
  TL_recall_micro:
  - 0.7684963671805777
  - 0.7643036469344608
  - 0.7577959830866807
  - 0.7555166490486258
  - 0.7652954988481304
  - 0.7623766737138831
  - 0.7537328224101479
  - 0.7521141649048626
  - 0.7757398546872231
  - 0.7742908738548273
  - 0.7672656800563777
  - 0.7624647639182522
  - 0.7666921890431329
  - 0.7609218481090861
  - 0.7610873306561935
  - 0.7523939808481532
  TL_recall_weighted:
  - 0.7684963671805777
  - 0.7643036469344608
  - 0.7577959830866807
  - 0.7555166490486258
  - 0.7652954988481304
  - 0.7623766737138831
  - 0.7537328224101479
  - 0.7521141649048626
  - 0.7757398546872231
  - 0.7742908738548273
  - 0.7672656800563777
  - 0.7624647639182522
  - 0.7666921890431329
  - 0.7609218481090861
  - 0.7610873306561935
  - 0.7523939808481532
  TL_roc_auc:
  - 0.9001022752576004
  - 0.8993791366293392
  - 0.8986745829225852
  - 0.8961868897615124
  - 0.901963642796393
  - 0.900084117442093
  - 0.8950385655800687
  - 0.8953460922305324
  - 0.9066588868103607
  - 0.9048680612680539
  - 0.9012481569109578
  - 0.8992236605309574
  - 0.8969565045995526
  - 0.8938485650262276
  - 0.8907625053425532
  - 0.8870269508302195
  TT_average_precision:
  - 0.3544209702431076
  - 0.32567000875539504
  - 0.32678309244238657
  - 0.30332319301702587
  - 0.3303372713960098
  - 0.3189829907712708
  - 0.30407219931364143
  - 0.289091798732535
  - 0.3506539457200928
  - 0.3179894794451247
  - 0.32276460048312194
  - 0.2886968108770259
  - 0.3364691882408781
  - 0.3057303158561586
  - 0.31043097282388366
  - 0.28348485769576776
  TT_balanced_accuracy:
  - 0.6506428416655241
  - 0.6143408771281623
  - 0.6403163961304821
  - 0.6019846085648468
  - 0.6403438060397076
  - 0.6185965792975618
  - 0.6440118863479329
  - 0.5998699930206779
  - 0.6554680540846061
  - 0.6112402192989308
  - 0.647197557569801
  - 0.5939220600931132
  - 0.6423232052858074
  - 0.6137264089972301
  - 0.6451596246658893
  - 0.5957040116673518
  TT_f1_macro:
  - 0.573499747735349
  - 0.5663083625412357
  - 0.5633242662895295
  - 0.5643340741992441
  - 0.5594552191182791
  - 0.5683409020266373
  - 0.559929959018822
  - 0.5572991588039269
  - 0.5808768365986128
  - 0.5694819320497713
  - 0.575046418066117
  - 0.560561635026148
  - 0.5681496865387237
  - 0.5660104364326376
  - 0.5666352153917101
  - 0.5615527537470804
  TT_f1_micro:
  - 0.6265347439916406
  - 0.6256645401382244
  - 0.6246012759170654
  - 0.6429425837320574
  - 0.6117097701149425
  - 0.6294524189261032
  - 0.6236709197235513
  - 0.6349681020733652
  - 0.6332941483803552
  - 0.6315457203615098
  - 0.6401182881446039
  - 0.6445707070707071
  - 0.6329254727474972
  - 0.6366723259762309
  - 0.6427976963281068
  - 0.656313459169746
  TT_f1_weighted:
  - 0.6642471003442716
  - 0.6577362811498538
  - 0.6654526156687561
  - 0.6735890802520467
  - 0.6521628286991612
  - 0.6621992119803206
  - 0.6671665848945103
  - 0.6687195276825977
  - 0.6692554250690298
  - 0.6613582813174155
  - 0.678513840931851
  - 0.6743400134726966
  - 0.6729028248374872
  - 0.6701348493637589
  - 0.6857022178688673
  - 0.6869028798675889
  TT_matthews_corrcoef:
  - 0.24151744942132608
  - 0.19069764450005303
  - 0.22094733527427662
  - 0.17045324481994253
  - 0.2228709087476982
  - 0.19659911141421116
  - 0.2228762999090982
  - 0.16433609588693154
  - 0.2511686153640152
  - 0.18770125453825615
  - 0.23349156236648339
  - 0.15778455449978243
  - 0.224381494372648
  - 0.1871492447933982
  - 0.2230467790070016
  - 0.15902154847413089
  TT_precision_macro:
  - 0.596802937547633
  - 0.5795113535317451
  - 0.5869779411228025
  - 0.5712222880454876
  - 0.5884817138847781
  - 0.581476234048624
  - 0.5862321963847452
  - 0.5676037706485249
  - 0.6014447529354571
  - 0.5791794577026105
  - 0.5925937743064943
  - 0.5662676202321725
  - 0.5884378884592254
  - 0.5769936379236075
  - 0.5856813072848361
  - 0.5660574526567547
  TT_precision_micro:
  - 0.6265347439916406
  - 0.6256645401382244
  - 0.6246012759170654
  - 0.6429425837320574
  - 0.6117097701149425
  - 0.6294524189261032
  - 0.6236709197235513
  - 0.6349681020733652
  - 0.6332941483803552
  - 0.6315457203615098
  - 0.6401182881446039
  - 0.6445707070707071
  - 0.6329254727474972
  - 0.6366723259762309
  - 0.6427976963281068
  - 0.656313459169746
  TT_precision_weighted:
  - 0.7728876553272389
  - 0.7341669124026161
  - 0.7750946150941168
  - 0.7345974436556123
  - 0.7709516501479339
  - 0.7402284805077406
  - 0.7845401124756723
  - 0.7385095744485829
  - 0.7724947414130574
  - 0.728358928759859
  - 0.7769235270265525
  - 0.7305234598786372
  - 0.7763616116751735
  - 0.7440397196205056
  - 0.7901640043379128
  - 0.7423606363634787
  TT_recall_macro:
  - 0.6506428416655241
  - 0.6143408771281623
  - 0.6403163961304821
  - 0.6019846085648468
  - 0.6403438060397076
  - 0.6185965792975618
  - 0.6440118863479329
  - 0.5998699930206779
  - 0.6554680540846061
  - 0.6112402192989308
  - 0.647197557569801
  - 0.5939220600931132
  - 0.6423232052858074
  - 0.6137264089972301
  - 0.6451596246658893
  - 0.5957040116673518
  TT_recall_micro:
  - 0.6265347439916406
  - 0.6256645401382244
  - 0.6246012759170654
  - 0.6429425837320574
  - 0.6117097701149425
  - 0.6294524189261032
  - 0.6236709197235513
  - 0.6349681020733652
  - 0.6332941483803552
  - 0.6315457203615098
  - 0.6401182881446039
  - 0.6445707070707071
  - 0.6329254727474972
  - 0.6366723259762309
  - 0.6427976963281068
  - 0.656313459169746
  TT_recall_weighted:
  - 0.6265347439916406
  - 0.6256645401382244
  - 0.6246012759170654
  - 0.6429425837320574
  - 0.6117097701149425
  - 0.6294524189261032
  - 0.6236709197235513
  - 0.6349681020733652
  - 0.6332941483803552
  - 0.6315457203615098
  - 0.6401182881446039
  - 0.6445707070707071
  - 0.6329254727474972
  - 0.6366723259762309
  - 0.6427976963281068
  - 0.656313459169746
  TT_roc_auc:
  - 0.7111449644842514
  - 0.6695659394335733
  - 0.6939713038588917
  - 0.6627432278108328
  - 0.7030077563011949
  - 0.6745365798629971
  - 0.6988039824748735
  - 0.661187629307181
  - 0.7156512094696426
  - 0.6696632842394419
  - 0.7038458663058563
  - 0.6606995766483184
  - 0.7095779897420096
  - 0.6694603602581197
  - 0.7019715296393012
  - 0.6597318455581527
  fit_time:
  - 3379.757253885269
  - 3096.797731399536
  - 2896.8917157649994
  - 2995.7864146232605
  - 3252.521423101425
  - 3153.3271012306213
  - 2808.1108515262604
  - 2848.6414012908936
  - 3113.605429172516
  - 3400.146171569824
  - 2787.307993412018
  - 2722.5583786964417
  - 3326.3756737709045
  - 3281.903841972351
  - 3101.218680381775
  - 2978.238137960434
  score_time:
  - 43.69430136680603
  - 43.0253803730011
  - 41.89361023902893
  - 41.55966877937317
  - 47.06588053703308
  - 41.89257478713989
  - 51.72137761116028
  - 44.083431243896484
  - 44.56715703010559
  - 42.97446346282959
  - 50.63142466545105
  - 55.98727560043335
  - 49.714383125305176
  - 43.412137508392334
  - 46.9822883605957
  - 40.93767738342285
start: 2023-08-12 04:01:35.846874
wrapper: null
