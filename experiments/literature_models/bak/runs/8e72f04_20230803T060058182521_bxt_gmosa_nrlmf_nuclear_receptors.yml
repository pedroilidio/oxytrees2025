active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: runs
end: 2023-08-03 06:00:59.239780
estimator:
  call: y_reconstruction.estimators.bxt_gmosa_nrlmf
  final_params:
    memory: /tmp
    steps:
    - - symmetryenforcer
      - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
        params:
          ndim: 2
          samplers:
            call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
            params:
              sampling_strategy: auto
          samplers__sampling_strategy: auto
    - - regressorassampler
      - call: y_reconstruction.estimators.RegressorAsSampler
        params:
          estimator:
            call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
            params:
              cv:
                call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                params: {}
              diagonal: false
              error_score: .nan
              estimator:
                call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
                params:
                  alpha_cols: same
                  alpha_rows: 0.1
                  keep_positives: true
                  lambda_cols: same
                  lambda_rows: 0.625
                  learning_rate: 1.0
                  max_iter: 100
                  n_components_cols: same
                  n_components_rows: 10
                  n_neighbors: 5
                  positive_importance: 5
                  random_state: null
                  resample_X: false
                  tol: 1.0e-05
                  verbose: false
              estimator__alpha_cols: same
              estimator__alpha_rows: 0.1
              estimator__keep_positives: true
              estimator__lambda_cols: same
              estimator__lambda_rows: 0.625
              estimator__learning_rate: 1.0
              estimator__max_iter: 100
              estimator__n_components_cols: same
              estimator__n_components_rows: 10
              estimator__n_neighbors: 5
              estimator__positive_importance: 5
              estimator__random_state: null
              estimator__resample_X: false
              estimator__tol: 1.0e-05
              estimator__verbose: false
              n_iter: 100
              n_jobs: 3
              pairwise: true
              param_distributions:
                alpha_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                alpha_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_cols:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                lambda_rows:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                learning_rate:
                  call: scipy.stats._distn_infrastructure.rv_frozen
                  params: {}
                n_components_rows:
                - 50
                - 100
                n_neighbors:
                - 3
                - 5
                - 10
              pre_dispatch: 2*n_jobs
              random_state: 0
              refit: true
              return_train_score: false
              scoring: null
              train_test_combinations: null
              verbose: 1
          estimator__cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          estimator__diagonal: false
          estimator__error_score: .nan
          estimator__estimator:
            call: bipartite_learn.matrix_factorization._nrlmf.NRLMF
            params:
              alpha_cols: same
              alpha_rows: 0.1
              keep_positives: true
              lambda_cols: same
              lambda_rows: 0.625
              learning_rate: 1.0
              max_iter: 100
              n_components_cols: same
              n_components_rows: 10
              n_neighbors: 5
              positive_importance: 5
              random_state: null
              resample_X: false
              tol: 1.0e-05
              verbose: false
          estimator__estimator__alpha_cols: same
          estimator__estimator__alpha_rows: 0.1
          estimator__estimator__keep_positives: true
          estimator__estimator__lambda_cols: same
          estimator__estimator__lambda_rows: 0.625
          estimator__estimator__learning_rate: 1.0
          estimator__estimator__max_iter: 100
          estimator__estimator__n_components_cols: same
          estimator__estimator__n_components_rows: 10
          estimator__estimator__n_neighbors: 5
          estimator__estimator__positive_importance: 5
          estimator__estimator__random_state: null
          estimator__estimator__resample_X: false
          estimator__estimator__tol: 1.0e-05
          estimator__estimator__verbose: false
          estimator__n_iter: 100
          estimator__n_jobs: 3
          estimator__pairwise: true
          estimator__param_distributions:
            alpha_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            alpha_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_cols:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            lambda_rows:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            learning_rate:
              call: scipy.stats._distn_infrastructure.rv_frozen
              params: {}
            n_components_rows:
            - 50
            - 100
            n_neighbors:
            - 3
            - 5
            - 10
          estimator__pre_dispatch: 2*n_jobs
          estimator__random_state: 0
          estimator__refit: true
          estimator__return_train_score: false
          estimator__scoring: null
          estimator__train_test_combinations: null
          estimator__verbose: 1
    - - regressortobinaryclassifier
      - call: bipartite_approaches.estimators.RegressorToBinaryClassifier
        params:
          estimator:
            call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 0
              warm_start: false
          estimator__bipartite_adapter: gmosa
          estimator__bootstrap: false
          estimator__ccp_alpha: 0.0
          estimator__criterion: squared_error
          estimator__max_col_features: null
          estimator__max_depth: null
          estimator__max_features: 1.0
          estimator__max_leaf_nodes: null
          estimator__max_row_features: null
          estimator__max_samples: null
          estimator__min_col_weight_fraction_leaf: 0.0
          estimator__min_cols_leaf: 1
          estimator__min_cols_split: 1
          estimator__min_impurity_decrease: 0.0
          estimator__min_row_weight_fraction_leaf: 0.0
          estimator__min_rows_leaf: 1
          estimator__min_rows_split: 1
          estimator__min_samples_leaf: 1
          estimator__min_samples_split: 2
          estimator__min_weight_fraction_leaf: 0.0
          estimator__n_estimators: 100
          estimator__n_jobs: 3
          estimator__oob_score: false
          estimator__prediction_weights: null
          estimator__random_state: 0
          estimator__verbose: 0
          estimator__warm_start: false
    verbose: false
  name: bxt_gmosa_nrlmf
  params:
    regressortobinaryclassifier__estimator__min_cols_leaf: 1
    regressortobinaryclassifier__estimator__min_rows_leaf: 1
    regressortobinaryclassifier__estimator__min_samples_leaf: 1
hash: f08f728d7e8825e5ad7a5a76243e846c191be729960384bbbdb96e0b1f9df0b4
path: /home/pedro/mestrado/biomal_repo/scripts/run_experiments/literature_models2/runs/f08f728_20230803T060058182521_bxt_gmosa_nrlmf_nuclear_receptors.yml
results:
  LL_average_precision:
  - 0.9791032720634565
  - 1.0
  - 1.0
  - 0.981535511674231
  - 0.8853804650498674
  - 1.0
  - 0.9994192799070848
  - 0.9730511104688171
  - 0.9387036187259058
  - 1.0
  - 1.0
  - 0.9759331338854874
  - 0.95098246312175
  - 0.9569631570166561
  - 0.9988406600310423
  - 0.9896166254204478
  LL_balanced_accuracy:
  - 0.9327195467422096
  - 0.9127094972067039
  - 0.9565517241379311
  - 0.9406077348066298
  - 0.894297635605007
  - 0.9112792297111416
  - 0.929539295392954
  - 0.9360544217687075
  - 0.9237516869095816
  - 0.9312169312169312
  - 0.9519480519480519
  - 0.9480263157894737
  - 0.9004065040650406
  - 0.89
  - 0.9178712220762155
  - 0.9355263157894738
  LL_f1_macro:
  - 0.7299430336897936
  - 0.6587533361351481
  - 0.7930785868781542
  - 0.7490410261020708
  - 0.6161156969866146
  - 0.6205515239477504
  - 0.6825292328913133
  - 0.7076012650140557
  - 0.7141402546807952
  - 0.6922348484848485
  - 0.7621175769550423
  - 0.7740960179105101
  - 0.6734775474165577
  - 0.6268814924740301
  - 0.698059628068377
  - 0.7407708486561118
  LL_f1_micro:
  - 0.875
  - 0.8355263157894737
  - 0.9191270860077022
  - 0.889602053915276
  - 0.8000000000000002
  - 0.8302631578947368
  - 0.8664955070603337
  - 0.8793324775353016
  - 0.85875
  - 0.87
  - 0.9097560975609756
  - 0.9036585365853659
  - 0.81625
  - 0.79375
  - 0.8475609756097561
  - 0.8804878048780487
  LL_f1_weighted:
  - 0.899740416157037
  - 0.8759223349060928
  - 0.9321880324635599
  - 0.9103366137642223
  - 0.8531376693118529
  - 0.8781442212206859
  - 0.8987594067459631
  - 0.9063722329406569
  - 0.8874686313199827
  - 0.9004071969696968
  - 0.9266682500762063
  - 0.9201407249514102
  - 0.8559240085628848
  - 0.8452141191435234
  - 0.8799486158916842
  - 0.9032324256583641
  LL_matthews_corrcoef:
  - 0.560043808498323
  - 0.4635752222791713
  - 0.649178219553541
  - 0.5862904832079467
  - 0.409298693265521
  - 0.40933874077239724
  - 0.4928609108000309
  - 0.5273174463677581
  - 0.5391784181518762
  - 0.506358821784766
  - 0.6037170160281863
  - 0.6219206610133072
  - 0.4874030709874187
  - 0.4259053284912145
  - 0.5176703889048294
  - 0.5751343150486117
  LL_precision_macro:
  - 0.6812080536912751
  - 0.6301775147928994
  - 0.7307692307692308
  - 0.6950354609929078
  - 0.6062176165803109
  - 0.6018518518518519
  - 0.6413793103448275
  - 0.6594202898550725
  - 0.6715116279069767
  - 0.6486486486486487
  - 0.7016129032258065
  - 0.7158273381294964
  - 0.6483253588516746
  - 0.6162790697674418
  - 0.6603260869565217
  - 0.689873417721519
  LL_precision_micro:
  - 0.875
  - 0.8355263157894737
  - 0.9191270860077022
  - 0.889602053915276
  - 0.8
  - 0.8302631578947368
  - 0.8664955070603337
  - 0.8793324775353016
  - 0.85875
  - 0.87
  - 0.9097560975609756
  - 0.9036585365853659
  - 0.81625
  - 0.79375
  - 0.8475609756097561
  - 0.8804878048780488
  LL_precision_weighted:
  - 0.9546979865771813
  - 0.9571784490812831
  - 0.9626740396958625
  - 0.9569369713853914
  - 0.9575129533678756
  - 0.965423976608187
  - 0.9622504537205082
  - 0.9615262971851687
  - 0.951547965116279
  - 0.9613513513513513
  - 0.9636113296616837
  - 0.9584137567994385
  - 0.9454904306220095
  - 0.9520348837209301
  - 0.9511200954400848
  - 0.9546156221055883
  LL_recall_macro:
  - 0.9327195467422096
  - 0.9127094972067039
  - 0.9565517241379311
  - 0.9406077348066298
  - 0.894297635605007
  - 0.9112792297111416
  - 0.929539295392954
  - 0.9360544217687075
  - 0.9237516869095816
  - 0.9312169312169312
  - 0.9519480519480519
  - 0.9480263157894737
  - 0.9004065040650406
  - 0.89
  - 0.9178712220762155
  - 0.9355263157894738
  LL_recall_micro:
  - 0.875
  - 0.8355263157894737
  - 0.9191270860077022
  - 0.889602053915276
  - 0.8
  - 0.8302631578947368
  - 0.8664955070603337
  - 0.8793324775353016
  - 0.85875
  - 0.87
  - 0.9097560975609756
  - 0.9036585365853659
  - 0.81625
  - 0.79375
  - 0.8475609756097561
  - 0.8804878048780488
  LL_recall_weighted:
  - 0.875
  - 0.8355263157894737
  - 0.9191270860077022
  - 0.889602053915276
  - 0.8
  - 0.8302631578947368
  - 0.8664955070603337
  - 0.8793324775353016
  - 0.85875
  - 0.87
  - 0.9097560975609756
  - 0.9036585365853659
  - 0.81625
  - 0.79375
  - 0.8475609756097561
  - 0.8804878048780488
  LL_roc_auc:
  - 0.9980458503829609
  - 1.0
  - 0.9999999999999999
  - 0.998455549974887
  - 0.9916211540418604
  - 1.0
  - 0.999966950889021
  - 0.9979282622139765
  - 0.9936183352775682
  - 1.0
  - 1.0
  - 0.9981140350877193
  - 0.9947001486143894
  - 0.9962133333333333
  - 0.9999109111561504
  - 0.9991337719298246
  LT_average_precision:
  - 0.32222870194807923
  - 0.45062257494351105
  - 0.29616153248060606
  - 0.4726732112362312
  - 0.31591798932283555
  - 0.3115725187667736
  - 0.18772436627683808
  - 0.3138411084489589
  - 0.36487185863826516
  - 0.4907089847680485
  - 0.2871951032446345
  - 0.44296634597520607
  - 0.37014643978231737
  - 0.4693973970705888
  - 0.40941716098844694
  - 0.41007836111070933
  LT_balanced_accuracy:
  - 0.7362549800796813
  - 0.7832365145228215
  - 0.7310344827586206
  - 0.7984365419987738
  - 0.6833989501312336
  - 0.635569105691057
  - 0.7388297872340426
  - 0.7556022408963585
  - 0.7587064676616915
  - 0.7779973649538867
  - 0.6811117752540347
  - 0.7719970792259949
  - 0.7723270440251573
  - 0.7967354706485141
  - 0.7598714416896235
  - 0.7726942628903413
  LT_f1_macro:
  - 0.6207983193277312
  - 0.6763274336283186
  - 0.6173352902804957
  - 0.6041261722080136
  - 0.529092411188481
  - 0.5633748172023756
  - 0.5239752624766287
  - 0.5701357466063348
  - 0.5893333333333333
  - 0.7085876627942955
  - 0.5770725924292134
  - 0.6425479912419166
  - 0.588951718138321
  - 0.6424908424908424
  - 0.6011363636363636
  - 0.6277980218636127
  LT_f1_micro:
  - 0.8571428571428571
  - 0.8345864661654135
  - 0.8461538461538461
  - 0.8097165991902834
  - 0.7744360902255639
  - 0.793233082706767
  - 0.728744939271255
  - 0.8380566801619433
  - 0.8428571428571429
  - 0.8678571428571429
  - 0.7730769230769231
  - 0.8961538461538462
  - 0.8071428571428572
  - 0.7821428571428573
  - 0.7923076923076923
  - 0.8307692307692308
  LT_f1_weighted:
  - 0.88640456182473
  - 0.8601121165746224
  - 0.8773019218224698
  - 0.857071697540132
  - 0.8383276733081375
  - 0.8325352731816111
  - 0.8058495706568858
  - 0.8847710993459981
  - 0.884342857142857
  - 0.8824760806406893
  - 0.8184790561648106
  - 0.9181561805982601
  - 0.8563428198595663
  - 0.8228414442700156
  - 0.8390384615384614
  - 0.866712049012934
  LT_matthews_corrcoef:
  - 0.30186326866201807
  - 0.40816446323834815
  - 0.2965998205232456
  - 0.33173554959040463
  - 0.1800625489778191
  - 0.17899691321511263
  - 0.22506449447577223
  - 0.25261263815776364
  - 0.27805498834326725
  - 0.44292069548909335
  - 0.23160975179820875
  - 0.3427407217305615
  - 0.2970997998767883
  - 0.3907676612367355
  - 0.3096022064321388
  - 0.33952781853818437
  LT_precision_macro:
  - 0.5964227642276423
  - 0.6470486859112452
  - 0.5951929907648591
  - 0.5921875
  - 0.5441967109424415
  - 0.5590840641332271
  - 0.5530231459612659
  - 0.5624145006839946
  - 0.5747126436781609
  - 0.6764214046822743
  - 0.5740469208211144
  - 0.6079710144927536
  - 0.5810315143349053
  - 0.6286494034018786
  - 0.5922124470511567
  - 0.6056853363354912
  LT_precision_micro:
  - 0.8571428571428571
  - 0.8345864661654135
  - 0.8461538461538461
  - 0.8097165991902834
  - 0.7744360902255639
  - 0.793233082706767
  - 0.728744939271255
  - 0.8380566801619433
  - 0.8428571428571429
  - 0.8678571428571429
  - 0.7730769230769231
  - 0.8961538461538462
  - 0.8071428571428572
  - 0.7821428571428571
  - 0.7923076923076923
  - 0.8307692307692308
  LT_precision_weighted:
  - 0.9308246225319395
  - 0.906716381647786
  - 0.9252445399734056
  - 0.9399164979757085
  - 0.9365764981714247
  - 0.8898195528683521
  - 0.9410029470318358
  - 0.9544769795687789
  - 0.947783251231527
  - 0.9065516005733397
  - 0.8930803067899843
  - 0.9509085841694537
  - 0.9388026263728039
  - 0.9084036013491459
  - 0.9217810862972153
  - 0.9276407802723592
  LT_recall_macro:
  - 0.7362549800796813
  - 0.7832365145228215
  - 0.7310344827586206
  - 0.7984365419987738
  - 0.6833989501312336
  - 0.635569105691057
  - 0.7388297872340426
  - 0.7556022408963585
  - 0.7587064676616915
  - 0.7779973649538867
  - 0.6811117752540347
  - 0.7719970792259949
  - 0.7723270440251573
  - 0.7967354706485141
  - 0.7598714416896235
  - 0.7726942628903413
  LT_recall_micro:
  - 0.8571428571428571
  - 0.8345864661654135
  - 0.8461538461538461
  - 0.8097165991902834
  - 0.7744360902255639
  - 0.793233082706767
  - 0.728744939271255
  - 0.8380566801619433
  - 0.8428571428571429
  - 0.8678571428571429
  - 0.7730769230769231
  - 0.8961538461538462
  - 0.8071428571428572
  - 0.7821428571428571
  - 0.7923076923076923
  - 0.8307692307692308
  LT_recall_weighted:
  - 0.8571428571428571
  - 0.8345864661654135
  - 0.8461538461538461
  - 0.8097165991902834
  - 0.7744360902255639
  - 0.793233082706767
  - 0.728744939271255
  - 0.8380566801619433
  - 0.8428571428571429
  - 0.8678571428571429
  - 0.7730769230769231
  - 0.8961538461538462
  - 0.8071428571428572
  - 0.7821428571428571
  - 0.7923076923076923
  - 0.8307692307692308
  LT_roc_auc:
  - 0.7320053120849933
  - 0.8240663900414938
  - 0.8479885057471265
  - 0.822501532801962
  - 0.7742782152230971
  - 0.5715447154471545
  - 0.8085106382978724
  - 0.8674136321195145
  - 0.7739427860696517
  - 0.8057385448689797
  - 0.8186889818688982
  - 0.8977729098211026
  - 0.7683018867924528
  - 0.8675157370809544
  - 0.8955463728191001
  - 0.8182038247397724
  TL_average_precision:
  - 0.40667958610911153
  - 0.5118755020651817
  - 0.5720173291093689
  - 0.437256360182302
  - 0.35329681387827255
  - 0.2993940644933752
  - 0.4566677442320079
  - 0.43815003973604577
  - 0.06864113082830821
  - 0.1187324173972989
  - 0.14046283746933705
  - 0.13634591886565336
  - 0.3286269071431112
  - 0.32196247347146334
  - 0.4733352225423708
  - 0.3556032438865052
  TL_balanced_accuracy:
  - 0.7483036471586091
  - 0.7806107749927975
  - 0.8113553113553114
  - 0.6905204460966543
  - 0.7382432957637
  - 0.6497395833333334
  - 0.7347578347578347
  - 0.7121090617481957
  - 0.4503558115892917
  - 0.4525584547610979
  - 0.5211988304093567
  - 0.5594255529877847
  - 0.6108695652173913
  - 0.5769466584917229
  - 0.70042194092827
  - 0.5721360184879498
  TL_f1_macro:
  - 0.649514530261511
  - 0.6191273412158627
  - 0.6764625850340136
  - 0.6127365476386375
  - 0.6583085814280123
  - 0.6118951612903225
  - 0.670247160988644
  - 0.683038828179493
  - 0.4574856546687533
  - 0.45914895497326674
  - 0.49938949938949945
  - 0.5040888516982998
  - 0.4772562265223019
  - 0.4567966981760085
  - 0.4972129319955408
  - 0.4910125436441226
  TL_f1_micro:
  - 0.8678571428571429
  - 0.8607142857142858
  - 0.8989547038327527
  - 0.8571428571428571
  - 0.8107142857142857
  - 0.8428571428571429
  - 0.8501742160278746
  - 0.8675958188153311
  - 0.7833333333333333
  - 0.7875
  - 0.7764227642276422
  - 0.7845528455284553
  - 0.7125
  - 0.7166666666666667
  - 0.7317073170731707
  - 0.7398373983739838
  TL_f1_weighted:
  - 0.8905805821770503
  - 0.8942981210481472
  - 0.9185863613738177
  - 0.8817978795928441
  - 0.8359794024676254
  - 0.8599654377880184
  - 0.8679971790270437
  - 0.8760230786617161
  - 0.8323856720570337
  - 0.8349089744156245
  - 0.8172965246135979
  - 0.8376136011179441
  - 0.7987073455601502
  - 0.8105955709403986
  - 0.8154553117437531
  - 0.8092768927172007
  TL_matthews_corrcoef:
  - 0.34451577589108
  - 0.3244735542101008
  - 0.40991831524815076
  - 0.26401250392828607
  - 0.360086726634386
  - 0.23958333333333334
  - 0.36728152059409874
  - 0.3731126095902284
  - -0.059712403032786035
  - -0.05762732135648112
  - 0.028558887563549393
  - 0.06709646661641681
  - 0.09790021769611194
  - 0.05772797029426892
  - 0.1675172397915876
  - 0.07474480592761104
  TL_precision_macro:
  - 0.6195019899989795
  - 0.5937981510015409
  - 0.6349206349206349
  - 0.5914634146341463
  - 0.63606096478248
  - 0.5958333333333333
  - 0.6436541143654114
  - 0.6640818858560794
  - 0.4820443681823753
  - 0.4825
  - 0.5096185737976783
  - 0.5189393939393939
  - 0.5216120010170353
  - 0.510827366059874
  - 0.5350036845983788
  - 0.5193619849357555
  TL_precision_micro:
  - 0.8678571428571429
  - 0.8607142857142858
  - 0.8989547038327527
  - 0.8571428571428571
  - 0.8107142857142857
  - 0.8428571428571429
  - 0.8501742160278746
  - 0.867595818815331
  - 0.7833333333333333
  - 0.7875
  - 0.7764227642276422
  - 0.7845528455284553
  - 0.7125
  - 0.7166666666666667
  - 0.7317073170731707
  - 0.7398373983739838
  TL_precision_weighted:
  - 0.9255558147332819
  - 0.9469059542152763
  - 0.9500580720092914
  - 0.9167587320472507
  - 0.8801277850589777
  - 0.8823809523809524
  - 0.8955870132520812
  - 0.8870708363233933
  - 0.8901192956653184
  - 0.8904374999999999
  - 0.8687780609149375
  - 0.9085057896033506
  - 0.933331214509704
  - 0.9496922899951111
  - 0.9502669087118285
  - 0.9105280410358378
  TL_recall_macro:
  - 0.7483036471586091
  - 0.7806107749927975
  - 0.8113553113553114
  - 0.6905204460966543
  - 0.7382432957637
  - 0.6497395833333334
  - 0.7347578347578347
  - 0.7121090617481957
  - 0.4503558115892917
  - 0.4525584547610979
  - 0.5211988304093567
  - 0.5594255529877847
  - 0.6108695652173913
  - 0.5769466584917229
  - 0.70042194092827
  - 0.5721360184879498
  TL_recall_micro:
  - 0.8678571428571429
  - 0.8607142857142858
  - 0.8989547038327527
  - 0.8571428571428571
  - 0.8107142857142857
  - 0.8428571428571429
  - 0.8501742160278746
  - 0.867595818815331
  - 0.7833333333333333
  - 0.7875
  - 0.7764227642276422
  - 0.7845528455284553
  - 0.7125
  - 0.7166666666666667
  - 0.7317073170731707
  - 0.7398373983739838
  TL_recall_weighted:
  - 0.8678571428571429
  - 0.8607142857142858
  - 0.8989547038327527
  - 0.8571428571428571
  - 0.8107142857142857
  - 0.8428571428571429
  - 0.8501742160278746
  - 0.867595818815331
  - 0.7833333333333333
  - 0.7875
  - 0.7764227642276422
  - 0.7845528455284553
  - 0.7125
  - 0.7166666666666667
  - 0.7317073170731707
  - 0.7398373983739838
  TL_roc_auc:
  - 0.8461620016963529
  - 0.8429847306251801
  - 0.8534798534798534
  - 0.7359562164394878
  - 0.7731571447078638
  - 0.7265625
  - 0.8009259259259259
  - 0.7786688051323176
  - 0.5930193154862758
  - 0.39545916638427653
  - 0.5611598440545809
  - 0.541762958071971
  - 0.7336956521739131
  - 0.6336603310852238
  - 0.7794186591654946
  - 0.6828986464179597
  TT_average_precision:
  - 0.07638888888888888
  - 0.27774950892063155
  - 0.11989424007111668
  - 0.5277777777777778
  - 0.24240091128678087
  - 0.3370466820363113
  - 0.41767000190155923
  - 0.23089654282765737
  - 0.13032397709817065
  - 0.07964401266389978
  - 0.014492753623188406
  - 0.16430007147786652
  - 0.045539529914529905
  - 0.25853442728442727
  - 0.06160624023527249
  - -0.0
  TT_balanced_accuracy:
  - 0.4631578947368421
  - 0.5236111111111111
  - 0.48809523809523814
  - 0.6496212121212122
  - 0.6340579710144928
  - 0.651131221719457
  - 0.8074074074074074
  - 0.5828313253012047
  - 0.48717948717948717
  - 0.47435897435897434
  - 0.4155844155844156
  - 0.5416666666666666
  - 0.3888888888888889
  - 0.4358974358974359
  - 0.3581081081081081
  - 0.9230769230769231
  TT_f1_macro:
  - 0.4731182795698925
  - 0.5236111111111111
  - 0.48295454545454547
  - 0.6285714285714286
  - 0.6153846153846154
  - 0.656140350877193
  - 0.6853772625584706
  - 0.57825311942959
  - 0.47500000000000003
  - 0.46835443037974683
  - 0.4507042253521127
  - 0.5384615384615384
  - 0.4285714285714286
  - 0.4318840579710145
  - 0.40458015267175573
  - 0.48000000000000004
  TT_f1_micro:
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.7802197802197802
  - 0.945054945054945
  - 0.8979591836734694
  - 0.8469387755102041
  - 0.8131868131868132
  - 0.8571428571428571
  - 0.9047619047619048
  - 0.8809523809523809
  - 0.8205128205128205
  - 0.8589743589743589
  - 0.75
  - 0.6666666666666666
  - 0.6794871794871795
  - 0.9230769230769231
  TT_f1_weighted:
  - 0.9172701338599956
  - 0.8571428571428571
  - 0.8146853146853147
  - 0.9488226059654631
  - 0.9046871495851088
  - 0.8443250984604368
  - 0.8418337814310968
  - 0.8609116373822256
  - 0.8821428571428572
  - 0.8698010849909584
  - 0.8898519321054533
  - 0.8639053254437871
  - 0.826530612244898
  - 0.744927536231884
  - 0.7676649050694853
  - 0.9600000000000001
  TT_matthews_corrcoef:
  - -0.049286405809014416
  - 0.04722222222222222
  - -0.017099639201419235
  - 0.26063666256136153
  - 0.23476098785162164
  - 0.31277028018538694
  - 0.4424543395299809
  - 0.15713772619883207
  - -0.043314808182421
  - -0.062017367294604234
  - -0.050964719143762556
  - 0.0776930968865506
  - -0.10050378152592121
  - -0.07308816827558577
  - -0.14111928108376567
  - 0.0
  TT_precision_macro:
  - 0.4835164835164835
  - 0.5236111111111111
  - 0.493859649122807
  - 0.6135057471264368
  - 0.6027777777777779
  - 0.6618217054263565
  - 0.6592071611253196
  - 0.5745257452574526
  - 0.4634146341463415
  - 0.4625
  - 0.49230769230769234
  - 0.5362173038229376
  - 0.4772727272727273
  - 0.47916666666666663
  - 0.4649122807017544
  - 0.5
  TT_precision_micro:
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.7802197802197802
  - 0.945054945054945
  - 0.8979591836734694
  - 0.8469387755102041
  - 0.8131868131868132
  - 0.8571428571428571
  - 0.9047619047619048
  - 0.8809523809523809
  - 0.8205128205128205
  - 0.8589743589743589
  - 0.75
  - 0.6666666666666666
  - 0.6794871794871795
  - 0.9230769230769231
  TT_precision_weighted:
  - 0.9374299170217537
  - 0.8571428571428571
  - 0.8553306342780027
  - 0.9530440823544273
  - 0.9123582766439909
  - 0.8419356114538838
  - 0.9021528343778983
  - 0.8648857917150601
  - 0.8606271777003485
  - 0.8589285714285715
  - 0.971992110453649
  - 0.869060516947841
  - 0.9204545454545455
  - 0.8541666666666666
  - 0.8821412505623031
  - 1.0
  TT_recall_macro:
  - 0.4631578947368421
  - 0.5236111111111111
  - 0.48809523809523814
  - 0.6496212121212122
  - 0.6340579710144928
  - 0.651131221719457
  - 0.8074074074074074
  - 0.5828313253012047
  - 0.48717948717948717
  - 0.47435897435897434
  - 0.4155844155844156
  - 0.5416666666666666
  - 0.3888888888888889
  - 0.4358974358974359
  - 0.3581081081081081
  - 0.46153846153846156
  TT_recall_micro:
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.7802197802197802
  - 0.945054945054945
  - 0.8979591836734694
  - 0.8469387755102041
  - 0.8131868131868132
  - 0.8571428571428571
  - 0.9047619047619048
  - 0.8809523809523809
  - 0.8205128205128205
  - 0.8589743589743589
  - 0.75
  - 0.6666666666666666
  - 0.6794871794871795
  - 0.9230769230769231
  TT_recall_weighted:
  - 0.8979591836734694
  - 0.8571428571428571
  - 0.7802197802197802
  - 0.945054945054945
  - 0.8979591836734694
  - 0.8469387755102041
  - 0.8131868131868132
  - 0.8571428571428571
  - 0.9047619047619048
  - 0.8809523809523809
  - 0.8205128205128205
  - 0.8589743589743589
  - 0.75
  - 0.6666666666666667
  - 0.6794871794871795
  - 0.9230769230769231
  TT_roc_auc:
  - 0.7403508771929825
  - 0.7583333333333333
  - 0.6547619047619047
  - 0.9545454545454546
  - 0.7789855072463768
  - 0.611764705882353
  - 0.808641975308642
  - 0.7936746987951807
  - 0.5641025641025641
  - 0.5192307692307693
  - 0.11688311688311692
  - 0.712962962962963
  - 0.49382716049382713
  - 0.6463675213675214
  - 0.4983108108108108
  - .nan
  fit_time:
  - 0.5906245708465576
  - 0.5129115581512451
  - 0.672935962677002
  - 0.6156280040740967
  - 0.4856996536254883
  - 0.5525374412536621
  - 0.5613086223602295
  - 0.6734967231750488
  - 0.5141165256500244
  - 0.4960591793060303
  - 0.6276581287384033
  - 0.5619313716888428
  - 0.6015419960021973
  - 0.6322569847106934
  - 0.6746101379394531
  - 0.6504619121551514
  score_time:
  - 0.3280367851257324
  - 0.30257225036621094
  - 0.333770751953125
  - 0.3273618221282959
  - 0.301593542098999
  - 0.3100097179412842
  - 0.32582807540893555
  - 0.3347742557525635
  - 0.3044462203979492
  - 0.3168797492980957
  - 0.3190903663635254
  - 0.29700160026550293
  - 0.32518506050109863
  - 0.32774925231933594
  - 0.32241201400756836
  - 0.32474541664123535
start: 2023-08-03 06:00:58.182521
