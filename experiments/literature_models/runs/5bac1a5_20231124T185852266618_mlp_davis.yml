active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - average_precision
    - roc_auc
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: literature_models/runs
end: 2023-11-24 19:02:48.238657
estimator:
  call: literature_models.estimators.mlp
  final_params:
    cv:
      call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
      params: {}
    diagonal: false
    error_score: .nan
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.neural_network._multilayer_perceptron.MLPRegressor
          params:
            activation: relu
            alpha: 0.0001
            batch_size: auto
            beta_1: 0.9
            beta_2: 0.999
            early_stopping: false
            epsilon: 1.0e-08
            hidden_layer_sizes:
            - 100
            learning_rate: constant
            learning_rate_init: 0.001
            max_fun: 15000
            max_iter: 200
            momentum: 0.9
            n_iter_no_change: 10
            nesterovs_momentum: true
            power_t: 0.5
            random_state: null
            shuffle: true
            solver: adam
            tol: 0.0001
            validation_fraction: 0.1
            verbose: false
            warm_start: false
        under_sampler:
          call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
          params:
            random_state: null
            replacement: false
            sampling_strategy: auto
    n_jobs: 4
    pairwise: true
    param_grid:
      estimator__hidden_layer_sizes:
      - - 100
        - 100
        - 100
        - 100
        - 100
      - - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
      - - 200
        - 100
        - 100
        - 100
        - 50
      - - 1024
        - 512
        - 256
        - 128
        - 64
        - 32
    pre_dispatch: 2*n_jobs
    refit: true
    return_train_score: false
    scoring: neg_mean_squared_error
    train_test_combinations: null
    verbose: 0
  name: mlp
  params: {}
hash: 5bac1a5891aa03a2c2f345cbcf741bbc564373ade3546298d4aaad0d0fc98c70
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/literature_models/runs/5bac1a5_20231124T185852266618_mlp_davis.yml"
results:
  LL_average_precision:
  - 0.38220593904703687
  - 0.2819241538247524
  - 0.33821231946080454
  - 0.3570304808938453
  - 0.3504104413310229
  - 0.2814292937971961
  - 0.31789520225646517
  - 0.3250531627082625
  - 0.37357982646313176
  - 0.35109415350696593
  - 0.3599587643538467
  - 0.31702417641505964
  - 0.37071835792521474
  - 0.3547516609942981
  - 0.3544224706800132
  - 0.37737846615806103
  LL_roc_auc:
  - 0.934192130099676
  - 0.8778369074862328
  - 0.9038522281467035
  - 0.9144502015479737
  - 0.9083120084509985
  - 0.8917748351303257
  - 0.8479088637371949
  - 0.8994759149765826
  - 0.9122835732946838
  - 0.9098138072513522
  - 0.9040146420906324
  - 0.9003077829023026
  - 0.9017204080129055
  - 0.8986133574762959
  - 0.903664528493078
  - 0.9132048603121727
  LT_average_precision:
  - 0.3893537139199571
  - 0.17650656743850576
  - 0.30930440700405293
  - 0.27178536505418827
  - 0.31334067109180325
  - 0.23345270434094592
  - 0.28936594468902144
  - 0.27698688355510914
  - 0.3662734583214666
  - 0.2735052795270589
  - 0.2974315146848021
  - 0.21827733772746313
  - 0.34561399066596366
  - 0.25313377966137174
  - 0.3624425242205977
  - 0.3575567489879167
  LT_roc_auc:
  - 0.906491930231732
  - 0.8259393208760296
  - 0.8590564866542519
  - 0.8754623134328359
  - 0.8749526833040666
  - 0.851572910007296
  - 0.8310727109904912
  - 0.865009138115738
  - 0.8904079173288765
  - 0.8485157688344357
  - 0.8696976032053518
  - 0.863289085797052
  - 0.888590783966491
  - 0.8546677566509224
  - 0.9019572547245829
  - 0.8934154680649788
  TL_average_precision:
  - 0.2515019923004767
  - 0.17466695644847535
  - 0.21203329103146618
  - 0.2365516901471419
  - 0.1475906486948907
  - 0.1764876214032058
  - 0.1888262355156648
  - 0.16941034124761833
  - 0.22139670015899487
  - 0.2861600531323034
  - 0.26856917656794765
  - 0.16907890707147444
  - 0.09333986246047501
  - 0.11630081477837097
  - 0.13302240281484395
  - 0.11579650191760532
  TL_roc_auc:
  - 0.7684686614696911
  - 0.7682294551317554
  - 0.7558893329876999
  - 0.7708841182561038
  - 0.7666563029719669
  - 0.7620901872454666
  - 0.7029236501148244
  - 0.7458936766528579
  - 0.812359658689934
  - 0.840938107535618
  - 0.8210425236494816
  - 0.7146678677952881
  - 0.6876564676407624
  - 0.7057375915288822
  - 0.7376754414865576
  - 0.7325783865257549
  TT_average_precision:
  - 0.3454511766289368
  - 0.1577290996122254
  - 0.17675130001907305
  - 0.22344787370783484
  - 0.20099694147397137
  - 0.1486925691322282
  - 0.12730915560065287
  - 0.13255662182215616
  - 0.23035859359433922
  - 0.21644805472785403
  - 0.21210739578146356
  - 0.16790540264893283
  - 0.18032645958672913
  - 0.10022150559126626
  - 0.06527180272980934
  - 0.11525357415132928
  TT_roc_auc:
  - 0.7805808379664712
  - 0.7266507281645689
  - 0.7303500325044694
  - 0.7494280802292264
  - 0.7750065305411642
  - 0.7058793230316409
  - 0.6621597288008205
  - 0.7218407722600193
  - 0.8025865054332056
  - 0.7812985609080466
  - 0.7713596567645266
  - 0.7679406779661018
  - 0.7729532517863632
  - 0.7161992551593589
  - 0.5989516300873641
  - 0.6822085109089753
  fit_time:
  - 209.40470719337463
  - 234.46163821220398
  - 212.4945409297943
  - 176.7691729068756
  - 220.2855474948883
  - 225.45612740516663
  - 209.6794035434723
  - 171.86873269081116
  - 179.5251588821411
  - 207.39665246009827
  - 208.28557181358337
  - 184.6513750553131
  - 214.13225436210632
  - 204.22361063957214
  - 194.93408060073853
  - 208.86349368095398
  score_time:
  - 0.39934754371643066
  - 1.3581693172454834
  - 0.3441598415374756
  - 0.4096541404724121
  - 0.29219484329223633
  - 0.3357396125793457
  - 0.3337218761444092
  - 0.6838662624359131
  - 0.3457057476043701
  - 1.4214537143707275
  - 0.4544663429260254
  - 0.3957407474517822
  - 0.27368664741516113
  - 1.4545512199401855
  - 0.3828861713409424
  - 0.35357093811035156
start: 2023-11-24 18:58:52.266618
wrapper: null
