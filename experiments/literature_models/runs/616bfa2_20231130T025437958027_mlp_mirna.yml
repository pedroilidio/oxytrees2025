active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 4
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: literature_models/runs
end: 2023-11-30 09:48:03.076536
estimator:
  call: literature_models.estimators.mlp
  final_params:
    cv:
      call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
      params: {}
    diagonal: false
    error_score: .nan
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.neural_network._multilayer_perceptron.MLPRegressor
          params:
            activation: relu
            alpha: 0.0001
            batch_size: auto
            beta_1: 0.9
            beta_2: 0.999
            early_stopping: false
            epsilon: 1.0e-08
            hidden_layer_sizes:
            - 100
            learning_rate: constant
            learning_rate_init: 0.001
            max_fun: 15000
            max_iter: 200
            momentum: 0.9
            n_iter_no_change: 10
            nesterovs_momentum: true
            power_t: 0.5
            random_state: null
            shuffle: true
            solver: adam
            tol: 0.0001
            validation_fraction: 0.1
            verbose: false
            warm_start: false
        under_sampler:
          call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
          params:
            random_state: null
            replacement: false
            sampling_strategy: auto
    n_jobs: 4
    pairwise: true
    param_grid:
      estimator__hidden_layer_sizes:
      - - 100
        - 100
        - 100
        - 100
        - 100
      - - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
      - - 200
        - 100
        - 100
        - 100
        - 50
      - - 1024
        - 512
        - 256
        - 128
        - 64
        - 32
    pre_dispatch: 2*n_jobs
    refit: true
    return_train_score: false
    scoring: average_precision
    train_test_combinations: null
    verbose: 0
  name: mlp
  params: {}
hash: 616bfa24286dc0ad22696665fec33c79c7bad51c738ccdbe955c360aac7dcb27
path: /home/pedro/master_thesis/experiments/literature_models/runs/616bfa2_20231130T025437958027_mlp_mirna.yml
results:
  LL_average_precision:
  - 0.07101693492652723
  - 0.0716054076213291
  - 0.14674123465557018
  - 0.07121012809336823
  - 0.17088422296863745
  - 0.0715748761314094
  - 0.06971157592323866
  - 0.15305300511777362
  - 0.1430167612464082
  - 0.07112186368442977
  - 0.132000646505866
  - 0.07066205497960942
  - 0.06632273898996259
  - 0.07105119776026718
  - 0.06947168472726024
  - 0.10381478192436797
  LL_roc_auc:
  - 0.4996843571216877
  - 0.4999617640819186
  - 0.6331060497023734
  - 0.5001594889305047
  - 0.6877843990595737
  - 0.499997535002958
  - 0.5000223318140865
  - 0.6588450347491751
  - 0.6159042039916327
  - 0.49999260868922496
  - 0.5950638326140925
  - 0.4999549609882103
  - 0.47624198863964456
  - 0.49996003952219586
  - 0.49999754057437423
  - 0.5482220214372789
  LT_average_precision:
  - 0.07063697587934484
  - 0.06895819636204252
  - 0.14720041794452615
  - 0.07034504392148486
  - 0.17213623476822243
  - 0.06855962485357663
  - 0.07415270203991248
  - 0.13894832641744576
  - 0.1381347911933789
  - 0.06844908084775203
  - 0.1355859408271413
  - 0.06944684379642746
  - 0.0643536344187035
  - 0.0687633378067227
  - 0.0734533260333972
  - 0.10042942899383325
  LT_roc_auc:
  - 0.5000960868626267
  - 0.4999521872494428
  - 0.6192128803383263
  - 0.49998606110582644
  - 0.6714675752071848
  - 0.5000389089090095
  - 0.5002588018064815
  - 0.6385135210575211
  - 0.6046250766191705
  - 0.500245352559233
  - 0.5880695835435412
  - 0.5
  - 0.4711270052046503
  - 0.4997798517763207
  - 0.5
  - 0.539538453642379
  TL_average_precision:
  - 0.07028208657613512
  - 0.07052749934868159
  - 0.10683933277647142
  - 0.07021647806241399
  - 0.1272658700231077
  - 0.07064144044310842
  - 0.06922839265981612
  - 0.11801008361548407
  - 0.12012310659461863
  - 0.07202909683226962
  - 0.11664128711833026
  - 0.07150586237124698
  - 0.06578479644235419
  - 0.07215895029946139
  - 0.0699132970757231
  - 0.09819741674444786
  TL_roc_auc:
  - 0.5005058340019672
  - 0.5
  - 0.5934305540260157
  - 0.5010033755829207
  - 0.6111991462433786
  - 0.5000227744981378
  - 0.5000414425194081
  - 0.5892203250725194
  - 0.5987931216965471
  - 0.5001270507905886
  - 0.5952641763501537
  - 0.4999704960354048
  - 0.47404948300313904
  - 0.4996616339734158
  - 0.49988065285665756
  - 0.5467649331560248
  TT_average_precision:
  - 0.06903624095001744
  - 0.06747170739708053
  - 0.10730675273151893
  - 0.0689380922018794
  - 0.12326898742472564
  - 0.06930393972199472
  - 0.07294064452482736
  - 0.10480653333109713
  - 0.12094866583476624
  - 0.06998785743852494
  - 0.11754613896777066
  - 0.07148784333250352
  - 0.06809980077332124
  - 0.06837115089349095
  - 0.07491777120170993
  - 0.0925538425332269
  TT_roc_auc:
  - 0.500187183439771
  - 0.4999780147301308
  - 0.5804120012123744
  - 0.501058081760732
  - 0.5996699396261934
  - 0.5002768151104785
  - 0.5001772931764289
  - 0.562738998012992
  - 0.5999210766730434
  - 0.49987375002719364
  - 0.5910814021188088
  - 0.5
  - 0.4838581213594323
  - 0.5001647600949402
  - 0.5000589407731484
  - 0.541908436018782
  fit_time:
  - 4854.0056681633
  - 4428.829648971558
  - 7431.306267738342
  - 5982.019520521164
  - 10416.933468341827
  - 5042.385018587112
  - 3108.4820284843445
  - 6028.662187576294
  - 10279.646552085876
  - 3805.4590656757355
  - 7409.873469114304
  - 3250.9743101596832
  - 7194.398331403732
  - 4030.590297460556
  - 2516.1376881599426
  - 3496.288829088211
  score_time:
  - 103.53799390792847
  - 25.578155517578125
  - 111.65444612503052
  - 114.8425874710083
  - 136.77291083335876
  - 18.369272708892822
  - 31.198830604553223
  - 106.79828953742981
  - 123.64096713066101
  - 110.04723644256592
  - 116.91491842269897
  - 31.0855073928833
  - 109.16620683670044
  - 129.22038960456848
  - 26.44090723991394
  - 101.0479850769043
start: 2023-11-30 02:54:37.958027
wrapper: null
