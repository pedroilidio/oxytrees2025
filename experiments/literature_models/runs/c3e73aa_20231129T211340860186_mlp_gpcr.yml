active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 4
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: literature_models/runs
end: 2023-11-29 21:16:05.499100
estimator:
  call: literature_models.estimators.mlp
  final_params:
    cv:
      call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
      params: {}
    diagonal: false
    error_score: .nan
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.neural_network._multilayer_perceptron.MLPRegressor
          params:
            activation: relu
            alpha: 0.0001
            batch_size: auto
            beta_1: 0.9
            beta_2: 0.999
            early_stopping: false
            epsilon: 1.0e-08
            hidden_layer_sizes:
            - 100
            learning_rate: constant
            learning_rate_init: 0.001
            max_fun: 15000
            max_iter: 200
            momentum: 0.9
            n_iter_no_change: 10
            nesterovs_momentum: true
            power_t: 0.5
            random_state: null
            shuffle: true
            solver: adam
            tol: 0.0001
            validation_fraction: 0.1
            verbose: false
            warm_start: false
        under_sampler:
          call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
          params:
            random_state: null
            replacement: false
            sampling_strategy: auto
    n_jobs: 4
    pairwise: true
    param_grid:
      estimator__hidden_layer_sizes:
      - - 100
        - 100
        - 100
        - 100
        - 100
      - - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
      - - 200
        - 100
        - 100
        - 100
        - 50
      - - 1024
        - 512
        - 256
        - 128
        - 64
        - 32
    pre_dispatch: 2*n_jobs
    refit: true
    return_train_score: false
    scoring: average_precision
    train_test_combinations: null
    verbose: 0
  name: mlp
  params: {}
hash: c3e73aac3676a622adda9f9ccea9f6446660e25f510ab8a47fe35f972dc910d3
path: /home/pedro/master_thesis/experiments/literature_models/runs/c3e73aa_20231129T211340860186_mlp_gpcr.yml
results:
  LL_average_precision:
  - 0.29362618845429095
  - 0.3521924620089013
  - 0.24605160028270104
  - 0.2590069960172219
  - 0.36848626608615365
  - 0.2528413227164432
  - 0.4446862738854399
  - 0.35812270493208775
  - 0.29206382983648377
  - 0.24868948024984203
  - 0.3295999267558831
  - 0.3241720131705997
  - 0.26192402060615294
  - 0.19272148777258363
  - 0.2665658486838997
  - 0.2667188706144707
  LL_roc_auc:
  - 0.9614529061854525
  - 0.9751801242236025
  - 0.9566042929845489
  - 0.9654273283534648
  - 0.9789360463357832
  - 0.952072647060232
  - 0.9696843484828291
  - 0.9781636190052643
  - 0.9503832787439837
  - 0.9180422195849965
  - 0.9696146457958477
  - 0.9721435233382438
  - 0.9515439020447024
  - 0.9003438198384048
  - 0.9541223372618505
  - 0.954730180198448
  LT_average_precision:
  - 0.13355805787892489
  - 0.1456535241957672
  - 0.14564311128929824
  - 0.19907447466467448
  - 0.17538843438712076
  - 0.14393469000386508
  - 0.18236386842500885
  - 0.1809582822648765
  - 0.19759222445523145
  - 0.12973944034975785
  - 0.15454247267826798
  - 0.15716259860263498
  - 0.10560690209484354
  - 0.07913293881619783
  - 0.1377692830211081
  - 0.26196185303474173
  LT_roc_auc:
  - 0.8169151873386105
  - 0.80091956640878
  - 0.8905229810996563
  - 0.8267959712907726
  - 0.8239259022676461
  - 0.8177056486254296
  - 0.8277182193868043
  - 0.8632143593975655
  - 0.7957437385639197
  - 0.7863336456236171
  - 0.8520093042201284
  - 0.7986622063102767
  - 0.8074891312862291
  - 0.7467730222037026
  - 0.8383356573101339
  - 0.8266526019690578
  TL_average_precision:
  - 0.1225424543390382
  - 0.1471676513082989
  - 0.11457777198664953
  - 0.09437897377539452
  - 0.2178812118400029
  - 0.16918467185167596
  - 0.24002336175057193
  - 0.1626346550364961
  - 0.1733362649798458
  - 0.11242183693504784
  - 0.15200836926509675
  - 0.10342370862168347
  - 0.1251784793634973
  - 0.0921418212091388
  - 0.21165996791271072
  - 0.14881002118651868
  TL_roc_auc:
  - 0.7926117183540369
  - 0.7962283998431688
  - 0.8115175957409111
  - 0.7656436269993672
  - 0.7903655862115743
  - 0.7968396229373506
  - 0.8293920205070936
  - 0.8104635976567218
  - 0.8411839678517341
  - 0.813292200773529
  - 0.8510086653208642
  - 0.7765456597019571
  - 0.8017737067824429
  - 0.8315765461038654
  - 0.8901781305784497
  - 0.8193666207853295
  TT_average_precision:
  - 0.06785159250621849
  - 0.10071305645283199
  - 0.109279905613832
  - 0.12234164495650872
  - 0.06910000958466492
  - 0.05943060222838108
  - 0.13427977388417606
  - 0.24643677571826308
  - 0.10004894638621628
  - 0.07618008796285035
  - 0.0763467671261452
  - 0.10311542396387752
  - 0.1293076650555186
  - 0.05442233977037141
  - 0.06437865116032548
  - 0.22776936322372737
  TT_roc_auc:
  - 0.7443870678042209
  - 0.7610237988325101
  - 0.7116914647549992
  - 0.7590398455327364
  - 0.685467791411043
  - 0.6747814104562082
  - 0.7875659916476243
  - 0.7685741450825924
  - 0.697970573313039
  - 0.7264503326718804
  - 0.7660569385228992
  - 0.7221250868951571
  - 0.8128632229351653
  - 0.6937344692935747
  - 0.7891053048297705
  - 0.7523469387755102
  fit_time:
  - 39.41424298286438
  - 28.204275608062744
  - 47.546308755874634
  - 27.540116548538208
  - 22.92966938018799
  - 34.398715019226074
  - 28.73546600341797
  - 21.895089149475098
  - 26.378573179244995
  - 38.94187331199646
  - 29.9009747505188
  - 29.479363441467285
  - 40.19317293167114
  - 42.1640419960022
  - 36.221402645111084
  - 38.4692497253418
  score_time:
  - 1.212097406387329
  - 0.15558958053588867
  - 1.3122038841247559
  - 0.12342238426208496
  - 0.18656110763549805
  - 1.161801815032959
  - 1.178006887435913
  - 0.19034647941589355
  - 0.17889094352722168
  - 1.1159484386444092
  - 0.15368199348449707
  - 0.16279077529907227
  - 1.4725291728973389
  - 1.0929570198059082
  - 1.2148663997650146
  - 1.1090407371520996
start: 2023-11-29 21:13:40.860186
wrapper: null
