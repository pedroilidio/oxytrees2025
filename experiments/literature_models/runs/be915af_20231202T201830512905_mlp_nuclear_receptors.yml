active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 4
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: literature_models/runs
end: 2023-12-02 20:18:51.066185
estimator:
  call: literature_models.estimators.mlp
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.model_selection._search.MultipartiteGridSearchCV
        params:
          cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          diagonal: false
          error_score: .nan
          estimator:
            call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
            params:
              estimator:
                call: sklearn.neural_network._multilayer_perceptron.MLPRegressor
                params:
                  activation: relu
                  alpha: 0.0001
                  batch_size: auto
                  beta_1: 0.9
                  beta_2: 0.999
                  early_stopping: false
                  epsilon: 1.0e-08
                  hidden_layer_sizes:
                  - 100
                  learning_rate: constant
                  learning_rate_init: 0.001
                  max_fun: 15000
                  max_iter: 200
                  momentum: 0.9
                  n_iter_no_change: 10
                  nesterovs_momentum: true
                  power_t: 0.5
                  random_state: null
                  shuffle: true
                  solver: adam
                  tol: 0.0001
                  validation_fraction: 0.1
                  verbose: false
                  warm_start: false
              under_sampler:
                call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
                params:
                  random_state: null
                  replacement: false
                  sampling_strategy: auto
          n_jobs: 4
          pairwise: true
          param_grid:
            estimator__hidden_layer_sizes:
            - - 100
              - 100
              - 100
              - 100
              - 100
            - - 100
              - 100
              - 100
              - 100
              - 100
              - 100
              - 100
              - 100
              - 100
              - 100
            - - 200
              - 100
              - 100
              - 100
              - 50
            - - 1024
              - 512
              - 256
              - 128
              - 64
              - 32
          pre_dispatch: 2*n_jobs
          refit: true
          return_train_score: false
          scoring: average_precision
          train_test_combinations: null
          verbose: 0
    verbose: false
  name: mlp
  params: {}
hash: be915afc5a5c82f85aa8569d29d3ae91b126b13755d1fed875cc0fcde744a250
path: /home/pedro/master_thesis/experiments/literature_models/runs/be915af_20231202T201830512905_mlp_nuclear_receptors.yml
results:
  LL_average_precision:
  - 0.1233127689380335
  - 0.13537439447586952
  - 0.08082864103348096
  - 0.08709963879820518
  - 0.07625036006365907
  - 0.10426397230339964
  - 0.09824950765423635
  - 0.1118286965926822
  - 0.17027102248157786
  - 0.21994289159658012
  - 0.13992119415895654
  - 0.12454555670930044
  - 0.1166922857917962
  - 0.18329171381738715
  - 0.1036054725660708
  - 0.12468849663127335
  LL_roc_auc:
  - 0.5989796453677474
  - 0.5895441848654138
  - 0.5667177522349937
  - 0.5666373681567052
  - 0.5517147800128905
  - 0.6657079738235172
  - 0.674334060413775
  - 0.5834879406307978
  - 0.6792698826597132
  - 0.6632696007696007
  - 0.6596623376623377
  - 0.6335964912280702
  - 0.5527690357548737
  - 0.70632
  - 0.479721151918751
  - 0.6745065789473684
  LT_average_precision:
  - 0.07466572179759963
  - 0.17639707503228347
  - 0.04608409329356586
  - 0.06698733675621191
  - 0.07428629304173656
  - 0.09891933523382931
  - 0.06893694241861455
  - 0.03507120942167945
  - 0.2119267650506956
  - 0.13200526612642777
  - 0.10410371699612538
  - 0.05584151459567809
  - 0.06607910988231729
  - 0.19396259177048103
  - 0.09186880606314421
  - 0.10593557716746331
  LT_roc_auc:
  - 0.503585657370518
  - 0.43751037344398336
  - 0.35
  - 0.5272838749233599
  - 0.5948162729658792
  - 0.44166666666666665
  - 0.5049645390070923
  - 0.3627450980392156
  - 0.7170398009950248
  - 0.5147123407992973
  - 0.522813309424188
  - 0.5633442862358525
  - 0.4249056603773585
  - 0.656272873664178
  - 0.5571625344352616
  - 0.5836359235052045
  TL_average_precision:
  - 0.21884828253829247
  - 0.046278616621369575
  - 0.12875340600685475
  - 0.10857798749991429
  - 0.09549844606174557
  - 0.14970517007618372
  - 0.13448637879590486
  - 0.10537389323663847
  - 0.0395237102807203
  - 0.048635389223148806
  - 0.06653148058606781
  - 0.045247963470309786
  - 0.05114603909500385
  - 0.11820929873580763
  - 0.1398180782284521
  - 0.09293167443986766
  TL_roc_auc:
  - 0.7473494486853265
  - 0.3716508210890233
  - 0.7551020408163265
  - 0.7022924411400249
  - 0.41767068273092367
  - 0.5838216145833334
  - 0.5136752136752136
  - 0.5136327185244587
  - 0.3120975940359201
  - 0.4357844798373433
  - 0.435672514619883
  - 0.3968306371739848
  - 0.5115217391304347
  - 0.6419374616799509
  - 0.7468354430379747
  - 0.6545064377682404
  TT_average_precision:
  - 0.39164696611505123
  - 0.06815362116213444
  - 0.11832186102372437
  - 0.08777777777777779
  - 0.08777768628312108
  - 0.09710181166236967
  - 0.14572167584889212
  - 0.08933137126777296
  - 0.08374613003095974
  - 0.1029413760062027
  - 0.02127659574468085
  - 0.08342292537290903
  - 0.031020800947516473
  - 0.07611586778113227
  - 0.0669445463251625
  - -0.0
  TT_roc_auc:
  - 0.7894736842105263
  - 0.36944444444444446
  - 0.6122448979591837
  - 0.7689393939393938
  - 0.5996376811594203
  - 0.28235294117647064
  - 0.5876543209876544
  - 0.42771084337349397
  - 0.45940170940170943
  - 0.6367521367521367
  - 0.4025974025974026
  - 0.49537037037037035
  - 0.25925925925925924
  - 0.46367521367521364
  - 0.5506756756756757
  - .nan
  fit_time:
  - 5.258026838302612
  - 5.198066473007202
  - 5.789269208908081
  - 5.527449607849121
  - 4.774268388748169
  - 5.123722553253174
  - 3.9310035705566406
  - 5.3245689868927
  - 3.789189100265503
  - 5.657933473587036
  - 5.1043617725372314
  - 4.333288669586182
  - 4.131389141082764
  - 4.771740674972534
  - 4.324984788894653
  - 4.831940412521362
  score_time:
  - 0.012505769729614258
  - 0.012630939483642578
  - 0.01269078254699707
  - 0.012383222579956055
  - 0.02187347412109375
  - 0.01709723472595215
  - 0.0203857421875
  - 0.06877946853637695
  - 0.013886690139770508
  - 0.012917041778564453
  - 0.01282644271850586
  - 0.017136335372924805
  - 0.013046741485595703
  - 0.01228785514831543
  - 0.01831793785095215
  - 0.012929201126098633
start: 2023-12-02 20:18:30.512905
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
