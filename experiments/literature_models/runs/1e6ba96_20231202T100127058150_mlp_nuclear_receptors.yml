active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 4
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: literature_models/runs
end: 2023-12-02 10:01:50.081644
estimator:
  call: literature_models.estimators.mlp
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.model_selection._search.MultipartiteGridSearchCV
        params:
          cv:
            call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
            params: {}
          diagonal: false
          error_score: .nan
          estimator:
            call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
            params:
              estimator:
                call: sklearn.neural_network._multilayer_perceptron.MLPRegressor
                params:
                  activation: relu
                  alpha: 0.0001
                  batch_size: auto
                  beta_1: 0.9
                  beta_2: 0.999
                  early_stopping: false
                  epsilon: 1.0e-08
                  hidden_layer_sizes:
                  - 100
                  learning_rate: constant
                  learning_rate_init: 0.001
                  max_fun: 15000
                  max_iter: 200
                  momentum: 0.9
                  n_iter_no_change: 10
                  nesterovs_momentum: true
                  power_t: 0.5
                  random_state: null
                  shuffle: true
                  solver: adam
                  tol: 0.0001
                  validation_fraction: 0.1
                  verbose: false
                  warm_start: false
              under_sampler:
                call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
                params:
                  random_state: null
                  replacement: false
                  sampling_strategy: auto
          n_jobs: 4
          pairwise: true
          param_grid:
            estimator__hidden_layer_sizes:
            - - 100
              - 100
              - 100
              - 100
              - 100
            - - 100
              - 100
              - 100
              - 100
              - 100
              - 100
              - 100
              - 100
              - 100
              - 100
            - - 200
              - 100
              - 100
              - 100
              - 50
            - - 1024
              - 512
              - 256
              - 128
              - 64
              - 32
          pre_dispatch: 2*n_jobs
          refit: true
          return_train_score: false
          scoring: average_precision
          train_test_combinations: null
          verbose: 0
    verbose: false
  name: mlp
  params: {}
hash: 1e6ba96c891a2f0c95d264638524bf3f5622be2c2c0f5238d737d3b1dab8e748
path: /home/pedro/master_thesis/experiments/literature_models/runs/1e6ba96_20231202T100127058150_mlp_nuclear_receptors.yml
results:
  LL_average_precision:
  - 0.1706923567461974
  - 0.13421014983698662
  - 0.20241117217596816
  - 0.19048975621950387
  - 0.10862957806887946
  - 0.055911400828346274
  - 0.11637034244274529
  - 0.10626207521038014
  - 0.20863190596226713
  - 0.18987221001771312
  - 0.1812666443137772
  - 0.3150320596413373
  - 0.21757172504559988
  - 0.1682724636859038
  - 0.23834022578628683
  - 0.17468385208483447
  LL_roc_auc:
  - 0.7850828874199979
  - 0.7274949212798375
  - 0.759667943805875
  - 0.7679432446007032
  - 0.7237016181010211
  - 0.5877620774457089
  - 0.701037742084738
  - 0.7397340754483612
  - 0.7357670578009561
  - 0.7730579605579606
  - 0.7889090909090909
  - 0.8335964912280701
  - 0.7909454497770783
  - 0.7346666666666667
  - 0.7760083743513219
  - 0.7173574561403508
  LT_average_precision:
  - 0.13236508339118097
  - 0.1458157678406658
  - 0.13250679977601093
  - 0.18798605605226706
  - 0.08451280700382478
  - 0.15834567632107913
  - 0.059272697866285744
  - 0.13914542148636275
  - 0.13222011498500436
  - 0.16272926609903032
  - 0.11340480193783195
  - 0.12821959315264297
  - 0.09903300746775678
  - 0.1770011731712863
  - 0.13194335705532795
  - 0.2183534631939063
  LT_roc_auc:
  - 0.7035856573705179
  - 0.5628215767634854
  - 0.6959770114942528
  - 0.6983445738810545
  - 0.6427165354330708
  - 0.6666666666666667
  - 0.5014184397163121
  - 0.6512605042016807
  - 0.5957711442786069
  - 0.5574586444151661
  - 0.5875672444710102
  - 0.7258123402701716
  - 0.5559748427672956
  - 0.7132191480017567
  - 0.6859504132231405
  - 0.7332365044783344
  TL_average_precision:
  - 0.18885046159509836
  - 0.04546004574467595
  - 0.1562629036677383
  - 0.15006764735774356
  - 0.1366910661513642
  - 0.09352701509638786
  - 0.12182215849879566
  - 0.1013253242247626
  - 0.05478278360579133
  - 0.10597598946269354
  - 0.09333812654168278
  - 0.04484445254509423
  - 0.12578087178191869
  - 0.05125670210913548
  - 0.24129359772186124
  - 0.23438232294363984
  TL_roc_auc:
  - 0.7439567430025446
  - 0.4736387208297321
  - 0.6449502878074307
  - 0.6306278397356463
  - 0.5539577665500712
  - 0.5030924479166666
  - 0.5329059829059829
  - 0.4647153167602246
  - 0.486953575059302
  - 0.6289393425957303
  - 0.5706627680311891
  - 0.41564872895344995
  - 0.5506521739130434
  - 0.5579399141630901
  - 0.5775902484763245
  - 0.7793000990425885
  TT_average_precision:
  - 0.379979035639413
  - 0.06395410190653526
  - 0.0654476955456389
  - 0.4305555555555555
  - 0.1020923253997616
  - 0.27351339636227157
  - 0.1244015814463346
  - 0.10945505413023107
  - 0.08073331141353582
  - 0.22629142300194932
  - 0.019230769230769232
  - 0.14873416712469228
  - 0.06571428571428573
  - 0.2629765296431963
  - 0.0665755404725993
  - -0.0
  TT_roc_auc:
  - 0.7473684210526316
  - 0.3083333333333333
  - 0.3622448979591837
  - 0.8901515151515151
  - 0.6811594202898551
  - 0.4606334841628959
  - 0.5308641975308642
  - 0.5376506024096386
  - 0.4764957264957265
  - 0.8525641025641025
  - 0.33766233766233766
  - 0.5925925925925926
  - 0.5308641975308642
  - 0.8226495726495726
  - 0.5033783783783784
  - .nan
  fit_time:
  - 5.6832685470581055
  - 5.950146436691284
  - 6.750461101531982
  - 5.615318059921265
  - 3.997047185897827
  - 5.645161867141724
  - 6.428483724594116
  - 4.83968448638916
  - 5.269499063491821
  - 4.618902921676636
  - 5.242044687271118
  - 5.396475553512573
  - 4.678559064865112
  - 4.639724493026733
  - 4.927547931671143
  - 5.04411244392395
  score_time:
  - 0.013776063919067383
  - 0.0171966552734375
  - 0.07166004180908203
  - 0.013096809387207031
  - 0.012612342834472656
  - 0.06816244125366211
  - 0.06936025619506836
  - 0.01732468605041504
  - 0.06774711608886719
  - 0.01764655113220215
  - 0.018724679946899414
  - 0.06781888008117676
  - 0.020056962966918945
  - 0.017568349838256836
  - 0.017882347106933594
  - 0.017926931381225586
start: 2023-12-02 10:01:27.058150
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
