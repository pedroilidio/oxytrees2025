active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 4
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: literature_models/runs
end: 2023-11-29 21:23:45.293166
estimator:
  call: literature_models.estimators.mlp
  final_params:
    cv:
      call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
      params: {}
    diagonal: false
    error_score: .nan
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.neural_network._multilayer_perceptron.MLPRegressor
          params:
            activation: relu
            alpha: 0.0001
            batch_size: auto
            beta_1: 0.9
            beta_2: 0.999
            early_stopping: false
            epsilon: 1.0e-08
            hidden_layer_sizes:
            - 100
            learning_rate: constant
            learning_rate_init: 0.001
            max_fun: 15000
            max_iter: 200
            momentum: 0.9
            n_iter_no_change: 10
            nesterovs_momentum: true
            power_t: 0.5
            random_state: null
            shuffle: true
            solver: adam
            tol: 0.0001
            validation_fraction: 0.1
            verbose: false
            warm_start: false
        under_sampler:
          call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
          params:
            random_state: null
            replacement: false
            sampling_strategy: auto
    n_jobs: 4
    pairwise: true
    param_grid:
      estimator__hidden_layer_sizes:
      - - 100
        - 100
        - 100
        - 100
        - 100
      - - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
      - - 200
        - 100
        - 100
        - 100
        - 50
      - - 1024
        - 512
        - 256
        - 128
        - 64
        - 32
    pre_dispatch: 2*n_jobs
    refit: true
    return_train_score: false
    scoring: average_precision
    train_test_combinations: null
    verbose: 0
  name: mlp
  params: {}
hash: e8d50648aa2458134208eace5db7c698cac242920e2c124d17f62cdc964d16aa
path: /home/pedro/master_thesis/experiments/literature_models/runs/e8d5064_20231129T211848365590_mlp_davis.yml
results:
  LL_average_precision:
  - 0.3021208531741048
  - 0.3294839604008925
  - 0.2785933353048239
  - 0.29108920709573843
  - 0.42214453897110504
  - 0.3922961830313259
  - 0.3301368270127507
  - 0.4197389143283238
  - 0.3109460298093695
  - 0.36763024382026044
  - 0.3875244427371762
  - 0.3227311779330621
  - 0.3823622668857054
  - 0.4361030055555342
  - 0.40629386864444017
  - 0.4513987989507486
  LL_roc_auc:
  - 0.899874279357624
  - 0.8816429654727953
  - 0.9122015567291076
  - 0.8872008476675897
  - 0.9272683564998256
  - 0.9228553958338771
  - 0.8907536212199924
  - 0.9229185298210665
  - 0.895563287807717
  - 0.9339767314348377
  - 0.9096143780337657
  - 0.8839300890108273
  - 0.9232341909385655
  - 0.938485113543482
  - 0.9338572597780117
  - 0.91908389393801
  LT_average_precision:
  - 0.3384649674980014
  - 0.21643966030684805
  - 0.3057412634916599
  - 0.2633748378884127
  - 0.3432894029433737
  - 0.3244781009837687
  - 0.30748776449922033
  - 0.35179354830807846
  - 0.3427049318691093
  - 0.24863723293520057
  - 0.35706947221463947
  - 0.2453902480619557
  - 0.37114696440674816
  - 0.35535548664680217
  - 0.3034648773345294
  - 0.37906951245788695
  LT_roc_auc:
  - 0.8843980533090194
  - 0.8367909776275215
  - 0.8661367163252638
  - 0.8632533582089552
  - 0.8870294225790392
  - 0.8778948694387125
  - 0.8614036271018244
  - 0.8939454713631043
  - 0.8852934168192503
  - 0.852540422267057
  - 0.8694374090072312
  - 0.8637873391837778
  - 0.9032841640180482
  - 0.8785498499589574
  - 0.8907423638526124
  - 0.885930776938022
  TL_average_precision:
  - 0.22378082234298632
  - 0.1913792763242712
  - 0.19646855840831418
  - 0.19622312268835776
  - 0.1901788055889331
  - 0.1600739070635892
  - 0.1657018906183989
  - 0.17165256518659538
  - 0.28591764877702663
  - 0.2756240067289398
  - 0.29377046757667163
  - 0.24378982007952316
  - 0.08597918349084445
  - 0.09627948239207593
  - 0.11192340988724123
  - 0.16600089963345283
  TL_roc_auc:
  - 0.7797968106173486
  - 0.7711807735069561
  - 0.7485812952011205
  - 0.6712315792478338
  - 0.7687807184169954
  - 0.8057747290666545
  - 0.7481254024438813
  - 0.7595118192882745
  - 0.8367435316976601
  - 0.8160488059658184
  - 0.8572466683103435
  - 0.8089045865657913
  - 0.721437585887764
  - 0.7293629684125144
  - 0.7422632775434898
  - 0.7661123963755543
  TT_average_precision:
  - 0.2409802365532399
  - 0.16923895884795226
  - 0.20617503284310051
  - 0.18987477314322332
  - 0.21322566085709624
  - 0.1630211672891124
  - 0.12297171170056316
  - 0.13883579424577278
  - 0.3129433995869844
  - 0.26986059471962054
  - 0.2784234236607085
  - 0.24694670342348343
  - 0.16089192108913103
  - 0.06529589448909197
  - 0.0552019252301084
  - 0.12529541982374187
  TT_roc_auc:
  - 0.7812449447003431
  - 0.7424688201072284
  - 0.7571662197302129
  - 0.6785146131805158
  - 0.763725020680047
  - 0.7727520235467256
  - 0.6947913159893211
  - 0.7353694149331789
  - 0.828264369214642
  - 0.763184919937842
  - 0.8294167610419025
  - 0.837319209039548
  - 0.7803045900448103
  - 0.7220736198843645
  - 0.606588536117622
  - 0.7195541702888564
  fit_time:
  - 83.75718688964844
  - 58.763638734817505
  - 56.302624464035034
  - 69.06135630607605
  - 67.04197406768799
  - 72.19422101974487
  - 61.36560249328613
  - 81.76088976860046
  - 62.04238152503967
  - 66.2434995174408
  - 72.9693500995636
  - 55.01353883743286
  - 71.52154564857483
  - 74.11464095115662
  - 73.65855979919434
  - 73.22886252403259
  score_time:
  - 2.108856439590454
  - 0.3114800453186035
  - 0.3722219467163086
  - 0.336223840713501
  - 0.38390374183654785
  - 0.29920029640197754
  - 0.2512807846069336
  - 0.283557653427124
  - 0.39817309379577637
  - 0.3179612159729004
  - 0.2352607250213623
  - 0.31003236770629883
  - 0.35912466049194336
  - 0.323880672454834
  - 0.27190113067626953
  - 0.27930498123168945
start: 2023-11-29 21:18:48.365590
wrapper: null
