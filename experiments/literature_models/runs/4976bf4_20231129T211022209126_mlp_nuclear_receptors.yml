active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - average_precision
    - roc_auc
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: literature_models/runs
end: 2023-11-29 21:10:53.988832
estimator:
  call: literature_models.estimators.mlp
  final_params:
    cv:
      call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
      params: {}
    diagonal: false
    error_score: .nan
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.neural_network._multilayer_perceptron.MLPRegressor
          params:
            activation: relu
            alpha: 0.0001
            batch_size: auto
            beta_1: 0.9
            beta_2: 0.999
            early_stopping: false
            epsilon: 1.0e-08
            hidden_layer_sizes:
            - 100
            learning_rate: constant
            learning_rate_init: 0.001
            max_fun: 15000
            max_iter: 200
            momentum: 0.9
            n_iter_no_change: 10
            nesterovs_momentum: true
            power_t: 0.5
            random_state: null
            shuffle: true
            solver: adam
            tol: 0.0001
            validation_fraction: 0.1
            verbose: false
            warm_start: false
        under_sampler:
          call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
          params:
            random_state: null
            replacement: false
            sampling_strategy: auto
    n_jobs: 4
    pairwise: true
    param_grid:
      estimator__hidden_layer_sizes:
      - - 100
        - 100
        - 100
        - 100
        - 100
      - - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
      - - 200
        - 100
        - 100
        - 100
        - 50
      - - 1024
        - 512
        - 256
        - 128
        - 64
        - 32
    pre_dispatch: 2*n_jobs
    refit: true
    return_train_score: false
    scoring: average_precision
    train_test_combinations: null
    verbose: 0
  name: mlp
  params: {}
hash: 4976bf491d85ec7e20d2e29779249c837a23ce4b0c05072641db0ec857c4f489
path: /home/pedro/master_thesis/experiments/literature_models/runs/4976bf4_20231129T211022209126_mlp_nuclear_receptors.yml
results:
  LL_average_precision:
  - 0.3762935121547172
  - 0.22492472604014513
  - 0.36764881693574003
  - 0.3255736391266018
  - 0.28067525201780436
  - 0.22057423502963597
  - 0.3252666910151735
  - 0.38079778770528405
  - 0.541006784423485
  - 0.19032078533847938
  - 0.6647674984481983
  - 0.3784454026233149
  - 0.46177994886847873
  - 0.3488579376116701
  - 0.35604598362396817
  - 0.3555280771875315
  LL_roc_auc:
  - 0.9434083516944707
  - 0.902393346876587
  - 0.9445210727969349
  - 0.9304244098442993
  - 0.9315105668441942
  - 0.9246384060689425
  - 0.9488069270936611
  - 0.9580705009276438
  - 0.9719572725817152
  - 0.8861531986531987
  - 0.9876103896103896
  - 0.9441447368421053
  - 0.9556670163475828
  - 0.9457866666666667
  - 0.9385064255328626
  - 0.9380811403508772
  LT_average_precision:
  - 0.18644861766338847
  - 0.32142889507437117
  - 0.0983374824035606
  - 0.12521702451790692
  - 0.11766415643355499
  - 0.15273456213337216
  - 0.06984192655638255
  - 0.11272325167638149
  - 0.37164734565791874
  - 0.3445529787269697
  - 0.2047289541212149
  - 0.19531062564821394
  - 0.20069529571560923
  - 0.3282210379076401
  - 0.2895748454205539
  - 0.1833594565148579
  LT_roc_auc:
  - 0.747675962815405
  - 0.8330290456431536
  - 0.6494252873563219
  - 0.7385039852851012
  - 0.6624015748031495
  - 0.6573170731707317
  - 0.5865248226950355
  - 0.8169934640522876
  - 0.8053482587064676
  - 0.8253549992680427
  - 0.7919904363419008
  - 0.7867834976268712
  - 0.7818867924528302
  - 0.8481920655833698
  - 0.730257116620753
  - 0.7811667877027354
  TL_average_precision:
  - 0.2912462545831584
  - 0.08283541719585771
  - 0.33402371813587695
  - 0.3122301599017361
  - 0.2213464059071416
  - 0.12511463971922074
  - 0.2501048706110277
  - 0.24735433173503055
  - 0.06849369537058389
  - 0.05033943464120334
  - 0.11996134978953042
  - 0.05187302212047795
  - 0.21555959929414442
  - 0.10004090623505432
  - 0.1266549317474492
  - 0.1273889275141459
  TL_roc_auc:
  - 0.7426844783715012
  - 0.693171996542783
  - 0.8916797488226059
  - 0.7514456836018174
  - 0.5596579867858531
  - 0.63623046875
  - 0.5762108262108263
  - 0.5811280406308474
  - 0.5713317519484921
  - 0.3744493392070485
  - 0.4683235867446394
  - 0.43578738857708815
  - 0.7663043478260869
  - 0.6584917228694053
  - 0.6783872480075012
  - 0.7423241994057446
  TT_average_precision:
  - 0.053654970760233914
  - 0.47665732959850604
  - 0.1404302898224716
  - 0.6428571428571428
  - 0.09035131545373666
  - 0.17805477254473429
  - 0.21130354023829642
  - 0.15370832333364892
  - 0.08606555934624706
  - 0.10349095349095348
  - 0.027777777777777776
  - 0.1244746754685027
  - 0.046028708133971294
  - 0.42547254582437644
  - 0.051186718589874974
  - -0.0
  TT_roc_auc:
  - 0.6000000000000001
  - 0.8791666666666667
  - 0.7040816326530612
  - 0.9772727272727273
  - 0.5905797101449276
  - 0.6208144796380091
  - 0.4913580246913581
  - 0.6671686746987951
  - 0.47649572649572647
  - 0.6047008547008548
  - 0.5454545454545454
  - 0.5439814814814815
  - 0.49382716049382713
  - 0.8653846153846154
  - 0.40202702702702703
  - .nan
  fit_time:
  - 26.107343673706055
  - 29.475613832473755
  - 25.337470769882202
  - 30.008050680160522
  - 28.89630365371704
  - 24.815546989440918
  - 29.508055925369263
  - 26.243696689605713
  - 29.84009099006653
  - 29.013551235198975
  - 31.63263201713562
  - 31.651410579681396
  - 29.729145288467407
  - 27.59477472305298
  - 29.739295482635498
  - 29.326920986175537
  score_time:
  - 0.018670082092285156
  - 0.07129883766174316
  - 0.032228708267211914
  - 0.014461994171142578
  - 0.013518095016479492
  - 0.023633241653442383
  - 0.07211685180664062
  - 0.01976156234741211
  - 0.07025909423828125
  - 0.014020442962646484
  - 0.07009458541870117
  - 0.07024145126342773
  - 0.018010377883911133
  - 0.026006460189819336
  - 0.013680219650268555
  - 0.019576072692871094
start: 2023-11-29 21:10:22.209126
wrapper: null
