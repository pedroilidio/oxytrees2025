active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: literature_models/runs
end: 2023-11-24 18:54:16.905011
estimator:
  call: literature_models.estimators.mlp
  final_params:
    cv:
      call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
      params: {}
    diagonal: false
    error_score: .nan
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.neural_network._multilayer_perceptron.MLPRegressor
          params:
            activation: relu
            alpha: 0.0001
            batch_size: auto
            beta_1: 0.9
            beta_2: 0.999
            early_stopping: false
            epsilon: 1.0e-08
            hidden_layer_sizes:
            - 100
            learning_rate: constant
            learning_rate_init: 0.001
            max_fun: 15000
            max_iter: 200
            momentum: 0.9
            n_iter_no_change: 10
            nesterovs_momentum: true
            power_t: 0.5
            random_state: null
            shuffle: true
            solver: adam
            tol: 0.0001
            validation_fraction: 0.1
            verbose: false
            warm_start: false
        under_sampler:
          call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
          params:
            random_state: null
            replacement: false
            sampling_strategy: auto
    n_jobs: 4
    pairwise: true
    param_grid:
      estimator__hidden_layer_sizes:
      - - 100
        - 100
        - 100
        - 100
        - 100
      - - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
        - 100
      - - 200
        - 100
        - 100
        - 100
        - 50
      - - 1024
        - 512
        - 256
        - 128
        - 64
        - 32
    pre_dispatch: 2*n_jobs
    refit: true
    return_train_score: false
    scoring: neg_mean_squared_error
    train_test_combinations: null
    verbose: 0
  name: mlp
  params: {}
hash: 2b1f5d862c22c7e0362f6886007753e87eaec165fee9b0612f19764528a21a69
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/literature_models/runs/2b1f5d8_20231124T185352443115_mlp_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.27777275866061807
  - 0.4563844230563513
  - 0.3634370160570266
  - 0.40011154516239655
  - 0.4118871521453715
  - 0.15146305598467955
  - 0.3482007883536724
  - 0.3075829977051494
  - 0.42087866508958666
  - 0.2811444160602785
  - 0.3764174434304256
  - 0.340749622659776
  - 0.42504297878110386
  - 0.32967029885897803
  - 0.44035294043132645
  - 0.43162901314859103
  LL_roc_auc:
  - 0.9095976287902633
  - 0.9693689690198071
  - 0.9433461047254151
  - 0.9510924158714215
  - 0.9652973303029275
  - 0.8770789045892209
  - 0.9538303919624562
  - 0.9399969078540508
  - 0.9539559459274
  - 0.9319684944684945
  - 0.9525714285714285
  - 0.9319078947368421
  - 0.9514489902963547
  - 0.9403999999999999
  - 0.9582618766564955
  - 0.9549451754385965
  LT_average_precision:
  - 0.1907829844735901
  - 0.34679045564610916
  - 0.1611290739389043
  - 0.3663130950063262
  - 0.2598827835548205
  - 0.13816906486689207
  - 0.09452122031587287
  - 0.15254523647213486
  - 0.44191102018446965
  - 0.20256611215560522
  - 0.15863217385183864
  - 0.18714082660187423
  - 0.23581601466269975
  - 0.19402508792102816
  - 0.307972271429085
  - 0.31183226711571266
  LT_roc_auc:
  - 0.7747675962815405
  - 0.7837344398340249
  - 0.6758620689655173
  - 0.7808093194359289
  - 0.7345800524934383
  - 0.7132113821138212
  - 0.6702127659574468
  - 0.8613445378151261
  - 0.841728855721393
  - 0.8014931927975406
  - 0.7575214186092847
  - 0.7929901423877328
  - 0.7932075471698113
  - 0.7635778070560679
  - 0.8149678604224059
  - 0.8184458968772695
  TL_average_precision:
  - 0.21244832887943246
  - 0.2916088423333741
  - 0.25026668759756704
  - 0.35071657286779756
  - 0.2818973328381943
  - 0.16772927752622932
  - 0.17692234575351953
  - 0.18891119403556073
  - 0.06618246417067114
  - 0.04333194742375347
  - 0.07718077351505875
  - 0.06717527898833486
  - 0.25214570133668274
  - 0.11528754059634526
  - 0.3190179556413262
  - 0.1742324123150093
  TL_roc_auc:
  - 0.7755513146734522
  - 0.679919331604725
  - 0.7001569858712715
  - 0.7492771581990914
  - 0.6129032258064515
  - 0.7257486979166666
  - 0.6316239316239316
  - 0.5961641272387063
  - 0.5730260928498815
  - 0.3368349711962047
  - 0.5190058479532164
  - 0.48894024430505123
  - 0.7845652173913044
  - 0.5726548129981606
  - 0.7665260196905767
  - 0.7621327170683394
  TT_average_precision:
  - 0.3644927536231884
  - 0.4068022724824195
  - 0.07583046277751468
  - 0.18308080808080807
  - 0.32009889052766444
  - 0.1936593602990364
  - 0.2743117100597942
  - 0.1937612982648299
  - 0.07389577458274399
  - 0.10470559899447152
  - 0.02857142857142857
  - 0.0810524981577613
  - 0.10797940797940797
  - 0.5522942893632549
  - 0.0763927192498621
  - -0.0
  TT_roc_auc:
  - 0.6350877192982456
  - 0.7486111111111111
  - 0.45918367346938777
  - 0.8371212121212122
  - 0.6684782608695652
  - 0.6823529411764706
  - 0.6962962962962963
  - 0.6310240963855422
  - 0.46794871794871795
  - 0.608974358974359
  - 0.5584415584415585
  - 0.48148148148148145
  - 0.7736625514403292
  - 0.8226495726495726
  - 0.6013513513513513
  - .nan
  fit_time:
  - 22.908350944519043
  - 20.34325933456421
  - 22.99053144454956
  - 21.737781286239624
  - 21.040205478668213
  - 20.554280996322632
  - 19.716278076171875
  - 18.476528644561768
  - 22.854214668273926
  - 20.346621990203857
  - 19.653051376342773
  - 23.282018899917603
  - 24.3424015045166
  - 23.70582890510559
  - 22.565080404281616
  - 21.832096815109253
  score_time:
  - 0.02969813346862793
  - 0.029657602310180664
  - 0.019646644592285156
  - 0.022884607315063477
  - 0.08762383460998535
  - 0.061591148376464844
  - 0.08033442497253418
  - 0.034865617752075195
  - 0.027324676513671875
  - 0.04125571250915527
  - 0.04845929145812988
  - 0.03365349769592285
  - 0.02758026123046875
  - 0.03520035743713379
  - 0.020416259765625
  - 0.017653226852416992
start: 2023-11-24 18:53:52.443115
wrapper: null
