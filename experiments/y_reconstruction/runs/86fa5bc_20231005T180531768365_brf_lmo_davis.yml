active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: y_reconstruction/runs
end: 2023-10-05 18:06:03.077928
estimator:
  call: bipartite_adaptations.estimators.brf_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: brf_lmo
  params: {}
hash: 86fa5bc10d151a1d656d69ce24312b40a6bea2537fbe424e37bd34e1e8916aac
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/86fa5bc_20231005T180531768365_brf_lmo_davis.yml"
results:
  LL_average_precision:
  - 0.858414091054177
  - 0.8322492253853563
  - 0.8432024306912993
  - 0.912172394682209
  - 0.8814118753862554
  - 0.8224160274303939
  - 0.8463809603330125
  - 0.8974666745453694
  - 0.8831504479515981
  - 0.8360239923352148
  - 0.8578534207138058
  - 0.8861545062402157
  - 0.9073220711853327
  - 0.8258764838433525
  - 0.8366119067628186
  - 0.8978724717735185
  LL_balanced_accuracy:
  - 0.747450713800136
  - 0.7754276827371696
  - 0.813536766526368
  - 0.8825621675120623
  - 0.76813988280763
  - 0.7962568186093172
  - 0.8556186435390278
  - 0.8654517133956386
  - 0.8092607535224381
  - 0.7861064320918336
  - 0.8069460854424476
  - 0.7885212316861188
  - 0.8313256771938584
  - 0.8380175658720201
  - 0.7853080864891888
  - 0.8721816251327212
  LL_f1_macro:
  - 0.4041818957336381
  - 0.44645360269624507
  - 0.48781483109870755
  - 0.5772094614854244
  - 0.4411027775724935
  - 0.48350515418780543
  - 0.5561991128342716
  - 0.567261263286094
  - 0.4823343199407868
  - 0.4634748953422079
  - 0.487951653101335
  - 0.46328968075865135
  - 0.5191462514674011
  - 0.5369047463724893
  - 0.46982421402687014
  - 0.5819060384885576
  LL_f1_micro:
  - 0.515846217641135
  - 0.5723002191813281
  - 0.6441648948736121
  - 0.7757500590597683
  - 0.5593270540844737
  - 0.615010959066406
  - 0.7266713914481455
  - 0.744920859910229
  - 0.6359220425330253
  - 0.5938036846158403
  - 0.6332978974722419
  - 0.5976257973068746
  - 0.679817546353889
  - 0.6940939517801078
  - 0.5942003307347036
  - 0.7582683675879991
  LL_f1_weighted:
  - 0.6407275125166103
  - 0.6851853690163758
  - 0.7448606868825699
  - 0.8407210707799947
  - 0.6726024782179898
  - 0.7153462755615956
  - 0.8018520380485847
  - 0.8156473598475172
  - 0.7385811119242051
  - 0.7012152841409962
  - 0.7333372313929781
  - 0.7056687629594592
  - 0.7688140977846606
  - 0.7766282737653586
  - 0.69840570787158
  - 0.8239090889669218
  LL_matthews_corrcoef:
  - 0.19759371771810558
  - 0.23519968468006172
  - 0.26748763358298266
  - 0.35838940149046933
  - 0.2331384876063642
  - 0.272604801364152
  - 0.34107604064041347
  - 0.35206338857794695
  - 0.2624189980573693
  - 0.251477759908688
  - 0.2720247857351528
  - 0.249520422508889
  - 0.30144858690301596
  - 0.3228022925271645
  - 0.26081848845754435
  - 0.369768670743314
  LL_precision_macro:
  - 0.5394455088470641
  - 0.5502118116122602
  - 0.5570504337597412
  - 0.5839360070129301
  - 0.5506764919062576
  - 0.5627102677970663
  - 0.5817820350623532
  - 0.5847913862718708
  - 0.5556680161943319
  - 0.5552600856142171
  - 0.5602691218130311
  - 0.5539478852952731
  - 0.568566411238825
  - 0.5770679770679771
  - 0.5596077425971029
  - 0.5918428400478659
  LL_precision_micro:
  - 0.515846217641135
  - 0.5723002191813281
  - 0.6441648948736121
  - 0.7757500590597685
  - 0.5593270540844737
  - 0.615010959066406
  - 0.7266713914481455
  - 0.7449208599102292
  - 0.6359220425330253
  - 0.5938036846158403
  - 0.6332978974722419
  - 0.5976257973068746
  - 0.679817546353889
  - 0.6940939517801078
  - 0.5942003307347036
  - 0.7582683675879991
  LL_precision_weighted:
  - 0.9618046153892477
  - 0.9570488383578558
  - 0.9593989058111929
  - 0.9623547107691831
  - 0.9553364820460103
  - 0.9517144682882371
  - 0.9552932603037361
  - 0.9567429722055032
  - 0.9594650047354583
  - 0.9551071136713836
  - 0.9557983726273198
  - 0.9565855253346687
  - 0.9560924764236894
  - 0.9528488793816676
  - 0.9516223955368894
  - 0.9555973606997502
  LL_recall_macro:
  - 0.747450713800136
  - 0.7754276827371696
  - 0.813536766526368
  - 0.8825621675120623
  - 0.76813988280763
  - 0.7962568186093172
  - 0.8556186435390278
  - 0.8654517133956386
  - 0.8092607535224381
  - 0.7861064320918336
  - 0.8069460854424476
  - 0.7885212316861188
  - 0.8313256771938584
  - 0.8380175658720201
  - 0.7853080864891888
  - 0.8721816251327212
  LL_recall_micro:
  - 0.515846217641135
  - 0.5723002191813281
  - 0.6441648948736121
  - 0.7757500590597685
  - 0.5593270540844737
  - 0.615010959066406
  - 0.7266713914481455
  - 0.7449208599102292
  - 0.6359220425330253
  - 0.5938036846158403
  - 0.6332978974722419
  - 0.5976257973068746
  - 0.679817546353889
  - 0.6940939517801078
  - 0.5942003307347036
  - 0.7582683675879991
  LL_recall_weighted:
  - 0.515846217641135
  - 0.5723002191813281
  - 0.6441648948736121
  - 0.7757500590597685
  - 0.5593270540844737
  - 0.615010959066406
  - 0.7266713914481455
  - 0.7449208599102292
  - 0.6359220425330253
  - 0.5938036846158403
  - 0.6332978974722419
  - 0.5976257973068746
  - 0.679817546353889
  - 0.6940939517801078
  - 0.5942003307347036
  - 0.7582683675879991
  LL_roc_auc:
  - 0.995971553938923
  - 0.9941956322912526
  - 0.9953298445823326
  - 0.9970104147924811
  - 0.9958099782469112
  - 0.9929685004535648
  - 0.994495132006176
  - 0.9961854606847931
  - 0.9963925993936547
  - 0.9941610745430012
  - 0.9943616083997793
  - 0.9959330948138897
  - 0.9970284601397177
  - 0.9932294590367439
  - 0.9935030970591041
  - 0.9960604920707675
  LT_average_precision:
  - 0.6437862538947661
  - 0.5736639799935356
  - 0.5477244258481718
  - 0.4614516286278074
  - 0.6305987997619864
  - 0.5553897280123423
  - 0.5230981504263815
  - 0.44959966230751697
  - 0.6546282916377766
  - 0.5725706230644134
  - 0.5124854113560435
  - 0.4247280377346639
  - 0.6119397471871572
  - 0.554911970048895
  - 0.5649987777257676
  - 0.5165902670255011
  LT_balanced_accuracy:
  - 0.6876839824276799
  - 0.7182640144665461
  - 0.7580307262569832
  - 0.8161455223880597
  - 0.7055703004081437
  - 0.7384849618968703
  - 0.8025558800333099
  - 0.8039793580256711
  - 0.7593742090537832
  - 0.7214052935185282
  - 0.7515528931188411
  - 0.7351452671040299
  - 0.771667929084096
  - 0.7829861531629728
  - 0.7422329369425038
  - 0.8161231423369173
  LT_f1_macro:
  - 0.359422377168182
  - 0.39252207505518766
  - 0.4384555255357659
  - 0.5246730433461663
  - 0.3927328829795722
  - 0.4260751299796853
  - 0.5140906234621424
  - 0.5207604211997328
  - 0.4511243783047274
  - 0.41145801609598887
  - 0.42695783730778003
  - 0.4194033466289275
  - 0.47581172700666874
  - 0.49556151494478645
  - 0.41980181936322286
  - 0.5310932565518529
  LT_f1_micro:
  - 0.42148030383324503
  - 0.5103338632750397
  - 0.5748663101604278
  - 0.7142602495543672
  - 0.46493552375905317
  - 0.5506094329623742
  - 0.6825311942959001
  - 0.6819964349376114
  - 0.5601483836777954
  - 0.5299417064122947
  - 0.5508021390374331
  - 0.5290552584670232
  - 0.5892951775304717
  - 0.6590708355414238
  - 0.5233511586452763
  - 0.7
  LT_f1_weighted:
  - 0.5365445753512703
  - 0.6401961954162967
  - 0.6915431657254643
  - 0.7981109839964363
  - 0.576457532954819
  - 0.6694294201843859
  - 0.7715196278729233
  - 0.7686100034728947
  - 0.6673142708459321
  - 0.6524836963575449
  - 0.66980283694177
  - 0.6469827862928995
  - 0.6888624722003687
  - 0.7547514370447614
  - 0.6398332424115017
  - 0.7828229977525665
  LT_matthews_corrcoef:
  - 0.17878390797060784
  - 0.1651725087378721
  - 0.20939585576736802
  - 0.27880499169767
  - 0.20081564220407017
  - 0.19752501679944762
  - 0.27479440907748426
  - 0.28576093201776936
  - 0.24274437473456237
  - 0.18093131175740268
  - 0.20686522405793048
  - 0.203189214713792
  - 0.2649205287702282
  - 0.2508665515521474
  - 0.21377399393115992
  - 0.2969213875619865
  LT_precision_macro:
  - 0.5425764699467086
  - 0.5312488040108692
  - 0.5424819798097221
  - 0.5614687049877966
  - 0.5490427387538073
  - 0.5408999921329358
  - 0.5623950584367509
  - 0.5671585982005792
  - 0.5567951914728105
  - 0.5369640434675458
  - 0.5425290486564996
  - 0.5438939910257075
  - 0.564585178309888
  - 0.5555981502842493
  - 0.5471646435225763
  - 0.569721493450307
  LT_precision_micro:
  - 0.42148030383324503
  - 0.5103338632750397
  - 0.5748663101604278
  - 0.7142602495543672
  - 0.46493552375905317
  - 0.5506094329623742
  - 0.6825311942959001
  - 0.6819964349376114
  - 0.5601483836777954
  - 0.5299417064122947
  - 0.5508021390374331
  - 0.5290552584670232
  - 0.5892951775304717
  - 0.6590708355414238
  - 0.5233511586452763
  - 0.7
  LT_precision_weighted:
  - 0.9472227286740231
  - 0.9611123506637395
  - 0.9578110165575225
  - 0.9565925879509424
  - 0.9420441845477336
  - 0.9543937821667808
  - 0.9516423073565109
  - 0.9485788235383182
  - 0.9469352054620999
  - 0.9540262913351624
  - 0.9573190899123234
  - 0.951959136389524
  - 0.9428853211760999
  - 0.9509922781667507
  - 0.9523156902863699
  - 0.9506874292698637
  LT_recall_macro:
  - 0.6876839824276799
  - 0.7182640144665461
  - 0.7580307262569832
  - 0.8161455223880597
  - 0.7055703004081437
  - 0.7384849618968703
  - 0.8025558800333099
  - 0.8039793580256711
  - 0.7593742090537832
  - 0.7214052935185282
  - 0.7515528931188411
  - 0.7351452671040299
  - 0.771667929084096
  - 0.7829861531629728
  - 0.7422329369425038
  - 0.8161231423369173
  LT_recall_micro:
  - 0.42148030383324503
  - 0.5103338632750397
  - 0.5748663101604278
  - 0.7142602495543672
  - 0.46493552375905317
  - 0.5506094329623742
  - 0.6825311942959001
  - 0.6819964349376114
  - 0.5601483836777954
  - 0.5299417064122947
  - 0.5508021390374331
  - 0.5290552584670232
  - 0.5892951775304717
  - 0.6590708355414238
  - 0.5233511586452763
  - 0.7
  LT_recall_weighted:
  - 0.42148030383324503
  - 0.5103338632750397
  - 0.5748663101604278
  - 0.7142602495543672
  - 0.46493552375905317
  - 0.5506094329623742
  - 0.6825311942959001
  - 0.6819964349376115
  - 0.5601483836777954
  - 0.5299417064122947
  - 0.5508021390374332
  - 0.5290552584670232
  - 0.5892951775304717
  - 0.6590708355414238
  - 0.5233511586452763
  - 0.7000000000000001
  LT_roc_auc:
  - 0.9357574214633337
  - 0.9069511055201754
  - 0.9216069211669771
  - 0.9182026119402984
  - 0.9361487626073913
  - 0.9161763913503785
  - 0.9178696569966658
  - 0.9236635660721724
  - 0.9402446546287028
  - 0.9030833990149993
  - 0.920688145973457
  - 0.9119379739286018
  - 0.9423508038561499
  - 0.915396700442722
  - 0.9336329556634446
  - 0.931988996429625
  TL_average_precision:
  - 0.3176372169519735
  - 0.3346779887638729
  - 0.34352481573537097
  - 0.3594268003256953
  - 0.28559725520489443
  - 0.2202595627362806
  - 0.2500615387555575
  - 0.2451398766076608
  - 0.3706827056962096
  - 0.3342838832291049
  - 0.28453145870431396
  - 0.2765889816367371
  - 0.23835802966179537
  - 0.26705597041113205
  - 0.3428148354249416
  - 0.3632125663658673
  TL_balanced_accuracy:
  - 0.6473067068270524
  - 0.6713272368480433
  - 0.686485329668011
  - 0.7264612693873632
  - 0.6460867824561105
  - 0.7006427320091917
  - 0.7226753166512203
  - 0.6932653691689836
  - 0.754489285288761
  - 0.7112665757479035
  - 0.7262162745014438
  - 0.7249540574405584
  - 0.6482892559665704
  - 0.6479443139696104
  - 0.6046026620980496
  - 0.6542107015791226
  TL_f1_macro:
  - 0.332706843802261
  - 0.3704503576132048
  - 0.4066359328628257
  - 0.5013551379667647
  - 0.33922835341461377
  - 0.39798077470414794
  - 0.45832380865962974
  - 0.4512529772575177
  - 0.47072513894051016
  - 0.43249197637892745
  - 0.4428842152529407
  - 0.43403961692430093
  - 0.3245256216218682
  - 0.3319335027390733
  - 0.2930967259844591
  - 0.3678249432962518
  TL_f1_micro:
  - 0.3760440732184112
  - 0.42811444819619693
  - 0.4836995038979447
  - 0.6481218993621545
  - 0.4215390083525858
  - 0.5093300159943132
  - 0.619950389794472
  - 0.6149893692416726
  - 0.6156033410342989
  - 0.5402523547183223
  - 0.5643160878809355
  - 0.5465981573352232
  - 0.40145725964101653
  - 0.40305669095432733
  - 0.3474486180014174
  - 0.47519489723600283
  TL_f1_weighted:
  - 0.4812441398834173
  - 0.535857922203878
  - 0.5918309845932396
  - 0.7368913448566883
  - 0.5544545523536312
  - 0.6343448459882715
  - 0.7281033696456491
  - 0.7245541362424224
  - 0.71948849206011
  - 0.6512209335547712
  - 0.6750564256134104
  - 0.6589778204471214
  - 0.5365231264950663
  - 0.5316285110449745
  - 0.4735519534094528
  - 0.6089688123337665
  TL_matthews_corrcoef:
  - 0.1539932228621465
  - 0.17626620717995115
  - 0.18846758596310334
  - 0.2280900274457051
  - 0.11526442615158405
  - 0.16400881224584385
  - 0.18597349851300685
  - 0.1614109609735531
  - 0.2260781158471434
  - 0.1971568910607723
  - 0.20412521391364263
  - 0.20407260827794402
  - 0.1127530274771851
  - 0.12297144131589692
  - 0.08777665444021025
  - 0.11735425571112369
  TL_precision_macro:
  - 0.5402458129678244
  - 0.5453368891677779
  - 0.5476177281907295
  - 0.557432624970402
  - 0.5227362936479991
  - 0.5335159043950072
  - 0.5388302379775439
  - 0.5337017159805099
  - 0.5502096919394858
  - 0.5459973845308265
  - 0.5460478617720146
  - 0.5462823719687381
  - 0.521433186649977
  - 0.5255534920091882
  - 0.5184143044502396
  - 0.5223266303707944
  TL_precision_micro:
  - 0.3760440732184112
  - 0.42811444819619693
  - 0.4836995038979447
  - 0.6481218993621545
  - 0.42153900835258573
  - 0.5093300159943132
  - 0.619950389794472
  - 0.6149893692416726
  - 0.6156033410342989
  - 0.5402523547183223
  - 0.5643160878809355
  - 0.5465981573352232
  - 0.40145725964101653
  - 0.40305669095432733
  - 0.3474486180014174
  - 0.47519489723600283
  TL_precision_weighted:
  - 0.9345064631233521
  - 0.9325117533639733
  - 0.9286327042189394
  - 0.9257360087398825
  - 0.9531355586267719
  - 0.951842196362567
  - 0.9480893568500064
  - 0.9438058960608464
  - 0.9470463019926437
  - 0.9376824992819657
  - 0.9427518408097025
  - 0.9433824703238458
  - 0.9589481873732453
  - 0.9513599717379865
  - 0.9483938333892908
  - 0.9527744868325971
  TL_recall_macro:
  - 0.6473067068270524
  - 0.6713272368480433
  - 0.686485329668011
  - 0.7264612693873632
  - 0.6460867824561105
  - 0.7006427320091917
  - 0.7226753166512203
  - 0.6932653691689836
  - 0.754489285288761
  - 0.7112665757479035
  - 0.7262162745014438
  - 0.7249540574405584
  - 0.6482892559665704
  - 0.6479443139696104
  - 0.6046026620980496
  - 0.6542107015791226
  TL_recall_micro:
  - 0.3760440732184112
  - 0.42811444819619693
  - 0.4836995038979447
  - 0.6481218993621545
  - 0.42153900835258573
  - 0.5093300159943132
  - 0.619950389794472
  - 0.6149893692416726
  - 0.6156033410342989
  - 0.5402523547183223
  - 0.5643160878809355
  - 0.5465981573352232
  - 0.40145725964101653
  - 0.40305669095432733
  - 0.3474486180014174
  - 0.47519489723600283
  TL_recall_weighted:
  - 0.3760440732184112
  - 0.42811444819619693
  - 0.4836995038979447
  - 0.6481218993621545
  - 0.42153900835258573
  - 0.5093300159943132
  - 0.619950389794472
  - 0.6149893692416726
  - 0.6156033410342989
  - 0.5402523547183223
  - 0.5643160878809355
  - 0.5465981573352232
  - 0.40145725964101653
  - 0.40305669095432733
  - 0.3474486180014174
  - 0.47519489723600283
  TL_roc_auc:
  - 0.8158646846535741
  - 0.8450052718597562
  - 0.8270333094203204
  - 0.8159486930640143
  - 0.8071667078375087
  - 0.8328377281793431
  - 0.8177332127397448
  - 0.8037443564806026
  - 0.8712634023905322
  - 0.8656498273510721
  - 0.8534754804819558
  - 0.8466437060677137
  - 0.7709491357470716
  - 0.7807472592424914
  - 0.7839046850289931
  - 0.7938802425644531
  TT_average_precision:
  - 0.3321396557246229
  - 0.28351638927619144
  - 0.26903603398615206
  - 0.2921187379254675
  - 0.390110166508912
  - 0.2647069278000554
  - 0.15835246222282495
  - 0.1725063125760785
  - 0.27480596531621354
  - 0.29631701043015146
  - 0.24829694547646738
  - 0.24071203633012844
  - 0.35988532596259654
  - 0.29132710405366985
  - 0.16513764020587418
  - 0.24575377697321307
  TT_balanced_accuracy:
  - 0.5937923048760759
  - 0.6277472527472527
  - 0.6538426377376889
  - 0.6877249283667621
  - 0.6127797248465323
  - 0.6212030905077263
  - 0.6588597734265516
  - 0.6927714144790924
  - 0.6809922035135667
  - 0.6744848321059388
  - 0.67024022127363
  - 0.696864406779661
  - 0.6205946469662105
  - 0.595574165140635
  - 0.5634562113786491
  - 0.5904310582448106
  TT_f1_macro:
  - 0.2475733685745534
  - 0.3060832639098798
  - 0.328680176247047
  - 0.4799899049853482
  - 0.2801700055870381
  - 0.3302409482495886
  - 0.42661005515654143
  - 0.4437307745358884
  - 0.4104924549348094
  - 0.37788657270565457
  - 0.4053003306389201
  - 0.37696935115589003
  - 0.2943787022044416
  - 0.29894442792901194
  - 0.24759740214727613
  - 0.3389512905776459
  TT_f1_micro:
  - 0.2580816110227875
  - 0.33916269210386857
  - 0.37272727272727274
  - 0.6181818181818182
  - 0.31107578166401695
  - 0.4075251722310546
  - 0.5909090909090909
  - 0.6171122994652406
  - 0.4965553789083201
  - 0.4774774774774775
  - 0.5053475935828877
  - 0.45294117647058824
  - 0.3370429252782194
  - 0.37413884472708003
  - 0.28609625668449196
  - 0.42406417112299466
  TT_f1_weighted:
  - 0.32386415119200174
  - 0.43848126656009234
  - 0.4800403449452756
  - 0.712221128406802
  - 0.413041129846377
  - 0.5396679327360263
  - 0.7102351638282752
  - 0.7307070916603337
  - 0.6068496115734018
  - 0.6051648891584374
  - 0.6220911403036843
  - 0.57126176811691
  - 0.4509674347360009
  - 0.5156454899312114
  - 0.405961484640788
  - 0.5561096385562406
  TT_matthews_corrcoef:
  - 0.12301575541712483
  - 0.13810807457940594
  - 0.15703488732939183
  - 0.1901363743712723
  - 0.11655691149390629
  - 0.09759295299567852
  - 0.12276932050439879
  - 0.15017805530874184
  - 0.1783872074484059
  - 0.14321081831859445
  - 0.15642723486067125
  - 0.18061747086439597
  - 0.11393515375597882
  - 0.06597510067973558
  - 0.052934093942817895
  - 0.0742282641022289
  TT_precision_macro:
  - 0.5403361344537815
  - 0.5373273003016515
  - 0.5400733441021102
  - 0.5481446992330475
  - 0.5301151506520456
  - 0.5196455066337801
  - 0.5237195133355778
  - 0.529248953167226
  - 0.5439549261839548
  - 0.5293855606758833
  - 0.5359337523516629
  - 0.5414278427917694
  - 0.5269108529855304
  - 0.5113856969174053
  - 0.5110391805651111
  - 0.5152321428571428
  TT_precision_micro:
  - 0.2580816110227875
  - 0.33916269210386857
  - 0.37272727272727274
  - 0.6181818181818182
  - 0.31107578166401695
  - 0.4075251722310546
  - 0.5909090909090909
  - 0.6171122994652406
  - 0.4965553789083201
  - 0.4774774774774775
  - 0.5053475935828877
  - 0.45294117647058824
  - 0.3370429252782194
  - 0.37413884472708003
  - 0.28609625668449196
  - 0.42406417112299466
  TT_precision_weighted:
  - 0.9299099395985209
  - 0.9334163171721294
  - 0.9404390904436546
  - 0.9165217534441141
  - 0.9396870964461237
  - 0.9476741239030857
  - 0.94745524343423
  - 0.9509930153976964
  - 0.9280547058313396
  - 0.9492805247643957
  - 0.9330759076149769
  - 0.9473968888257597
  - 0.9441303121926925
  - 0.959893300130193
  - 0.948847555903229
  - 0.9370688120702826
  TT_recall_macro:
  - 0.5937923048760759
  - 0.6277472527472527
  - 0.6538426377376889
  - 0.6877249283667621
  - 0.6127797248465323
  - 0.6212030905077263
  - 0.6588597734265516
  - 0.6927714144790924
  - 0.6809922035135667
  - 0.6744848321059388
  - 0.67024022127363
  - 0.696864406779661
  - 0.6205946469662105
  - 0.595574165140635
  - 0.5634562113786491
  - 0.5904310582448106
  TT_recall_micro:
  - 0.2580816110227875
  - 0.33916269210386857
  - 0.37272727272727274
  - 0.6181818181818182
  - 0.31107578166401695
  - 0.4075251722310546
  - 0.5909090909090909
  - 0.6171122994652406
  - 0.4965553789083201
  - 0.4774774774774775
  - 0.5053475935828877
  - 0.45294117647058824
  - 0.3370429252782194
  - 0.37413884472708003
  - 0.28609625668449196
  - 0.42406417112299466
  TT_recall_weighted:
  - 0.2580816110227875
  - 0.33916269210386857
  - 0.37272727272727274
  - 0.6181818181818182
  - 0.31107578166401695
  - 0.4075251722310546
  - 0.5909090909090909
  - 0.6171122994652406
  - 0.4965553789083201
  - 0.4774774774774775
  - 0.5053475935828877
  - 0.45294117647058824
  - 0.3370429252782194
  - 0.37413884472708003
  - 0.28609625668449196
  - 0.42406417112299466
  TT_roc_auc:
  - 0.8099249899958281
  - 0.7693947488497662
  - 0.8098996424508369
  - 0.7807495702005732
  - 0.823479472332274
  - 0.7418910963944076
  - 0.7590288814599662
  - 0.7909949972206782
  - 0.8306276499162322
  - 0.8542936288088643
  - 0.78154673752069
  - 0.8633813559322033
  - 0.7906776068790117
  - 0.7460134565132405
  - 0.6552652887278927
  - 0.7138010728749231
  fit_time:
  - 3.06643009185791
  - 2.5111899375915527
  - 2.910142421722412
  - 2.663045883178711
  - 2.068877696990967
  - 1.9629297256469727
  - 2.370326280593872
  - 2.300881862640381
  - 2.5637707710266113
  - 2.693894386291504
  - 2.494380474090576
  - 2.5365819931030273
  - 2.162126302719116
  - 2.0034232139587402
  - 2.268716812133789
  - 2.354830026626587
  score_time:
  - 27.44939875602722
  - 26.287420511245728
  - 27.513994932174683
  - 28.47121548652649
  - 21.97483539581299
  - 24.05970525741577
  - 24.039907217025757
  - 24.75548005104065
  - 25.343566417694092
  - 26.54324197769165
  - 24.874085187911987
  - 28.148728370666504
  - 23.437885999679565
  - 22.57841682434082
  - 20.713356971740723
  - 22.22525405883789
start: 2023-10-05 18:05:31.768365
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
