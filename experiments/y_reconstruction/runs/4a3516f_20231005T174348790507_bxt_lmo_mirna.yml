active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-05 18:05:16.680627
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: bxt_lmo
  params: {}
hash: 4a3516f65208f928449fa0e73ccf395befd7f8a09eb1f43eeff57ec43fd359c1
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/4a3516f_20231005T174348790507_bxt_lmo_mirna.yml"
results:
  LL_average_precision:
  - 0.999999421601104
  - 0.9999958815103839
  - 0.9999998379861031
  - 0.9999995683645378
  - 0.9999977225936819
  - 0.999988694453379
  - 0.9999976497107994
  - 0.9999919741669052
  - 0.9999990472904356
  - 0.9999970546890226
  - 0.9999946786166096
  - 0.9999978841835747
  - 0.9999919696702596
  - 0.9999722949195431
  - 0.9999970687843819
  - 0.9999836341752334
  LL_balanced_accuracy:
  - 0.7256860468269641
  - 0.7279896787689515
  - 0.7847447610135685
  - 0.8735960441008046
  - 0.8106759646080479
  - 0.7255755768093078
  - 0.7220686058411399
  - 0.7257449400069742
  - 0.7219167862832043
  - 0.7269674437398062
  - 0.72427604112883
  - 0.8732154429236298
  - 0.7232721595050928
  - 0.7240595205833805
  - 0.7844411816064476
  - 0.7577989803457594
  LL_f1_macro:
  - 0.4200097113232597
  - 0.4236318813374228
  - 0.4923524770695523
  - 0.6162987502466348
  - 0.5268932785867922
  - 0.4205491061946074
  - 0.4137205563019543
  - 0.4200871111715281
  - 0.4145218824098678
  - 0.4217065403785518
  - 0.4158285653932086
  - 0.6148506723725029
  - 0.41653516346009367
  - 0.41795852895788227
  - 0.49122851965224845
  - 0.459630845068427
  LL_f1_micro:
  - 0.4903514075539799
  - 0.4949340881816766
  - 0.5996143311255852
  - 0.7651764190225727
  - 0.6482040484718106
  - 0.4904349418132302
  - 0.4828849652710233
  - 0.4904621772059494
  - 0.483031433442803
  - 0.49276698973578514
  - 0.48670686912839994
  - 0.7643489369468018
  - 0.485681591925942
  - 0.4873293588584637
  - 0.5988328317561304
  - 0.549817501596861
  LL_f1_weighted:
  - 0.5932922239965287
  - 0.5973221964015432
  - 0.6930434621962842
  - 0.8213009976378631
  - 0.7324831846811694
  - 0.5929771203021439
  - 0.5870161557149501
  - 0.5933981599998908
  - 0.5865683034840271
  - 0.5955912572187845
  - 0.5911529788079143
  - 0.820894958046605
  - 0.5889872928815402
  - 0.5903451631245862
  - 0.6926973812100458
  - 0.6491988822485901
  LL_matthews_corrcoef:
  - 0.2350014761058768
  - 0.23794735964117525
  - 0.291070258351153
  - 0.41680629147300846
  - 0.3228628603186563
  - 0.23572246755987092
  - 0.22969137503201018
  - 0.2350581338171418
  - 0.23075676795343858
  - 0.23625243881246716
  - 0.2308271856343398
  - 0.414961945182054
  - 0.2323250493640826
  - 0.23354587705754487
  - 0.28978190416332633
  - 0.2644500458272527
  LL_precision_macro:
  - 0.5611753523848587
  - 0.5620849880857823
  - 0.5743840685558477
  - 0.6162535627415576
  - 0.5838819529414312
  - 0.5615814470015594
  - 0.5593939512119026
  - 0.5611888867496768
  - 0.5599872218413015
  - 0.5614793182726514
  - 0.5593924225696314
  - 0.615344514284012
  - 0.5604362504058553
  - 0.5608584680407278
  - 0.5738057262895822
  - 0.5678181762435996
  LL_precision_micro:
  - 0.4903514075539799
  - 0.4949340881816766
  - 0.5996143311255852
  - 0.7651764190225728
  - 0.6482040484718106
  - 0.4904349418132302
  - 0.4828849652710233
  - 0.4904621772059494
  - 0.483031433442803
  - 0.49276698973578514
  - 0.48670686912839994
  - 0.7643489369468017
  - 0.485681591925942
  - 0.4873293588584637
  - 0.5988328317561304
  - 0.549817501596861
  LL_precision_weighted:
  - 0.9376441355293349
  - 0.9372859777644492
  - 0.9404353699153332
  - 0.9454018441912869
  - 0.9409813370978527
  - 0.9372404927508498
  - 0.9385729897127317
  - 0.937643895732756
  - 0.9379769838259077
  - 0.9376313206471425
  - 0.9390285549383697
  - 0.9456378851832355
  - 0.9378330478025908
  - 0.9375993003413368
  - 0.9407831315684524
  - 0.9389388879630237
  LL_recall_macro:
  - 0.7256860468269641
  - 0.7279896787689515
  - 0.7847447610135685
  - 0.8735960441008046
  - 0.8106759646080479
  - 0.7255755768093078
  - 0.7220686058411399
  - 0.7257449400069742
  - 0.7219167862832043
  - 0.7269674437398062
  - 0.72427604112883
  - 0.8732154429236298
  - 0.7232721595050928
  - 0.7240595205833805
  - 0.7844411816064476
  - 0.7577989803457594
  LL_recall_micro:
  - 0.4903514075539799
  - 0.4949340881816766
  - 0.5996143311255852
  - 0.7651764190225728
  - 0.6482040484718106
  - 0.4904349418132302
  - 0.4828849652710233
  - 0.4904621772059494
  - 0.483031433442803
  - 0.49276698973578514
  - 0.48670686912839994
  - 0.7643489369468017
  - 0.485681591925942
  - 0.4873293588584637
  - 0.5988328317561304
  - 0.549817501596861
  LL_recall_weighted:
  - 0.4903514075539799
  - 0.4949340881816766
  - 0.5996143311255852
  - 0.7651764190225728
  - 0.6482040484718106
  - 0.4904349418132302
  - 0.4828849652710233
  - 0.4904621772059494
  - 0.483031433442803
  - 0.49276698973578514
  - 0.48670686912839994
  - 0.7643489369468017
  - 0.485681591925942
  - 0.4873293588584637
  - 0.5988328317561306
  - 0.549817501596861
  LL_roc_auc:
  - 0.9999999560141083
  - 0.9999996687850471
  - 0.9999999877898145
  - 0.9999999673091311
  - 0.9999998226114609
  - 0.9999990460402335
  - 0.999999818963216
  - 0.9999993097106539
  - 0.9999999274468552
  - 0.9999997706147666
  - 0.99999957634032
  - 0.9999998365180067
  - 0.9999993521018095
  - 0.9999975915122863
  - 0.9999997780067791
  - 0.9999986496233032
  LT_average_precision:
  - 0.17074352353032385
  - 0.14549837338624938
  - 0.14943349606878087
  - 0.1653904728394246
  - 0.16406872584195006
  - 0.13924159484936044
  - 0.14697432392098553
  - 0.16580590570778214
  - 0.16817530378636458
  - 0.14108982501037082
  - 0.14861519116379182
  - 0.1702956841708051
  - 0.15990420587026533
  - 0.13902114040980815
  - 0.14124893929075832
  - 0.16226670064750456
  LT_balanced_accuracy:
  - 0.558496940495736
  - 0.5607387461494029
  - 0.5677706141305717
  - 0.6107833542486939
  - 0.5940487148087412
  - 0.5570884963070716
  - 0.5518133987609941
  - 0.5580253734436778
  - 0.5564075422684972
  - 0.5611675085139538
  - 0.5476838981327384
  - 0.6112956178525188
  - 0.554323777745386
  - 0.5565840528898807
  - 0.5639133712801305
  - 0.5634346933986099
  LT_f1_macro:
  - 0.24593432399321816
  - 0.2505775041824003
  - 0.30824191685422864
  - 0.40509197182266915
  - 0.34814014311421787
  - 0.2495059410886028
  - 0.253230132206215
  - 0.23866476178956353
  - 0.24341330594725996
  - 0.25599886886128687
  - 0.24515247030819826
  - 0.401856188952207
  - 0.23526316646774115
  - 0.24607889290124513
  - 0.3056172494465995
  - 0.2636353041170998
  LT_f1_micro:
  - 0.2588004054350208
  - 0.26545036160420776
  - 0.34112015121630507
  - 0.49636959588415897
  - 0.4015124555160143
  - 0.26459074733096083
  - 0.266958664111689
  - 0.24989116539405037
  - 0.25604982206405696
  - 0.2729811114152751
  - 0.2571037503421845
  - 0.4916421932764399
  - 0.2460511908020805
  - 0.2600875992335067
  - 0.338139885026006
  - 0.281836713540407
  LT_f1_weighted:
  - 0.3305200569219929
  - 0.341591872025972
  - 0.43678235537079513
  - 0.6053339213614652
  - 0.5083630309529176
  - 0.3413225750291035
  - 0.33947347366368014
  - 0.3181554676509814
  - 0.32750060817330917
  - 0.353090586641187
  - 0.32610214439459273
  - 0.6014117808917142
  - 0.313424283137279
  - 0.3347195835563107
  - 0.43381750291765964
  - 0.363211061515503
  LT_matthews_corrcoef:
  - 0.07475858582425753
  - 0.07559218313157993
  - 0.07796593155471147
  - 0.11365063788630646
  - 0.10052386190668945
  - 0.07078735120465174
  - 0.06668236167324793
  - 0.07529257579657397
  - 0.07206820980064492
  - 0.07450172704342566
  - 0.06239452160058765
  - 0.1135940595015306
  - 0.0707533088382541
  - 0.07091828151176692
  - 0.07350044130655711
  - 0.0772279395163986
  LT_precision_macro:
  - 0.5238852071026273
  - 0.5235194933747184
  - 0.5224237546065406
  - 0.5291480330676949
  - 0.5268612038803107
  - 0.5219433397913391
  - 0.5214545728742527
  - 0.5244245389285835
  - 0.523019203882113
  - 0.5226856850446463
  - 0.5204108539686132
  - 0.5289849919588394
  - 0.5230379353173139
  - 0.5222209367998526
  - 0.5211313953717934
  - 0.5235050976146092
  LT_precision_micro:
  - 0.2588004054350208
  - 0.26545036160420776
  - 0.34112015121630507
  - 0.49636959588415897
  - 0.4015124555160142
  - 0.26459074733096083
  - 0.266958664111689
  - 0.24989116539405037
  - 0.25604982206405696
  - 0.2729811114152751
  - 0.2571037503421845
  - 0.4916421932764399
  - 0.2460511908020805
  - 0.2600875992335067
  - 0.338139885026006
  - 0.281836713540407
  LT_precision_weighted:
  - 0.9048713090523385
  - 0.9068802780168901
  - 0.8936147570466334
  - 0.9002527410714553
  - 0.9024107694432322
  - 0.9052424549403352
  - 0.8948168342325048
  - 0.9070271971673124
  - 0.9047077821287898
  - 0.9067393646534476
  - 0.8940427999476663
  - 0.901889299820624
  - 0.9056405196888997
  - 0.9055007734530812
  - 0.8925915264726887
  - 0.9044326424637237
  LT_recall_macro:
  - 0.558496940495736
  - 0.5607387461494029
  - 0.5677706141305717
  - 0.6107833542486939
  - 0.5940487148087412
  - 0.5570884963070716
  - 0.5518133987609941
  - 0.5580253734436778
  - 0.5564075422684972
  - 0.5611675085139538
  - 0.5476838981327384
  - 0.6112956178525188
  - 0.554323777745386
  - 0.5565840528898807
  - 0.5639133712801305
  - 0.5634346933986099
  LT_recall_micro:
  - 0.2588004054350208
  - 0.26545036160420776
  - 0.34112015121630507
  - 0.49636959588415897
  - 0.4015124555160142
  - 0.26459074733096083
  - 0.266958664111689
  - 0.24989116539405037
  - 0.25604982206405696
  - 0.2729811114152751
  - 0.2571037503421845
  - 0.4916421932764399
  - 0.2460511908020805
  - 0.2600875992335067
  - 0.338139885026006
  - 0.281836713540407
  LT_recall_weighted:
  - 0.2588004054350208
  - 0.26545036160420776
  - 0.34112015121630507
  - 0.49636959588415897
  - 0.4015124555160142
  - 0.26459074733096083
  - 0.266958664111689
  - 0.24989116539405037
  - 0.25604982206405696
  - 0.2729811114152751
  - 0.2571037503421845
  - 0.4916421932764399
  - 0.2460511908020805
  - 0.2600875992335067
  - 0.338139885026006
  - 0.281836713540407
  LT_roc_auc:
  - 0.6751363265503201
  - 0.6714849433324794
  - 0.6547318433727378
  - 0.6768526359656796
  - 0.6753026923221699
  - 0.6659576813612105
  - 0.6545735247978302
  - 0.6807030070854715
  - 0.672932744823292
  - 0.6664902110723163
  - 0.6541175728814193
  - 0.6758301737515962
  - 0.6706778416010608
  - 0.6618334899065296
  - 0.6447955219723549
  - 0.6744920983049393
  TL_average_precision:
  - 0.27535517772986257
  - 0.28071335078090537
  - 0.28479142575667915
  - 0.29584167514470905
  - 0.26361595445540664
  - 0.27115859386375996
  - 0.2532293743821686
  - 0.2672073366994866
  - 0.28651617251305683
  - 0.28911162438435256
  - 0.27749144872199644
  - 0.2991954107253573
  - 0.28258305030544073
  - 0.2952370607302103
  - 0.2975729234497829
  - 0.2886185757093991
  TL_balanced_accuracy:
  - 0.5232832746412992
  - 0.5222399913185811
  - 0.5413883268122214
  - 0.5922003319388718
  - 0.5610961286481079
  - 0.5288650434747033
  - 0.5282110016922786
  - 0.5276660954378201
  - 0.5216795991856655
  - 0.5268526489456145
  - 0.5219486486544938
  - 0.597118541612333
  - 0.5236476640306807
  - 0.5254773614145485
  - 0.5481027015134158
  - 0.5312341064191124
  TL_f1_macro:
  - 0.1236622441388506
  - 0.12127395398165453
  - 0.1683878059757315
  - 0.30715884217475126
  - 0.2165586837533852
  - 0.1340181729295054
  - 0.13154740908414062
  - 0.1305860439499397
  - 0.12197962764364892
  - 0.13187751245750165
  - 0.1209233443406518
  - 0.30693855119824554
  - 0.12186697521581474
  - 0.12799512471349744
  - 0.1821805833603931
  - 0.14333507348639507
  TL_f1_micro:
  - 0.1238456317402423
  - 0.12155574904531088
  - 0.1694924550421983
  - 0.33915586900661526
  - 0.22264819853244291
  - 0.1340451260065408
  - 0.13157171517300134
  - 0.1306500657462196
  - 0.12231016571852585
  - 0.13197020914062715
  - 0.1212314837716767
  - 0.3369699211045365
  - 0.12217275400555143
  - 0.12818451644818205
  - 0.18408360128617363
  - 0.14334045584045585
  TL_f1_weighted:
  - 0.11276024234711356
  - 0.10775760844176573
  - 0.19454924555795572
  - 0.43518154528266567
  - 0.27590297943221354
  - 0.12986925789895737
  - 0.1275890520309509
  - 0.12417497382509972
  - 0.10738749528001326
  - 0.12419872631571885
  - 0.10679461430438182
  - 0.43057551260156207
  - 0.10780790594219246
  - 0.11699963217096067
  - 0.21611344479954908
  - 0.1451750150456054
  TL_matthews_corrcoef:
  - 0.05187780575635504
  - 0.05100654516137396
  - 0.06821035492378456
  - 0.10428483811091993
  - 0.08558209812274366
  - 0.05997547158349584
  - 0.058543962833033834
  - 0.05878058756911035
  - 0.050243951537466996
  - 0.057710089669486424
  - 0.05067874285682383
  - 0.11150769062027945
  - 0.05453789932231766
  - 0.05666844923321141
  - 0.0760053315997574
  - 0.06148524847391513
  TL_precision_macro:
  - 0.5288974249923628
  - 0.5292453761787852
  - 0.5281036519061142
  - 0.5294883088572584
  - 0.5299703748877294
  - 0.5311540946994857
  - 0.5303728632324116
  - 0.5312219471187699
  - 0.5291109471683463
  - 0.5310067589272611
  - 0.5292539078142999
  - 0.5320071864266158
  - 0.5314447809584094
  - 0.5315114376077351
  - 0.5300233159980523
  - 0.5302588757396449
  TL_precision_micro:
  - 0.1238456317402423
  - 0.12155574904531088
  - 0.1694924550421983
  - 0.33915586900661526
  - 0.22264819853244291
  - 0.1340451260065408
  - 0.13157171517300134
  - 0.1306500657462196
  - 0.12231016571852585
  - 0.13197020914062715
  - 0.1212314837716767
  - 0.3369699211045365
  - 0.12217275400555143
  - 0.12818451644818205
  - 0.18408360128617363
  - 0.14334045584045585
  TL_precision_weighted:
  - 0.9207656266550809
  - 0.9206160474383711
  - 0.9197924359810894
  - 0.91005034866796
  - 0.916649378364822
  - 0.9231696710474084
  - 0.9243357928858954
  - 0.9239501565525828
  - 0.9182809269359081
  - 0.920636258792595
  - 0.9202227242996953
  - 0.9113089575134783
  - 0.9236559547755588
  - 0.9214068603293314
  - 0.9196669036202701
  - 0.9194543110376492
  TL_recall_macro:
  - 0.5232832746412992
  - 0.5222399913185811
  - 0.5413883268122214
  - 0.5922003319388718
  - 0.5610961286481079
  - 0.5288650434747033
  - 0.5282110016922786
  - 0.5276660954378201
  - 0.5216795991856655
  - 0.5268526489456145
  - 0.5219486486544938
  - 0.597118541612333
  - 0.5236476640306807
  - 0.5254773614145485
  - 0.5481027015134158
  - 0.5312341064191124
  TL_recall_micro:
  - 0.1238456317402423
  - 0.12155574904531088
  - 0.1694924550421983
  - 0.33915586900661526
  - 0.22264819853244291
  - 0.1340451260065408
  - 0.13157171517300134
  - 0.1306500657462196
  - 0.12231016571852585
  - 0.13197020914062715
  - 0.1212314837716767
  - 0.3369699211045365
  - 0.12217275400555143
  - 0.12818451644818205
  - 0.18408360128617363
  - 0.14334045584045585
  TL_recall_weighted:
  - 0.1238456317402423
  - 0.12155574904531088
  - 0.1694924550421983
  - 0.33915586900661526
  - 0.22264819853244291
  - 0.1340451260065408
  - 0.13157171517300134
  - 0.1306500657462196
  - 0.12231016571852585
  - 0.13197020914062715
  - 0.1212314837716767
  - 0.3369699211045365
  - 0.12217275400555143
  - 0.12818451644818205
  - 0.18408360128617363
  - 0.14334045584045585
  TL_roc_auc:
  - 0.7109978172504277
  - 0.7181843050859935
  - 0.7186652605175763
  - 0.716440991501382
  - 0.7119081324901497
  - 0.7216038266450674
  - 0.7108237552906947
  - 0.7157339524428521
  - 0.7259655879694475
  - 0.7330235528663311
  - 0.7220776159697119
  - 0.7330719673252282
  - 0.7209237947278343
  - 0.7255078156007745
  - 0.7271026318804586
  - 0.721794028608181
  TT_average_precision:
  - 0.12382948563034454
  - 0.10334940897948888
  - 0.11315074973380118
  - 0.11518589325793356
  - 0.11257706853052392
  - 0.10048234709232456
  - 0.10969480793962016
  - 0.10249667723329325
  - 0.1266718343950986
  - 0.11341834706509261
  - 0.11785828707116361
  - 0.11854425528780739
  - 0.13071752363554248
  - 0.10800582404477296
  - 0.1224577524009311
  - 0.12376179852008459
  TT_balanced_accuracy:
  - 0.5009429436926619
  - 0.5013420367211459
  - 0.5019362666274846
  - 0.524695974424504
  - 0.5039946822669129
  - 0.5042728445128298
  - 0.5019391441171908
  - 0.503532237766454
  - 0.5015345372331714
  - 0.502587871553524
  - 0.5029970856464955
  - 0.5210566117388314
  - 0.5015895250734205
  - 0.5023479177887817
  - 0.503800461580082
  - 0.5018702677215288
  TT_f1_macro:
  - 0.0709426278570411
  - 0.07615383952230026
  - 0.08736893398190737
  - 0.16042898667558209
  - 0.0950566544904581
  - 0.08053474662324298
  - 0.08359215647994478
  - 0.07798062088439137
  - 0.07481126977004571
  - 0.08059286274390964
  - 0.0814695062585233
  - 0.15118120775611818
  - 0.07417770760393413
  - 0.07785073740373893
  - 0.09560584260586304
  - 0.07575384022896084
  TT_f1_micro:
  - 0.07460636378546827
  - 0.07891175988190914
  - 0.09014679350500247
  - 0.1612395719046929
  - 0.09644148586456278
  - 0.08314842209072978
  - 0.08662064431295201
  - 0.08100987469919509
  - 0.07842291255752794
  - 0.08339497041420119
  - 0.08493589743589744
  - 0.15137747904738197
  - 0.07805309007232084
  - 0.0805802103879027
  - 0.09779750164365549
  - 0.07908057422620529
  TT_f1_weighted:
  - 0.020652678991617938
  - 0.03248866441785871
  - 0.04444682362505344
  - 0.18292718203200156
  - 0.06456708978327895
  - 0.03825262865596126
  - 0.038593459850408594
  - 0.03248370636874734
  - 0.025196015218957906
  - 0.036941719140239034
  - 0.033357387910354086
  - 0.1622430898634707
  - 0.02286365634897938
  - 0.034517261476909325
  - 0.05775490313013211
  - 0.028066051643287904
  TT_matthews_corrcoef:
  - 0.006083833199702506
  - 0.005981458904500855
  - 0.007493046278857996
  - 0.041695287134427654
  - 0.011852732361485326
  - 0.01754287811164659
  - 0.008181052144314385
  - 0.016345169466141382
  - 0.00864693473366744
  - 0.01093881885463267
  - 0.014238618444296115
  - 0.03855898466917854
  - 0.009859530367238908
  - 0.010169756895016731
  - 0.012649152199893678
  - 0.009591970743564195
  TT_precision_macro:
  - 0.5098131592294005
  - 0.506664841964176
  - 0.5072492266483526
  - 0.5175989914321562
  - 0.5087921425939572
  - 0.5180063053731548
  - 0.5086287570885849
  - 0.5189090162201261
  - 0.5121811121085957
  - 0.5115594761428095
  - 0.516911283085897
  - 0.5176523568601505
  - 0.5152892113323698
  - 0.5110123058607392
  - 0.5105251064906583
  - 0.5122984936442929
  TT_precision_micro:
  - 0.07460636378546827
  - 0.07891175988190914
  - 0.09014679350500246
  - 0.1612395719046929
  - 0.09644148586456279
  - 0.08314842209072978
  - 0.08662064431295201
  - 0.08100987469919509
  - 0.07842291255752794
  - 0.08339497041420119
  - 0.08493589743589744
  - 0.15137747904738197
  - 0.07805309007232084
  - 0.0805802103879027
  - 0.09779750164365549
  - 0.07908057422620529
  TT_precision_weighted:
  - 0.8896727089002473
  - 0.8864437651478133
  - 0.8765503460661903
  - 0.9016309057841477
  - 0.8868042911702391
  - 0.9050178368591884
  - 0.8805720532627246
  - 0.9053486762838298
  - 0.8908154583922978
  - 0.8910079407597659
  - 0.8944803333065159
  - 0.8974030909915838
  - 0.8951491378244106
  - 0.8932872191123457
  - 0.8804174284296902
  - 0.8924738125984895
  TT_recall_macro:
  - 0.5009429436926619
  - 0.5013420367211459
  - 0.5019362666274846
  - 0.524695974424504
  - 0.5039946822669129
  - 0.5042728445128298
  - 0.5019391441171908
  - 0.503532237766454
  - 0.5015345372331714
  - 0.502587871553524
  - 0.5029970856464955
  - 0.5210566117388314
  - 0.5015895250734205
  - 0.5023479177887817
  - 0.503800461580082
  - 0.5018702677215288
  TT_recall_micro:
  - 0.07460636378546827
  - 0.07891175988190914
  - 0.09014679350500246
  - 0.1612395719046929
  - 0.09644148586456279
  - 0.08314842209072978
  - 0.08662064431295201
  - 0.08100987469919509
  - 0.07842291255752794
  - 0.08339497041420119
  - 0.08493589743589744
  - 0.15137747904738197
  - 0.07805309007232084
  - 0.0805802103879027
  - 0.09779750164365549
  - 0.07908057422620529
  TT_recall_weighted:
  - 0.07460636378546827
  - 0.07891175988190914
  - 0.09014679350500246
  - 0.1612395719046929
  - 0.09644148586456279
  - 0.08314842209072978
  - 0.08662064431295201
  - 0.08100987469919509
  - 0.07842291255752794
  - 0.08339497041420119
  - 0.08493589743589744
  - 0.15137747904738197
  - 0.07805309007232084
  - 0.0805802103879027
  - 0.09779750164365549
  - 0.07908057422620529
  TT_roc_auc:
  - 0.6165171017924362
  - 0.5903687148874914
  - 0.5879959823425644
  - 0.6114809657938899
  - 0.5915017095030309
  - 0.5884622351579903
  - 0.5821860028848107
  - 0.5937832211015852
  - 0.625527055475954
  - 0.6073539798618001
  - 0.6027214606953424
  - 0.6209118803521366
  - 0.6115938897446038
  - 0.5883594093998201
  - 0.5916655054351604
  - 0.6170848086977069
  fit_time:
  - 85.03179287910461
  - 83.01401567459106
  - 88.64387249946594
  - 93.65312504768372
  - 103.59868669509888
  - 89.78190040588379
  - 92.59282398223877
  - 79.48656582832336
  - 94.75280046463013
  - 91.43028569221497
  - 81.48334836959839
  - 93.05220580101013
  - 78.58885049819946
  - 76.25042605400085
  - 91.71043300628662
  - 74.86303687095642
  score_time:
  - 1046.3470673561096
  - 983.0949852466583
  - 1075.6966454982758
  - 1162.584532737732
  - 1125.6297137737274
  - 981.9805481433868
  - 1041.1494660377502
  - 962.1329960823059
  - 1033.1641352176666
  - 1044.8663506507874
  - 961.0868389606476
  - 1194.1583316326141
  - 1021.6198616027832
  - 1031.4583933353424
  - 1084.6139965057373
  - 1007.7882614135742
start: 2023-10-05 17:43:48.790507
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
