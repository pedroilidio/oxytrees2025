active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: y_reconstruction/runs
end: 2023-10-07 06:51:18.043249
estimator:
  call: bipartite_adaptations.estimators.bxt_gmosa
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 1000
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gmosa_1k
  params:
    n_estimators: 1000
hash: 202985fbb1ee3b34fea5e2a6a29a405631978d2e2c50722c665a48325e31c8c0
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/202985f_20231007T065109302265_bxt_gmosa_1k_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9909627664848648
  - 1.0
  - 1.0
  - 0.9944093050298627
  - 0.9849726900635047
  - 1.0
  - 1.0
  - 0.986765917958652
  - 0.9901701635401936
  - 1.0
  - 1.0
  - 0.9904878927499172
  - 0.996233541731977
  - 1.0
  - 1.0
  - 0.995982706116369
  LL_balanced_accuracy:
  - 0.6501416430594901
  - 0.7562849162011174
  - 0.5924137931034483
  - 0.7541436464088398
  - 0.7878998609179415
  - 0.5729023383768913
  - 0.6815718157181572
  - 0.6
  - 0.6450742240215924
  - 0.6898148148148149
  - 0.648051948051948
  - 0.7203947368421053
  - 0.8888888888888888
  - 0.5646666666666667
  - 0.7877792378449409
  - 0.8789473684210527
  LL_f1_macro:
  - 0.3206378158498542
  - 0.4395599983941547
  - 0.23324856230670457
  - 0.4550220880692984
  - 0.47134474115733993
  - 0.17528583485796065
  - 0.34067695277609705
  - 0.2317554240631164
  - 0.3165103043218379
  - 0.35416239923848997
  - 0.30633853376535003
  - 0.4160278161786268
  - 0.6527777777777778
  - 0.18092290421156776
  - 0.4990912684228543
  - 0.6285061456035297
  LL_f1_micro:
  - 0.35
  - 0.5407894736842105
  - 0.24133504492939667
  - 0.5430038510911425
  - 0.5986842105263158
  - 0.18289473684210525
  - 0.39666238767650835
  - 0.24518613607188702
  - 0.3425
  - 0.41375
  - 0.33902439024390246
  - 0.4817073170731707
  - 0.795
  - 0.18375
  - 0.6060975609756097
  - 0.775609756097561
  LL_f1_weighted:
  - 0.4418032846213421
  - 0.6501674516291934
  - 0.30107393530453447
  - 0.6430725655824412
  - 0.7028089777047009
  - 0.24762251947434916
  - 0.5125793674262586
  - 0.3218585502578788
  - 0.4301319226071364
  - 0.5287565216343547
  - 0.4385509869370227
  - 0.5832120002738295
  - 0.8405555555555557
  - 0.22302858616694185
  - 0.6972928973728131
  - 0.8280653071264403
  LL_matthews_corrcoef:
  - 0.1720173213695074
  - 0.23955574141742403
  - 0.12439428222341938
  - 0.2608044876735963
  - 0.26120988280788
  - 0.08577363649125522
  - 0.17069495851605068
  - 0.11800021454603968
  - 0.17106383291289579
  - 0.1804461856985224
  - 0.15814162958808478
  - 0.23351800045875018
  - 0.46192279084290516
  - 0.09590970939673987
  - 0.29815290915914316
  - 0.4317030903756214
  LL_precision_macro:
  - 0.5492700729927007
  - 0.5559796437659033
  - 0.541860465116279
  - 0.5669099756690997
  - 0.5592485549132948
  - 0.5252293577981652
  - 0.5401174168297456
  - 0.5348101265822784
  - 0.5504273504273505
  - 0.5428849902534113
  - 0.5422297297297297
  - 0.5618556701030928
  - 0.6371681415929203
  - 0.5355618776671408
  - 0.5772251308900523
  - 0.6229508196721312
  LL_precision_micro:
  - 0.35
  - 0.5407894736842105
  - 0.24133504492939667
  - 0.5430038510911425
  - 0.5986842105263158
  - 0.18289473684210528
  - 0.39666238767650835
  - 0.24518613607188702
  - 0.3425
  - 0.41375
  - 0.33902439024390246
  - 0.4817073170731707
  - 0.795
  - 0.18375
  - 0.6060975609756097
  - 0.775609756097561
  LL_precision_weighted:
  - 0.9359489051094891
  - 0.9485871166465784
  - 0.9364838642266472
  - 0.938844797591272
  - 0.9524452388195924
  - 0.9587699179140512
  - 0.9515913070347101
  - 0.9474496677012073
  - 0.9336880341880343
  - 0.9497173489278752
  - 0.9441743572841135
  - 0.9358813175760624
  - 0.9437610619469027
  - 0.9419452347083925
  - 0.9391616651768612
  - 0.9448220711715313
  LL_recall_macro:
  - 0.6501416430594901
  - 0.7562849162011174
  - 0.5924137931034483
  - 0.7541436464088398
  - 0.7878998609179415
  - 0.5729023383768913
  - 0.6815718157181572
  - 0.6
  - 0.6450742240215924
  - 0.6898148148148149
  - 0.648051948051948
  - 0.7203947368421053
  - 0.8888888888888888
  - 0.5646666666666667
  - 0.7877792378449409
  - 0.8789473684210527
  LL_recall_micro:
  - 0.35
  - 0.5407894736842105
  - 0.24133504492939667
  - 0.5430038510911425
  - 0.5986842105263158
  - 0.18289473684210528
  - 0.39666238767650835
  - 0.24518613607188702
  - 0.3425
  - 0.41375
  - 0.33902439024390246
  - 0.4817073170731707
  - 0.795
  - 0.18375
  - 0.6060975609756097
  - 0.775609756097561
  LL_recall_weighted:
  - 0.35
  - 0.5407894736842105
  - 0.24133504492939667
  - 0.5430038510911425
  - 0.5986842105263157
  - 0.18289473684210528
  - 0.39666238767650835
  - 0.24518613607188702
  - 0.3425
  - 0.41375
  - 0.33902439024390246
  - 0.4817073170731707
  - 0.795
  - 0.18375
  - 0.6060975609756097
  - 0.775609756097561
  LL_roc_auc:
  - 0.9992524394082467
  - 1.0
  - 1.0
  - 0.9996107483676545
  - 0.9991519386682045
  - 1.0
  - 1.0
  - 0.9992269635126777
  - 0.9992680527916924
  - 1.0
  - 1.0
  - 0.999298245614035
  - 0.9997268117842469
  - 1.0
  - 0.9999999999999999
  - 0.9997258771929826
  LT_average_precision:
  - 0.3216519802511343
  - 0.4636326955868346
  - 0.24603896148126136
  - 0.43286071078426047
  - 0.3053477629350055
  - 0.32028787255833846
  - 0.1738499844916395
  - 0.291798704867095
  - 0.40666246042198445
  - 0.5039689682568637
  - 0.23748913219836626
  - 0.4123434790652635
  - 0.39414169174475083
  - 0.5159368228318221
  - 0.34373655276361953
  - 0.41521210222347565
  LT_balanced_accuracy:
  - 0.5533864541832669
  - 0.6855601659751037
  - 0.540948275862069
  - 0.6796443899448191
  - 0.7043963254593175
  - 0.41097560975609754
  - 0.597872340425532
  - 0.5525210084033614
  - 0.6063432835820896
  - 0.691699604743083
  - 0.5397489539748954
  - 0.7168674698795181
  - 0.7232704402515723
  - 0.5177865612648221
  - 0.7252066115702479
  - 0.7691842168966352
  LT_f1_macro:
  - 0.2923298913288542
  - 0.47523901057210793
  - 0.13742560621710687
  - 0.41689340588988477
  - 0.40131578947368424
  - 0.16238297872340424
  - 0.22003909578467246
  - 0.13401807318157127
  - 0.22644844517184942
  - 0.4057142857142857
  - 0.15379608260843836
  - 0.37000567098004844
  - 0.5205068927134172
  - 0.12495517188380552
  - 0.4170501862809555
  - 0.5851250845165652
  LT_f1_micro:
  - 0.33458646616541354
  - 0.5601503759398496
  - 0.13765182186234817
  - 0.5222672064777328
  - 0.5112781954887218
  - 0.16541353383458646
  - 0.23481781376518218
  - 0.13765182186234817
  - 0.24642857142857144
  - 0.44285714285714284
  - 0.15384615384615385
  - 0.4576923076923077
  - 0.7142857142857143
  - 0.12857142857142856
  - 0.48846153846153845
  - 0.7730769230769231
  LT_f1_weighted:
  - 0.4457537630431311
  - 0.6466488696322222
  - 0.14969780497144727
  - 0.6366730471159678
  - 0.6347447566284131
  - 0.20518956966885296
  - 0.31697009900978046
  - 0.1860261011751906
  - 0.3401131634323124
  - 0.5256326530612245
  - 0.14833831769745137
  - 0.585154326006004
  - 0.7926681589666433
  - 0.07955106013920503
  - 0.5928319762639289
  - 0.8278514588859416
  LT_matthews_corrcoef:
  - 0.053708385468004397
  - 0.21659773399510673
  - 0.07340252743933794
  - 0.1662674238260523
  - 0.1699265619430247
  - -0.13724811434838752
  - 0.10810295834549852
  - 0.06525687811114689
  - 0.10698138654518698
  - 0.23783838311249403
  - 0.08322982396523902
  - 0.17716859977354824
  - 0.21726587056663396
  - 0.05953306341424783
  - 0.23171457117231328
  - 0.3028322440087146
  LT_precision_macro:
  - 0.5135080645161291
  - 0.5632066938037088
  - 0.5328947368421053
  - 0.5384716386554622
  - 0.5353174603174603
  - 0.44710144927536233
  - 0.5298507462686567
  - 0.5202702702702703
  - 0.5269058295964125
  - 0.5737704918032787
  - 0.5435684647302904
  - 0.5361842105263158
  - 0.5528556965040796
  - 0.5498154981549815
  - 0.5596026490066225
  - 0.585171568627451
  LT_precision_micro:
  - 0.33458646616541354
  - 0.5601503759398496
  - 0.13765182186234817
  - 0.5222672064777328
  - 0.5112781954887218
  - 0.16541353383458646
  - 0.23481781376518218
  - 0.13765182186234817
  - 0.24642857142857144
  - 0.44285714285714284
  - 0.15384615384615385
  - 0.4576923076923077
  - 0.7142857142857143
  - 0.12857142857142856
  - 0.48846153846153845
  - 0.7730769230769231
  LT_precision_weighted:
  - 0.9118618117875333
  - 0.8932890231004921
  - 0.943266567227786
  - 0.932779488313544
  - 0.9508533237856547
  - 0.7752533507682249
  - 0.9543174814188169
  - 0.9650399387241493
  - 0.959449071108264
  - 0.9177985948477753
  - 0.9262687519948931
  - 0.960754048582996
  - 0.9335868705173689
  - 0.9131787032156036
  - 0.9390219052470707
  - 0.9276442307692307
  LT_recall_macro:
  - 0.5533864541832669
  - 0.6855601659751037
  - 0.540948275862069
  - 0.6796443899448191
  - 0.7043963254593175
  - 0.41097560975609754
  - 0.597872340425532
  - 0.5525210084033614
  - 0.6063432835820896
  - 0.691699604743083
  - 0.5397489539748954
  - 0.7168674698795181
  - 0.7232704402515723
  - 0.5177865612648221
  - 0.7252066115702479
  - 0.7691842168966352
  LT_recall_micro:
  - 0.33458646616541354
  - 0.5601503759398496
  - 0.13765182186234817
  - 0.5222672064777328
  - 0.5112781954887218
  - 0.16541353383458646
  - 0.23481781376518218
  - 0.13765182186234817
  - 0.24642857142857144
  - 0.44285714285714284
  - 0.15384615384615385
  - 0.4576923076923077
  - 0.7142857142857143
  - 0.12857142857142856
  - 0.48846153846153845
  - 0.7730769230769231
  LT_recall_weighted:
  - 0.33458646616541354
  - 0.5601503759398496
  - 0.13765182186234817
  - 0.5222672064777328
  - 0.5112781954887218
  - 0.16541353383458646
  - 0.23481781376518218
  - 0.13765182186234817
  - 0.24642857142857144
  - 0.44285714285714284
  - 0.15384615384615385
  - 0.4576923076923077
  - 0.7142857142857143
  - 0.12857142857142856
  - 0.48846153846153845
  - 0.7730769230769231
  LT_roc_auc:
  - 0.7248339973439576
  - 0.8278838174273859
  - 0.7538793103448276
  - 0.8166768853464133
  - 0.7670603674540682
  - 0.5597560975609757
  - 0.7755319148936171
  - 0.8720821661998133
  - 0.831778606965174
  - 0.8580002927829015
  - 0.8049412233512652
  - 0.8882803943044908
  - 0.7949685534591194
  - 0.857268335529205
  - 0.8642102846648301
  - 0.8395061728395061
  TL_average_precision:
  - 0.45004550566894674
  - 0.468216141714934
  - 0.5943707399534467
  - 0.5000430601068493
  - 0.43634293673517766
  - 0.24311064355427298
  - 0.44967067026146346
  - 0.35069938557302344
  - 0.05053305055817313
  - 0.1139485350682247
  - 0.12381921744105102
  - 0.12472804057305187
  - 0.32655574235622054
  - 0.35721916244305457
  - 0.41155185504818975
  - 0.343675981923898
  TL_balanced_accuracy:
  - 0.6106870229007634
  - 0.6345433592624603
  - 0.5476190476190477
  - 0.6046055349029327
  - 0.6842207539836767
  - 0.5520833333333333
  - 0.6771367521367522
  - 0.48609997326917936
  - 0.552863436123348
  - 0.40681125042358524
  - 0.5358187134502924
  - 0.502641135688346
  - 0.6934782608695652
  - 0.5429184549356223
  - 0.6146272855133614
  - 0.6360184879498184
  TL_f1_macro:
  - 0.25625
  - 0.42901960784313725
  - 0.13786561264822134
  - 0.4003798670465337
  - 0.5341865559783235
  - 0.24347691832638568
  - 0.4414199561403509
  - 0.2800049677098857
  - 0.15238608883244317
  - 0.2018637406412833
  - 0.18505267342476645
  - 0.23875468020721138
  - 0.48274375700451166
  - 0.10988838780449584
  - 0.35719376039274686
  - 0.47051226861816614
  TL_f1_micro:
  - 0.2714285714285714
  - 0.5821428571428572
  - 0.13937282229965156
  - 0.5017421602787456
  - 0.6392857142857142
  - 0.25
  - 0.5052264808362369
  - 0.2961672473867596
  - 0.15416666666666667
  - 0.22083333333333333
  - 0.18699186991869918
  - 0.26422764227642276
  - 0.6875
  - 0.1125
  - 0.4634146341463415
  - 0.6544715447154471
  TL_f1_weighted:
  - 0.3488392857142857
  - 0.6972492997198879
  - 0.170396220958257
  - 0.6159894907862388
  - 0.7064543492941971
  - 0.30168287787555964
  - 0.5946871752552112
  - 0.3660785036634696
  - 0.1870264212437006
  - 0.3115797632385457
  - 0.21898861206858938
  - 0.3632891614344671
  - 0.7810641110376736
  - 0.15529026135710683
  - 0.5993773525509426
  - 0.7496228944209372
  TL_matthews_corrcoef:
  - 0.1339747997083054
  - 0.1141855401324579
  - 0.07147416898918632
  - 0.10158723151749462
  - 0.2346919281270752
  - 0.0761386987626881
  - 0.20878658191194574
  - -0.019327202850573627
  - 0.07976961442314873
  - -0.10387625458564996
  - 0.057010670850814106
  - 0.0027840525249649517
  - 0.16455065106551323
  - 0.05226063915600485
  - 0.08664428033832575
  - 0.12697192253635908
  TL_precision_macro:
  - 0.5405405405405406
  - 0.5242270180535381
  - 0.5268199233716475
  - 0.5246640046747175
  - 0.5747476871320437
  - 0.5278260869565217
  - 0.5615228577082921
  - 0.49328165374677
  - 0.5300925925925926
  - 0.4710526315789474
  - 0.5226851851851851
  - 0.5007336757153338
  - 0.534987027282019
  - 0.5159090909090909
  - 0.5163731333288689
  - 0.5296317606444189
  TL_precision_micro:
  - 0.2714285714285714
  - 0.5821428571428572
  - 0.13937282229965156
  - 0.5017421602787456
  - 0.6392857142857142
  - 0.25
  - 0.5052264808362369
  - 0.2961672473867596
  - 0.15416666666666667
  - 0.22083333333333333
  - 0.18699186991869918
  - 0.26422764227642276
  - 0.6875
  - 0.1125
  - 0.4634146341463415
  - 0.6544715447154471
  TL_precision_weighted:
  - 0.940926640926641
  - 0.9328554382948447
  - 0.9538360900850388
  - 0.9082228675673145
  - 0.8678578937882975
  - 0.8859130434782608
  - 0.89785762209775
  - 0.8089403884072063
  - 0.9490933641975309
  - 0.853530701754386
  - 0.9016937669376693
  - 0.9009746553811833
  - 0.9441681735985533
  - 0.9717613636363637
  - 0.947606626672307
  - 0.9219853677247936
  TL_recall_macro:
  - 0.6106870229007634
  - 0.6345433592624603
  - 0.5476190476190477
  - 0.6046055349029327
  - 0.6842207539836767
  - 0.5520833333333333
  - 0.6771367521367522
  - 0.48609997326917936
  - 0.552863436123348
  - 0.40681125042358524
  - 0.5358187134502924
  - 0.502641135688346
  - 0.6934782608695652
  - 0.5429184549356223
  - 0.6146272855133614
  - 0.6360184879498184
  TL_recall_micro:
  - 0.2714285714285714
  - 0.5821428571428572
  - 0.13937282229965156
  - 0.5017421602787456
  - 0.6392857142857142
  - 0.25
  - 0.5052264808362369
  - 0.2961672473867596
  - 0.15416666666666667
  - 0.22083333333333333
  - 0.18699186991869918
  - 0.26422764227642276
  - 0.6875
  - 0.1125
  - 0.4634146341463415
  - 0.6544715447154471
  TL_recall_weighted:
  - 0.2714285714285714
  - 0.5821428571428572
  - 0.13937282229965156
  - 0.5017421602787456
  - 0.6392857142857142
  - 0.25
  - 0.5052264808362369
  - 0.2961672473867596
  - 0.15416666666666667
  - 0.22083333333333333
  - 0.18699186991869918
  - 0.26422764227642276
  - 0.6875
  - 0.1125
  - 0.4634146341463415
  - 0.6544715447154471
  TL_roc_auc:
  - 0.8692748091603053
  - 0.8346297896859696
  - 0.8440607012035584
  - 0.7853159851301115
  - 0.8140950900375696
  - 0.685546875
  - 0.7776353276353275
  - 0.6394012296177493
  - 0.46492714334124025
  - 0.3124364622161979
  - 0.4761208576998051
  - 0.46946186860349953
  - 0.7071739130434783
  - 0.5833844267320663
  - 0.7381622128457572
  - 0.6251238032353912
  TT_average_precision:
  - 0.06962233169129721
  - 0.3092750667207189
  - 0.10452885260609382
  - 0.4666666666666667
  - 0.2688853417114287
  - 0.3274777192031669
  - 0.3796522890239238
  - 0.15761791307489947
  - 0.09423305722307537
  - 0.0915493925297847
  - 0.017241379310344827
  - 0.15583768472423934
  - 0.04280055456526045
  - 0.24428571428571427
  - 0.06807953273797676
  - -0.0
  TT_balanced_accuracy:
  - 0.5631578947368421
  - 0.7083333333333333
  - 0.5
  - 0.7670454545454546
  - 0.7119565217391304
  - 0.4493212669683258
  - 0.6358024691358024
  - 0.5602409638554217
  - 0.532051282051282
  - 0.5641025641025641
  - 0.5064935064935064
  - 0.5763888888888888
  - 0.3271604938271605
  - 0.5
  - 0.5641891891891893
  - 0.7051282051282052
  TT_f1_macro:
  - 0.1458573978788197
  - 0.5311004784688995
  - 0.07142857142857144
  - 0.41197793538219063
  - 0.39001761597181445
  - 0.21420389461626577
  - 0.3401745114907214
  - 0.19741452216986832
  - 0.13082919914953933
  - 0.18863636363636363
  - 0.025641025641025647
  - 0.21472190130384552
  - 0.3868613138686131
  - 0.06666666666666667
  - 0.3284484337790804
  - 0.41353383458646614
  TT_f1_micro:
  - 0.15306122448979592
  - 0.673469387755102
  - 0.07692307692307693
  - 0.5494505494505495
  - 0.45918367346938777
  - 0.21428571428571427
  - 0.3516483516483517
  - 0.1978021978021978
  - 0.13095238095238096
  - 0.19047619047619047
  - 0.02564102564102564
  - 0.21794871794871795
  - 0.6309523809523809
  - 0.07142857142857142
  - 0.3974358974358974
  - 0.7051282051282052
  TT_f1_weighted:
  - 0.21949651434657663
  - 0.7472903036812812
  - 0.010989010989010992
  - 0.67755003074152
  - 0.5702685536927631
  - 0.22009491081656032
  - 0.4080613990900337
  - 0.2119523583822243
  - 0.1219601093449428
  - 0.22175324675324673
  - 0.025641025641025647
  - 0.25731588101616165
  - 0.746089676746611
  - 0.009523809523809525
  - 0.521613332018168
  - 0.8270676691729323
  TT_matthews_corrcoef:
  - 0.06638045457122153
  - 0.23665076426961032
  - 0.0
  - 0.190827904815303
  - 0.20762899853268943
  - -0.09825015015781494
  - 0.1984011958938672
  - 0.10908459859418132
  - 0.06977498959044452
  - 0.10195592378577321
  - 0.012987012987012988
  - 0.11696833776625619
  - -0.13608276348795434
  - 0.0
  - 0.058592321026789754
  - 0.0
  TT_precision_macro:
  - 0.5174418604651163
  - 0.5672043010752689
  - 0.038461538461538464
  - 0.5340909090909091
  - 0.5508474576271186
  - 0.4523809523809524
  - 0.572463768115942
  - 0.5493827160493827
  - 0.5379746835443038
  - 0.5405405405405406
  - 0.5064935064935064
  - 0.5447761194029851
  - 0.4732142857142857
  - 0.03571428571428571
  - 0.5133708655876144
  - 0.5
  TT_precision_micro:
  - 0.15306122448979592
  - 0.673469387755102
  - 0.07692307692307693
  - 0.5494505494505495
  - 0.45918367346938777
  - 0.21428571428571427
  - 0.3516483516483517
  - 0.1978021978021978
  - 0.13095238095238096
  - 0.19047619047619047
  - 0.02564102564102564
  - 0.21794871794871795
  - 0.6309523809523809
  - 0.07142857142857142
  - 0.3974358974358974
  - 0.7051282051282052
  TT_precision_weighted:
  - 0.9704556241101092
  - 0.9023480359885889
  - 0.00591715976331361
  - 0.9692807192807192
  - 0.9450017295053614
  - 0.6972789115646258
  - 0.9060359929925148
  - 0.9207705874372542
  - 0.9339963833634719
  - 0.9343629343629344
  - 0.9873459873459873
  - 0.9299655568312284
  - 0.912627551020408
  - 0.00510204081632653
  - 0.9191432541186236
  - 1.0
  TT_recall_macro:
  - 0.5631578947368421
  - 0.7083333333333333
  - 0.5
  - 0.7670454545454546
  - 0.7119565217391304
  - 0.4493212669683258
  - 0.6358024691358024
  - 0.5602409638554217
  - 0.532051282051282
  - 0.5641025641025641
  - 0.5064935064935064
  - 0.5763888888888888
  - 0.3271604938271605
  - 0.5
  - 0.5641891891891893
  - 0.3525641025641026
  TT_recall_micro:
  - 0.15306122448979592
  - 0.673469387755102
  - 0.07692307692307693
  - 0.5494505494505495
  - 0.45918367346938777
  - 0.21428571428571427
  - 0.3516483516483517
  - 0.1978021978021978
  - 0.13095238095238096
  - 0.19047619047619047
  - 0.02564102564102564
  - 0.21794871794871795
  - 0.6309523809523809
  - 0.07142857142857142
  - 0.3974358974358974
  - 0.7051282051282052
  TT_recall_weighted:
  - 0.15306122448979592
  - 0.673469387755102
  - 0.07692307692307693
  - 0.5494505494505495
  - 0.45918367346938777
  - 0.21428571428571427
  - 0.3516483516483517
  - 0.1978021978021978
  - 0.13095238095238096
  - 0.19047619047619047
  - 0.02564102564102564
  - 0.21794871794871795
  - 0.6309523809523809
  - 0.07142857142857142
  - 0.3974358974358974
  - 0.7051282051282052
  TT_roc_auc:
  - 0.6596491228070176
  - 0.7805555555555556
  - 0.5697278911564625
  - 0.9242424242424242
  - 0.8731884057971014
  - 0.6027149321266969
  - 0.7839506172839507
  - 0.6671686746987953
  - 0.5427350427350427
  - 0.579059829059829
  - 0.2597402597402597
  - 0.6597222222222222
  - 0.4732510288065844
  - 0.5566239316239316
  - 0.5591216216216216
  - .nan
  fit_time:
  - 4.942571640014648
  - 5.303198575973511
  - 4.713800668716431
  - 4.755500793457031
  - 5.370795488357544
  - 4.535547494888306
  - 5.5028674602508545
  - 4.8603575229644775
  - 5.489849090576172
  - 5.707521677017212
  - 5.129965305328369
  - 5.578575372695923
  - 5.401633977890015
  - 4.950503349304199
  - 5.72851300239563
  - 5.600115776062012
  score_time:
  - 1.6747984886169434
  - 1.701542615890503
  - 1.8309884071350098
  - 1.8886780738830566
  - 1.8420958518981934
  - 1.6901578903198242
  - 1.9711647033691406
  - 1.8190317153930664
  - 1.9386773109436035
  - 1.9020497798919678
  - 1.937518835067749
  - 1.8854076862335205
  - 1.907243251800537
  - 1.9008443355560303
  - 1.9531822204589844
  - 1.8951444625854492
start: 2023-10-07 06:51:09.302265
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
