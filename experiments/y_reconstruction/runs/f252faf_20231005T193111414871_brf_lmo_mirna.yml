active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-05 20:17:10.133054
estimator:
  call: bipartite_adaptations.estimators.brf_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: brf_lmo
  params: {}
hash: f252fafba7be99aa1724e65e20bde3c7686b9501fbf868337f72bdfc474a0f19
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/f252faf_20231005T193111414871_brf_lmo_mirna.yml"
results:
  LL_average_precision:
  - 0.9634564855229186
  - 0.9374158744558334
  - 0.9745086643398571
  - 0.9883359177117501
  - 0.9797046956967864
  - 0.9370433900977675
  - 0.9603700431076563
  - 0.9339392466187664
  - 0.9643938735967472
  - 0.9588944766916154
  - 0.9443037568488748
  - 0.9882467707057959
  - 0.9415797747700123
  - 0.9401009881785923
  - 0.9743276264937325
  - 0.9403928500391764
  LL_balanced_accuracy:
  - 0.5431400248014773
  - 0.542771191332534
  - 0.5846573419685291
  - 0.7053044341658352
  - 0.6180782721790881
  - 0.5392489154013015
  - 0.5400569747303786
  - 0.5397321801313314
  - 0.5406318707698217
  - 0.5449145318097378
  - 0.5407575690520798
  - 0.7008755866700704
  - 0.5378125184703588
  - 0.5398142445369664
  - 0.5864438918934872
  - 0.5589185381192117
  LL_f1_macro:
  - 0.15112837402325424
  - 0.1509705310427953
  - 0.22148209462026236
  - 0.39422422572512955
  - 0.2743236848512506
  - 0.1444527785555324
  - 0.14421692227107547
  - 0.14486296584062736
  - 0.14599318984682855
  - 0.15442515202340512
  - 0.14502707440006823
  - 0.3879450011525154
  - 0.14099147116318866
  - 0.1450122075734092
  - 0.22386410362881076
  - 0.17891502932016617
  LL_f1_micro:
  - 0.15119868817618012
  - 0.15102234314452964
  - 0.2274415771200337
  - 0.4525371648769085
  - 0.29032509068439544
  - 0.1444542344177318
  - 0.1442368207252463
  - 0.14486951364175563
  - 0.14601503587325926
  - 0.15455367257497912
  - 0.14506528132187524
  - 0.4440254585272379
  - 0.14099163529425227
  - 0.1450195100181941
  - 0.23034866290579117
  - 0.18015557988867598
  LL_f1_weighted:
  - 0.15775634107351558
  - 0.15665318393169933
  - 0.2800638871505384
  - 0.5554318775352597
  - 0.3667984195467653
  - 0.1454090629182882
  - 0.14776820609216493
  - 0.14689298931524636
  - 0.14970368306814924
  - 0.16336717159179004
  - 0.1499515816866798
  - 0.5470298885940491
  - 0.1406690893965734
  - 0.14715584967543
  - 0.28494998334961585
  - 0.20632130247597763
  LL_matthews_corrcoef:
  - 0.08163470463375858
  - 0.08157021985682592
  - 0.11858346289398375
  - 0.21730044162408363
  - 0.14647372340729756
  - 0.07784684304904248
  - 0.07768053799417102
  - 0.07807711971137463
  - 0.07871043161816461
  - 0.0834836597893461
  - 0.07812248715610198
  - 0.21284695842524504
  - 0.07584202646546373
  - 0.07816267611301812
  - 0.11963913127291669
  - 0.0966854736691577
  LL_precision_macro:
  - 0.5386197332483499
  - 0.5388912522669771
  - 0.5415263382506041
  - 0.5574993449628566
  - 0.5454244274853921
  - 0.5386006269902002
  - 0.5376605199449045
  - 0.5383570483816542
  - 0.5381186733968892
  - 0.5387932433613404
  - 0.5374355189808842
  - 0.5563829438682456
  - 0.5380298192971271
  - 0.5383619230265451
  - 0.5413954109949571
  - 0.5396652781833925
  LL_precision_micro:
  - 0.15119868817618012
  - 0.15102234314452964
  - 0.2274415771200337
  - 0.4525371648769085
  - 0.29032509068439544
  - 0.1444542344177318
  - 0.1442368207252463
  - 0.14486951364175563
  - 0.14601503587325926
  - 0.15455367257497912
  - 0.14506528132187524
  - 0.4440254585272379
  - 0.14099163529425227
  - 0.1450195100181941
  - 0.2303486629057912
  - 0.18015557988867598
  LL_precision_weighted:
  - 0.9344390395130292
  - 0.9339643915564134
  - 0.9358369552262665
  - 0.9370424911778277
  - 0.9355268470871821
  - 0.9339507940594273
  - 0.9355430274376164
  - 0.9343994371242587
  - 0.9348944521331972
  - 0.9344047897424995
  - 0.9359901502230163
  - 0.9373050372719354
  - 0.9346641342310394
  - 0.9344026085082404
  - 0.9362799331563337
  - 0.9349612860183644
  LL_recall_macro:
  - 0.5431400248014773
  - 0.542771191332534
  - 0.5846573419685291
  - 0.7053044341658352
  - 0.6180782721790881
  - 0.5392489154013015
  - 0.5400569747303786
  - 0.5397321801313314
  - 0.5406318707698217
  - 0.5449145318097378
  - 0.5407575690520798
  - 0.7008755866700704
  - 0.5378125184703588
  - 0.5398142445369664
  - 0.5864438918934872
  - 0.5589185381192117
  LL_recall_micro:
  - 0.15119868817618012
  - 0.15102234314452964
  - 0.2274415771200337
  - 0.4525371648769085
  - 0.29032509068439544
  - 0.1444542344177318
  - 0.1442368207252463
  - 0.14486951364175563
  - 0.14601503587325926
  - 0.15455367257497912
  - 0.14506528132187524
  - 0.4440254585272379
  - 0.14099163529425227
  - 0.1450195100181941
  - 0.2303486629057912
  - 0.18015557988867598
  LL_recall_weighted:
  - 0.15119868817618012
  - 0.15102234314452964
  - 0.2274415771200337
  - 0.4525371648769085
  - 0.29032509068439544
  - 0.1444542344177318
  - 0.1442368207252463
  - 0.14486951364175563
  - 0.14601503587325926
  - 0.15455367257497912
  - 0.14506528132187524
  - 0.4440254585272379
  - 0.14099163529425227
  - 0.1450195100181941
  - 0.2303486629057912
  - 0.18015557988867598
  LL_roc_auc:
  - 0.9977955347463808
  - 0.9962307380165001
  - 0.998545375893689
  - 0.9993227570699463
  - 0.9988373790998416
  - 0.9962530007151841
  - 0.9977793296747877
  - 0.9960708035795012
  - 0.9979365953972571
  - 0.9976255333061379
  - 0.9968012034735074
  - 0.9993347388338594
  - 0.9965250506184231
  - 0.9964894850670251
  - 0.9986000044513368
  - 0.9965023520309374
  LT_average_precision:
  - 0.17858021560724785
  - 0.15657746715629195
  - 0.16984181246472752
  - 0.1750274929456606
  - 0.17579211008063442
  - 0.1507217300173602
  - 0.16216426563065195
  - 0.16514068297822215
  - 0.1742124490104786
  - 0.1519169894507148
  - 0.15964391842783598
  - 0.17336076884602816
  - 0.16806336956814105
  - 0.15277046024191854
  - 0.15904243472062699
  - 0.1660273511332381
  LT_balanced_accuracy:
  - 0.5087768090793329
  - 0.5095137861977364
  - 0.517573293857127
  - 0.5719892105391359
  - 0.5346701563481585
  - 0.5079424821296502
  - 0.5071968891148436
  - 0.5086530448899906
  - 0.5074973742131001
  - 0.512013093838145
  - 0.5061873381303217
  - 0.5664566633287356
  - 0.5076458095855058
  - 0.5080398517313672
  - 0.5155919797687313
  - 0.5116669695476408
  LT_f1_macro:
  - 0.09227140661029093
  - 0.09998257664528498
  - 0.13966533678295906
  - 0.28173184842378857
  - 0.17369700886696798
  - 0.09461532719057107
  - 0.0989822829074346
  - 0.09335643433323941
  - 0.08976530691587892
  - 0.1023096350567212
  - 0.10093754041172184
  - 0.2710498893802129
  - 0.08734156983002286
  - 0.09569429432683571
  - 0.14350728462644785
  - 0.10791736322869097
  LT_f1_micro:
  - 0.09418145956607495
  - 0.10105741836511067
  - 0.13966962524654833
  - 0.30530661355904076
  - 0.1750615932110594
  - 0.0959964412811388
  - 0.10081439912400766
  - 0.09508343986456137
  - 0.09177388447851081
  - 0.1031754722146181
  - 0.10253900903367096
  - 0.29183567702035035
  - 0.08953599781001917
  - 0.09702299479879552
  - 0.14351902545852724
  - 0.10864112220571467
  LT_f1_weighted:
  - 0.05651366396596839
  - 0.07316947200631987
  - 0.1380281697659783
  - 0.39355068747479205
  - 0.20254126089340413
  - 0.06410061930413993
  - 0.06437533430906063
  - 0.05933338631917013
  - 0.05299405742282469
  - 0.0782283721552658
  - 0.06859810578130027
  - 0.37704575330687023
  - 0.048831119836340586
  - 0.06579628006473262
  - 0.14621253727344202
  - 0.08606219495379568
  LT_matthews_corrcoef:
  - 0.02894558326029845
  - 0.026453369780205908
  - 0.03564739858447774
  - 0.08486079236491086
  - 0.056475629654149366
  - 0.023729206340269524
  - 0.022460979327958385
  - 0.027535520192794365
  - 0.025504660747251908
  - 0.03204378477601903
  - 0.018485250292488445
  - 0.07930585548550134
  - 0.027354155101272717
  - 0.023693778380422522
  - 0.03048753107738208
  - 0.02985349106893539
  LT_precision_macro:
  - 0.5238653587740614
  - 0.5183885983504342
  - 0.5180776728052787
  - 0.5250084492761787
  - 0.5229988632932863
  - 0.5177235284998963
  - 0.5175247799542463
  - 0.5219057245723074
  - 0.5216905179514655
  - 0.5213684367367428
  - 0.5138066027417099
  - 0.523659849890356
  - 0.524466009548647
  - 0.5174566382782381
  - 0.5149033279445752
  - 0.5190973098319096
  LT_precision_micro:
  - 0.09418145956607495
  - 0.10105741836511067
  - 0.13966962524654833
  - 0.30530661355904076
  - 0.1750615932110594
  - 0.0959964412811388
  - 0.10081439912400766
  - 0.09508343986456137
  - 0.09177388447851081
  - 0.10317547221461812
  - 0.10253900903367096
  - 0.29183567702035035
  - 0.08953599781001917
  - 0.09702299479879552
  - 0.14351902545852724
  - 0.10864112220571467
  LT_precision_weighted:
  - 0.9120756038203754
  - 0.9047445171133418
  - 0.8945136163321618
  - 0.9048919623449417
  - 0.9072974763841063
  - 0.904444194373295
  - 0.8943376804477982
  - 0.9093906405141152
  - 0.9092656618821588
  - 0.9115067087760322
  - 0.8880123960230971
  - 0.9050750583269457
  - 0.914900075915571
  - 0.9035715438774417
  - 0.8895394821064875
  - 0.9040567502118221
  LT_recall_macro:
  - 0.5087768090793329
  - 0.5095137861977364
  - 0.517573293857127
  - 0.5719892105391359
  - 0.5346701563481585
  - 0.5079424821296502
  - 0.5071968891148436
  - 0.5086530448899906
  - 0.5074973742131001
  - 0.512013093838145
  - 0.5061873381303217
  - 0.5664566633287356
  - 0.5076458095855058
  - 0.5080398517313672
  - 0.5155919797687313
  - 0.5116669695476408
  LT_recall_micro:
  - 0.09418145956607495
  - 0.10105741836511067
  - 0.13966962524654833
  - 0.30530661355904076
  - 0.1750615932110594
  - 0.0959964412811388
  - 0.10081439912400766
  - 0.09508343986456137
  - 0.09177388447851081
  - 0.10317547221461812
  - 0.10253900903367096
  - 0.29183567702035035
  - 0.08953599781001917
  - 0.09702299479879552
  - 0.14351902545852724
  - 0.10864112220571467
  LT_recall_weighted:
  - 0.09418145956607495
  - 0.10105741836511067
  - 0.13966962524654833
  - 0.30530661355904076
  - 0.1750615932110594
  - 0.0959964412811388
  - 0.10081439912400766
  - 0.09508343986456137
  - 0.09177388447851081
  - 0.10317547221461812
  - 0.10253900903367096
  - 0.29183567702035035
  - 0.08953599781001917
  - 0.09702299479879552
  - 0.14351902545852724
  - 0.10864112220571467
  LT_roc_auc:
  - 0.6806430895013273
  - 0.6737132110285047
  - 0.6666677614548109
  - 0.6866695621925282
  - 0.6827854986965538
  - 0.6735816946777502
  - 0.666879743708447
  - 0.6893231881001479
  - 0.6783271606390281
  - 0.6721172382700842
  - 0.658263487604996
  - 0.6858279308540283
  - 0.6798703133078007
  - 0.6694425904807173
  - 0.6557774707546289
  - 0.686434450760583
  TL_average_precision:
  - 0.24472041320429683
  - 0.2504245668495037
  - 0.2539240913314962
  - 0.27007816674922147
  - 0.24456269648808987
  - 0.24167960773258507
  - 0.22903760249244748
  - 0.23791404821311316
  - 0.24745630763175733
  - 0.2535561618403028
  - 0.24953701950060975
  - 0.2610778894437001
  - 0.2509843593196348
  - 0.2581304681278008
  - 0.2625584945635895
  - 0.255294998407206
  TL_balanced_accuracy:
  - 0.5042569534104228
  - 0.5043845795411748
  - 0.5116062289652643
  - 0.5419310037582968
  - 0.5186917354270413
  - 0.5068821816702588
  - 0.5073901120161308
  - 0.5065558091546559
  - 0.5055425153844928
  - 0.5061718177239307
  - 0.5063002764280857
  - 0.5443862315797364
  - 0.5042880503145662
  - 0.5046333731623119
  - 0.5137777602263952
  - 0.506282176015256
  TL_f1_macro:
  - 0.0754145842165419
  - 0.07621861489534182
  - 0.09127611934505424
  - 0.1820894451833176
  - 0.11153350018535393
  - 0.08155646970144204
  - 0.08072382812036653
  - 0.08036090831992233
  - 0.07965214707350424
  - 0.08110400869794065
  - 0.08058774843905503
  - 0.1811913439946974
  - 0.07577890324615694
  - 0.07854589883709881
  - 0.09709948153452994
  - 0.08095168549656376
  TL_f1_micro:
  - 0.07885697831467375
  - 0.07967969066015809
  - 0.09298706284836727
  - 0.1841206057623968
  - 0.11220353422925772
  - 0.08449446230796713
  - 0.08349135680325391
  - 0.0833675761560377
  - 0.08299667463654602
  - 0.08435705059499271
  - 0.08364938027317449
  - 0.18282243041858426
  - 0.07939648775661637
  - 0.08209662791656361
  - 0.09859977464479072
  - 0.08413461538461539
  TL_f1_weighted:
  - 0.026898100654837276
  - 0.027649968256116077
  - 0.057241346691616714
  - 0.21713560011181285
  - 0.09057050362336916
  - 0.03694694930848962
  - 0.03726745925275927
  - 0.035174821355167474
  - 0.03212966573267699
  - 0.034303779613654196
  - 0.03504201071481517
  - 0.2125101054749273
  - 0.026168812830152884
  - 0.029605180107280204
  - 0.06544185553423165
  - 0.03460751514005656
  TL_matthews_corrcoef:
  - 0.02301006967367513
  - 0.023369190465468696
  - 0.037514109395780336
  - 0.06590095863040188
  - 0.047173972160486445
  - 0.029952245609118973
  - 0.031542549906710675
  - 0.029418799285516873
  - 0.02689655331023388
  - 0.028713992175472224
  - 0.028453853391322188
  - 0.07139361025177227
  - 0.02406361831425602
  - 0.023961987297510198
  - 0.04176250276096566
  - 0.028903258020563687
  TL_precision_macro:
  - 0.5310940275439148
  - 0.5311386221804655
  - 0.5303136446810253
  - 0.5258933483529273
  - 0.5297642727996632
  - 0.5325891214448011
  - 0.5336575566258549
  - 0.5330037731035413
  - 0.5326306978774609
  - 0.5333975087864379
  - 0.532126438500606
  - 0.5287084947481153
  - 0.5337599657125744
  - 0.5309804981776789
  - 0.5316471365483326
  - 0.5332447834227556
  TL_precision_micro:
  - 0.07885697831467375
  - 0.07967969066015809
  - 0.09298706284836726
  - 0.1841206057623968
  - 0.1122035342292577
  - 0.08449446230796713
  - 0.08349135680325391
  - 0.0833675761560377
  - 0.08299667463654602
  - 0.08435705059499271
  - 0.08364938027317449
  - 0.18282243041858426
  - 0.07939648775661637
  - 0.08209662791656361
  - 0.09859977464479072
  - 0.08413461538461539
  TL_precision_weighted:
  - 0.9271309896695813
  - 0.9262807005194577
  - 0.9276878612572345
  - 0.9124762540045749
  - 0.9222360906649606
  - 0.9285302454326924
  - 0.9329639237854681
  - 0.9298305194093615
  - 0.9267852611355918
  - 0.9276321721257547
  - 0.9274547382331143
  - 0.9148111421505376
  - 0.9302928243256532
  - 0.9229834583841079
  - 0.9272027796441624
  - 0.9281153248365093
  TL_recall_macro:
  - 0.5042569534104228
  - 0.5043845795411748
  - 0.5116062289652643
  - 0.5419310037582968
  - 0.5186917354270413
  - 0.5068821816702588
  - 0.5073901120161308
  - 0.5065558091546559
  - 0.5055425153844928
  - 0.5061718177239307
  - 0.5063002764280857
  - 0.5443862315797364
  - 0.5042880503145662
  - 0.5046333731623119
  - 0.5137777602263952
  - 0.506282176015256
  TL_recall_micro:
  - 0.07885697831467375
  - 0.07967969066015809
  - 0.09298706284836726
  - 0.1841206057623968
  - 0.1122035342292577
  - 0.08449446230796713
  - 0.08349135680325391
  - 0.0833675761560377
  - 0.08299667463654602
  - 0.08435705059499271
  - 0.08364938027317449
  - 0.18282243041858426
  - 0.07939648775661637
  - 0.08209662791656361
  - 0.09859977464479072
  - 0.08413461538461539
  TL_recall_weighted:
  - 0.07885697831467375
  - 0.07967969066015809
  - 0.09298706284836726
  - 0.1841206057623968
  - 0.1122035342292577
  - 0.08449446230796713
  - 0.08349135680325391
  - 0.0833675761560377
  - 0.08299667463654602
  - 0.08435705059499271
  - 0.08364938027317449
  - 0.18282243041858426
  - 0.07939648775661637
  - 0.08209662791656361
  - 0.09859977464479072
  - 0.08413461538461539
  TL_roc_auc:
  - 0.6921877594655659
  - 0.6994133251898638
  - 0.7025730823431982
  - 0.6935285879887163
  - 0.7013907918073752
  - 0.7078570292335697
  - 0.6981673302394464
  - 0.6994756981380843
  - 0.7129188524307656
  - 0.7209747095582276
  - 0.7140184977921583
  - 0.7204661964086707
  - 0.7046656311773765
  - 0.7067466538696764
  - 0.7118402903315444
  - 0.7091084192328644
  TT_average_precision:
  - 0.11554665532139817
  - 0.09910806753729699
  - 0.11465497563989499
  - 0.11379682706758576
  - 0.11544879993067286
  - 0.10199473216052413
  - 0.11057149451844504
  - 0.10523963859726221
  - 0.12523315095426574
  - 0.11233373785834772
  - 0.11967982264880475
  - 0.11715102097501992
  - 0.12842181161578467
  - 0.11165773536947562
  - 0.12578828692710076
  - 0.1237832226691597
  TT_balanced_accuracy:
  - 0.5011451222197754
  - 0.5001225423269053
  - 0.5000243739721806
  - 0.5087153333791092
  - 0.5026261695580916
  - 0.501947411643547
  - 0.5022494071759414
  - 0.5012609202503517
  - 0.5016864492623058
  - 0.5017768176064957
  - 0.5016474495454545
  - 0.509503808149466
  - 0.5005663894989214
  - 0.4997926070669341
  - 0.5011622406548113
  - 0.49947085882371145
  TT_f1_macro:
  - 0.06696851172419502
  - 0.06708127336783759
  - 0.07506749359772265
  - 0.10450672612982603
  - 0.07532042394064493
  - 0.07136601554147665
  - 0.07464631406181968
  - 0.071518279916877
  - 0.07085645884007082
  - 0.07234420946316454
  - 0.07567076687113414
  - 0.1039390503325649
  - 0.06920596357796094
  - 0.06723714560641934
  - 0.07781715399787634
  - 0.06783135095393565
  TT_f1_micro:
  - 0.07114154502214204
  - 0.07085451861571264
  - 0.07926029194685912
  - 0.10526424741755853
  - 0.07858727810650888
  - 0.07495069033530571
  - 0.07877218934911243
  - 0.07524271844660194
  - 0.07497123602892834
  - 0.07608070348454964
  - 0.07982001972386588
  - 0.1050535225292507
  - 0.0736974030243261
  - 0.07112919132149902
  - 0.08195677186061802
  - 0.0720687079910381
  TT_f1_weighted:
  - 0.013182180645444432
  - 0.015756866537134706
  - 0.021980844585209276
  - 0.08204473725564558
  - 0.02798322150959869
  - 0.021602573793809796
  - 0.021868117386771007
  - 0.020893730258663548
  - 0.017784852837690247
  - 0.021712235767101816
  - 0.022866721060534178
  - 0.07685606480933944
  - 0.013815529045088462
  - 0.01519465137551939
  - 0.025288056432635396
  - 0.013780928390822405
  TT_matthews_corrcoef:
  - 0.012585149482565465
  - 0.0009895168972936378
  - 0.00015932535548700673
  - 0.022593129895807928
  - 0.01346283059498594
  - 0.012156211525499484
  - 0.014969694909337571
  - 0.008157816656356173
  - 0.013234060015314495
  - 0.011254090694332036
  - 0.010569189110439891
  - 0.026210074442322834
  - 0.006238385073342877
  - -0.0017612195225911802
  - 0.006907495288245924
  - -0.005330468614296623
  TT_precision_macro:
  - 0.5345784023668639
  - 0.5019975622194323
  - 0.5002603655316517
  - 0.5146422832118047
  - 0.5172540085112591
  - 0.5189704985001959
  - 0.5249056471495508
  - 0.5131947227788911
  - 0.5259628837350094
  - 0.5178204218729636
  - 0.5169516205762509
  - 0.5180708614764783
  - 0.5171778645249502
  - 0.49626084871733395
  - 0.5102632554969623
  - 0.4865754656218131
  TT_precision_micro:
  - 0.07114154502214204
  - 0.07085451861571264
  - 0.07926029194685912
  - 0.10526424741755853
  - 0.07858727810650888
  - 0.07495069033530571
  - 0.07877218934911243
  - 0.07524271844660194
  - 0.07497123602892834
  - 0.07608070348454964
  - 0.07982001972386588
  - 0.10505352252925068
  - 0.0736974030243261
  - 0.07112919132149902
  - 0.08195677186061802
  - 0.0720687079910381
  TT_precision_weighted:
  - 0.9357631172038242
  - 0.8778736228379567
  - 0.863830670833132
  - 0.8981528485065831
  - 0.902717248744503
  - 0.9070764272659595
  - 0.9107181939439807
  - 0.8949721422348472
  - 0.9164098326836819
  - 0.9027471670703621
  - 0.8947151755171942
  - 0.8996814426758849
  - 0.8987735003896169
  - 0.8660782398140253
  - 0.8802545354617222
  - 0.8448995990845999
  TT_recall_macro:
  - 0.5011451222197754
  - 0.5001225423269053
  - 0.5000243739721806
  - 0.5087153333791092
  - 0.5026261695580916
  - 0.501947411643547
  - 0.5022494071759414
  - 0.5012609202503517
  - 0.5016864492623058
  - 0.5017768176064957
  - 0.5016474495454545
  - 0.509503808149466
  - 0.5005663894989214
  - 0.4997926070669341
  - 0.5011622406548113
  - 0.49947085882371145
  TT_recall_micro:
  - 0.07114154502214204
  - 0.07085451861571264
  - 0.07926029194685912
  - 0.10526424741755853
  - 0.07858727810650888
  - 0.07495069033530571
  - 0.07877218934911243
  - 0.07524271844660194
  - 0.07497123602892834
  - 0.07608070348454964
  - 0.07982001972386588
  - 0.10505352252925068
  - 0.0736974030243261
  - 0.07112919132149902
  - 0.08195677186061802
  - 0.0720687079910381
  TT_recall_weighted:
  - 0.07114154502214204
  - 0.07085451861571264
  - 0.07926029194685912
  - 0.10526424741755853
  - 0.07858727810650888
  - 0.07495069033530571
  - 0.07877218934911243
  - 0.07524271844660194
  - 0.07497123602892834
  - 0.07608070348454964
  - 0.07982001972386588
  - 0.10505352252925068
  - 0.0736974030243261
  - 0.07112919132149902
  - 0.08195677186061802
  - 0.0720687079910381
  TT_roc_auc:
  - 0.6030840419689728
  - 0.5868863576991383
  - 0.5875653590955433
  - 0.6048919911551525
  - 0.5864747507077197
  - 0.5940721292271208
  - 0.5808274296023167
  - 0.592240179055144
  - 0.618356587092331
  - 0.6051944633777976
  - 0.6078309930783826
  - 0.619891217662525
  - 0.6054895429107812
  - 0.5865625336767506
  - 0.5985668388976648
  - 0.6151665892925405
  fit_time:
  - 173.9893763065338
  - 153.53857898712158
  - 200.199152469635
  - 244.2976839542389
  - 213.6692032814026
  - 138.40115666389465
  - 161.6683201789856
  - 149.40487265586853
  - 167.3295292854309
  - 152.57983660697937
  - 139.45279240608215
  - 242.51248002052307
  - 160.8735408782959
  - 170.67461967468262
  - 180.03802800178528
  - 162.68594527244568
  score_time:
  - 2016.4995572566986
  - 1914.664321899414
  - 2119.5973987579346
  - 2513.747594356537
  - 2254.0627353191376
  - 1848.618045091629
  - 1873.6389560699463
  - 1799.0518250465393
  - 1953.2520487308502
  - 1982.4510028362274
  - 1828.298856973648
  - 2480.2955594062805
  - 1898.2304408550262
  - 1908.8391263484955
  - 2163.3118028640747
  - 2016.2889339923859
start: 2023-10-05 19:31:11.414871
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
