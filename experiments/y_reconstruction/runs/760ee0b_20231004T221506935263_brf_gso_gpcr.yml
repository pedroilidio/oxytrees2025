active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: y_reconstruction/runs
end: 2023-10-04 22:15:55.820573
estimator:
  call: bipartite_adaptations.estimators.brf_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - bipartiterandomforestregressor
          - call: bipartite_learn.ensemble._forest.BipartiteRandomForestRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: true
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: 0.5
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: 0.5
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: brf_gso
  params: {}
hash: 760ee0bfffc339e6d20773ad1706953c6b05ae6fc58e2bd5379b4a2fd46ffc4c
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/760ee0b_20231004T221506935263_brf_gso_gpcr.yml"
results:
  LL_average_precision:
  - 0.9774269238016305
  - 0.9894194166573689
  - 0.9809251237691541
  - 0.9819172541371357
  - 0.9583522282079575
  - 0.9868715546099817
  - 0.9798331362336906
  - 0.9786924276863539
  - 0.9293946132988944
  - 0.985061232897863
  - 0.9870130252154485
  - 0.9898590786171388
  - 0.9682144885614234
  - 0.975927599027113
  - 0.9766758706066407
  - 0.9659367880401156
  LL_balanced_accuracy:
  - 0.8253174465124369
  - 0.8070434782608695
  - 0.8216244450248107
  - 0.8026859504132231
  - 0.85874653259362
  - 0.8619373861763941
  - 0.8567959059762338
  - 0.8531838102603764
  - 0.7390810621942697
  - 0.8620569233455562
  - 0.8564321871181707
  - 0.8462734260298816
  - 0.805261800361104
  - 0.8640192539109506
  - 0.8488621726062688
  - 0.738548483045806
  LL_f1_macro:
  - 0.46999088026654035
  - 0.449748170643156
  - 0.46792734305417977
  - 0.43699921119275964
  - 0.500042611956787
  - 0.5048958186124095
  - 0.49930058794094423
  - 0.4867280047085347
  - 0.38370212513898383
  - 0.5216056145047364
  - 0.5137853546246313
  - 0.49113776863284575
  - 0.4530116858007615
  - 0.5201935735392995
  - 0.4995690269799752
  - 0.371300589124236
  LL_f1_micro:
  - 0.6612127856962132
  - 0.6257063338112507
  - 0.6543813780888926
  - 0.6156941649899397
  - 0.7251412667622501
  - 0.7314666441764358
  - 0.7215147170447836
  - 0.7135311871227364
  - 0.49616260436872733
  - 0.7334907649489752
  - 0.7225267774310534
  - 0.7015425888665325
  - 0.623253493013972
  - 0.736859614105123
  - 0.7072521623419827
  - 0.4913194444444444
  LL_f1_weighted:
  - 0.7690670954562521
  - 0.7421720054204982
  - 0.7632414201992007
  - 0.737589651330159
  - 0.8173479681210994
  - 0.8214057426175104
  - 0.8144063557713159
  - 0.8112719456432721
  - 0.6288060205421702
  - 0.8183414905102214
  - 0.8109241620408009
  - 0.7992011494965098
  - 0.7382200086185999
  - 0.8217026032573839
  - 0.8016292132681725
  - 0.6310500058039985
  LL_matthews_corrcoef:
  - 0.23103471578644066
  - 0.21382315765214455
  - 0.2307989361054804
  - 0.19641186606490219
  - 0.2536412336314302
  - 0.25929071331884
  - 0.25392679923949263
  - 0.2354463831641405
  - 0.17503980383699366
  - 0.2861857716220345
  - 0.2776742297343771
  - 0.2486591576058641
  - 0.2207662017626623
  - 0.2826511567907607
  - 0.26042635098456945
  - 0.15561331806252818
  LL_precision_macro:
  - 0.5410191956124315
  - 0.5372262773722628
  - 0.5414055505819159
  - 0.5318627450980392
  - 0.5448324022346369
  - 0.5464387464387465
  - 0.5451790633608815
  - 0.5392394822006472
  - 0.5320382265392448
  - 0.5565534661801852
  - 0.5540796963946869
  - 0.5446405730365822
  - 0.5399146861669714
  - 0.5548677546426561
  - 0.5486022056937676
  - 0.525377969762419
  LL_precision_micro:
  - 0.6612127856962132
  - 0.6257063338112507
  - 0.6543813780888926
  - 0.6156941649899397
  - 0.7251412667622501
  - 0.7314666441764358
  - 0.7215147170447836
  - 0.7135311871227364
  - 0.49616260436872733
  - 0.7334907649489752
  - 0.7225267774310534
  - 0.7015425888665325
  - 0.623253493013972
  - 0.7368596141051231
  - 0.7072521623419827
  - 0.4913194444444444
  LL_precision_weighted:
  - 0.9722064419709644
  - 0.9721328803275529
  - 0.9713789413368152
  - 0.9755099222787706
  - 0.9753548454275649
  - 0.9750592951571276
  - 0.9748365915125865
  - 0.9775182242321242
  - 0.9677158867596444
  - 0.9698559579776698
  - 0.9699886647316319
  - 0.9733533802799744
  - 0.9699245628183001
  - 0.9711241557402921
  - 0.9715436187554787
  - 0.9741814404847612
  LL_recall_macro:
  - 0.8253174465124369
  - 0.8070434782608695
  - 0.8216244450248107
  - 0.8026859504132231
  - 0.85874653259362
  - 0.8619373861763941
  - 0.8567959059762338
  - 0.8531838102603764
  - 0.7390810621942697
  - 0.8620569233455562
  - 0.8564321871181707
  - 0.8462734260298816
  - 0.805261800361104
  - 0.8640192539109506
  - 0.8488621726062688
  - 0.738548483045806
  LL_recall_micro:
  - 0.6612127856962132
  - 0.6257063338112507
  - 0.6543813780888926
  - 0.6156941649899397
  - 0.7251412667622501
  - 0.7314666441764358
  - 0.7215147170447836
  - 0.7135311871227364
  - 0.49616260436872733
  - 0.7334907649489752
  - 0.7225267774310534
  - 0.7015425888665325
  - 0.623253493013972
  - 0.7368596141051231
  - 0.7072521623419827
  - 0.4913194444444444
  LL_recall_weighted:
  - 0.6612127856962132
  - 0.6257063338112507
  - 0.6543813780888925
  - 0.6156941649899397
  - 0.7251412667622501
  - 0.7314666441764358
  - 0.7215147170447836
  - 0.7135311871227364
  - 0.49616260436872733
  - 0.7334907649489752
  - 0.7225267774310534
  - 0.7015425888665325
  - 0.623253493013972
  - 0.7368596141051231
  - 0.7072521623419827
  - 0.4913194444444444
  LL_roc_auc:
  - 0.9994587892480757
  - 0.9996974789915966
  - 0.9994230846150407
  - 0.9995985312036448
  - 0.9991401696328654
  - 0.9997142937709126
  - 0.9995916977124494
  - 0.9995558662129651
  - 0.9980024484049488
  - 0.9996899887824033
  - 0.9997136758810975
  - 0.999746106910767
  - 0.999292055997583
  - 0.9995801430819481
  - 0.9996716857881183
  - 0.9993343395302354
  LT_average_precision:
  - 0.1756674971368849
  - 0.25025402356185705
  - 0.22351902055668532
  - 0.31453364806608186
  - 0.25024483354286287
  - 0.3714289143472895
  - 0.27689904790963316
  - 0.3358665155931999
  - 0.1963905780490633
  - 0.3518476559411439
  - 0.23509575169294714
  - 0.3339232472994504
  - 0.16831617770121185
  - 0.26531581521943615
  - 0.18661991653468038
  - 0.26847133567219994
  LT_balanced_accuracy:
  - 0.7468664172200308
  - 0.7016248994669076
  - 0.7663015463917526
  - 0.7598259511749248
  - 0.7472909613541999
  - 0.7307345360824742
  - 0.7863625900226907
  - 0.7792924266880261
  - 0.6880260596948824
  - 0.7420803405514471
  - 0.7895466872474302
  - 0.7779813755062536
  - 0.7192053109822967
  - 0.7329579141615572
  - 0.7686250140737725
  - 0.6894778481012658
  LT_f1_macro:
  - 0.42740172992273834
  - 0.40179892420973623
  - 0.4239436121534846
  - 0.43055312874379886
  - 0.44525027595526434
  - 0.4432376091022444
  - 0.4580734073472973
  - 0.4654991948470209
  - 0.35289562434173943
  - 0.4649373273069955
  - 0.46986537562344133
  - 0.47640716336678546
  - 0.38972879660734416
  - 0.441505706760316
  - 0.45770153335194236
  - 0.3594360585395755
  LT_f1_micro:
  - 0.6046277665995976
  - 0.5583501006036218
  - 0.6033702213279678
  - 0.5685019206145967
  - 0.6483903420523138
  - 0.6529175050301811
  - 0.6740442655935613
  - 0.6517285531370038
  - 0.4615191146881288
  - 0.6763078470824949
  - 0.6695171026156942
  - 0.6394366197183099
  - 0.5349702380952381
  - 0.6393849206349206
  - 0.6545138888888888
  - 0.44343434343434346
  LT_f1_weighted:
  - 0.7288141847049918
  - 0.6910414615195798
  - 0.7299149006240772
  - 0.6887226419380026
  - 0.7638914270152249
  - 0.7684133165577004
  - 0.7840087105492289
  - 0.7598304539578269
  - 0.6032164240718472
  - 0.7814433237055223
  - 0.7753979775042085
  - 0.7429853886905493
  - 0.672089382397739
  - 0.7562985561658326
  - 0.765276544310464
  - 0.5717162429598257
  LT_matthews_corrcoef:
  - 0.1620584329080491
  - 0.13209372171681436
  - 0.16576576775621896
  - 0.2026869962611276
  - 0.16123031928024495
  - 0.14737988334044158
  - 0.1830376469785346
  - 0.20762335809592702
  - 0.12487449802079256
  - 0.17247712860528586
  - 0.20776407908195788
  - 0.23239767528494998
  - 0.139044761265634
  - 0.15442126126962968
  - 0.1877371246165271
  - 0.15562310940016816
  LT_precision_macro:
  - 0.5265963025392034
  - 0.5216351643114682
  - 0.5257962168565347
  - 0.5395284018663136
  - 0.5262799898880819
  - 0.5235344374342797
  - 0.5292485657857613
  - 0.538586311968979
  - 0.5207333497830692
  - 0.5307215776218744
  - 0.5372702524825357
  - 0.5485722104398987
  - 0.5220494721920521
  - 0.525590379723659
  - 0.5328015133668844
  - 0.5319543318942924
  LT_precision_micro:
  - 0.6046277665995976
  - 0.5583501006036218
  - 0.6033702213279678
  - 0.5685019206145967
  - 0.6483903420523138
  - 0.6529175050301811
  - 0.6740442655935613
  - 0.6517285531370038
  - 0.4615191146881288
  - 0.6763078470824949
  - 0.6695171026156942
  - 0.6394366197183099
  - 0.5349702380952381
  - 0.6393849206349206
  - 0.6545138888888888
  - 0.44343434343434346
  LT_precision_weighted:
  - 0.9700319034383014
  - 0.9667149403950589
  - 0.9746341876820743
  - 0.9614625999941453
  - 0.9702534668320234
  - 0.9702365613237786
  - 0.9744483311038998
  - 0.964829522491331
  - 0.9688991533040491
  - 0.9644666574957933
  - 0.9681688025673645
  - 0.9558047768033939
  - 0.971222279590081
  - 0.9680217007004379
  - 0.9678487614662525
  - 0.9562882448292861
  LT_recall_macro:
  - 0.7468664172200308
  - 0.7016248994669076
  - 0.7663015463917526
  - 0.7598259511749248
  - 0.7472909613541999
  - 0.7307345360824742
  - 0.7863625900226907
  - 0.7792924266880261
  - 0.6880260596948824
  - 0.7420803405514471
  - 0.7895466872474302
  - 0.7779813755062536
  - 0.7192053109822967
  - 0.7329579141615572
  - 0.7686250140737725
  - 0.6894778481012658
  LT_recall_micro:
  - 0.6046277665995976
  - 0.5583501006036218
  - 0.6033702213279678
  - 0.5685019206145967
  - 0.6483903420523138
  - 0.6529175050301811
  - 0.6740442655935613
  - 0.6517285531370038
  - 0.4615191146881288
  - 0.6763078470824949
  - 0.6695171026156942
  - 0.6394366197183099
  - 0.5349702380952381
  - 0.6393849206349206
  - 0.6545138888888888
  - 0.44343434343434346
  LT_recall_weighted:
  - 0.6046277665995976
  - 0.5583501006036218
  - 0.6033702213279678
  - 0.5685019206145967
  - 0.6483903420523138
  - 0.6529175050301811
  - 0.6740442655935613
  - 0.6517285531370038
  - 0.4615191146881288
  - 0.6763078470824949
  - 0.6695171026156942
  - 0.6394366197183099
  - 0.5349702380952381
  - 0.6393849206349206
  - 0.6545138888888888
  - 0.44343434343434346
  LT_roc_auc:
  - 0.8620257353562828
  - 0.814881507367682
  - 0.8969260094501718
  - 0.8897627299386831
  - 0.8487895241137017
  - 0.8392504295532647
  - 0.8777308253039123
  - 0.8879416012330247
  - 0.8629674953090218
  - 0.8103046934350382
  - 0.8820164860490294
  - 0.8750677353981275
  - 0.8552208992636692
  - 0.8214965176498601
  - 0.865448238829755
  - 0.8514384920634921
  TL_average_precision:
  - 0.2973623994388274
  - 0.3549500077742911
  - 0.29874389184778094
  - 0.2698976593507725
  - 0.3939373499641483
  - 0.47426797122680203
  - 0.5132954008852576
  - 0.3877702285000017
  - 0.352790828026916
  - 0.45796750238112893
  - 0.46411133472710303
  - 0.3783668272925342
  - 0.4301536831173681
  - 0.4104918393260926
  - 0.4714788215801665
  - 0.41140385597140666
  TL_balanced_accuracy:
  - 0.7185873712597183
  - 0.701070086352813
  - 0.7065527365996473
  - 0.6857788236338813
  - 0.7397404496160251
  - 0.7395464209780298
  - 0.744711428643943
  - 0.7170325522406088
  - 0.6675338501446972
  - 0.7836985472675614
  - 0.7768631813125695
  - 0.7453211937278705
  - 0.7914081113993752
  - 0.8178814719254912
  - 0.8235097231189943
  - 0.7013124952583264
  TL_f1_macro:
  - 0.38511405058883114
  - 0.3693673439699728
  - 0.3776350715077955
  - 0.35867404941338876
  - 0.4666441219955771
  - 0.46083783451403304
  - 0.4637279273714211
  - 0.43781307054965163
  - 0.34359750910033915
  - 0.46455797665812054
  - 0.4622033898305085
  - 0.43921817576242383
  - 0.4660982181816546
  - 0.5096876318891224
  - 0.5088386639551365
  - 0.3824637896901308
  TL_f1_micro:
  - 0.5044910179640718
  - 0.47754491017964074
  - 0.500249500998004
  - 0.4714781746031746
  - 0.6339820359281437
  - 0.627744510978044
  - 0.6334830339321357
  - 0.6108630952380952
  - 0.46182634730538924
  - 0.6951097804391217
  - 0.687125748502994
  - 0.6607142857142857
  - 0.6782087997917209
  - 0.7568341577714137
  - 0.7406925279875033
  - 0.5243271221532091
  TL_f1_weighted:
  - 0.6377930449538651
  - 0.6129623695674057
  - 0.6370621162526774
  - 0.6122998826313463
  - 0.7396024475283427
  - 0.7359718895282502
  - 0.7407562165702813
  - 0.7286794508932135
  - 0.610359579077401
  - 0.8003045198068791
  - 0.793859738150817
  - 0.7780180661228883
  - 0.7849211865744803
  - 0.8393069625212798
  - 0.8264406792931456
  - 0.6634328520414113
  TL_matthews_corrcoef:
  - 0.15795099622810138
  - 0.14589659606504088
  - 0.14212449553158812
  - 0.12437424493289964
  - 0.19918211355411883
  - 0.19468230558915176
  - 0.19820653934458068
  - 0.15924350920726338
  - 0.09712665392343868
  - 0.17899408522829788
  - 0.17727622329285198
  - 0.14148159274637093
  - 0.19639624545301582
  - 0.23204183939379877
  - 0.2425807601119304
  - 0.1266093126012182
  TL_precision_macro:
  - 0.528533804429862
  - 0.5264656681775328
  - 0.5244482021427536
  - 0.5208163563802002
  - 0.5413713188819701
  - 0.5395551725994938
  - 0.5401348564477101
  - 0.5292104743768237
  - 0.5140771355970983
  - 0.5282332099118036
  - 0.5283776080264508
  - 0.520398809395423
  - 0.5330906070551851
  - 0.5423455123879302
  - 0.5454742322805219
  - 0.5199067599067599
  TL_precision_micro:
  - 0.5044910179640718
  - 0.47754491017964074
  - 0.500249500998004
  - 0.4714781746031746
  - 0.6339820359281437
  - 0.627744510978044
  - 0.6334830339321357
  - 0.6108630952380952
  - 0.46182634730538924
  - 0.6951097804391217
  - 0.687125748502994
  - 0.6607142857142857
  - 0.6782087997917209
  - 0.7568341577714137
  - 0.7406925279875033
  - 0.5243271221532091
  TL_precision_weighted:
  - 0.9648053374838587
  - 0.9639436428094009
  - 0.9666031104380801
  - 0.9674443733236555
  - 0.9509612292963271
  - 0.9530551826499406
  - 0.954015932523236
  - 0.9592018671476655
  - 0.9740278820731983
  - 0.9751823463590963
  - 0.973851464782213
  - 0.9766595360832684
  - 0.9720640928143321
  - 0.9716769396084748
  - 0.969836312244886
  - 0.9702925576838621
  TL_recall_macro:
  - 0.7185873712597183
  - 0.701070086352813
  - 0.7065527365996473
  - 0.6857788236338813
  - 0.7397404496160251
  - 0.7395464209780298
  - 0.744711428643943
  - 0.7170325522406088
  - 0.6675338501446972
  - 0.7836985472675614
  - 0.7768631813125695
  - 0.7453211937278705
  - 0.7914081113993752
  - 0.8178814719254912
  - 0.8235097231189943
  - 0.7013124952583264
  TL_recall_micro:
  - 0.5044910179640718
  - 0.47754491017964074
  - 0.500249500998004
  - 0.4714781746031746
  - 0.6339820359281437
  - 0.627744510978044
  - 0.6334830339321357
  - 0.6108630952380952
  - 0.46182634730538924
  - 0.6951097804391217
  - 0.687125748502994
  - 0.6607142857142857
  - 0.6782087997917209
  - 0.7568341577714137
  - 0.7406925279875033
  - 0.5243271221532091
  TL_recall_weighted:
  - 0.5044910179640718
  - 0.47754491017964074
  - 0.500249500998004
  - 0.4714781746031746
  - 0.6339820359281437
  - 0.627744510978044
  - 0.6334830339321357
  - 0.6108630952380952
  - 0.46182634730538924
  - 0.6951097804391217
  - 0.687125748502994
  - 0.6607142857142857
  - 0.6782087997917209
  - 0.7568341577714137
  - 0.7406925279875033
  - 0.5243271221532092
  TL_roc_auc:
  - 0.8818085320021802
  - 0.8837134578420404
  - 0.8813036288315349
  - 0.8618796550154844
  - 0.8511805623591654
  - 0.8535746316865589
  - 0.8703570340854293
  - 0.8332924417200145
  - 0.8599181298825928
  - 0.8908744778391643
  - 0.8852222634202611
  - 0.864616162795222
  - 0.9217239370995922
  - 0.9016041827268485
  - 0.9206245964525807
  - 0.8969431107546576
  TT_average_precision:
  - 0.0984437876618762
  - 0.08463092634582013
  - 0.0881264461361117
  - 0.1504306092392706
  - 0.0571501501674201
  - 0.08093183263670828
  - 0.09758072699066447
  - 0.22063625965572486
  - 0.12228982282719705
  - 0.15146916733871157
  - 0.113997017941046
  - 0.20703334998728082
  - 0.19591441939391654
  - 0.2321968023042917
  - 0.12379666180086445
  - 0.2388508986100275
  TT_balanced_accuracy:
  - 0.6938706780422093
  - 0.6490121239335429
  - 0.6912925080792007
  - 0.6933473758118308
  - 0.6536042944785276
  - 0.6381092209517873
  - 0.6879205736348594
  - 0.7048615101712447
  - 0.6911719939117199
  - 0.6965682269172406
  - 0.7404070966854628
  - 0.7766847127720082
  - 0.7640914295590555
  - 0.7526180333688322
  - 0.8042121931908155
  - 0.7213775510204081
  TT_f1_macro:
  - 0.3488367753462617
  - 0.313848008902323
  - 0.36253076255615546
  - 0.3498301541677555
  - 0.39131102814159263
  - 0.4051619326684316
  - 0.4269812343003497
  - 0.45434775445648945
  - 0.3453544198828306
  - 0.4359547640712336
  - 0.4348572005247755
  - 0.45058201058201053
  - 0.4509605070697221
  - 0.47606408683692053
  - 0.47727027470851807
  - 0.3718618566782428
  TT_f1_micro:
  - 0.45907738095238093
  - 0.3995535714285714
  - 0.4635416666666667
  - 0.4287878787878788
  - 0.5394345238095238
  - 0.5587797619047619
  - 0.5877976190476191
  - 0.5818181818181818
  - 0.45982142857142855
  - 0.6636904761904762
  - 0.6651785714285714
  - 0.6424242424242425
  - 0.6436335403726708
  - 0.702639751552795
  - 0.7313664596273292
  - 0.48379446640316204
  TT_f1_weighted:
  - 0.6032075036526057
  - 0.544080214762308
  - 0.5985375478610883
  - 0.557866593819037
  - 0.6737063501993078
  - 0.6863073009633262
  - 0.708409907608071
  - 0.6873109492899271
  - 0.6068769094845383
  - 0.7804916962235304
  - 0.7838289746214361
  - 0.7570376783710115
  - 0.7575202219187126
  - 0.8013486302778927
  - 0.8275721421132934
  - 0.6202516366857885
  TT_matthews_corrcoef:
  - 0.12275812342308694
  - 0.0964771749721552
  - 0.14184299605756231
  - 0.15708435388558797
  - 0.104519053367634
  - 0.10186523057044987
  - 0.1421381450952586
  - 0.1927261226724477
  - 0.11377394100148422
  - 0.11389046567287661
  - 0.12832285720814002
  - 0.18807641134752603
  - 0.1818690991079773
  - 0.17936590656839932
  - 0.18626489402065885
  - 0.1556204420292476
  TT_precision_macro:
  - 0.5194324858954134
  - 0.5156159194381374
  - 0.5262940714884866
  - 0.5319056492647556
  - 0.5177798292586042
  - 0.518783186827897
  - 0.5268773821571778
  - 0.5453273998728544
  - 0.5169278320874066
  - 0.5164968652037618
  - 0.5171238244514107
  - 0.5319612313876837
  - 0.531311475409836
  - 0.5318387092264026
  - 0.5285118508734176
  - 0.5273488909170672
  TT_precision_micro:
  - 0.45907738095238093
  - 0.39955357142857145
  - 0.4635416666666667
  - 0.4287878787878788
  - 0.5394345238095238
  - 0.5587797619047619
  - 0.5877976190476191
  - 0.5818181818181818
  - 0.45982142857142855
  - 0.6636904761904762
  - 0.6651785714285714
  - 0.6424242424242425
  - 0.6436335403726708
  - 0.702639751552795
  - 0.7313664596273292
  - 0.48379446640316204
  TT_precision_weighted:
  - 0.9724508029972334
  - 0.9698967662485861
  - 0.962074660528903
  - 0.95991502535371
  - 0.9592561826838041
  - 0.9497807630872169
  - 0.9533190403902664
  - 0.9321296884933249
  - 0.9752067203031299
  - 0.9736462531721153
  - 0.979794908755038
  - 0.9702953452461301
  - 0.9683595102331738
  - 0.9663451265253421
  - 0.9785727928758235
  - 0.9684770366348238
  TT_recall_macro:
  - 0.6938706780422093
  - 0.6490121239335429
  - 0.6912925080792007
  - 0.6933473758118308
  - 0.6536042944785276
  - 0.6381092209517873
  - 0.6879205736348594
  - 0.7048615101712447
  - 0.6911719939117199
  - 0.6965682269172406
  - 0.7404070966854628
  - 0.7766847127720082
  - 0.7640914295590555
  - 0.7526180333688322
  - 0.8042121931908155
  - 0.7213775510204081
  TT_recall_micro:
  - 0.45907738095238093
  - 0.39955357142857145
  - 0.4635416666666667
  - 0.4287878787878788
  - 0.5394345238095238
  - 0.5587797619047619
  - 0.5877976190476191
  - 0.5818181818181818
  - 0.45982142857142855
  - 0.6636904761904762
  - 0.6651785714285714
  - 0.6424242424242425
  - 0.6436335403726708
  - 0.702639751552795
  - 0.7313664596273292
  - 0.48379446640316204
  TT_recall_weighted:
  - 0.45907738095238093
  - 0.39955357142857145
  - 0.4635416666666667
  - 0.4287878787878788
  - 0.5394345238095238
  - 0.5587797619047619
  - 0.5877976190476191
  - 0.5818181818181818
  - 0.45982142857142855
  - 0.6636904761904762
  - 0.6651785714285714
  - 0.6424242424242425
  - 0.6436335403726708
  - 0.702639751552795
  - 0.7313664596273292
  - 0.48379446640316204
  TT_roc_auc:
  - 0.8019083969465649
  - 0.7880556802873822
  - 0.7744877704686757
  - 0.8301298929261015
  - 0.7171395705521473
  - 0.7063764169359734
  - 0.7605704830194626
  - 0.8125816259364128
  - 0.8116945712836124
  - 0.7992587837049142
  - 0.8218264337780223
  - 0.8460744454509069
  - 0.8672629463996371
  - 0.7987220447284346
  - 0.8875059382422803
  - 0.8876122448979592
  fit_time:
  - 44.928369998931885
  - 44.12144660949707
  - 44.01479530334473
  - 46.65662980079651
  - 47.06095767021179
  - 45.141765832901
  - 46.46883010864258
  - 47.94536375999451
  - 45.56354904174805
  - 47.50508379936218
  - 45.428481101989746
  - 47.51380014419556
  - 46.53090572357178
  - 48.10416030883789
  - 46.64466094970703
  - 46.71153378486633
  score_time:
  - 0.7388195991516113
  - 0.7466621398925781
  - 0.7716443538665771
  - 0.7700667381286621
  - 0.7723448276519775
  - 0.7026190757751465
  - 0.7048938274383545
  - 0.6954495906829834
  - 0.7149443626403809
  - 0.72566819190979
  - 0.7927179336547852
  - 0.7124607563018799
  - 0.7769219875335693
  - 0.6935293674468994
  - 0.7795512676239014
  - 0.739295482635498
start: 2023-10-04 22:15:06.935263
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
