active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: y_reconstruction/runs
end: 2023-10-05 00:45:16.296715
estimator:
  call: bipartite_adaptations.estimators.bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 1000
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gso_1k
  params:
    n_estimators: 1000
hash: fafa9a0b17de3d6d19efba807a583d54ee941fbf28dec615c2888f9680c3a437
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/fafa9a0_20231005T003754930632_bxt_gso_1k_davis.yml"
results:
  LL_average_precision:
  - 0.9901362617350733
  - 0.981304134490447
  - 0.9851975567410802
  - 0.988723900805917
  - 0.987345379691922
  - 0.981852999550394
  - 0.9871278525139165
  - 0.9874694573492125
  - 0.9915199953379843
  - 0.9832892080219131
  - 0.9853321257123454
  - 0.9895499522954786
  - 0.9914674606582599
  - 0.9825065413249612
  - 0.9858066363313485
  - 0.9884916756718023
  LL_balanced_accuracy:
  - 0.871577776404425
  - 0.8743701399688958
  - 0.9236816043575142
  - 0.9700606210565383
  - 0.8825582845031792
  - 0.9018433757602358
  - 0.9425656704311474
  - 0.9482554517133956
  - 0.9165477003289677
  - 0.8865805727119596
  - 0.8982028480815869
  - 0.8945865408492675
  - 0.9371489202346773
  - 0.9287954830614806
  - 0.8877952755905512
  - 0.9628380488414215
  LL_f1_macro:
  - 0.5523176524946287
  - 0.5707894181735662
  - 0.6518188422820353
  - 0.7909682948603495
  - 0.587523202935529
  - 0.6321665914532741
  - 0.7174102763830651
  - 0.7302341718257623
  - 0.6365507964018144
  - 0.5955860272822366
  - 0.6143537721022136
  - 0.6044449923256879
  - 0.6966383562846585
  - 0.6883061202179391
  - 0.6074179924267846
  - 0.7844617626479975
  LL_f1_micro:
  - 0.7538060541437118
  - 0.7607369231680587
  - 0.8543586109142453
  - 0.9428301441058351
  - 0.7767904744979561
  - 0.8145252058527337
  - 0.8912709662178124
  - 0.9019017245452398
  - 0.8407084888335999
  - 0.7846099164741426
  - 0.8066383179777935
  - 0.7994330262225372
  - 0.8806942716663705
  - 0.8655292932883123
  - 0.7879163713678242
  - 0.929718875502008
  LL_f1_weighted:
  - 0.8277474048945805
  - 0.8290537506545018
  - 0.8930347042584477
  - 0.9530159998479104
  - 0.839156812866756
  - 0.8625619567937324
  - 0.9153713750714959
  - 0.9230122453912494
  - 0.8840992598539186
  - 0.8441620229728662
  - 0.8592930188139134
  - 0.8551345204279291
  - 0.9088856636793575
  - 0.8971340228719203
  - 0.8443722270230174
  - 0.9421545563866319
  LL_matthews_corrcoef:
  - 0.3273026673141081
  - 0.35292809256291136
  - 0.4503593225647648
  - 0.644438934759201
  - 0.373280821958145
  - 0.4293662950361715
  - 0.5401046078577046
  - 0.5576207168590502
  - 0.4306430572526784
  - 0.3831143185566815
  - 0.40534048461639904
  - 0.3925486715738647
  - 0.5112796082256669
  - 0.50131968450621
  - 0.39942981164415786
  - 0.6354995148172573
  LL_precision_macro:
  - 0.5720757825370676
  - 0.5831785345717234
  - 0.6196792103639729
  - 0.720876585928489
  - 0.5910570870414587
  - 0.61469357617524
  - 0.6647851420247632
  - 0.6734172237514746
  - 0.6113038450419196
  - 0.5949197860962567
  - 0.6031515151515151
  - 0.5976303317535545
  - 0.6494953010790114
  - 0.6465275615073186
  - 0.6028533510285335
  - 0.7181430601610611
  LL_precision_micro:
  - 0.7538060541437118
  - 0.7607369231680587
  - 0.8543586109142453
  - 0.9428301441058351
  - 0.7767904744979562
  - 0.8145252058527338
  - 0.8912709662178124
  - 0.9019017245452398
  - 0.8407084888335999
  - 0.7846099164741426
  - 0.8066383179777935
  - 0.7994330262225372
  - 0.8806942716663705
  - 0.8655292932883123
  - 0.7879163713678242
  - 0.929718875502008
  LL_precision_weighted:
  - 0.9645107573930392
  - 0.9601968957839949
  - 0.9651395071158095
  - 0.9747450348241463
  - 0.9593503816157554
  - 0.9574544651377671
  - 0.9641661414519739
  - 0.9659761388316561
  - 0.9645404846492835
  - 0.9591104386889415
  - 0.9601088990543277
  - 0.9608371596225996
  - 0.9643287084446266
  - 0.9605926705027411
  - 0.9563729761937794
  - 0.9693373208608951
  LL_recall_macro:
  - 0.871577776404425
  - 0.8743701399688958
  - 0.9236816043575142
  - 0.9700606210565383
  - 0.8825582845031792
  - 0.9018433757602358
  - 0.9425656704311474
  - 0.9482554517133956
  - 0.9165477003289677
  - 0.8865805727119596
  - 0.8982028480815869
  - 0.8945865408492675
  - 0.9371489202346773
  - 0.9287954830614806
  - 0.8877952755905512
  - 0.9628380488414215
  LL_recall_micro:
  - 0.7538060541437118
  - 0.7607369231680587
  - 0.8543586109142453
  - 0.9428301441058351
  - 0.7767904744979562
  - 0.8145252058527338
  - 0.8912709662178124
  - 0.9019017245452398
  - 0.8407084888335999
  - 0.7846099164741426
  - 0.8066383179777935
  - 0.7994330262225372
  - 0.8806942716663705
  - 0.8655292932883123
  - 0.7879163713678242
  - 0.929718875502008
  LL_recall_weighted:
  - 0.7538060541437118
  - 0.7607369231680587
  - 0.8543586109142453
  - 0.9428301441058351
  - 0.7767904744979562
  - 0.8145252058527338
  - 0.8912709662178124
  - 0.9019017245452398
  - 0.8407084888335999
  - 0.7846099164741426
  - 0.8066383179777935
  - 0.7994330262225372
  - 0.8806942716663705
  - 0.8655292932883123
  - 0.7879163713678242
  - 0.929718875502008
  LL_roc_auc:
  - 0.9995317259219366
  - 0.9989264806331981
  - 0.9992391355673931
  - 0.9994299110824414
  - 0.9991444166452812
  - 0.9987582804847103
  - 0.999206380669085
  - 0.9991824019327357
  - 0.9995550753014597
  - 0.9990038228832306
  - 0.9990547997647923
  - 0.9993570402212251
  - 0.9994836116637644
  - 0.9988628317935083
  - 0.998934944959837
  - 0.9992432252229415
  LT_average_precision:
  - 0.691108675241873
  - 0.6191491398166867
  - 0.5892728520649959
  - 0.5125458016398008
  - 0.6796690362404753
  - 0.61509140292304
  - 0.5667791690785976
  - 0.5170682861372902
  - 0.6951854846773257
  - 0.6190607529120438
  - 0.5657181946984855
  - 0.4781444027290619
  - 0.6578752445414328
  - 0.6083992289363
  - 0.6079047062213288
  - 0.538849860877983
  LT_balanced_accuracy:
  - 0.8058877337154089
  - 0.812047592840108
  - 0.8440526070763501
  - 0.8573358208955224
  - 0.8308754863180181
  - 0.8327528910467475
  - 0.8557987617608346
  - 0.8606400152756561
  - 0.8623474257622157
  - 0.8090533016067206
  - 0.8299909157632563
  - 0.8209559512652296
  - 0.8658593691564909
  - 0.8466260950304791
  - 0.836565532129651
  - 0.8742574433673418
  LT_f1_macro:
  - 0.5137064090438066
  - 0.5208145323411676
  - 0.567462397768619
  - 0.6667476311294279
  - 0.5543187308219625
  - 0.5575507767054977
  - 0.6186109107053666
  - 0.6405055544323441
  - 0.6104151926843743
  - 0.5395884861426518
  - 0.5422954654564481
  - 0.5420657379190248
  - 0.6308608116700622
  - 0.6009906192331351
  - 0.5429327101644739
  - 0.6658050777311241
  LT_f1_micro:
  - 0.6643702526055467
  - 0.7350291467938528
  - 0.7814616755793227
  - 0.8877005347593583
  - 0.7102985338279456
  - 0.7629394099982334
  - 0.8253119429590018
  - 0.8390374331550802
  - 0.7917329093799682
  - 0.7456279809220986
  - 0.7411764705882353
  - 0.7283422459893049
  - 0.8048048048048048
  - 0.8095742801625155
  - 0.7180035650623886
  - 0.8645276292335116
  LT_f1_weighted:
  - 0.7541660946267933
  - 0.8174324436612527
  - 0.8456723053126916
  - 0.9139169256891793
  - 0.7856569456713854
  - 0.8319525468266976
  - 0.871256627610052
  - 0.8787057121131132
  - 0.8453019188956784
  - 0.8207097086209728
  - 0.8173299328020294
  - 0.8054975799636354
  - 0.8522074524449726
  - 0.8613507276348464
  - 0.7968661275797672
  - 0.896315887587569
  LT_matthews_corrcoef:
  - 0.28827980602161357
  - 0.25882288894533684
  - 0.31995802385044714
  - 0.423509308351311
  - 0.3334439500789462
  - 0.30896358001958674
  - 0.3786450883051426
  - 0.40620441707629057
  - 0.386705810355967
  - 0.2790032499236587
  - 0.29700654783733277
  - 0.29882959217817834
  - 0.41112500427295534
  - 0.3557266200420158
  - 0.3154128934533446
  - 0.43930245458158296
  LT_precision_macro:
  - 0.5679213624803099
  - 0.5536691272253582
  - 0.574387706211717
  - 0.6254842950048429
  - 0.5840080879680116
  - 0.5717187561302878
  - 0.6007396022038315
  - 0.6143813924296291
  - 0.6031754147614665
  - 0.5629687606177242
  - 0.5668297862489766
  - 0.56955715013957
  - 0.6154977727699931
  - 0.5912665188950862
  - 0.5738974165945545
  - 0.6289130316721472
  LT_precision_micro:
  - 0.6643702526055467
  - 0.7350291467938527
  - 0.7814616755793227
  - 0.8877005347593583
  - 0.7102985338279456
  - 0.7629394099982335
  - 0.8253119429590018
  - 0.8390374331550802
  - 0.7917329093799682
  - 0.7456279809220986
  - 0.7411764705882353
  - 0.7283422459893049
  - 0.8048048048048048
  - 0.8095742801625154
  - 0.7180035650623886
  - 0.8645276292335116
  LT_precision_weighted:
  - 0.9489437257480366
  - 0.9617875740087328
  - 0.9589964907359084
  - 0.9583022247479064
  - 0.9463908982431659
  - 0.9564747223081577
  - 0.9536789472013719
  - 0.951230767642071
  - 0.9498689633011078
  - 0.9550751965598523
  - 0.9575436090846334
  - 0.9528837651203229
  - 0.9466344099868816
  - 0.9537411215324916
  - 0.9542530579383764
  - 0.9542608716729526
  LT_recall_macro:
  - 0.8058877337154089
  - 0.812047592840108
  - 0.8440526070763501
  - 0.8573358208955224
  - 0.8308754863180181
  - 0.8327528910467475
  - 0.8557987617608346
  - 0.8606400152756561
  - 0.8623474257622157
  - 0.8090533016067206
  - 0.8299909157632563
  - 0.8209559512652296
  - 0.8658593691564909
  - 0.8466260950304791
  - 0.836565532129651
  - 0.8742574433673418
  LT_recall_micro:
  - 0.6643702526055467
  - 0.7350291467938527
  - 0.7814616755793227
  - 0.8877005347593583
  - 0.7102985338279456
  - 0.7629394099982335
  - 0.8253119429590018
  - 0.8390374331550802
  - 0.7917329093799682
  - 0.7456279809220986
  - 0.7411764705882353
  - 0.7283422459893049
  - 0.8048048048048048
  - 0.8095742801625154
  - 0.7180035650623886
  - 0.8645276292335116
  LT_recall_weighted:
  - 0.6643702526055467
  - 0.7350291467938527
  - 0.7814616755793227
  - 0.8877005347593583
  - 0.7102985338279456
  - 0.7629394099982335
  - 0.8253119429590018
  - 0.8390374331550802
  - 0.7917329093799682
  - 0.7456279809220986
  - 0.7411764705882353
  - 0.7283422459893049
  - 0.8048048048048048
  - 0.8095742801625154
  - 0.7180035650623887
  - 0.8645276292335116
  LT_roc_auc:
  - 0.9513342056340364
  - 0.914299691624953
  - 0.93260086902545
  - 0.9269742537313432
  - 0.9502678477492437
  - 0.9281658072285999
  - 0.924789759117005
  - 0.9333115936278692
  - 0.9495250902391251
  - 0.904717713410576
  - 0.9318125759526416
  - 0.9227993524750786
  - 0.9514668096587049
  - 0.92041567424273
  - 0.9505819528821412
  - 0.942129853319635
  TL_average_precision:
  - 0.3573206810063792
  - 0.36095748491171054
  - 0.34040701426783865
  - 0.3621527006675883
  - 0.24328474619666843
  - 0.23086415187240808
  - 0.26553266672052506
  - 0.2551264480214803
  - 0.39852006878237556
  - 0.3837488634719949
  - 0.3546727425851067
  - 0.33277942974998986
  - 0.14882214850974831
  - 0.1619687476477671
  - 0.18099261538914774
  - 0.18509904038086844
  TL_balanced_accuracy:
  - 0.7063839345667091
  - 0.747524328504556
  - 0.7463412085516149
  - 0.7566013696035208
  - 0.7487290986992854
  - 0.7688159321699695
  - 0.7844609206054989
  - 0.7609206054989188
  - 0.7764872741936962
  - 0.7524066390041494
  - 0.7527350844052764
  - 0.7420640370006206
  - 0.7398421067392097
  - 0.7353353360434371
  - 0.742453545071165
  - 0.7641621536358378
  TL_f1_macro:
  - 0.49555552865083224
  - 0.5110485934899237
  - 0.5617324404213343
  - 0.634936317076458
  - 0.502385702429087
  - 0.5239340292465949
  - 0.56179915342883
  - 0.576884981776426
  - 0.5749500857041008
  - 0.5516153650187309
  - 0.5528346870374763
  - 0.5581873773020607
  - 0.5499505558163573
  - 0.5513959243768987
  - 0.5108065824478881
  - 0.5939840768129772
  TL_f1_micro:
  - 0.6486582548427225
  - 0.6547005509152302
  - 0.7420269312544294
  - 0.8476257973068745
  - 0.7167229429536165
  - 0.7328949706770926
  - 0.7893338058114812
  - 0.8212260807937632
  - 0.7924293584503288
  - 0.7456904211835793
  - 0.7588589652728561
  - 0.7705527994330261
  - 0.8189088324151412
  - 0.7995379420650436
  - 0.7313961729270021
  - 0.8632175761871014
  TL_f1_weighted:
  - 0.7382974316292648
  - 0.7411272203825865
  - 0.8051798081539778
  - 0.8775445124924903
  - 0.8037811235078527
  - 0.8118718930149604
  - 0.8497001421578988
  - 0.8700487251998855
  - 0.8480824394263822
  - 0.8125315061674208
  - 0.8237692507936348
  - 0.8311743625611346
  - 0.873504271090251
  - 0.8570523404300376
  - 0.8132296727195178
  - 0.9000057915062811
  TL_matthews_corrcoef:
  - 0.20642420080349236
  - 0.2516420581756379
  - 0.27096742258257017
  - 0.3344288408118293
  - 0.20802310047089953
  - 0.24083125803720287
  - 0.27542810203798185
  - 0.26997525630474734
  - 0.286934316762132
  - 0.26106070446433494
  - 0.2573679264122601
  - 0.25279404349646484
  - 0.22387938178977976
  - 0.2299184875451607
  - 0.20888136671557242
  - 0.28122644964906607
  TL_precision_macro:
  - 0.5516161187240902
  - 0.5639570722456334
  - 0.5745138668969965
  - 0.6089653669225867
  - 0.5434947203160214
  - 0.5539399714700589
  - 0.5666705282669138
  - 0.5698360319966336
  - 0.5744440249337419
  - 0.5675028712441023
  - 0.5655214230560975
  - 0.5659999201235423
  - 0.5522447645578281
  - 0.55615658043943
  - 0.5449894693725336
  - 0.5748482654438515
  TL_precision_micro:
  - 0.6486582548427225
  - 0.6547005509152302
  - 0.7420269312544295
  - 0.8476257973068746
  - 0.7167229429536165
  - 0.7328949706770926
  - 0.7893338058114813
  - 0.8212260807937632
  - 0.7924293584503288
  - 0.7456904211835792
  - 0.7588589652728561
  - 0.7705527994330262
  - 0.8189088324151412
  - 0.7995379420650436
  - 0.7313961729270021
  - 0.8632175761871014
  TL_precision_weighted:
  - 0.9227928494813492
  - 0.9287981366908846
  - 0.922644759150029
  - 0.9257609787292832
  - 0.9536972557273443
  - 0.9503573198644237
  - 0.9501461729270021
  - 0.946774607494894
  - 0.9423625093832733
  - 0.9329084897232025
  - 0.9367236096750112
  - 0.9339902573648529
  - 0.9547406016207988
  - 0.9463994790957403
  - 0.9512685095021554
  - 0.9544957652731703
  TL_recall_macro:
  - 0.7063839345667091
  - 0.747524328504556
  - 0.7463412085516149
  - 0.7566013696035208
  - 0.7487290986992854
  - 0.7688159321699695
  - 0.7844609206054989
  - 0.7609206054989188
  - 0.7764872741936962
  - 0.7524066390041494
  - 0.7527350844052764
  - 0.7420640370006206
  - 0.7398421067392097
  - 0.7353353360434371
  - 0.742453545071165
  - 0.7641621536358378
  TL_recall_micro:
  - 0.6486582548427225
  - 0.6547005509152302
  - 0.7420269312544295
  - 0.8476257973068746
  - 0.7167229429536165
  - 0.7328949706770926
  - 0.7893338058114813
  - 0.8212260807937632
  - 0.7924293584503288
  - 0.7456904211835792
  - 0.7588589652728561
  - 0.7705527994330262
  - 0.8189088324151412
  - 0.7995379420650436
  - 0.7313961729270021
  - 0.8632175761871014
  TL_recall_weighted:
  - 0.6486582548427225
  - 0.6547005509152302
  - 0.7420269312544295
  - 0.8476257973068746
  - 0.7167229429536164
  - 0.7328949706770926
  - 0.7893338058114813
  - 0.8212260807937632
  - 0.7924293584503288
  - 0.7456904211835792
  - 0.7588589652728561
  - 0.7705527994330262
  - 0.8189088324151412
  - 0.7995379420650436
  - 0.7313961729270021
  - 0.8632175761871014
  TL_roc_auc:
  - 0.8072450700142182
  - 0.8524330555863252
  - 0.8332830959112767
  - 0.831299254995887
  - 0.8034417404192612
  - 0.8289904367544119
  - 0.8168108951096322
  - 0.8084363403567932
  - 0.8430655190157156
  - 0.8348486782926617
  - 0.8395023737535708
  - 0.8230971907139574
  - 0.7757887651793476
  - 0.7801200368473507
  - 0.8003863007380075
  - 0.7983538391433128
  TT_average_precision:
  - 0.32928113250974433
  - 0.29614120436011687
  - 0.26323822169238453
  - 0.3073243543134891
  - 0.3043643657092392
  - 0.29093600300620975
  - 0.16476114939107925
  - 0.19772622056060818
  - 0.31326057180232053
  - 0.3063658410496768
  - 0.28758773440530877
  - 0.2817861741263893
  - 0.22993344560295806
  - 0.15747414571180313
  - 0.10664243434136832
  - 0.16702284696582223
  TT_balanced_accuracy:
  - 0.7172757149790125
  - 0.6948125404007757
  - 0.7338442629611571
  - 0.7472091690544413
  - 0.7340001741477644
  - 0.6703090507726269
  - 0.6928497052353029
  - 0.7247218720885625
  - 0.7617649261065301
  - 0.7592020809404769
  - 0.766845979614949
  - 0.7861581920903955
  - 0.7782063703524282
  - 0.7144811835147424
  - 0.6223311314724057
  - 0.6681084748637703
  TT_f1_macro:
  - 0.46498028596551166
  - 0.5077858738815422
  - 0.5309726153675769
  - 0.6231212259799855
  - 0.49640468950274586
  - 0.4977535985009795
  - 0.5121769430003541
  - 0.5385650907831876
  - 0.5838374291115311
  - 0.5580420853356634
  - 0.5740661343051611
  - 0.570227287668613
  - 0.57238677505891
  - 0.5385428907168037
  - 0.483729662077597
  - 0.5492964071856287
  TT_f1_micro:
  - 0.5707472178060413
  - 0.6777954425013248
  - 0.711764705882353
  - 0.8331550802139036
  - 0.6613672496025437
  - 0.7350291467938528
  - 0.7604278074866309
  - 0.7957219251336898
  - 0.7774244833068362
  - 0.7954425013248543
  - 0.7818181818181819
  - 0.7737967914438504
  - 0.7938526762056174
  - 0.8367779544250132
  - 0.7433155080213903
  - 0.827807486631016
  TT_f1_weighted:
  - 0.6690764273836495
  - 0.7605773785289918
  - 0.7872893948570872
  - 0.8668567874835296
  - 0.7531658594358572
  - 0.8155235502239715
  - 0.8337492772074656
  - 0.8568795676869614
  - 0.8312738736735178
  - 0.8538055826237154
  - 0.8384489083990665
  - 0.8343773042223397
  - 0.8501161047001787
  - 0.8886791125126646
  - 0.8243626725920771
  - 0.873657609913862
  TT_matthews_corrcoef:
  - 0.22333409164980222
  - 0.19866420592165063
  - 0.23805307434018974
  - 0.31693483212107854
  - 0.21982825464095443
  - 0.14938148836014326
  - 0.1705411128199845
  - 0.20890677076147807
  - 0.29468660900119653
  - 0.2536523971521892
  - 0.2839972971008417
  - 0.294178558982224
  - 0.2840524152810753
  - 0.1895733725104691
  - 0.10266701802133979
  - 0.17935055182927168
  TT_precision_macro:
  - 0.5573903490524242
  - 0.5506480058127753
  - 0.5605844093470758
  - 0.6015816769618841
  - 0.5516286598017367
  - 0.5327563757819356
  - 0.5377032870317223
  - 0.5485511695683871
  - 0.5829371975232492
  - 0.5620553839186063
  - 0.5755627505396238
  - 0.5756059296543921
  - 0.5725053262842263
  - 0.5418895296268762
  - 0.521540952949846
  - 0.5478361077089229
  TT_precision_micro:
  - 0.5707472178060413
  - 0.6777954425013248
  - 0.711764705882353
  - 0.8331550802139037
  - 0.6613672496025437
  - 0.7350291467938527
  - 0.760427807486631
  - 0.7957219251336899
  - 0.7774244833068362
  - 0.7954425013248543
  - 0.7818181818181819
  - 0.7737967914438503
  - 0.7938526762056174
  - 0.8367779544250132
  - 0.7433155080213903
  - 0.827807486631016
  TT_precision_weighted:
  - 0.923911883155918
  - 0.9191297687291519
  - 0.9286950130409607
  - 0.9216746063716722
  - 0.9367446711903725
  - 0.9427304752541644
  - 0.9471372991020226
  - 0.9499713440203074
  - 0.9273199586793317
  - 0.9476028463260514
  - 0.9364011997869537
  - 0.9417328535353603
  - 0.944622341996101
  - 0.961040594723031
  - 0.944663459336345
  - 0.9381545121996587
  TT_recall_macro:
  - 0.7172757149790125
  - 0.6948125404007757
  - 0.7338442629611571
  - 0.7472091690544413
  - 0.7340001741477644
  - 0.6703090507726269
  - 0.6928497052353029
  - 0.7247218720885625
  - 0.7617649261065301
  - 0.7592020809404769
  - 0.766845979614949
  - 0.7861581920903955
  - 0.7782063703524282
  - 0.7144811835147424
  - 0.6223311314724057
  - 0.6681084748637703
  TT_recall_micro:
  - 0.5707472178060413
  - 0.6777954425013248
  - 0.711764705882353
  - 0.8331550802139037
  - 0.6613672496025437
  - 0.7350291467938527
  - 0.760427807486631
  - 0.7957219251336899
  - 0.7774244833068362
  - 0.7954425013248543
  - 0.7818181818181819
  - 0.7737967914438503
  - 0.7938526762056174
  - 0.8367779544250132
  - 0.7433155080213903
  - 0.827807486631016
  TT_recall_weighted:
  - 0.5707472178060413
  - 0.6777954425013248
  - 0.711764705882353
  - 0.8331550802139037
  - 0.6613672496025437
  - 0.7350291467938527
  - 0.760427807486631
  - 0.7957219251336899
  - 0.7774244833068362
  - 0.7954425013248543
  - 0.7818181818181819
  - 0.7737967914438503
  - 0.7938526762056174
  - 0.8367779544250132
  - 0.7433155080213903
  - 0.827807486631016
  TT_roc_auc:
  - 0.8229346706286025
  - 0.7744282101981064
  - 0.8007120510320169
  - 0.8127724928366762
  - 0.7932757194479516
  - 0.7448712288447388
  - 0.7494617510510534
  - 0.7841758723547511
  - 0.8183198712129012
  - 0.8351530302006622
  - 0.7977665737433574
  - 0.8715451977401131
  - 0.7996275887126075
  - 0.7270838048599824
  - 0.6711527807372683
  - 0.7045989440875263
  fit_time:
  - 411.40945839881897
  - 375.5215094089508
  - 374.557026386261
  - 371.93353748321533
  - 369.4448745250702
  - 385.1502571105957
  - 409.4685568809509
  - 405.70950984954834
  - 434.87371945381165
  - 413.7696957588196
  - 406.624475479126
  - 402.3174350261688
  - 413.5868237018585
  - 415.641086101532
  - 403.9153718948364
  - 403.6043977737427
  score_time:
  - 6.553097248077393
  - 7.709627389907837
  - 8.291964054107666
  - 8.633858680725098
  - 8.059653043746948
  - 6.499713659286499
  - 9.752845048904419
  - 10.741920948028564
  - 6.308114528656006
  - 8.776023864746094
  - 10.716577529907227
  - 10.560342788696289
  - 8.383992671966553
  - 7.456111669540405
  - 10.134333848953247
  - 10.834722518920898
start: 2023-10-05 00:37:54.930632
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
