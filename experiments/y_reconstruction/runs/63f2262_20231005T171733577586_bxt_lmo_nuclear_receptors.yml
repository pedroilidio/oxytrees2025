active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: y_reconstruction/runs
end: 2023-10-05 17:17:38.491293
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: bxt_lmo
  params: {}
hash: 63f2262992f4000ef0456ca76496920145e2a5c9c67ed5c9f98dd805ee59871d
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/63f2262_20231005T171733577586_bxt_lmo_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9918546282462918
  - 1.0
  - 1.0
  - 0.9933596666690929
  - 0.987769572920127
  - 1.0
  - 1.0
  - 0.9885442608868639
  - 0.9901701635401936
  - 1.0
  - 1.0
  - 0.9900523910365975
  - 0.996233541731977
  - 1.0
  - 1.0
  - 0.995982706116369
  LL_balanced_accuracy:
  - 0.6572237960339944
  - 0.7150837988826816
  - 0.6289655172413793
  - 0.7430939226519337
  - 0.7878998609179415
  - 0.5749656121045392
  - 0.790650406504065
  - 0.6183673469387755
  - 0.7192982456140351
  - 0.6865079365079365
  - 0.5331168831168831
  - 0.7605263157894737
  - 0.9044715447154472
  - 0.5673333333333334
  - 0.7634691195795007
  - 0.8953947368421052
  LL_f1_macro:
  - 0.3304403541472507
  - 0.38949092741935487
  - 0.2886351909184727
  - 0.44124543028582885
  - 0.47134474115733993
  - 0.17862838915470494
  - 0.4724685895370778
  - 0.25921575208368297
  - 0.4153649401662556
  - 0.3499681155246539
  - 0.12316942767612682
  - 0.4665274957819783
  - 0.6811532753868985
  - 0.1854395755249067
  - 0.468525626714869
  - 0.656640831772969
  LL_f1_micro:
  - 0.3631578947368421
  - 0.4631578947368421
  - 0.30937098844672656
  - 0.5224646983311938
  - 0.5986842105263158
  - 0.1868421052631579
  - 0.6033376123234917
  - 0.2798459563543004
  - 0.48
  - 0.4075
  - 0.12317073170731707
  - 0.5560975609756098
  - 0.82375
  - 0.18875
  - 0.5609756097560976
  - 0.8060975609756098
  LL_f1_weighted:
  - 0.45741557119733167
  - 0.5770068442275043
  - 0.3932496280722951
  - 0.6241938825496307
  - 0.7028089777047009
  - 0.25363258625031476
  - 0.707560622738445
  - 0.36887322247596493
  - 0.5810834018452544
  - 0.5220803077366137
  - 0.12410833013310658
  - 0.6531317982687105
  - 0.8613315666737332
  - 0.23087677420265795
  - 0.6582913813784432
  - 0.8500229213142787
  LL_matthews_corrcoef:
  - 0.17765599968038662
  - 0.20463313980478037
  - 0.15338674326763585
  - 0.2502473319475518
  - 0.26120988280788
  - 0.0871791276942441
  - 0.26095064302514775
  - 0.1312138279513256
  - 0.23340587185351
  - 0.17800209541030765
  - 0.06562382761787193
  - 0.2715397999544174
  - 0.4970577051904926
  - 0.09814687348275378
  - 0.2723948248362443
  - 0.4654617603245633
  LL_precision_macro:
  - 0.550185873605948
  - 0.5486725663716814
  - 0.5456081081081081
  - 0.5644028103044496
  - 0.5592485549132948
  - 0.5253456221198156
  - 0.5585714285714286
  - 0.5363636363636364
  - 0.5621052631578948
  - 0.5424710424710425
  - 0.5325097529258778
  - 0.5707547169811321
  - 0.6527093596059114
  - 0.5357653791130186
  - 0.5704057279236276
  - 0.636986301369863
  LL_precision_micro:
  - 0.3631578947368421
  - 0.4631578947368421
  - 0.30937098844672656
  - 0.5224646983311938
  - 0.5986842105263158
  - 0.1868421052631579
  - 0.6033376123234917
  - 0.2798459563543004
  - 0.48
  - 0.4075
  - 0.12317073170731707
  - 0.5560975609756098
  - 0.82375
  - 0.18875
  - 0.5609756097560976
  - 0.8060975609756098
  LL_precision_weighted:
  - 0.9360790451966348
  - 0.9477410340009315
  - 0.9370034347569649
  - 0.9384907691058915
  - 0.9524452388195924
  - 0.9587800145525104
  - 0.9535338345864662
  - 0.947625160462131
  - 0.9354105263157895
  - 0.9496718146718146
  - 0.9429889942592534
  - 0.9371836171191901
  - 0.9461699507389163
  - 0.9419706723891274
  - 0.9381803364573026
  - 0.9468760441029068
  LL_recall_macro:
  - 0.6572237960339944
  - 0.7150837988826816
  - 0.6289655172413793
  - 0.7430939226519337
  - 0.7878998609179415
  - 0.5749656121045392
  - 0.790650406504065
  - 0.6183673469387755
  - 0.7192982456140351
  - 0.6865079365079365
  - 0.5331168831168831
  - 0.7605263157894737
  - 0.9044715447154472
  - 0.5673333333333334
  - 0.7634691195795007
  - 0.8953947368421052
  LL_recall_micro:
  - 0.3631578947368421
  - 0.4631578947368421
  - 0.30937098844672656
  - 0.5224646983311938
  - 0.5986842105263158
  - 0.1868421052631579
  - 0.6033376123234917
  - 0.2798459563543004
  - 0.48
  - 0.4075
  - 0.12317073170731707
  - 0.5560975609756098
  - 0.82375
  - 0.18875
  - 0.5609756097560976
  - 0.8060975609756098
  LL_recall_weighted:
  - 0.3631578947368421
  - 0.4631578947368421
  - 0.30937098844672656
  - 0.5224646983311938
  - 0.5986842105263157
  - 0.1868421052631579
  - 0.6033376123234917
  - 0.2798459563543004
  - 0.48
  - 0.4075
  - 0.12317073170731707
  - 0.5560975609756097
  - 0.82375
  - 0.18875
  - 0.5609756097560976
  - 0.8060975609756098
  LL_roc_auc:
  - 0.9993573601930542
  - 1.0
  - 1.0
  - 0.9995102963335007
  - 0.9993554733878354
  - 1.0
  - 0.9999999999999999
  - 0.9993506493506494
  - 0.9992680527916924
  - 1.0
  - 1.0
  - 0.9992543859649122
  - 0.9997268117842469
  - 1.0
  - 1.0
  - 0.9997258771929824
  LT_average_precision:
  - 0.30865657359248216
  - 0.43429622902359677
  - 0.227548823449385
  - 0.3853758307485015
  - 0.2474321342991716
  - 0.3256552165344133
  - 0.15052685819451148
  - 0.2717583287734481
  - 0.4118730681009409
  - 0.4827105805811136
  - 0.22735666637018567
  - 0.30159166762669165
  - 0.38643626260089925
  - 0.48134172591859903
  - 0.2974857372166695
  - 0.4236128862748878
  LT_balanced_accuracy:
  - 0.5807436918990704
  - 0.5775103734439834
  - 0.5646551724137931
  - 0.6560392397302268
  - 0.6729002624671916
  - 0.3784552845528455
  - 0.6285460992907801
  - 0.6050420168067226
  - 0.5926616915422885
  - 0.6304347826086957
  - 0.5083682008368201
  - 0.7469879518072289
  - 0.6911949685534591
  - 0.5039525691699605
  - 0.6384297520661157
  - 0.7841926894214476
  LT_f1_macro:
  - 0.2897143283359439
  - 0.26139518988423255
  - 0.17915898920768625
  - 0.38928181243171756
  - 0.36492673992673996
  - 0.10526315789473684
  - 0.314962309771014
  - 0.21730043149946066
  - 0.2613720055169459
  - 0.31892974674488483
  - 0.09227317971802527
  - 0.4049694856146469
  - 0.4824596505268774
  - 0.09636772741883638
  - 0.30213653583643924
  - 0.5744252222306162
  LT_f1_micro:
  - 0.32706766917293234
  - 0.2669172932330827
  - 0.18218623481781376
  - 0.4777327935222672
  - 0.45112781954887216
  - 0.10526315789473684
  - 0.3684210526315789
  - 0.2388663967611336
  - 0.29642857142857143
  - 0.33214285714285713
  - 0.09615384615384616
  - 0.5153846153846153
  - 0.6535714285714286
  - 0.10357142857142858
  - 0.3269230769230769
  - 0.75
  LT_f1_weighted:
  - 0.43422889288560407
  - 0.31325494307343393
  - 0.2229531423675312
  - 0.5953537790150193
  - 0.5777906304222096
  - 0.10526315789473682
  - 0.48773476858124537
  - 0.3377542374731951
  - 0.40849464278540726
  - 0.39549802751262186
  - 0.04250933954102827
  - 0.6396016363758299
  - 0.7481611692295965
  - 0.031246268999403044
  - 0.41544643794678304
  - 0.8120294125053512
  LT_matthews_corrcoef:
  - 0.08245889152481171
  - 0.11763037597086688
  - 0.09454365710443549
  - 0.14547438229001236
  - 0.14573856460172152
  - -0.24308943089430896
  - 0.11773806634314476
  - 0.09796809546241592
  - 0.08549518116329516
  - 0.1814206433048552
  - 0.03705277249803036
  - 0.1991539576065661
  - 0.1781976686516961
  - 0.027708576911360028
  - 0.16068943228986204
  - 0.3089262320861282
  LT_precision_macro:
  - 0.5210526315789474
  - 0.5446292048929664
  - 0.5345622119815668
  - 0.53390620836664
  - 0.5307109557109557
  - 0.3784552845528455
  - 0.526959690614309
  - 0.5228426395939086
  - 0.5197207332406856
  - 0.5630841121495327
  - 0.541015625
  - 0.5401459854014599
  - 0.5415209790209791
  - 0.5485611510791367
  - 0.5466321243523315
  - 0.5839530892448512
  LT_precision_micro:
  - 0.32706766917293234
  - 0.2669172932330827
  - 0.18218623481781376
  - 0.4777327935222672
  - 0.45112781954887216
  - 0.10526315789473684
  - 0.3684210526315789
  - 0.2388663967611336
  - 0.29642857142857143
  - 0.33214285714285713
  - 0.09615384615384616
  - 0.5153846153846153
  - 0.6535714285714286
  - 0.10357142857142858
  - 0.3269230769230769
  - 0.75
  LT_precision_weighted:
  - 0.9226355362089433
  - 0.8974866926490538
  - 0.9434690945726599
  - 0.9307442035575318
  - 0.9493874546506126
  - 0.6516474112109542
  - 0.9428904702631187
  - 0.9652273988368031
  - 0.9463087438668142
  - 0.9157376502002671
  - 0.9258563701923077
  - 0.9610892756878158
  - 0.93058503996004
  - 0.912936793422405
  - 0.9372259864487843
  - 0.9314216247139588
  LT_recall_macro:
  - 0.5807436918990704
  - 0.5775103734439834
  - 0.5646551724137931
  - 0.6560392397302268
  - 0.6729002624671916
  - 0.3784552845528455
  - 0.6285460992907801
  - 0.6050420168067226
  - 0.5926616915422885
  - 0.6304347826086957
  - 0.5083682008368201
  - 0.7469879518072289
  - 0.6911949685534591
  - 0.5039525691699605
  - 0.6384297520661157
  - 0.7841926894214476
  LT_recall_micro:
  - 0.32706766917293234
  - 0.2669172932330827
  - 0.18218623481781376
  - 0.4777327935222672
  - 0.45112781954887216
  - 0.10526315789473684
  - 0.3684210526315789
  - 0.2388663967611336
  - 0.29642857142857143
  - 0.33214285714285713
  - 0.09615384615384616
  - 0.5153846153846153
  - 0.6535714285714286
  - 0.10357142857142858
  - 0.3269230769230769
  - 0.75
  LT_recall_weighted:
  - 0.32706766917293234
  - 0.2669172932330827
  - 0.18218623481781376
  - 0.4777327935222672
  - 0.45112781954887216
  - 0.10526315789473684
  - 0.3684210526315789
  - 0.2388663967611336
  - 0.29642857142857143
  - 0.33214285714285713
  - 0.09615384615384616
  - 0.5153846153846153
  - 0.6535714285714286
  - 0.10357142857142858
  - 0.3269230769230769
  - 0.75
  LT_roc_auc:
  - 0.7354581673306773
  - 0.8295435684647303
  - 0.7533045977011494
  - 0.82158185162477
  - 0.7509842519685039
  - 0.5888211382113822
  - 0.725886524822695
  - 0.8543417366946778
  - 0.8355099502487562
  - 0.8784950958864002
  - 0.7957760510061765
  - 0.8667396860167944
  - 0.7655345911949686
  - 0.8596105987410335
  - 0.8580119375573921
  - 0.8254659888646818
  TL_average_precision:
  - 0.4058291747718708
  - 0.4234261665597327
  - 0.5961509623942481
  - 0.46500473285939337
  - 0.3712753362016086
  - 0.1802388725815057
  - 0.3762793345062676
  - 0.3131620331909487
  - 0.045182811885938416
  - 0.11261090031140321
  - 0.08624760310366902
  - 0.12334654408364518
  - 0.3443031350930105
  - 0.35810531785556265
  - 0.38217819372410233
  - 0.35289944215242197
  TL_balanced_accuracy:
  - 0.583969465648855
  - 0.6731489484298473
  - 0.652014652014652
  - 0.6101817430813713
  - 0.6802694649566006
  - 0.5546875
  - 0.6819088319088319
  - 0.6339214113873296
  - 0.4376482548288716
  - 0.3453066757031515
  - 0.5021929824561403
  - 0.4346318917134368
  - 0.7217391304347827
  - 0.5493562231759657
  - 0.5872011251758087
  - 0.6317266424562562
  TL_f1_macro:
  - 0.21465699140548605
  - 0.36362703265443774
  - 0.2973662509019689
  - 0.40674462556106783
  - 0.5150828137792053
  - 0.27522470375525177
  - 0.5155534121051362
  - 0.3495974658503299
  - 0.24507718322151315
  - 0.21274601686972824
  - 0.0728078768658575
  - 0.3217986500617929
  - 0.46947368421052627
  - 0.12109375
  - 0.3263074395149867
  - 0.46584471011056483
  TL_f1_micro:
  - 0.22142857142857142
  - 0.44642857142857145
  - 0.33797909407665505
  - 0.5121951219512195
  - 0.6071428571428571
  - 0.2892857142857143
  - 0.6341463414634146
  - 0.3693379790940767
  - 0.2791666666666667
  - 0.24166666666666667
  - 0.07723577235772358
  - 0.4105691056910569
  - 0.65
  - 0.125
  - 0.4105691056910569
  - 0.6463414634146342
  TL_f1_weighted:
  - 0.278205665468287
  - 0.5718606054131502
  - 0.44981156078955903
  - 0.6254890436927049
  - 0.67958354700278
  - 0.35886968947492626
  - 0.7101460356296352
  - 0.44000901650669005
  - 0.38811932944235356
  - 0.34728990940331156
  - 0.018110344319276623
  - 0.5412312370105352
  - 0.7531578947368421
  - 0.17626953125
  - 0.5471311163902052
  - 0.743532022886056
  TL_matthews_corrcoef:
  - 0.11317641777179485
  - 0.14831008750544802
  - 0.14444637814384204
  - 0.10690887735062106
  - 0.22724017234312197
  - 0.07332355751067665
  - 0.21585791652353342
  - 0.18073557792012285
  - -0.06382883136080617
  - -0.16263757102222912
  - 0.01795088178392981
  - -0.05936961290947219
  - 0.18304984669977628
  - 0.05642935816545787
  - 0.0671222129210352
  - 0.1223685181242847
  TL_precision_macro:
  - 0.538135593220339
  - 0.5317586134009723
  - 0.5343137254901961
  - 0.5259333074081276
  - 0.5716123719829139
  - 0.5245775729646697
  - 0.5640357035402668
  - 0.5609785783836417
  - 0.4836647727272727
  - 0.45725255173705404
  - 0.536734693877551
  - 0.48651960784313725
  - 0.5377777777777778
  - 0.5161290322580645
  - 0.5129166666666667
  - 0.5284188034188034
  TL_precision_micro:
  - 0.22142857142857142
  - 0.44642857142857145
  - 0.33797909407665505
  - 0.5121951219512195
  - 0.6071428571428571
  - 0.2892857142857143
  - 0.6341463414634146
  - 0.3693379790940767
  - 0.2791666666666667
  - 0.24166666666666667
  - 0.07723577235772358
  - 0.4105691056910569
  - 0.65
  - 0.125
  - 0.4105691056910569
  - 0.6463414634146342
  TL_precision_weighted:
  - 0.9406174334140435
  - 0.948563049189238
  - 0.9545671927307507
  - 0.9090760351507852
  - 0.8695218244778227
  - 0.8790432301953038
  - 0.884345088561707
  - 0.9011777817736447
  - 0.8744022253787879
  - 0.8354113993195368
  - 0.9322050771528123
  - 0.8843555714968914
  - 0.9492592592592592
  - 0.9717741935483871
  - 0.94505081300813
  - 0.9214943367382392
  TL_recall_macro:
  - 0.583969465648855
  - 0.6731489484298473
  - 0.652014652014652
  - 0.6101817430813713
  - 0.6802694649566006
  - 0.5546875
  - 0.6819088319088319
  - 0.6339214113873296
  - 0.4376482548288716
  - 0.3453066757031515
  - 0.5021929824561403
  - 0.4346318917134368
  - 0.7217391304347827
  - 0.5493562231759657
  - 0.5872011251758087
  - 0.6317266424562562
  TL_recall_micro:
  - 0.22142857142857142
  - 0.44642857142857145
  - 0.33797909407665505
  - 0.5121951219512195
  - 0.6071428571428571
  - 0.2892857142857143
  - 0.6341463414634146
  - 0.3693379790940767
  - 0.2791666666666667
  - 0.24166666666666667
  - 0.07723577235772358
  - 0.4105691056910569
  - 0.65
  - 0.125
  - 0.4105691056910569
  - 0.6463414634146342
  TL_recall_weighted:
  - 0.22142857142857142
  - 0.44642857142857145
  - 0.33797909407665505
  - 0.5121951219512195
  - 0.6071428571428571
  - 0.2892857142857143
  - 0.6341463414634146
  - 0.3693379790940767
  - 0.2791666666666667
  - 0.24166666666666667
  - 0.07723577235772358
  - 0.4105691056910569
  - 0.65
  - 0.125
  - 0.4105691056910569
  - 0.6463414634146342
  TL_roc_auc:
  - 0.8569762510602206
  - 0.8038029386343993
  - 0.8568812140240711
  - 0.7411193721602644
  - 0.8096903744008291
  - 0.6673177083333334
  - 0.7662393162393163
  - 0.7428495054798182
  - 0.3944425618434429
  - 0.28193832599118945
  - 0.4846491228070175
  - 0.45229448662925054
  - 0.7658695652173914
  - 0.6048436541998774
  - 0.7100328176277543
  - 0.6657312644437109
  TT_average_precision:
  - 0.04922027290448343
  - 0.36312895477766166
  - 0.10478086322184466
  - 0.3032679738562092
  - 0.265076164874552
  - 0.3099896881069843
  - 0.3083878090986893
  - 0.1682578369414701
  - 0.13041645854145856
  - 0.06363665011740652
  - 0.017857142857142856
  - 0.1790956503117206
  - 0.03708841463414634
  - 0.2569052898321191
  - 0.058352051512428865
  - -0.0
  TT_balanced_accuracy:
  - 0.5421052631578948
  - 0.5444444444444444
  - 0.5416666666666666
  - 0.75
  - 0.6902173913043479
  - 0.4493212669683258
  - 0.591358024691358
  - 0.6626506024096386
  - 0.5576923076923077
  - 0.5448717948717948
  - 0.5
  - 0.6458333333333334
  - 0.4074074074074074
  - 0.5
  - 0.6081081081081081
  - 0.6025641025641025
  TT_f1_macro:
  - 0.10992796742875038
  - 0.163265306122449
  - 0.15384615384615385
  - 0.3933333333333333
  - 0.3625470729202328
  - 0.21420389461626577
  - 0.38957688338493285
  - 0.35656565656565653
  - 0.17752234993614302
  - 0.1546420978029766
  - 0.012658227848101266
  - 0.3210445468509985
  - 0.34141126158232354
  - 0.06666666666666667
  - 0.2383838383838384
  - 0.37599999999999995
  TT_f1_micro:
  - 0.11224489795918367
  - 0.16326530612244897
  - 0.15384615384615385
  - 0.5164835164835165
  - 0.41836734693877553
  - 0.21428571428571427
  - 0.42857142857142855
  - 0.38461538461538464
  - 0.17857142857142858
  - 0.15476190476190477
  - 0.01282051282051282
  - 0.34615384615384615
  - 0.47619047619047616
  - 0.07142857142857142
  - 0.2564102564102564
  - 0.6025641025641025
  TT_f1_weighted:
  - 0.15255948918872275
  - 0.16326530612244902
  - 0.15384615384615385
  - 0.6486446886446886
  - 0.5280830579407387
  - 0.22009491081656032
  - 0.5099513489606368
  - 0.4672882672882673
  - 0.2027002371829958
  - 0.1632681988458034
  - 0.0003245699448231094
  - 0.43152546378352835
  - 0.618063333672742
  - 0.009523809523809525
  - 0.3435379435379436
  - 0.7519999999999999
  TT_matthews_corrcoef:
  - 0.05298129428260175
  - 0.08888888888888889
  - 0.08333333333333333
  - 0.1786474002526241
  - 0.19034674690672024
  - -0.09825015015781494
  - 0.11886342475872037
  - 0.20164982172669937
  - 0.09607689228305227
  - 0.08362420100070908
  - 0.0
  - 0.17521916101261562
  - -0.06875166509955269
  - 0.0
  - 0.11810771907149852
  - 0.0
  TT_precision_macro:
  - 0.5166666666666667
  - 0.5444444444444444
  - 0.5416666666666666
  - 0.5319148936170213
  - 0.5476190476190477
  - 0.4523809523809524
  - 0.5386624869383491
  - 0.5625
  - 0.54
  - 0.538961038961039
  - 0.00641025641025641
  - 0.5526315789473684
  - 0.48723766307430516
  - 0.03571428571428571
  - 0.532258064516129
  - 0.5
  TT_precision_micro:
  - 0.11224489795918367
  - 0.16326530612244897
  - 0.15384615384615385
  - 0.5164835164835165
  - 0.41836734693877553
  - 0.21428571428571427
  - 0.42857142857142855
  - 0.38461538461538464
  - 0.17857142857142858
  - 0.15476190476190477
  - 0.01282051282051282
  - 0.34615384615384615
  - 0.47619047619047616
  - 0.07142857142857142
  - 0.2564102564102564
  - 0.6025641025641025
  TT_precision_weighted:
  - 0.9704081632653061
  - 0.9256235827664399
  - 0.9294871794871794
  - 0.9691372457329904
  - 0.9446064139941691
  - 0.6972789115646258
  - 0.8513210927004031
  - 0.9230769230769231
  - 0.9342857142857144
  - 0.9341372912801484
  - 0.00016436554898093358
  - 0.9311740890688259
  - 0.918077951543635
  - 0.00510204081632653
  - 0.9520264681555005
  - 1.0
  TT_recall_macro:
  - 0.5421052631578948
  - 0.5444444444444444
  - 0.5416666666666666
  - 0.75
  - 0.6902173913043479
  - 0.4493212669683258
  - 0.591358024691358
  - 0.6626506024096386
  - 0.5576923076923077
  - 0.5448717948717948
  - 0.5
  - 0.6458333333333334
  - 0.4074074074074074
  - 0.5
  - 0.6081081081081081
  - 0.30128205128205127
  TT_recall_micro:
  - 0.11224489795918367
  - 0.16326530612244897
  - 0.15384615384615385
  - 0.5164835164835165
  - 0.41836734693877553
  - 0.21428571428571427
  - 0.42857142857142855
  - 0.38461538461538464
  - 0.17857142857142858
  - 0.15476190476190477
  - 0.01282051282051282
  - 0.34615384615384615
  - 0.47619047619047616
  - 0.07142857142857142
  - 0.2564102564102564
  - 0.6025641025641025
  TT_recall_weighted:
  - 0.11224489795918367
  - 0.16326530612244897
  - 0.15384615384615385
  - 0.5164835164835165
  - 0.41836734693877553
  - 0.21428571428571427
  - 0.42857142857142855
  - 0.38461538461538464
  - 0.17857142857142858
  - 0.15476190476190477
  - 0.01282051282051282
  - 0.34615384615384615
  - 0.47619047619047616
  - 0.07142857142857142
  - 0.2564102564102564
  - 0.6025641025641025
  TT_roc_auc:
  - 0.5578947368421052
  - 0.7930555555555556
  - 0.5731292517006803
  - 0.9280303030303031
  - 0.8568840579710146
  - 0.6180995475113124
  - 0.7685185185185186
  - 0.677710843373494
  - 0.6538461538461539
  - 0.37393162393162394
  - 0.2857142857142857
  - 0.6412037037037037
  - 0.3868312757201646
  - 0.6228632478632479
  - 0.48817567567567566
  - .nan
  fit_time:
  - 0.1814289093017578
  - 0.20337414741516113
  - 0.2062528133392334
  - 0.18874025344848633
  - 0.19325709342956543
  - 0.1481642723083496
  - 0.15165472030639648
  - 0.1526196002960205
  - 0.13375616073608398
  - 0.1562654972076416
  - 0.15803170204162598
  - 0.15529942512512207
  - 0.15101861953735352
  - 0.1567075252532959
  - 0.1415557861328125
  - 0.15637445449829102
  score_time:
  - 1.7765698432922363
  - 1.716550588607788
  - 1.7369422912597656
  - 1.7431392669677734
  - 1.7155265808105469
  - 1.6812670230865479
  - 1.7069098949432373
  - 1.7200815677642822
  - 1.767204999923706
  - 1.7206759452819824
  - 1.6975245475769043
  - 1.6692352294921875
  - 1.7547245025634766
  - 1.7443146705627441
  - 1.76676344871521
  - 1.8166892528533936
start: 2023-10-05 17:17:33.577586
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
