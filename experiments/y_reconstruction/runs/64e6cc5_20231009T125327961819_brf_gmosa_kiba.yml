active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-09 15:36:51.287664
estimator:
  call: bipartite_adaptations.estimators.brf_gmosa
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiterandomforestregressor
          - call: bipartite_learn.ensemble._forest.BipartiteRandomForestRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: true
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: 0.5
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: 0.5
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: brf_gmosa
  params: {}
hash: 64e6cc55f298b1cb90e2a53d71d6eba5aa51d2ed54bb3dada060b5e107174697
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/64e6cc5_20231009T125327961819_brf_gmosa_kiba.yml"
results:
  LL_average_precision:
  - 0.9900320760444774
  - 0.9812492039590458
  - 0.9852265371717508
  - 0.9504484204600867
  - 0.9723344515604572
  - 0.9893171847877014
  - 0.9699298344988799
  - 0.9897042326632115
  - 0.9891855342004067
  - 0.9865629224208537
  - 0.9685734727435965
  - 0.9828318085010497
  - 0.9839692428048651
  - 0.9742977749390747
  - 0.9830306277892383
  - 0.9633346306123777
  LL_balanced_accuracy:
  - 0.9606138083895117
  - 0.9564245074400505
  - 0.9561594702717616
  - 0.9237753397650623
  - 0.9446489719676662
  - 0.9614240917769963
  - 0.9386568635580493
  - 0.9607922542003743
  - 0.9655282557540996
  - 0.9615618518568945
  - 0.936316149750309
  - 0.9532569058255083
  - 0.9550652640587431
  - 0.9522351261538529
  - 0.957176177170173
  - 0.9364037163271546
  LL_f1_macro:
  - 0.9101988642634191
  - 0.899383409756379
  - 0.9029839090275547
  - 0.8391942121188685
  - 0.8794103773062152
  - 0.9105252397799386
  - 0.8701524362081923
  - 0.9107035471933114
  - 0.9202731510989317
  - 0.909906117378378
  - 0.8647640427902566
  - 0.8942914611827175
  - 0.9007684718547848
  - 0.8928069222336457
  - 0.906531282908982
  - 0.8644462108469361
  LL_f1_micro:
  - 0.9367179794084073
  - 0.9295090276043426
  - 0.9299681205835255
  - 0.877311992243165
  - 0.9112906502938753
  - 0.9377543375104673
  - 0.9021874862272107
  - 0.9370418252067755
  - 0.9445829777644785
  - 0.9377873922049685
  - 0.898176849961069
  - 0.9246756967195052
  - 0.9282259731821135
  - 0.9231596488137186
  - 0.9319356354240075
  - 0.8982044280009396
  LL_f1_weighted:
  - 0.9398061463306828
  - 0.9333899618148737
  - 0.9335513328314241
  - 0.8869174209453831
  - 0.9167904795441139
  - 0.9408263624511575
  - 0.9084959560002549
  - 0.9400947228828114
  - 0.9470226777110236
  - 0.9409054371539515
  - 0.9050214661516702
  - 0.9289445803408375
  - 0.9319716757901757
  - 0.9275422310543545
  - 0.93525234160854
  - 0.9050900495578073
  LL_matthews_corrcoef:
  - 0.8348333410024098
  - 0.816653107690212
  - 0.8227001780465661
  - 0.7214308320945583
  - 0.7840184657552127
  - 0.8353724387199348
  - 0.769286265581089
  - 0.8356864756975996
  - 0.8520530645150614
  - 0.8343194463338831
  - 0.7607782809729542
  - 0.8082315642445623
  - 0.8189924949322973
  - 0.8057883942460525
  - 0.8286664637911809
  - 0.7602663037514162
  LL_precision_macro:
  - 0.8782706328790097
  - 0.865297156171921
  - 0.8709424154641687
  - 0.8070391293799605
  - 0.8456012458125374
  - 0.8780942108405108
  - 0.8372803480216047
  - 0.878897366056955
  - 0.8898766700924974
  - 0.8770290675726689
  - 0.8316308559351884
  - 0.8603024317144609
  - 0.8684903901327239
  - 0.8589365900343278
  - 0.8755051895215973
  - 0.8311182003011024
  LL_precision_micro:
  - 0.9367179794084073
  - 0.9295090276043426
  - 0.9299681205835255
  - 0.877311992243165
  - 0.9112906502938753
  - 0.9377543375104673
  - 0.9021874862272107
  - 0.9370418252067755
  - 0.9445829777644785
  - 0.9377873922049685
  - 0.898176849961069
  - 0.9246756967195052
  - 0.9282259731821135
  - 0.9231596488137186
  - 0.9319356354240075
  - 0.8982044280009396
  LL_precision_weighted:
  - 0.9521245400419114
  - 0.948499696496146
  - 0.9480444109795152
  - 0.9246599618259591
  - 0.9386806754043876
  - 0.9529281459175798
  - 0.9340195226276912
  - 0.9522882228726556
  - 0.9567883918087461
  - 0.9530880769835501
  - 0.9324646031971444
  - 0.9457209407216803
  - 0.947098580180114
  - 0.9448355265575674
  - 0.9488829557604497
  - 0.93258371778329
  LL_recall_macro:
  - 0.9606138083895117
  - 0.9564245074400505
  - 0.9561594702717616
  - 0.9237753397650623
  - 0.9446489719676662
  - 0.9614240917769963
  - 0.9386568635580493
  - 0.9607922542003743
  - 0.9655282557540996
  - 0.9615618518568945
  - 0.936316149750309
  - 0.9532569058255083
  - 0.9550652640587431
  - 0.9522351261538529
  - 0.957176177170173
  - 0.9364037163271546
  LL_recall_micro:
  - 0.9367179794084073
  - 0.9295090276043426
  - 0.9299681205835255
  - 0.877311992243165
  - 0.9112906502938753
  - 0.9377543375104673
  - 0.9021874862272107
  - 0.9370418252067755
  - 0.9445829777644785
  - 0.9377873922049685
  - 0.898176849961069
  - 0.9246756967195052
  - 0.9282259731821135
  - 0.9231596488137186
  - 0.9319356354240075
  - 0.8982044280009396
  LL_recall_weighted:
  - 0.9367179794084073
  - 0.9295090276043426
  - 0.9299681205835255
  - 0.877311992243165
  - 0.9112906502938753
  - 0.9377543375104673
  - 0.9021874862272107
  - 0.9370418252067755
  - 0.9445829777644785
  - 0.9377873922049685
  - 0.898176849961069
  - 0.9246756967195052
  - 0.9282259731821135
  - 0.9231596488137186
  - 0.9319356354240075
  - 0.8982044280009396
  LL_roc_auc:
  - 0.9983212890458061
  - 0.9971373896445003
  - 0.9974778823767215
  - 0.9922301614826755
  - 0.9953816558180699
  - 0.9982348210110885
  - 0.9949310865104251
  - 0.9982540209361566
  - 0.9981945483536198
  - 0.9978746689709903
  - 0.9947660183967527
  - 0.9970957881643103
  - 0.9972446819442164
  - 0.9958695091068644
  - 0.997074645754832
  - 0.9940706274497356
  LT_average_precision:
  - 0.45519151253998974
  - 0.4190727039566723
  - 0.43571881101116877
  - 0.37110785270804936
  - 0.4538004488031312
  - 0.42430486008046214
  - 0.42271105342516585
  - 0.38423391209553653
  - 0.4504872167098312
  - 0.40660586415892724
  - 0.41422164716887
  - 0.37983694005267077
  - 0.4819704820996142
  - 0.4262613816121809
  - 0.4231613174604303
  - 0.3786429991814153
  LT_balanced_accuracy:
  - 0.7352589389427839
  - 0.7105458716381728
  - 0.7229558975881991
  - 0.7128073335443549
  - 0.7359993942746703
  - 0.7105478587205785
  - 0.721375880304935
  - 0.7055292034955287
  - 0.7347877403683492
  - 0.7033801438854153
  - 0.7204202203641299
  - 0.7097269680588806
  - 0.7394017568745321
  - 0.7064230200059805
  - 0.7141968582416409
  - 0.7086384236970906
  LT_f1_macro:
  - 0.6639975906181019
  - 0.6509518787656503
  - 0.643916666804772
  - 0.6338489470831963
  - 0.6500152237440054
  - 0.6558826894473895
  - 0.6336438656739793
  - 0.6528019947471145
  - 0.6669769164148267
  - 0.6497913108538135
  - 0.6301755908513793
  - 0.6522704004360913
  - 0.6621396089427529
  - 0.6471509370523143
  - 0.64136774146653
  - 0.6413427978980549
  LT_f1_micro:
  - 0.7286034809506174
  - 0.7091908545843447
  - 0.7168822245126399
  - 0.690073256419634
  - 0.7053390550460714
  - 0.7162394299076815
  - 0.6987953142489831
  - 0.7244738504505104
  - 0.7345502864486897
  - 0.7131362835389168
  - 0.6966231117908479
  - 0.7219248373618823
  - 0.7201541274817137
  - 0.702319245082403
  - 0.7132398546872231
  - 0.7013335105440368
  LT_f1_weighted:
  - 0.754047867366722
  - 0.7333858568291244
  - 0.7469616482042808
  - 0.7203193842517621
  - 0.734707485984364
  - 0.7388206995000921
  - 0.731587633586411
  - 0.7473184240302809
  - 0.7590190419404237
  - 0.7362920692542686
  - 0.7305009756316626
  - 0.7459703134212734
  - 0.7466393476605195
  - 0.7266683397752717
  - 0.7423432683561186
  - 0.7285426438212644
  LT_matthews_corrcoef:
  - 0.38630233975175654
  - 0.35380920547067185
  - 0.3557154714850102
  - 0.34534601335430415
  - 0.3811946930342133
  - 0.3568527954402165
  - 0.35017568024693285
  - 0.34610166043385115
  - 0.3871226896845419
  - 0.3438873251287401
  - 0.346290769735184
  - 0.3502912686001046
  - 0.39182490168685874
  - 0.34782424487346225
  - 0.3455415433626238
  - 0.3442449002021549
  LT_precision_macro:
  - 0.6585800505267675
  - 0.6486385756483912
  - 0.6418817555652994
  - 0.6401077995684455
  - 0.6539298378752705
  - 0.6512054294773156
  - 0.6384782828051261
  - 0.6457047919684985
  - 0.6595738949502629
  - 0.6453663200902579
  - 0.6360098644825838
  - 0.6462663266354731
  - 0.6603233363721492
  - 0.64652157656434
  - 0.6393565703642663
  - 0.6419975156244964
  LT_precision_micro:
  - 0.7286034809506176
  - 0.7091908545843446
  - 0.7168822245126398
  - 0.690073256419634
  - 0.7053390550460714
  - 0.7162394299076814
  - 0.6987953142489831
  - 0.7244738504505104
  - 0.7345502864486897
  - 0.7131362835389168
  - 0.6966231117908479
  - 0.7219248373618823
  - 0.7201541274817137
  - 0.702319245082403
  - 0.7132398546872231
  - 0.7013335105440368
  LT_precision_weighted:
  - 0.8195960651827572
  - 0.7952596868022439
  - 0.8220896970111043
  - 0.8064217848846469
  - 0.8216776992520484
  - 0.7939909582222991
  - 0.8210442995088117
  - 0.7981804126034302
  - 0.819672448459185
  - 0.7912302620379341
  - 0.8227188415087923
  - 0.801700603956964
  - 0.820672169964481
  - 0.7904864996791858
  - 0.81379263320991
  - 0.7998327912371149
  LT_recall_macro:
  - 0.7352589389427839
  - 0.7105458716381728
  - 0.7229558975881991
  - 0.7128073335443549
  - 0.7359993942746703
  - 0.7105478587205785
  - 0.721375880304935
  - 0.7055292034955287
  - 0.7347877403683492
  - 0.7033801438854153
  - 0.7204202203641299
  - 0.7097269680588806
  - 0.7394017568745321
  - 0.7064230200059805
  - 0.7141968582416409
  - 0.7086384236970906
  LT_recall_micro:
  - 0.7286034809506176
  - 0.7091908545843446
  - 0.7168822245126398
  - 0.690073256419634
  - 0.7053390550460714
  - 0.7162394299076814
  - 0.6987953142489831
  - 0.7244738504505104
  - 0.7345502864486897
  - 0.7131362835389168
  - 0.6966231117908479
  - 0.7219248373618823
  - 0.7201541274817137
  - 0.702319245082403
  - 0.7132398546872231
  - 0.7013335105440368
  LT_recall_weighted:
  - 0.7286034809506176
  - 0.7091908545843446
  - 0.7168822245126398
  - 0.690073256419634
  - 0.7053390550460714
  - 0.7162394299076814
  - 0.6987953142489831
  - 0.7244738504505104
  - 0.7345502864486897
  - 0.7131362835389168
  - 0.6966231117908479
  - 0.7219248373618823
  - 0.7201541274817137
  - 0.702319245082403
  - 0.7132398546872231
  - 0.7013335105440368
  LT_roc_auc:
  - 0.8046127072206266
  - 0.7665692536541503
  - 0.7831540619557174
  - 0.7559444445726029
  - 0.8035865929810992
  - 0.7671437579108649
  - 0.7766462351907859
  - 0.7590909996860076
  - 0.8073842646277822
  - 0.7637061992386511
  - 0.7745611520553557
  - 0.7592532242895675
  - 0.810083438655997
  - 0.7634204507350419
  - 0.7727751824648793
  - 0.755120894076605
  TL_average_precision:
  - 0.6816161574590229
  - 0.6713843622376117
  - 0.6797957737553366
  - 0.650451139989228
  - 0.6475391263764375
  - 0.6417731504529647
  - 0.6402407243505351
  - 0.6336774017542027
  - 0.6767717640253572
  - 0.6609805254135461
  - 0.6639878641547036
  - 0.6585472518360791
  - 0.6456879783275664
  - 0.6312918469495392
  - 0.6406058094861312
  - 0.6124591303140237
  TL_balanced_accuracy:
  - 0.805656159181021
  - 0.8083504834498647
  - 0.8033162042763131
  - 0.7966668326653354
  - 0.8116627492693881
  - 0.8120611333974446
  - 0.8039706726432783
  - 0.8027083068219556
  - 0.8150362138516322
  - 0.8119331154998695
  - 0.8100598404799141
  - 0.8077320944590373
  - 0.8113139175952553
  - 0.8104350425234931
  - 0.8059357903227853
  - 0.8018244455075391
  TL_f1_macro:
  - 0.7350399696783051
  - 0.7291010286855164
  - 0.7310095767818299
  - 0.6945008288828103
  - 0.7209694520414001
  - 0.7325908762873484
  - 0.7130419410438857
  - 0.7253347269698007
  - 0.7529201324983791
  - 0.743273762278075
  - 0.7271605980951952
  - 0.7367593485882991
  - 0.7283285389152974
  - 0.7236956401801566
  - 0.7319467594519756
  - 0.7050984724533715
  TL_f1_micro:
  - 0.7889863547758285
  - 0.7838046159267089
  - 0.7822630373502466
  - 0.7388015327695561
  - 0.771641857168173
  - 0.7909399224806202
  - 0.7605708245243129
  - 0.7825383192389006
  - 0.8074605706184654
  - 0.8000682699083862
  - 0.7727603065539113
  - 0.7899268851303735
  - 0.7872210570702531
  - 0.7854794580998191
  - 0.7907859317770619
  - 0.7613631349013725
  TL_f1_weighted:
  - 0.8061580956188495
  - 0.8028737958358785
  - 0.8000456945486221
  - 0.7642100994524235
  - 0.7930692412884712
  - 0.8097064678170257
  - 0.78272525105572
  - 0.8017635294383527
  - 0.821660113253973
  - 0.8161473049259059
  - 0.7922532085645312
  - 0.8069763465471096
  - 0.80695997414955
  - 0.8062950826379487
  - 0.8088112127403608
  - 0.785662113589483
  TL_matthews_corrcoef:
  - 0.5164321026122047
  - 0.5130281798934176
  - 0.5119402972201261
  - 0.4814076445287241
  - 0.5113754850024973
  - 0.517663781183751
  - 0.4998007462213832
  - 0.5035230089004322
  - 0.5414769513027226
  - 0.5283887367381123
  - 0.517960961956239
  - 0.5201675184727844
  - 0.5128929856642472
  - 0.5066082022088383
  - 0.5116564119994154
  - 0.48622171078848797
  TL_precision_macro:
  - 0.7181390008000066
  - 0.713391844257921
  - 0.7160145618852928
  - 0.6952976324725616
  - 0.7097659146582076
  - 0.7146821260885454
  - 0.705448097797746
  - 0.7093892162672523
  - 0.732669512186759
  - 0.7237616360996906
  - 0.7163159518622116
  - 0.7198131525327065
  - 0.7112491603134762
  - 0.7066872577101604
  - 0.7139274745069095
  - 0.6958187578581826
  TL_precision_micro:
  - 0.7889863547758285
  - 0.7838046159267089
  - 0.7822630373502466
  - 0.7388015327695561
  - 0.7716418571681729
  - 0.7909399224806202
  - 0.7605708245243129
  - 0.7825383192389006
  - 0.8074605706184653
  - 0.8000682699083862
  - 0.7727603065539113
  - 0.7899268851303735
  - 0.7872210570702531
  - 0.7854794580998191
  - 0.7907859317770619
  - 0.7613631349013724
  TL_precision_weighted:
  - 0.8551500078334734
  - 0.8591651402842305
  - 0.8526571606154641
  - 0.8558207709565486
  - 0.8623129897122723
  - 0.8632494209845791
  - 0.8568260785325528
  - 0.8565966020774012
  - 0.8601117976276295
  - 0.8603371042528809
  - 0.8570497639600049
  - 0.8561209652168097
  - 0.8638220812029331
  - 0.865546882336471
  - 0.8586743511595512
  - 0.8610113346934505
  TL_recall_macro:
  - 0.805656159181021
  - 0.8083504834498647
  - 0.8033162042763131
  - 0.7966668326653354
  - 0.8116627492693881
  - 0.8120611333974446
  - 0.8039706726432783
  - 0.8027083068219556
  - 0.8150362138516322
  - 0.8119331154998695
  - 0.8100598404799141
  - 0.8077320944590373
  - 0.8113139175952553
  - 0.8104350425234931
  - 0.8059357903227853
  - 0.8018244455075391
  TL_recall_micro:
  - 0.7889863547758285
  - 0.7838046159267089
  - 0.7822630373502466
  - 0.7388015327695561
  - 0.7716418571681729
  - 0.7909399224806202
  - 0.7605708245243129
  - 0.7825383192389006
  - 0.8074605706184653
  - 0.8000682699083862
  - 0.7727603065539113
  - 0.7899268851303735
  - 0.7872210570702531
  - 0.7854794580998191
  - 0.7907859317770619
  - 0.7613631349013724
  TL_recall_weighted:
  - 0.7889863547758285
  - 0.7838046159267089
  - 0.7822630373502466
  - 0.7388015327695561
  - 0.7716418571681729
  - 0.7909399224806202
  - 0.7605708245243129
  - 0.7825383192389006
  - 0.8074605706184653
  - 0.8000682699083862
  - 0.7727603065539113
  - 0.7899268851303735
  - 0.7872210570702531
  - 0.7854794580998191
  - 0.7907859317770619
  - 0.7613631349013724
  TL_roc_auc:
  - 0.8876514380882125
  - 0.8900825031375941
  - 0.8863957274108136
  - 0.8833116700063883
  - 0.8904030153863467
  - 0.8904316000148507
  - 0.8843549034268845
  - 0.8839828354073418
  - 0.8931228362012222
  - 0.890979018372168
  - 0.889057368903064
  - 0.886154165142144
  - 0.8863279710404542
  - 0.8865333495065931
  - 0.8827575440009643
  - 0.8787018827291324
  TT_average_precision:
  - 0.35103082848284256
  - 0.3328414352515066
  - 0.339500827225689
  - 0.2961099858073825
  - 0.31818507329266676
  - 0.3225895294295118
  - 0.3121643994770019
  - 0.28655928479121473
  - 0.33200808129902826
  - 0.3194137746750072
  - 0.3186141688621831
  - 0.2915989391552883
  - 0.3323848897519528
  - 0.3069132742517061
  - 0.3007458461447277
  - 0.2756051557578443
  TT_balanced_accuracy:
  - 0.642937387657531
  - 0.6168055253647433
  - 0.632033686476678
  - 0.6084724234346439
  - 0.632622393961316
  - 0.6205392151038449
  - 0.6357447909658893
  - 0.5976699099986771
  - 0.6429357348546243
  - 0.6077918439317531
  - 0.6389889544367137
  - 0.6011995208015964
  - 0.6381754255226628
  - 0.6143026354722281
  - 0.6264670735662341
  - 0.6069308279270923
  TT_f1_macro:
  - 0.5834472176512284
  - 0.573052531921078
  - 0.5801323925871527
  - 0.5419804073699348
  - 0.5525093148677389
  - 0.5811126366312529
  - 0.5576906450966649
  - 0.5628355134361652
  - 0.5947841393676198
  - 0.5781079947508682
  - 0.565969396255632
  - 0.5670935925752817
  - 0.5749471868293303
  - 0.5721064943059403
  - 0.5778923406330662
  - 0.5566554790697508
  TT_f1_micro:
  - 0.6499477533960293
  - 0.6369284954811271
  - 0.6629452418926103
  - 0.5925372142477405
  - 0.6042972831765935
  - 0.6534423179160022
  - 0.6251329080276449
  - 0.6496544391281234
  - 0.6682667189132706
  - 0.6537081339712919
  - 0.6293195108984583
  - 0.6508506113769271
  - 0.6486619119282864
  - 0.6487233263424215
  - 0.6804820400146476
  - 0.6336096408002929
  TT_f1_weighted:
  - 0.6838719397411621
  - 0.6671572286872358
  - 0.6965511744552918
  - 0.6318187256622493
  - 0.6455268290734681
  - 0.6817009795789865
  - 0.6682771330714764
  - 0.6798973574723546
  - 0.6976744010426128
  - 0.6784888389465263
  - 0.6691433610148565
  - 0.6798536461394853
  - 0.6858117242866649
  - 0.6797654697605536
  - 0.7142745009224303
  - 0.6702451098846375
  TT_matthews_corrcoef:
  - 0.23246766294526747
  - 0.19608387098105126
  - 0.21385852861629934
  - 0.17558477111041118
  - 0.21047782533839798
  - 0.20337530244997706
  - 0.21063628871800133
  - 0.1631753829060573
  - 0.237367703943977
  - 0.18599653571385028
  - 0.21983924955394266
  - 0.17028733684237352
  - 0.22018337779633249
  - 0.1899193544229449
  - 0.20242299528101532
  - 0.17280836354882967
  TT_precision_macro:
  - 0.5945190324254314
  - 0.5822925207066424
  - 0.5865981089417037
  - 0.5710549531155054
  - 0.5835094919416534
  - 0.5857843516132625
  - 0.5817115076924796
  - 0.5681535530925007
  - 0.5985467821132007
  - 0.5802349928243569
  - 0.5869301014607722
  - 0.5716351640283917
  - 0.5877158866607777
  - 0.5788900471004272
  - 0.5809994804637395
  - 0.5698178698587875
  TT_precision_micro:
  - 0.6499477533960293
  - 0.6369284954811271
  - 0.6629452418926103
  - 0.5925372142477405
  - 0.6042972831765935
  - 0.6534423179160022
  - 0.6251329080276449
  - 0.6496544391281234
  - 0.6682667189132706
  - 0.6537081339712919
  - 0.6293195108984583
  - 0.6508506113769271
  - 0.6486619119282864
  - 0.6487233263424215
  - 0.6804820400146476
  - 0.6336096408002929
  TT_precision_weighted:
  - 0.7653918896317556
  - 0.7350986145393906
  - 0.7672280042007737
  - 0.7422194445045431
  - 0.7666456263993751
  - 0.740207888350434
  - 0.7793332328834656
  - 0.7367876518417226
  - 0.7613038833621496
  - 0.7253624631234639
  - 0.7728280127324605
  - 0.7347710205855446
  - 0.7725037719507977
  - 0.7438539672883997
  - 0.7782115587920778
  - 0.7495380749224493
  TT_recall_macro:
  - 0.642937387657531
  - 0.6168055253647433
  - 0.632033686476678
  - 0.6084724234346439
  - 0.632622393961316
  - 0.6205392151038449
  - 0.6357447909658893
  - 0.5976699099986771
  - 0.6429357348546243
  - 0.6077918439317531
  - 0.6389889544367137
  - 0.6011995208015964
  - 0.6381754255226628
  - 0.6143026354722281
  - 0.6264670735662341
  - 0.6069308279270923
  TT_recall_micro:
  - 0.6499477533960293
  - 0.6369284954811271
  - 0.6629452418926103
  - 0.5925372142477405
  - 0.6042972831765935
  - 0.6534423179160022
  - 0.6251329080276449
  - 0.6496544391281234
  - 0.6682667189132706
  - 0.6537081339712919
  - 0.6293195108984583
  - 0.6508506113769271
  - 0.6486619119282864
  - 0.6487233263424215
  - 0.6804820400146476
  - 0.6336096408002929
  TT_recall_weighted:
  - 0.6499477533960293
  - 0.6369284954811271
  - 0.6629452418926103
  - 0.5925372142477405
  - 0.6042972831765935
  - 0.6534423179160022
  - 0.6251329080276449
  - 0.6496544391281234
  - 0.6682667189132706
  - 0.6537081339712919
  - 0.6293195108984583
  - 0.6508506113769271
  - 0.6486619119282864
  - 0.6487233263424215
  - 0.6804820400146476
  - 0.6336096408002929
  TT_roc_auc:
  - 0.7080361547970964
  - 0.6752115709879819
  - 0.6894935092296124
  - 0.6577747173665207
  - 0.6940158930475833
  - 0.6791922701564378
  - 0.6952055144396287
  - 0.6573860621183161
  - 0.7051676532466046
  - 0.6707711665519939
  - 0.6953796439722321
  - 0.6621474495873583
  - 0.7047949196215303
  - 0.6711050660848081
  - 0.6908689253896515
  - 0.6567060125734743
  fit_time:
  - 7651.784663438797
  - 7355.853819608688
  - 6041.13544344902
  - 5342.923631191254
  - 7732.90305685997
  - 7547.918716669083
  - 6500.278520822525
  - 7269.969952106476
  - 9751.2690346241
  - 7411.182754278183
  - 6508.2482743263245
  - 7208.98720574379
  - 7951.85383939743
  - 7264.918585300446
  - 5947.803547859192
  - 5650.122473239899
  score_time:
  - 46.68936228752136
  - 40.86073875427246
  - 47.6189968585968
  - 52.54497742652893
  - 42.561962842941284
  - 41.636805295944214
  - 49.27613806724548
  - 43.06367206573486
  - 49.634318113327026
  - 41.40509295463562
  - 45.948647022247314
  - 44.886393785476685
  - 41.69631242752075
  - 47.78681969642639
  - 49.39724373817444
  - 56.66786503791809
start: 2023-10-09 12:53:27.961819
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
