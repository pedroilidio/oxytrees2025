active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: y_reconstruction/runs
end: 2023-10-17 04:28:59.367791
estimator:
  call: bipartite_adaptations.estimators.bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state:
                        call: numpy.random.mtrand.RandomState
                        params: {}
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gso
  params: {}
hash: cbca7a103490f958ea8b5a36f20ffb89202c2034c829fe179a60f5902f3f21b9
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/cbca7a1_20231017T042821065023_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9900538943022603
  - 1.0
  - 1.0
  - 0.9952338529924737
  - 0.979229393454928
  - 1.0
  - 1.0
  - 0.986765917958652
  - 0.9901701635401936
  - 1.0
  - 1.0
  - 0.9904878927499172
  - 0.9955938828833629
  - 1.0
  - 1.0
  - 0.995982706116369
  LL_balanced_accuracy:
  - 0.6565155807365439
  - 0.5782122905027933
  - 0.643448275862069
  - 0.8756906077348066
  - 0.8358831710709318
  - 0.5756533700137552
  - 0.6693766937669376
  - 0.6537414965986394
  - 0.6430499325236168
  - 0.7268518518518519
  - 0.7201298701298702
  - 0.7822368421052632
  - 0.8875338753387534
  - 0.7006666666666667
  - 0.764126149802891
  - 0.8690789473684211
  LL_f1_macro:
  - 0.32946584659939493
  - 0.1988495155119935
  - 0.30933676312968916
  - 0.6186772544327206
  - 0.5307611004719598
  - 0.1797379961551312
  - 0.3249662618083671
  - 0.30887353869590756
  - 0.31364551217906195
  - 0.39992626212543064
  - 0.39984275207640274
  - 0.4938450951907638
  - 0.6504343248223217
  - 0.37746859179998576
  - 0.4693475090626245
  - 0.612766048329493
  LL_f1_micro:
  - 0.3618421052631579
  - 0.20526315789473687
  - 0.3363286264441592
  - 0.7689345314505777
  - 0.6894736842105263
  - 0.1881578947368421
  - 0.37355584082156607
  - 0.3465982028241335
  - 0.33875
  - 0.48375
  - 0.474390243902439
  - 0.5963414634146341
  - 0.7925
  - 0.43875
  - 0.5621951219512196
  - 0.7573170731707317
  LL_f1_weighted:
  - 0.45586896425672085
  - 0.262231393176751
  - 0.4269441675713085
  - 0.8242439585737151
  - 0.7742161497360959
  - 0.2556264327227595
  - 0.48700902052702605
  - 0.4521028953585675
  - 0.4255491768449426
  - 0.5995332901076827
  - 0.5855666071447282
  - 0.6882826500869947
  - 0.8387409844695973
  - 0.5483729174573958
  - 0.659373818822956
  - 0.8147335481076707
  LL_matthews_corrcoef:
  - 0.17709091571728292
  - 0.10306028414013811
  - 0.16471816291115454
  - 0.4193509009035665
  - 0.3153270036549269
  - 0.08764546081456061
  - 0.16203391141302825
  - 0.15641353185958343
  - 0.1694322855420156
  - 0.20900390499719498
  - 0.21392766479594394
  - 0.2943127633864226
  - 0.45909044584366604
  - 0.20053369007486854
  - 0.27306030003704035
  - 0.4135236739251645
  LL_precision_macro:
  - 0.5500927643784786
  - 0.5339506172839507
  - 0.5472854640980735
  - 0.6170212765957447
  - 0.5740072202166064
  - 0.5253846153846153
  - 0.5387523629489603
  - 0.5397830018083183
  - 0.5501700680272109
  - 0.5481400437636762
  - 0.5519750519750519
  - 0.5767263427109974
  - 0.6359649122807017
  - 0.5501002004008017
  - 0.5705741626794258
  - 0.6158301158301158
  LL_precision_micro:
  - 0.3618421052631579
  - 0.20526315789473684
  - 0.3363286264441592
  - 0.7689345314505777
  - 0.6894736842105263
  - 0.1881578947368421
  - 0.3735558408215661
  - 0.3465982028241335
  - 0.33875
  - 0.48375
  - 0.474390243902439
  - 0.5963414634146341
  - 0.7925
  - 0.43875
  - 0.5621951219512196
  - 0.7573170731707317
  LL_precision_weighted:
  - 0.9360658138853628
  - 0.9460363872644574
  - 0.9372359821856123
  - 0.9459208477863054
  - 0.9540376211286339
  - 0.9587834008097166
  - 0.9514476171525222
  - 0.9480114302427882
  - 0.9336500850340136
  - 0.9502954048140043
  - 0.9453628112164697
  - 0.938057513567463
  - 0.9435745614035088
  - 0.9437625250501002
  - 0.9382045746294784
  - 0.9437800169507486
  LL_recall_macro:
  - 0.6565155807365439
  - 0.5782122905027933
  - 0.643448275862069
  - 0.8756906077348066
  - 0.8358831710709318
  - 0.5756533700137552
  - 0.6693766937669376
  - 0.6537414965986394
  - 0.6430499325236168
  - 0.7268518518518519
  - 0.7201298701298702
  - 0.7822368421052632
  - 0.8875338753387534
  - 0.7006666666666667
  - 0.764126149802891
  - 0.8690789473684211
  LL_recall_micro:
  - 0.3618421052631579
  - 0.20526315789473684
  - 0.3363286264441592
  - 0.7689345314505777
  - 0.6894736842105263
  - 0.1881578947368421
  - 0.3735558408215661
  - 0.3465982028241335
  - 0.33875
  - 0.48375
  - 0.474390243902439
  - 0.5963414634146341
  - 0.7925
  - 0.43875
  - 0.5621951219512196
  - 0.7573170731707317
  LL_recall_weighted:
  - 0.3618421052631579
  - 0.20526315789473684
  - 0.3363286264441592
  - 0.7689345314505777
  - 0.6894736842105263
  - 0.1881578947368421
  - 0.3735558408215661
  - 0.3465982028241335
  - 0.33875
  - 0.48375
  - 0.474390243902439
  - 0.5963414634146341
  - 0.7925
  - 0.43875
  - 0.5621951219512196
  - 0.7573170731707317
  LL_roc_auc:
  - 0.9991737488196412
  - 1.0
  - 0.9999999999999999
  - 0.9996860873932698
  - 0.9987448692289426
  - 1.0
  - 1.0
  - 0.9992269635126778
  - 0.9992680527916925
  - 1.0
  - 1.0
  - 0.9992982456140351
  - 0.9996612466124661
  - 1.0
  - 1.0
  - 0.9997258771929824
  LT_average_precision:
  - 0.28722540904400456
  - 0.3785388069253335
  - 0.25462509072998435
  - 0.4446254533806031
  - 0.280703524182176
  - 0.3597375100437248
  - 0.1663913745588479
  - 0.28230887801844895
  - 0.41554595020711027
  - 0.46715468384370784
  - 0.23458625959904378
  - 0.4257216795204275
  - 0.3715843863467333
  - 0.49653536200946574
  - 0.31165568240737723
  - 0.44999648724437935
  LT_balanced_accuracy:
  - 0.551394422310757
  - 0.5871369294605809
  - 0.5711206896551724
  - 0.7233292458614347
  - 0.6446850393700787
  - 0.40284552845528454
  - 0.5851063829787234
  - 0.6239495798319328
  - 0.6119402985074627
  - 0.717391304347826
  - 0.5836820083682008
  - 0.8072289156626506
  - 0.7138364779874213
  - 0.6719367588932806
  - 0.640495867768595
  - 0.7841926894214476
  LT_f1_macro:
  - 0.28970897089708975
  - 0.2488115004186357
  - 0.190030485292906
  - 0.5006410256410256
  - 0.412933127344957
  - 0.14864329009233557
  - 0.20024906600249065
  - 0.24433847784101592
  - 0.23465096719932715
  - 0.44008614059375484
  - 0.23050610508782104
  - 0.47381735390842394
  - 0.5089847537702956
  - 0.37860962566844925
  - 0.30506912442396317
  - 0.5744252222306162
  LT_f1_micro:
  - 0.3308270676691729
  - 0.2518796992481203
  - 0.19433198380566802
  - 0.6680161943319838
  - 0.5488721804511278
  - 0.15037593984962405
  - 0.21052631578947367
  - 0.27530364372469635
  - 0.2571428571428571
  - 0.48928571428571427
  - 0.23461538461538461
  - 0.6307692307692307
  - 0.6964285714285714
  - 0.40714285714285714
  - 0.33076923076923076
  - 0.75
  LT_f1_weighted:
  - 0.4413319527441466
  - 0.2877956737814991
  - 0.2418874395856482
  - 0.756970829440465
  - 0.6699428996238113
  - 0.18127486052126862
  - 0.28210001966310544
  - 0.38615893758827236
  - 0.35460771356482035
  - 0.5740512448634276
  - 0.27765468071986604
  - 0.736877541886396
  - 0.7798573226406363
  - 0.48608479755538586
  - 0.4202056008507622
  - 0.8120294125053512
  LT_matthews_corrcoef:
  - 0.05189124920734499
  - 0.13946400061980033
  - 0.09985083944852728
  - 0.2146082892033263
  - 0.12028509440910737
  - -0.15750430295026654
  - 0.09933482129732166
  - 0.10893811528859795
  - 0.1105064203025636
  - 0.2627807231132027
  - 0.12639484223266456
  - 0.2513335673937382
  - 0.20502532857748182
  - 0.2193323002402745
  - 0.16230519155779205
  - 0.3089262320861282
  LT_precision_macro:
  - 0.5130982197251743
  - 0.5558035714285714
  - 0.5350467289719626
  - 0.5515569709837226
  - 0.525
  - 0.4361645299145299
  - 0.5289855072463768
  - 0.523936170212766
  - 0.5272727272727272
  - 0.5794117647058823
  - 0.5477272727272727
  - 0.5514018691588785
  - 0.5491443108233117
  - 0.5699481865284974
  - 0.546875
  - 0.5839530892448512
  LT_precision_micro:
  - 0.3308270676691729
  - 0.2518796992481203
  - 0.19433198380566802
  - 0.6680161943319838
  - 0.5488721804511278
  - 0.15037593984962405
  - 0.21052631578947367
  - 0.27530364372469635
  - 0.2571428571428571
  - 0.48928571428571427
  - 0.23461538461538461
  - 0.6307692307692307
  - 0.6964285714285714
  - 0.40714285714285714
  - 0.33076923076923076
  - 0.75
  LT_precision_weighted:
  - 0.9113944408845848
  - 0.9165044307196564
  - 0.9435279427901169
  - 0.9322221935698302
  - 0.9376476906552095
  - 0.7559081999871474
  - 0.9542334096109839
  - 0.9653070893272461
  - 0.9594805194805194
  - 0.9188865546218489
  - 0.9269405594405594
  - 0.9620416966211359
  - 0.9326970728161754
  - 0.917061435973353
  - 0.9372596153846153
  - 0.9314216247139588
  LT_recall_macro:
  - 0.551394422310757
  - 0.5871369294605809
  - 0.5711206896551724
  - 0.7233292458614347
  - 0.6446850393700787
  - 0.40284552845528454
  - 0.5851063829787234
  - 0.6239495798319328
  - 0.6119402985074627
  - 0.717391304347826
  - 0.5836820083682008
  - 0.8072289156626506
  - 0.7138364779874213
  - 0.6719367588932806
  - 0.640495867768595
  - 0.7841926894214476
  LT_recall_micro:
  - 0.3308270676691729
  - 0.2518796992481203
  - 0.19433198380566802
  - 0.6680161943319838
  - 0.5488721804511278
  - 0.15037593984962405
  - 0.21052631578947367
  - 0.27530364372469635
  - 0.2571428571428571
  - 0.48928571428571427
  - 0.23461538461538461
  - 0.6307692307692307
  - 0.6964285714285714
  - 0.40714285714285714
  - 0.33076923076923076
  - 0.75
  LT_recall_weighted:
  - 0.3308270676691729
  - 0.2518796992481203
  - 0.19433198380566802
  - 0.6680161943319838
  - 0.5488721804511278
  - 0.15037593984962405
  - 0.21052631578947367
  - 0.27530364372469635
  - 0.2571428571428571
  - 0.48928571428571427
  - 0.23461538461538461
  - 0.6307692307692307
  - 0.6964285714285714
  - 0.40714285714285714
  - 0.33076923076923076
  - 0.75
  LT_roc_auc:
  - 0.7386454183266933
  - 0.7940248962655602
  - 0.7306034482758621
  - 0.8099325567136726
  - 0.7769028871391076
  - 0.6140243902439024
  - 0.7677304964539007
  - 0.8123249299719888
  - 0.8370646766169154
  - 0.8476064997804128
  - 0.8009563658099224
  - 0.8985031033223805
  - 0.7823899371069183
  - 0.8628312106572975
  - 0.876147842056933
  - 0.8472524812394093
  TL_average_precision:
  - 0.40910177896475236
  - 0.4539767579335905
  - 0.5724656020767097
  - 0.4784194580040336
  - 0.3988646487914376
  - 0.2644857966597288
  - 0.40767572311900313
  - 0.36166494314203756
  - 0.04979035617397837
  - 0.1174765100087547
  - 0.09197714582769125
  - 0.11812127607310167
  - 0.3285719789831157
  - 0.3253665500184303
  - 0.49808377008367627
  - 0.34641903270335184
  TL_balanced_accuracy:
  - 0.6049618320610687
  - 0.5037453183520599
  - 0.6153846153846154
  - 0.6940313919867823
  - 0.6921881072677808
  - 0.5462239583333333
  - 0.6196581196581197
  - 0.4923148890670943
  - 0.5440528634361234
  - 0.5123686885801424
  - 0.5614035087719298
  - 0.40277319247276333
  - 0.6717391304347826
  - 0.5594727161250767
  - 0.578762306610408
  - 0.59755694948828
  TL_f1_macro:
  - 0.24757565136114032
  - 0.05210848375681856
  - 0.24632352941176472
  - 0.5545233406695239
  - 0.5585453016607105
  - 0.2341179643256154
  - 0.4225829566751185
  - 0.32676605181187746
  - 0.13676565133533736
  - 0.2534722222222222
  - 0.29914529914529914
  - 0.3538730926373718
  - 0.4591585142766245
  - 0.2392120934493816
  - 0.3165010162791131
  - 0.46030612244897956
  TL_f1_micro:
  - 0.26071428571428573
  - 0.05357142857142857
  - 0.2682926829268293
  - 0.7665505226480837
  - 0.6785714285714286
  - 0.2392857142857143
  - 0.4912891986062718
  - 0.3623693379790941
  - 0.1375
  - 0.2833333333333333
  - 0.32926829268292684
  - 0.4878048780487805
  - 0.6458333333333334
  - 0.2791666666666667
  - 0.3943089430894309
  - 0.6504065040650406
  TL_f1_weighted:
  - 0.3342196184467478
  - 0.018327758037641917
  - 0.36244619799139166
  - 0.8233052733797183
  - 0.7377623952671251
  - 0.28624483348835156
  - 0.584285526068641
  - 0.4502986659375227
  - 0.15921573908359543
  - 0.3866030092592593
  - 0.42318115488847197
  - 0.6169533854097817
  - 0.7504241894005673
  - 0.4033890670331349
  - 0.5302384537821547
  - 0.7467587522814002
  TL_matthews_corrcoef:
  - 0.12959125406357866
  - 0.018715810762422586
  - 0.12009611535381536
  - 0.21805112797449575
  - 0.2501104170101682
  - 0.06924618357037363
  - 0.14078050381332233
  - -0.009844112572181823
  - 0.07215433110352001
  - 0.012860173339083422
  - 0.07118945724430337
  - -0.08701977708794342
  - 0.1420952944517586
  - 0.04572659925021372
  - 0.061120876780027186
  - 0.09130186645003063
  TL_precision_macro:
  - 0.54
  - 0.5233812949640287
  - 0.53125
  - 0.5612610850286907
  - 0.5813723876912951
  - 0.5259337046845037
  - 0.541407867494824
  - 0.49684758771929827
  - 0.5295454545454545
  - 0.5033427969594285
  - 0.5206337509211496
  - 0.48052892561983473
  - 0.5293920678621922
  - 0.5087894164552375
  - 0.5118577075098815
  - 0.5213619605291694
  TL_precision_micro:
  - 0.26071428571428573
  - 0.05357142857142857
  - 0.2682926829268293
  - 0.7665505226480837
  - 0.6785714285714286
  - 0.2392857142857143
  - 0.4912891986062718
  - 0.3623693379790941
  - 0.1375
  - 0.2833333333333333
  - 0.32926829268292684
  - 0.4878048780487805
  - 0.6458333333333334
  - 0.2791666666666667
  - 0.3943089430894309
  - 0.6504065040650406
  TL_precision_weighted:
  - 0.9408571428571428
  - 0.9557425488180885
  - 0.9542682926829268
  - 0.9166241804939846
  - 0.8677155081219587
  - 0.8834731335690152
  - 0.8750550060957574
  - 0.814327167002873
  - 0.949034090909091
  - 0.9023430106542113
  - 0.8927332530510272
  - 0.8807063092118524
  - 0.9425707517920482
  - 0.9561578772502114
  - 0.9441338089270221
  - 0.9156647324443317
  TL_recall_macro:
  - 0.6049618320610687
  - 0.5037453183520599
  - 0.6153846153846154
  - 0.6940313919867823
  - 0.6921881072677808
  - 0.5462239583333333
  - 0.6196581196581197
  - 0.4923148890670943
  - 0.5440528634361234
  - 0.5123686885801424
  - 0.5614035087719298
  - 0.40277319247276333
  - 0.6717391304347826
  - 0.5594727161250767
  - 0.578762306610408
  - 0.59755694948828
  TL_recall_micro:
  - 0.26071428571428573
  - 0.05357142857142857
  - 0.2682926829268293
  - 0.7665505226480837
  - 0.6785714285714286
  - 0.2392857142857143
  - 0.4912891986062718
  - 0.3623693379790941
  - 0.1375
  - 0.2833333333333333
  - 0.32926829268292684
  - 0.4878048780487805
  - 0.6458333333333334
  - 0.2791666666666667
  - 0.3943089430894309
  - 0.6504065040650406
  TL_recall_weighted:
  - 0.26071428571428573
  - 0.05357142857142857
  - 0.2682926829268293
  - 0.7665505226480837
  - 0.6785714285714286
  - 0.2392857142857143
  - 0.4912891986062718
  - 0.3623693379790941
  - 0.1375
  - 0.2833333333333333
  - 0.32926829268292684
  - 0.4878048780487805
  - 0.6458333333333334
  - 0.2791666666666667
  - 0.3943089430894309
  - 0.6504065040650406
  TL_roc_auc:
  - 0.8641857506361323
  - 0.8228176318063959
  - 0.8437990580847724
  - 0.780152829409335
  - 0.7769141080450835
  - 0.6848958333333333
  - 0.7498575498575498
  - 0.6233627372360332
  - 0.4486614706879024
  - 0.37580481192815995
  - 0.4641812865497076
  - 0.3955100693298118
  - 0.7154347826086958
  - 0.6238503985285101
  - 0.7461322081575246
  - 0.6115879828326181
  TT_average_precision:
  - 0.05340157622973095
  - 0.2607619517913635
  - 0.10208128470068531
  - 0.4880952380952381
  - 0.23113127182894627
  - 0.26769012287710897
  - 0.35457597852048983
  - 0.17202845545495193
  - 0.09399259366364629
  - 0.09313776341426111
  - 0.015873015873015872
  - 0.11045728603868138
  - 0.04654403567447046
  - 0.2656003256003256
  - 0.07135416666666666
  - -0.0
  TT_balanced_accuracy:
  - 0.5736842105263158
  - 0.5
  - 0.5357142857142857
  - 0.9090909090909092
  - 0.7282608695652174
  - 0.44343891402714936
  - 0.5858024691358025
  - 0.6144578313253012
  - 0.532051282051282
  - 0.5833333333333334
  - 0.525974025974026
  - 0.5902777777777777
  - 0.49382716049382713
  - 0.6474358974358975
  - 0.6283783783783784
  - 0.717948717948718
  TT_f1_macro:
  - 0.16292312559316668
  - 0.07547169811320753
  - 0.1427536231884058
  - 0.5863636363636364
  - 0.41020702936928255
  - 0.2040816326530612
  - 0.32692307692307687
  - 0.28627450980392155
  - 0.13082919914953933
  - 0.2207792207792208
  - 0.06271604938271605
  - 0.4222222222222222
  - 0.4209558823529412
  - 0.3172750110831979
  - 0.2677931387608807
  - 0.417910447761194
  TT_f1_micro:
  - 0.17346938775510204
  - 0.08163265306122448
  - 0.14285714285714285
  - 0.8241758241758241
  - 0.4897959183673469
  - 0.20408163265306123
  - 0.34065934065934067
  - 0.2967032967032967
  - 0.13095238095238096
  - 0.2261904761904762
  - 0.0641025641025641
  - 0.5256410256410257
  - 0.6428571428571429
  - 0.34523809523809523
  - 0.2948717948717949
  - 0.717948717948718
  TT_f1_weighted:
  - 0.2511282273111712
  - 0.012321909896033883
  - 0.13478260869565217
  - 0.8793206793206793
  - 0.6003360419757696
  - 0.20408163265306123
  - 0.4019442096365173
  - 0.35737987502693386
  - 0.1219601093449428
  - 0.2764378478664193
  - 0.09784108895220008
  - 0.6290598290598292
  - 0.7538077731092437
  - 0.43570689691570436
  - 0.39416020061181345
  - 0.8358208955223879
  TT_matthews_corrcoef:
  - 0.07254762501100116
  - 0.0
  - 0.07669649888473704
  - 0.35942537872389224
  - 0.2211629342323457
  - -0.11312217194570136
  - 0.12349629155555691
  - 0.15948377230252836
  - 0.06977498959044452
  - 0.11867816581938534
  - 0.026495295846634775
  - 0.09622504486493763
  - -0.004818787490218393
  - 0.17030497086739352
  - 0.13193649133663057
  - 0.0
  TT_precision_macro:
  - 0.5178571428571429
  - 0.04081632653061224
  - 0.5411764705882353
  - 0.5789473684210527
  - 0.5535714285714286
  - 0.44343891402714936
  - 0.5444373401534527
  - 0.5555555555555556
  - 0.5379746835443038
  - 0.5422535211267605
  - 0.5067567567567568
  - 0.5256410256410257
  - 0.4990595611285266
  - 0.5491803278688525
  - 0.5338983050847458
  - 0.5
  TT_precision_micro:
  - 0.17346938775510204
  - 0.08163265306122448
  - 0.14285714285714285
  - 0.8241758241758241
  - 0.4897959183673469
  - 0.20408163265306123
  - 0.34065934065934067
  - 0.2967032967032967
  - 0.13095238095238096
  - 0.2261904761904762
  - 0.0641025641025641
  - 0.5256410256410257
  - 0.6428571428571429
  - 0.34523809523809523
  - 0.2948717948717949
  - 0.717948717948718
  TT_precision_weighted:
  - 0.9704810495626822
  - 0.0066638900458142435
  - 0.9294117647058824
  - 0.9722382880277617
  - 0.94533527696793
  - 0.6827961954012375
  - 0.865953739355274
  - 0.9218559218559218
  - 0.9339963833634719
  - 0.9346076458752515
  - 0.9873527373527374
  - 0.883629191321499
  - 0.9304523063143751
  - 0.9355971896955504
  - 0.9521946979574099
  - 1.0
  TT_recall_macro:
  - 0.5736842105263158
  - 0.5
  - 0.5357142857142857
  - 0.9090909090909092
  - 0.7282608695652174
  - 0.44343891402714936
  - 0.5858024691358025
  - 0.6144578313253012
  - 0.532051282051282
  - 0.5833333333333334
  - 0.525974025974026
  - 0.5902777777777777
  - 0.49382716049382713
  - 0.6474358974358975
  - 0.6283783783783784
  - 0.358974358974359
  TT_recall_micro:
  - 0.17346938775510204
  - 0.08163265306122448
  - 0.14285714285714285
  - 0.8241758241758241
  - 0.4897959183673469
  - 0.20408163265306123
  - 0.34065934065934067
  - 0.2967032967032967
  - 0.13095238095238096
  - 0.2261904761904762
  - 0.0641025641025641
  - 0.5256410256410257
  - 0.6428571428571429
  - 0.34523809523809523
  - 0.2948717948717949
  - 0.717948717948718
  TT_recall_weighted:
  - 0.17346938775510204
  - 0.08163265306122448
  - 0.14285714285714285
  - 0.8241758241758241
  - 0.4897959183673469
  - 0.20408163265306123
  - 0.34065934065934067
  - 0.2967032967032967
  - 0.13095238095238096
  - 0.2261904761904762
  - 0.0641025641025641
  - 0.5256410256410257
  - 0.6428571428571429
  - 0.34523809523809523
  - 0.2948717948717949
  - 0.717948717948718
  TT_roc_auc:
  - 0.5649122807017544
  - 0.7374999999999999
  - 0.54421768707483
  - 0.9356060606060606
  - 0.7989130434782609
  - 0.6009049773755657
  - 0.7493827160493827
  - 0.6475903614457832
  - 0.49786324786324787
  - 0.5918803418803419
  - 0.19480519480519476
  - 0.6111111111111112
  - 0.49794238683127573
  - 0.6655982905982907
  - 0.5827702702702703
  - .nan
  fit_time:
  - 31.5057954788208
  - 34.29951572418213
  - 30.828202486038208
  - 33.55773115158081
  - 7.130481958389282
  - 8.87734055519104
  - 8.376152992248535
  - 8.40549373626709
  - 34.33424139022827
  - 36.25760531425476
  - 34.94235420227051
  - 36.414955139160156
  - 36.39095449447632
  - 35.64753556251526
  - 34.13041090965271
  - 36.696892976760864
  score_time:
  - 0.29898643493652344
  - 0.3103182315826416
  - 0.29561614990234375
  - 0.3216726779937744
  - 0.3258492946624756
  - 0.32295799255371094
  - 0.32834935188293457
  - 0.364654541015625
  - 0.34522104263305664
  - 0.3145408630371094
  - 0.3733828067779541
  - 0.33025145530700684
  - 0.3404507637023926
  - 0.3272836208343506
  - 0.334000825881958
  - 0.39905500411987305
start: 2023-10-17 04:28:21.065023
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
