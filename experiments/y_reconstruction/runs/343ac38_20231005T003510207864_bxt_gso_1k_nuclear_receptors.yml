active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: y_reconstruction/runs
end: 2023-10-05 00:35:17.582611
estimator:
  call: bipartite_adaptations.estimators.bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 1000
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gso_1k
  params:
    n_estimators: 1000
hash: 343ac38a064d7351e2aeb27bbe768df22f9bb2ce75a187ece09c3564dce4494c
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/343ac38_20231005T003510207864_bxt_gso_1k_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9918546282462918
  - 1.0
  - 1.0
  - 0.9933596666690929
  - 0.987769572920127
  - 1.0
  - 1.0
  - 0.9885442608868639
  - 0.9901701635401936
  - 1.0
  - 1.0
  - 0.9900523910365975
  - 0.996233541731977
  - 1.0
  - 1.0
  - 0.995982706116369
  LL_balanced_accuracy:
  - 0.6572237960339944
  - 0.7150837988826816
  - 0.6289655172413793
  - 0.7430939226519337
  - 0.7878998609179415
  - 0.5749656121045392
  - 0.790650406504065
  - 0.6183673469387755
  - 0.7192982456140351
  - 0.6865079365079365
  - 0.5331168831168831
  - 0.7605263157894737
  - 0.9044715447154472
  - 0.5673333333333334
  - 0.7634691195795007
  - 0.8953947368421052
  LL_f1_macro:
  - 0.3304403541472507
  - 0.38949092741935487
  - 0.2886351909184727
  - 0.44124543028582885
  - 0.47134474115733993
  - 0.17862838915470494
  - 0.4724685895370778
  - 0.25921575208368297
  - 0.4153649401662556
  - 0.3499681155246539
  - 0.12316942767612682
  - 0.4665274957819783
  - 0.6811532753868985
  - 0.1854395755249067
  - 0.468525626714869
  - 0.656640831772969
  LL_f1_micro:
  - 0.3631578947368421
  - 0.4631578947368421
  - 0.30937098844672656
  - 0.5224646983311938
  - 0.5986842105263158
  - 0.1868421052631579
  - 0.6033376123234917
  - 0.2798459563543004
  - 0.48
  - 0.4075
  - 0.12317073170731707
  - 0.5560975609756098
  - 0.82375
  - 0.18875
  - 0.5609756097560976
  - 0.8060975609756098
  LL_f1_weighted:
  - 0.45741557119733167
  - 0.5770068442275043
  - 0.3932496280722951
  - 0.6241938825496307
  - 0.7028089777047009
  - 0.25363258625031476
  - 0.707560622738445
  - 0.36887322247596493
  - 0.5810834018452544
  - 0.5220803077366137
  - 0.12410833013310658
  - 0.6531317982687105
  - 0.8613315666737332
  - 0.23087677420265795
  - 0.6582913813784432
  - 0.8500229213142787
  LL_matthews_corrcoef:
  - 0.17765599968038662
  - 0.20463313980478037
  - 0.15338674326763585
  - 0.2502473319475518
  - 0.26120988280788
  - 0.0871791276942441
  - 0.26095064302514775
  - 0.1312138279513256
  - 0.23340587185351
  - 0.17800209541030765
  - 0.06562382761787193
  - 0.2715397999544174
  - 0.4970577051904926
  - 0.09814687348275378
  - 0.2723948248362443
  - 0.4654617603245633
  LL_precision_macro:
  - 0.550185873605948
  - 0.5486725663716814
  - 0.5456081081081081
  - 0.5644028103044496
  - 0.5592485549132948
  - 0.5253456221198156
  - 0.5585714285714286
  - 0.5363636363636364
  - 0.5621052631578948
  - 0.5424710424710425
  - 0.5325097529258778
  - 0.5707547169811321
  - 0.6527093596059114
  - 0.5357653791130186
  - 0.5704057279236276
  - 0.636986301369863
  LL_precision_micro:
  - 0.3631578947368421
  - 0.4631578947368421
  - 0.30937098844672656
  - 0.5224646983311938
  - 0.5986842105263158
  - 0.1868421052631579
  - 0.6033376123234917
  - 0.2798459563543004
  - 0.48
  - 0.4075
  - 0.12317073170731707
  - 0.5560975609756098
  - 0.82375
  - 0.18875
  - 0.5609756097560976
  - 0.8060975609756098
  LL_precision_weighted:
  - 0.9360790451966348
  - 0.9477410340009315
  - 0.9370034347569649
  - 0.9384907691058915
  - 0.9524452388195924
  - 0.9587800145525104
  - 0.9535338345864662
  - 0.947625160462131
  - 0.9354105263157895
  - 0.9496718146718146
  - 0.9429889942592534
  - 0.9371836171191901
  - 0.9461699507389163
  - 0.9419706723891274
  - 0.9381803364573026
  - 0.9468760441029068
  LL_recall_macro:
  - 0.6572237960339944
  - 0.7150837988826816
  - 0.6289655172413793
  - 0.7430939226519337
  - 0.7878998609179415
  - 0.5749656121045392
  - 0.790650406504065
  - 0.6183673469387755
  - 0.7192982456140351
  - 0.6865079365079365
  - 0.5331168831168831
  - 0.7605263157894737
  - 0.9044715447154472
  - 0.5673333333333334
  - 0.7634691195795007
  - 0.8953947368421052
  LL_recall_micro:
  - 0.3631578947368421
  - 0.4631578947368421
  - 0.30937098844672656
  - 0.5224646983311938
  - 0.5986842105263158
  - 0.1868421052631579
  - 0.6033376123234917
  - 0.2798459563543004
  - 0.48
  - 0.4075
  - 0.12317073170731707
  - 0.5560975609756098
  - 0.82375
  - 0.18875
  - 0.5609756097560976
  - 0.8060975609756098
  LL_recall_weighted:
  - 0.3631578947368421
  - 0.4631578947368421
  - 0.30937098844672656
  - 0.5224646983311938
  - 0.5986842105263157
  - 0.1868421052631579
  - 0.6033376123234917
  - 0.2798459563543004
  - 0.48
  - 0.4075
  - 0.12317073170731707
  - 0.5560975609756097
  - 0.82375
  - 0.18875
  - 0.5609756097560976
  - 0.8060975609756098
  LL_roc_auc:
  - 0.9993573601930542
  - 1.0
  - 1.0
  - 0.9995102963335007
  - 0.9993554733878354
  - 1.0
  - 0.9999999999999999
  - 0.9993506493506494
  - 0.9992680527916924
  - 1.0
  - 1.0
  - 0.9992543859649122
  - 0.9997268117842469
  - 1.0
  - 1.0
  - 0.9997258771929824
  LT_average_precision:
  - 0.29697708039234677
  - 0.4829279174869652
  - 0.25732750583655184
  - 0.4287095811883384
  - 0.29272363985038263
  - 0.3505103086411664
  - 0.1749066805754041
  - 0.3155596248657172
  - 0.40375895506464643
  - 0.5063575863321587
  - 0.23446920640198174
  - 0.4165817436673052
  - 0.38774111839916364
  - 0.504856931848703
  - 0.3142278556188246
  - 0.41459610159126886
  LT_balanced_accuracy:
  - 0.5533864541832669
  - 0.6397510373443983
  - 0.5625
  - 0.6517473942366646
  - 0.6489501312335958
  - 0.40081300813008125
  - 0.6306737588652482
  - 0.6008403361344538
  - 0.6206467661691542
  - 0.658102766798419
  - 0.50418410041841
  - 0.7650602409638554
  - 0.7213836477987421
  - 0.5158102766798419
  - 0.6425619834710744
  - 0.7965383684337932
  LT_f1_macro:
  - 0.2923298913288542
  - 0.35405536668285575
  - 0.1754887935145446
  - 0.3842040156056714
  - 0.37879916063088065
  - 0.14515466836554117
  - 0.31766739738722843
  - 0.2111013986013986
  - 0.29830359109936105
  - 0.35918297151777334
  - 0.08356757239102308
  - 0.4255933835608679
  - 0.5181746723035414
  - 0.12095234434065016
  - 0.30798935368236435
  - 0.5927902099758435
  LT_f1_micro:
  - 0.33458646616541354
  - 0.37969924812030076
  - 0.17813765182186234
  - 0.46963562753036436
  - 0.48120300751879697
  - 0.14661654135338345
  - 0.3724696356275303
  - 0.23076923076923078
  - 0.35
  - 0.3821428571428571
  - 0.08846153846153847
  - 0.55
  - 0.7107142857142857
  - 0.125
  - 0.3346153846153846
  - 0.7730769230769231
  LT_f1_weighted:
  - 0.4457537630431311
  - 0.45856627971093344
  - 0.21654609727796986
  - 0.5875683961655385
  - 0.6082596323612117
  - 0.1751895133884829
  - 0.4922516706384761
  - 0.32658687466379777
  - 0.4724388631857237
  - 0.4570873894662441
  - 0.02741575116089907
  - 0.6702940010196569
  - 0.790123278815892
  - 0.0728065454452261
  - 0.42493505817249255
  - 0.8283092687090459
  LT_matthews_corrcoef:
  - 0.053708385468004397
  - 0.17915846612932107
  - 0.09274113128053085
  - 0.14178514356663072
  - 0.12425426830412228
  - -0.16302435410570681
  - 0.11931472247098367
  - 0.09550516443770045
  - 0.10527172775802178
  - 0.20661013294505456
  - 0.026098517702214382
  - 0.21344139456924155
  - 0.21475938464105498
  - 0.05602503841218013
  - 0.16392169317064245
  - 0.3305313568241735
  LT_precision_macro:
  - 0.5135080645161291
  - 0.5574195308237861
  - 0.5344036697247706
  - 0.5331192292252107
  - 0.5259132420091324
  - 0.43301304049416606
  - 0.5272357723577236
  - 0.5226130653266332
  - 0.5229640151515151
  - 0.5675
  - 0.5406976744186046
  - 0.54296875
  - 0.5520833333333333
  - 0.5496323529411765
  - 0.5471204188481675
  - 0.5921052631578947
  LT_precision_micro:
  - 0.33458646616541354
  - 0.37969924812030076
  - 0.17813765182186234
  - 0.46963562753036436
  - 0.48120300751879697
  - 0.14661654135338345
  - 0.3724696356275304
  - 0.23076923076923078
  - 0.35
  - 0.3821428571428571
  - 0.08846153846153847
  - 0.55
  - 0.7107142857142857
  - 0.125
  - 0.3346153846153846
  - 0.7730769230769231
  LT_precision_weighted:
  - 0.9118618117875333
  - 0.9063975404960848
  - 0.9434498384281097
  - 0.9303451941158211
  - 0.9420623476499468
  - 0.7502954366011115
  - 0.9430532240545078
  - 0.9652106687282567
  - 0.9487215909090908
  - 0.9165892857142857
  - 0.9258050089445439
  - 0.961328125
  - 0.9334077380952379
  - 0.9131433823529412
  - 0.9372935964559
  - 0.9329352226720647
  LT_recall_macro:
  - 0.5533864541832669
  - 0.6397510373443983
  - 0.5625
  - 0.6517473942366646
  - 0.6489501312335958
  - 0.40081300813008125
  - 0.6306737588652482
  - 0.6008403361344538
  - 0.6206467661691542
  - 0.658102766798419
  - 0.50418410041841
  - 0.7650602409638554
  - 0.7213836477987421
  - 0.5158102766798419
  - 0.6425619834710744
  - 0.7965383684337932
  LT_recall_micro:
  - 0.33458646616541354
  - 0.37969924812030076
  - 0.17813765182186234
  - 0.46963562753036436
  - 0.48120300751879697
  - 0.14661654135338345
  - 0.3724696356275304
  - 0.23076923076923078
  - 0.35
  - 0.3821428571428571
  - 0.08846153846153847
  - 0.55
  - 0.7107142857142857
  - 0.125
  - 0.3346153846153846
  - 0.7730769230769231
  LT_recall_weighted:
  - 0.33458646616541354
  - 0.37969924812030076
  - 0.17813765182186234
  - 0.46963562753036436
  - 0.48120300751879697
  - 0.14661654135338345
  - 0.3724696356275304
  - 0.23076923076923078
  - 0.35
  - 0.3821428571428571
  - 0.08846153846153847
  - 0.55
  - 0.7107142857142857
  - 0.125
  - 0.3346153846153846
  - 0.7730769230769231
  LT_roc_auc:
  - 0.7420982735723771
  - 0.8589211618257262
  - 0.7432471264367816
  - 0.8136112814224402
  - 0.7582020997375329
  - 0.6073170731707317
  - 0.7929078014184398
  - 0.8636788048552755
  - 0.8383084577114428
  - 0.873078612209047
  - 0.7880055788005579
  - 0.9014238773274919
  - 0.7826415094339623
  - 0.8653198653198654
  - 0.8612258953168044
  - 0.8375695957395304
  TL_average_precision:
  - 0.43067439195115986
  - 0.40236985308757567
  - 0.5901057693302313
  - 0.4836317491454399
  - 0.4411573728768048
  - 0.255172072251296
  - 0.41397417909429457
  - 0.4052327766165188
  - 0.04619891215608498
  - 0.1134233906012535
  - 0.1272638432117159
  - 0.12487947811772601
  - 0.32988803541662837
  - 0.347517962948533
  - 0.4864639956387306
  - 0.35023505329043253
  TL_balanced_accuracy:
  - 0.6106870229007634
  - 0.6787669259579372
  - 0.6007326007326007
  - 0.6046055349029327
  - 0.6681564969555642
  - 0.5481770833333333
  - 0.6838319088319088
  - 0.5322106388666132
  - 0.5111826499491697
  - 0.36834971196204674
  - 0.5
  - 0.44965335094090464
  - 0.6347826086956522
  - 0.5364806866952789
  - 0.5914205344585092
  - 0.6190161769560911
  TL_f1_macro:
  - 0.25625
  - 0.37026515151515155
  - 0.22459349593495936
  - 0.4003798670465337
  - 0.5138191955396256
  - 0.23725328947368424
  - 0.5179586563307494
  - 0.3054141716566866
  - 0.20083158618016528
  - 0.19652396894365692
  - 0.06818181818181818
  - 0.3382456140350877
  - 0.4621246077991932
  - 0.09843478260869565
  - 0.331153151440251
  - 0.4832504145936982
  TL_f1_micro:
  - 0.2714285714285714
  - 0.45714285714285713
  - 0.24041811846689895
  - 0.5017421602787456
  - 0.6107142857142858
  - 0.24285714285714285
  - 0.6376306620209059
  - 0.3240418118466899
  - 0.2125
  - 0.21666666666666667
  - 0.07317073170731707
  - 0.43902439024390244
  - 0.6666666666666666
  - 0.10000000000000002
  - 0.4186991869918699
  - 0.6910569105691057
  TL_f1_weighted:
  - 0.3488392857142857
  - 0.5824472402597404
  - 0.3245587943684315
  - 0.6159894907862388
  - 0.6828042328042327
  - 0.2914238721804511
  - 0.7129487075601653
  - 0.3961743759867026
  - 0.286936432988601
  - 0.3099591613837643
  - 0.00997782705099778
  - 0.5691969761802881
  - 0.7661736142238159
  - 0.1338086956521739
  - 0.5554283885837242
  - 0.7763108576359395
  TL_matthews_corrcoef:
  - 0.1339747997083054
  - 0.1525308679655497
  - 0.11026052261366268
  - 0.10158723151749462
  - 0.2124472070110973
  - 0.07157007825573874
  - 0.21842485542075182
  - 0.04400379801419622
  - 0.013323001919445632
  - -0.14568687371851594
  - 0.0
  - -0.04534993512624331
  - 0.11357749916264037
  - 0.047856737521074416
  - 0.07011731604006417
  - 0.11484098614820207
  TL_precision_macro:
  - 0.5405405405405406
  - 0.532536311677416
  - 0.5301724137931034
  - 0.5246640046747175
  - 0.5671009098428453
  - 0.5265804597701149
  - 0.5648818501759678
  - 0.5150286854577201
  - 0.503968253968254
  - 0.45969498910675377
  - 0.036585365853658534
  - 0.4897877184758589
  - 0.5239271380055572
  - 0.515695067264574
  - 0.5134445670159956
  - 0.5277030661646046
  TL_precision_micro:
  - 0.2714285714285714
  - 0.45714285714285713
  - 0.24041811846689895
  - 0.5017421602787456
  - 0.6107142857142858
  - 0.24285714285714285
  - 0.6376306620209059
  - 0.3240418118466899
  - 0.2125
  - 0.21666666666666667
  - 0.07317073170731707
  - 0.43902439024390244
  - 0.6666666666666666
  - 0.1
  - 0.4186991869918699
  - 0.6910569105691057
  TL_precision_weighted:
  - 0.940926640926641
  - 0.9488392997595453
  - 0.9541631623212785
  - 0.9082228675673145
  - 0.864217032967033
  - 0.8843185550082102
  - 0.8847020984754127
  - 0.8389990118053196
  - 0.90380291005291
  - 0.8365649963689179
  - 0.005353955978584175
  - 0.8886424402983734
  - 0.9371205104456107
  - 0.9717488789237668
  - 0.9454834999260086
  - 0.9183318245231942
  TL_recall_macro:
  - 0.6106870229007634
  - 0.6787669259579372
  - 0.6007326007326007
  - 0.6046055349029327
  - 0.6681564969555642
  - 0.5481770833333333
  - 0.6838319088319088
  - 0.5322106388666132
  - 0.5111826499491697
  - 0.36834971196204674
  - 0.5
  - 0.44965335094090464
  - 0.6347826086956522
  - 0.5364806866952789
  - 0.5914205344585092
  - 0.6190161769560911
  TL_recall_micro:
  - 0.2714285714285714
  - 0.45714285714285713
  - 0.24041811846689895
  - 0.5017421602787456
  - 0.6107142857142858
  - 0.24285714285714285
  - 0.6376306620209059
  - 0.3240418118466899
  - 0.2125
  - 0.21666666666666667
  - 0.07317073170731707
  - 0.43902439024390244
  - 0.6666666666666666
  - 0.1
  - 0.4186991869918699
  - 0.6910569105691057
  TL_recall_weighted:
  - 0.2714285714285714
  - 0.45714285714285713
  - 0.24041811846689895
  - 0.5017421602787456
  - 0.6107142857142858
  - 0.24285714285714285
  - 0.6376306620209059
  - 0.3240418118466899
  - 0.2125
  - 0.21666666666666667
  - 0.07317073170731707
  - 0.43902439024390244
  - 0.6666666666666666
  - 0.1
  - 0.4186991869918699
  - 0.6910569105691057
  TL_roc_auc:
  - 0.8713952502120441
  - 0.7948717948717949
  - 0.8547880690737832
  - 0.763424204874019
  - 0.8033424018655266
  - 0.6917317708333335
  - 0.7467236467236468
  - 0.7175888799786153
  - 0.4018976618095561
  - 0.298881735005083
  - 0.5104775828460039
  - 0.45691647408385605
  - 0.7323913043478262
  - 0.6066830165542612
  - 0.7484763244256915
  - 0.6383294816771211
  TT_average_precision:
  - 0.05726408281174771
  - 0.30009933569255604
  - 0.10822328931572629
  - 0.48333333333333334
  - 0.3045751633986928
  - 0.2745132057137329
  - 0.3964724837262723
  - 0.1461044634466442
  - 0.11725995953937131
  - 0.07545860218672248
  - 0.01818181818181818
  - 0.14164239429106995
  - 0.046869488536155204
  - 0.2512607716412064
  - 0.06896412411118294
  - -0.0
  TT_balanced_accuracy:
  - 0.5842105263157895
  - 0.6555555555555556
  - 0.5238095238095238
  - 0.7613636363636364
  - 0.7119565217391304
  - 0.40226244343891404
  - 0.6098765432098765
  - 0.6506024096385542
  - 0.5512820512820513
  - 0.5192307692307693
  - 0.5
  - 0.6388888888888888
  - 0.345679012345679
  - 0.5
  - 0.6216216216216216
  - 0.6794871794871795
  TT_f1_macro:
  - 0.17943826179120298
  - 0.3398522381573229
  - 0.11992263056092842
  - 0.40578358208955223
  - 0.39001761597181445
  - 0.1282051282051282
  - 0.4136752136752137
  - 0.3395895895895896
  - 0.16619398752127054
  - 0.10600255427841634
  - 0.012658227848101266
  - 0.3111413043478261
  - 0.3999999999999999
  - 0.06666666666666667
  - 0.25815217391304346
  - 0.40458015267175573
  TT_f1_micro:
  - 0.19387755102040816
  - 0.36734693877551017
  - 0.12087912087912088
  - 0.5384615384615384
  - 0.45918367346938777
  - 0.1326530612244898
  - 0.46153846153846156
  - 0.3626373626373626
  - 0.16666666666666666
  - 0.10714285714285714
  - 0.01282051282051282
  - 0.3333333333333333
  - 0.6666666666666666
  - 0.07142857142857142
  - 0.28205128205128205
  - 0.6794871794871795
  TT_f1_weighted:
  - 0.28162400095173207
  - 0.45258051069189087
  - 0.09537271239398899
  - 0.6680539609644087
  - 0.5702685536927631
  - 0.0824549600059804
  - 0.5443786982248521
  - 0.44127094127094135
  - 0.18321043675553034
  - 0.07863528553183725
  - 0.0003245699448231094
  - 0.41576086956521746
  - 0.7714285714285712
  - 0.009523809523809525
  - 0.37764771460423635
  - 0.8091603053435115
  TT_matthews_corrcoef:
  - 0.07849678864759116
  - 0.18856180831641267
  - 0.061898446059017294
  - 0.18667748886377503
  - 0.20762899853268943
  - -0.27656872863088133
  - 0.14055454633814318
  - 0.1910750508671709
  - 0.08998425413316952
  - 0.05337605126836238
  - 0.0
  - 0.1695158759052026
  - -0.1252743380004715
  - 0.0
  - 0.12734290799340264
  - 0.0
  TT_precision_macro:
  - 0.5182926829268293
  - 0.5571428571428572
  - 0.5402298850574713
  - 0.5333333333333333
  - 0.5508474576271186
  - 0.30434782608695654
  - 0.544949494949495
  - 0.5606060606060606
  - 0.5394736842105263
  - 0.537037037037037
  - 0.00641025641025641
  - 0.5517241379310345
  - 0.4745762711864407
  - 0.03571428571428571
  - 0.5333333333333333
  - 0.5
  TT_precision_micro:
  - 0.19387755102040816
  - 0.3673469387755102
  - 0.12087912087912088
  - 0.5384615384615384
  - 0.45918367346938777
  - 0.1326530612244898
  - 0.46153846153846156
  - 0.3626373626373626
  - 0.16666666666666666
  - 0.10714285714285714
  - 0.01282051282051282
  - 0.3333333333333333
  - 0.6666666666666666
  - 0.07142857142857142
  - 0.28205128205128205
  - 0.6794871794871795
  TT_precision_weighted:
  - 0.9705077152812345
  - 0.9276967930029154
  - 0.9292661361626878
  - 0.9692307692307692
  - 0.9450017295053614
  - 0.44809228039041704
  - 0.8566433566433567
  - 0.9227439227439227
  - 0.9342105263157895
  - 0.9338624338624338
  - 0.00016436554898093358
  - 0.9310344827586207
  - 0.9152542372881356
  - 0.00510204081632653
  - 0.9521367521367521
  - 1.0
  TT_recall_macro:
  - 0.5842105263157895
  - 0.6555555555555556
  - 0.5238095238095238
  - 0.7613636363636364
  - 0.7119565217391304
  - 0.40226244343891404
  - 0.6098765432098765
  - 0.6506024096385542
  - 0.5512820512820513
  - 0.5192307692307693
  - 0.5
  - 0.6388888888888888
  - 0.345679012345679
  - 0.5
  - 0.6216216216216216
  - 0.33974358974358976
  TT_recall_micro:
  - 0.19387755102040816
  - 0.3673469387755102
  - 0.12087912087912088
  - 0.5384615384615384
  - 0.45918367346938777
  - 0.1326530612244898
  - 0.46153846153846156
  - 0.3626373626373626
  - 0.16666666666666666
  - 0.10714285714285714
  - 0.01282051282051282
  - 0.3333333333333333
  - 0.6666666666666666
  - 0.07142857142857142
  - 0.28205128205128205
  - 0.6794871794871795
  TT_recall_weighted:
  - 0.19387755102040816
  - 0.3673469387755102
  - 0.12087912087912088
  - 0.5384615384615384
  - 0.45918367346938777
  - 0.1326530612244898
  - 0.46153846153846156
  - 0.3626373626373626
  - 0.16666666666666666
  - 0.10714285714285714
  - 0.01282051282051282
  - 0.3333333333333333
  - 0.6666666666666666
  - 0.07142857142857142
  - 0.28205128205128205
  - 0.6794871794871795
  TT_roc_auc:
  - 0.6210526315789474
  - 0.7625
  - 0.5850340136054422
  - 0.9356060606060606
  - 0.9057971014492754
  - 0.6226244343891403
  - 0.7777777777777778
  - 0.6626506024096385
  - 0.5982905982905983
  - 0.4850427350427351
  - 0.2987012987012987
  - 0.6018518518518519
  - 0.5185185185185186
  - 0.5972222222222222
  - 0.5692567567567568
  - .nan
  fit_time:
  - 4.977004289627075
  - 4.538317680358887
  - 5.049155235290527
  - 4.897852182388306
  - 4.301318883895874
  - 4.4431312084198
  - 4.302252292633057
  - 4.274767875671387
  - 5.180269002914429
  - 5.2019147872924805
  - 4.69045877456665
  - 5.135730266571045
  - 4.924847841262817
  - 5.279188632965088
  - 5.256299018859863
  - 5.127597808837891
  score_time:
  - 1.916372299194336
  - 1.7669646739959717
  - 1.929556131362915
  - 1.9700820446014404
  - 1.7075896263122559
  - 1.8698694705963135
  - 1.8263335227966309
  - 1.7887625694274902
  - 1.9734861850738525
  - 1.9785900115966797
  - 1.7887849807739258
  - 2.000419855117798
  - 1.9245808124542236
  - 2.0356853008270264
  - 1.9455645084381104
  - 1.9769742488861084
start: 2023-10-05 00:35:10.207864
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
