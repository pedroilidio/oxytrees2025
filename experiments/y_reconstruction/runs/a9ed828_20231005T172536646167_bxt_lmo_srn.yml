active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: y_reconstruction/runs
end: 2023-10-05 17:30:40.846819
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: bxt_lmo
  params: {}
hash: a9ed8281c7cd5d995bbcaea1cf41456845c29a342f6c49842b56350ae8d4c6d6
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/a9ed828_20231005T172536646167_bxt_lmo_srn.yml"
results:
  LL_average_precision:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_balanced_accuracy:
  - 0.8216511730854361
  - 0.748928263963315
  - 0.8086957668700867
  - 0.7189622492497236
  - 0.7888021017620834
  - 0.6780017197809911
  - 0.623646090462679
  - 0.6528607989903062
  - 0.9129398129716626
  - 0.680978633003845
  - 0.886756642766765
  - 0.8584075064673127
  - 0.8111269387646762
  - 0.6875993012701784
  - 0.8837005992232941
  - 0.6287215104399604
  LL_f1_macro:
  - 0.43059163313607046
  - 0.36798044022229043
  - 0.4295830196157255
  - 0.3348668899856421
  - 0.39928936814822746
  - 0.2901137640395411
  - 0.2234538532484834
  - 0.25835762709949306
  - 0.5264521491495744
  - 0.29425467053166526
  - 0.5119209787401594
  - 0.47446429512435545
  - 0.4208764295648657
  - 0.30180419192922714
  - 0.5081070538867718
  - 0.2281170775952898
  LL_f1_micro:
  - 0.6486220129077271
  - 0.5073389355742297
  - 0.6249859943977591
  - 0.44793794440853263
  - 0.5838475214390295
  - 0.3678839031952459
  - 0.26202738782189305
  - 0.3177762466626475
  - 0.828479049013456
  - 0.3740246318146585
  - 0.7780036172594953
  - 0.7218758074239945
  - 0.6279195426340375
  - 0.38697786581689775
  - 0.7720006890018085
  - 0.2707260356558436
  LL_f1_weighted:
  - 0.7724289496756414
  - 0.6535499952418666
  - 0.7501874262723698
  - 0.599335165215201
  - 0.7224119524666719
  - 0.5164082549772178
  - 0.38975023670732384
  - 0.4609902162794482
  - 0.8933457667827094
  - 0.5225501038397257
  - 0.8580053213359494
  - 0.8221640066368712
  - 0.75676018322078
  - 0.536469697941389
  - 0.8541460967553551
  - 0.40298249213441584
  LL_matthews_corrcoef:
  - 0.16184010364225743
  - 0.13556750794192643
  - 0.17616847630233412
  - 0.11700473478136547
  - 0.1407531499179414
  - 0.10047475687071698
  - 0.07994011498279233
  - 0.08710694269160844
  - 0.2571526842223387
  - 0.10303094888281973
  - 0.2518276794080439
  - 0.20803454961003992
  - 0.15527781374768532
  - 0.10580424837762839
  - 0.24747697297833454
  - 0.07850847812101704
  LL_precision_macro:
  - 0.520357627562561
  - 0.5184576762366896
  - 0.5251342384423975
  - 0.5156306715063521
  - 0.517149675410035
  - 0.5141784820683903
  - 0.5129207926420264
  - 0.512409361188738
  - 0.5400345891371412
  - 0.5146638532012073
  - 0.5409929482156849
  - 0.5301879655493482
  - 0.5193740853315322
  - 0.5149181512123979
  - 0.539904063401578
  - 0.5119707675815246
  LL_precision_micro:
  - 0.6486220129077271
  - 0.5073389355742297
  - 0.6249859943977591
  - 0.44793794440853263
  - 0.5838475214390295
  - 0.3678839031952459
  - 0.26202738782189305
  - 0.3177762466626475
  - 0.828479049013456
  - 0.3740246318146585
  - 0.7780036172594953
  - 0.7218758074239945
  - 0.6279195426340375
  - 0.38697786581689775
  - 0.7720006890018086
  - 0.2707260356558436
  LL_precision_weighted:
  - 0.9856935556101863
  - 0.9818132431568125
  - 0.9811486171279094
  - 0.9827417987158565
  - 0.9857262401431957
  - 0.9820751065126259
  - 0.9809296178051042
  - 0.9830680780666006
  - 0.9862664583976839
  - 0.9816415781867169
  - 0.9817994275564983
  - 0.9832079929121506
  - 0.9855825629375926
  - 0.9817096862114192
  - 0.9818038020768242
  - 0.9825400617391581
  LL_recall_macro:
  - 0.8216511730854361
  - 0.748928263963315
  - 0.8086957668700867
  - 0.7189622492497236
  - 0.7888021017620834
  - 0.6780017197809911
  - 0.623646090462679
  - 0.6528607989903062
  - 0.9129398129716626
  - 0.680978633003845
  - 0.886756642766765
  - 0.8584075064673127
  - 0.8111269387646762
  - 0.6875993012701784
  - 0.8837005992232941
  - 0.6287215104399604
  LL_recall_micro:
  - 0.6486220129077271
  - 0.5073389355742297
  - 0.6249859943977591
  - 0.44793794440853263
  - 0.5838475214390295
  - 0.3678839031952459
  - 0.26202738782189305
  - 0.3177762466626475
  - 0.828479049013456
  - 0.3740246318146585
  - 0.7780036172594953
  - 0.7218758074239945
  - 0.6279195426340375
  - 0.38697786581689775
  - 0.7720006890018086
  - 0.2707260356558436
  LL_recall_weighted:
  - 0.6486220129077271
  - 0.5073389355742297
  - 0.6249859943977591
  - 0.44793794440853263
  - 0.5838475214390295
  - 0.3678839031952459
  - 0.26202738782189305
  - 0.3177762466626475
  - 0.828479049013456
  - 0.3740246318146585
  - 0.7780036172594953
  - 0.7218758074239945
  - 0.6279195426340375
  - 0.38697786581689775
  - 0.7720006890018086
  - 0.2707260356558436
  LL_roc_auc:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LT_average_precision:
  - 0.03421343685343325
  - 0.02581902094997204
  - 0.020075439355333104
  - 0.032890550643266944
  - 0.03336044576930748
  - 0.030895315496491736
  - 0.020457739110230508
  - 0.02854736603365982
  - 0.03289158511921924
  - 0.026215597530137184
  - 0.017188256992521283
  - 0.028041706559273287
  - 0.0327900447142602
  - 0.02676396032461944
  - 0.0171353194160218
  - 0.03277174937308944
  LT_balanced_accuracy:
  - 0.5264302818146522
  - 0.5564817819532545
  - 0.5673214678564338
  - 0.5443477102376071
  - 0.5184469848754871
  - 0.5595969544201633
  - 0.49374039793201907
  - 0.5142468487296074
  - 0.5220268184018736
  - 0.5498347900404407
  - 0.5606898440268593
  - 0.5433296335777064
  - 0.5221556668301885
  - 0.544238249275939
  - 0.5515382835598532
  - 0.5164056851744951
  LT_f1_macro:
  - 0.3738572757023182
  - 0.38258785013757135
  - 0.3982809020378517
  - 0.3106080233099957
  - 0.35796989199494916
  - 0.31172084890598
  - 0.19498939756414044
  - 0.26470019945345274
  - 0.4464891516580035
  - 0.31137492642114234
  - 0.4661979188624172
  - 0.42544040261950444
  - 0.3709684458442236
  - 0.3195086084430881
  - 0.4574260433879209
  - 0.22169596766522826
  LT_f1_micro:
  - 0.535632183908046
  - 0.5770015698587128
  - 0.6222919937205651
  - 0.4166666666666667
  - 0.5036350785075984
  - 0.4231855260405773
  - 0.23211671198494038
  - 0.33536394059820124
  - 0.7220931993739587
  - 0.42331625183016103
  - 0.810865927630203
  - 0.6798263961514327
  - 0.5303932952996415
  - 0.4396046852122987
  - 0.7875183016105417
  - 0.26579167538171933
  LT_f1_weighted:
  - 0.6752887693428399
  - 0.718784802486044
  - 0.7566986487301932
  - 0.5712444332399373
  - 0.648142292791889
  - 0.5804903413158972
  - 0.3639290741884185
  - 0.4843853496666365
  - 0.8163800919546362
  - 0.5808006597640603
  - 0.8848146765667154
  - 0.7940152209101261
  - 0.6710161969077375
  - 0.5968327827301675
  - 0.8703373460511382
  - 0.4003262071845814
  LT_matthews_corrcoef:
  - 0.01700592890298527
  - 0.027609670736898927
  - 0.030084102429038136
  - 0.024008267717807688
  - 0.01164779717913291
  - 0.029211823782185706
  - -0.0031768415453649963
  - 0.008094271805429095
  - 0.015971789734543843
  - 0.02439955998388087
  - 0.03411525521942631
  - 0.02474252869713273
  - 0.014194724108018579
  - 0.021660794846193886
  - 0.02783838885683439
  - 0.009964922087013188
  LT_precision_macro:
  - 0.5027355139445872
  - 0.5033740698851839
  - 0.5033609383744088
  - 0.5032493048441605
  - 0.501838663337694
  - 0.5035795900016359
  - 0.4995969263662949
  - 0.5011496794361971
  - 0.502895312235638
  - 0.5029865608289104
  - 0.5047942561780663
  - 0.5035321826875742
  - 0.5022735740030653
  - 0.5026514952617264
  - 0.5037592244086103
  - 0.5015131899573847
  LT_precision_micro:
  - 0.535632183908046
  - 0.5770015698587128
  - 0.6222919937205651
  - 0.4166666666666667
  - 0.5036350785075984
  - 0.4231855260405773
  - 0.23211671198494038
  - 0.33536394059820124
  - 0.7220931993739587
  - 0.42331625183016103
  - 0.8108659276302029
  - 0.6798263961514327
  - 0.5303932952996415
  - 0.4396046852122987
  - 0.7875183016105417
  - 0.26579167538171933
  LT_precision_weighted:
  - 0.9510557806112675
  - 0.9736973077457144
  - 0.9790851597590344
  - 0.9683563900670932
  - 0.9519963527134481
  - 0.9749453545910086
  - 0.9768425103226395
  - 0.9659499460201798
  - 0.9500637697604473
  - 0.9743036135540581
  - 0.9780769136745598
  - 0.9670052204222326
  - 0.9510174596942624
  - 0.9735228398820902
  - 0.9775967598937398
  - 0.9670985293720452
  LT_recall_macro:
  - 0.5264302818146522
  - 0.5564817819532545
  - 0.5673214678564338
  - 0.5443477102376071
  - 0.5184469848754871
  - 0.5595969544201633
  - 0.49374039793201907
  - 0.5142468487296074
  - 0.5220268184018736
  - 0.5498347900404407
  - 0.5606898440268593
  - 0.5433296335777064
  - 0.5221556668301885
  - 0.544238249275939
  - 0.5515382835598532
  - 0.5164056851744951
  LT_recall_micro:
  - 0.535632183908046
  - 0.5770015698587128
  - 0.6222919937205651
  - 0.4166666666666667
  - 0.5036350785075984
  - 0.4231855260405773
  - 0.23211671198494038
  - 0.33536394059820124
  - 0.7220931993739587
  - 0.42331625183016103
  - 0.8108659276302029
  - 0.6798263961514327
  - 0.5303932952996415
  - 0.4396046852122987
  - 0.7875183016105417
  - 0.26579167538171933
  LT_recall_weighted:
  - 0.535632183908046
  - 0.5770015698587128
  - 0.6222919937205651
  - 0.41666666666666663
  - 0.5036350785075984
  - 0.4231855260405773
  - 0.23211671198494038
  - 0.33536394059820124
  - 0.7220931993739587
  - 0.42331625183016103
  - 0.8108659276302029
  - 0.6798263961514327
  - 0.5303932952996415
  - 0.4396046852122987
  - 0.7875183016105417
  - 0.26579167538171933
  LT_roc_auc:
  - 0.5405783388583382
  - 0.5703407218525534
  - 0.5607359928668095
  - 0.5861851195372205
  - 0.5283075670284898
  - 0.6066696912215873
  - 0.57421470490898
  - 0.5492604497530605
  - 0.5308200273960852
  - 0.5960892182543783
  - 0.5820513528564394
  - 0.549140462712435
  - 0.532036275929183
  - 0.5948265557565907
  - 0.5554114198824698
  - 0.5649928605277792
  TL_average_precision:
  - 0.1941994395922312
  - 0.2033818896439403
  - 0.20749172097495852
  - 0.22075825787393247
  - 0.22290600538774583
  - 0.2572858731602116
  - 0.26171070928441714
  - 0.251309348276008
  - 0.2035741058884759
  - 0.24273999519045203
  - 0.24610891721347308
  - 0.25086507432914396
  - 0.17077448031049455
  - 0.22135767098396245
  - 0.2255104281787311
  - 0.21273031888949406
  TL_balanced_accuracy:
  - 0.6798272115333651
  - 0.6644693852605537
  - 0.6900421781379411
  - 0.6404586655809796
  - 0.6802298367782522
  - 0.62515864519284
  - 0.5848700478925754
  - 0.5957303270541772
  - 0.7362971422276126
  - 0.643821588824399
  - 0.7487336554624722
  - 0.7354736317098889
  - 0.6692485533427647
  - 0.6273228069811874
  - 0.717658099393604
  - 0.5782082925474333
  TL_f1_macro:
  - 0.3951883898998211
  - 0.329410307708426
  - 0.3872205658046236
  - 0.3033079585938025
  - 0.36936526076888565
  - 0.26349146254400757
  - 0.18444574406331954
  - 0.19860098830336073
  - 0.49162429312228695
  - 0.27406339814094044
  - 0.48145532668698976
  - 0.4540094630894586
  - 0.3907411374456178
  - 0.28043338742512036
  - 0.4762253362434008
  - 0.19585229516837147
  TL_f1_micro:
  - 0.5887635756056808
  - 0.44099587203302376
  - 0.5538183694530444
  - 0.39597523219814235
  - 0.5295918367346939
  - 0.32421460892049125
  - 0.20736910148674856
  - 0.22782159017453135
  - 0.8055729984301413
  - 0.3427795733678087
  - 0.7538720103425984
  - 0.7063219133807369
  - 0.5808738880167451
  - 0.3544149967679379
  - 0.7502521008403361
  - 0.22590820943762122
  TL_f1_weighted:
  - 0.727169386742118
  - 0.5928654412380722
  - 0.6942848006340978
  - 0.5485065085299039
  - 0.6775259196157647
  - 0.46661462494357897
  - 0.31562575288446904
  - 0.3458593687826235
  - 0.8792754229723647
  - 0.4892093018367952
  - 0.8426076245855838
  - 0.812310225008932
  - 0.7211380889556158
  - 0.5026049150064339
  - 0.8401478475589347
  - 0.345946956516441
  TL_matthews_corrcoef:
  - 0.08824599756051128
  - 0.08950024106416588
  - 0.10540893118668833
  - 0.07578802606645534
  - 0.08849711726890389
  - 0.07552610306402525
  - 0.06126859571024734
  - 0.0639477136438533
  - 0.14301592421632395
  - 0.08237538103648642
  - 0.1578759109839482
  - 0.13372402478365866
  - 0.08215965733833497
  - 0.07255355367526527
  - 0.13844965776179885
  - 0.04997972708041629
  TL_precision_macro:
  - 0.5108261647653988
  - 0.5121759638394918
  - 0.5146165483930824
  - 0.5102233366508423
  - 0.5108635449946919
  - 0.5113939237582209
  - 0.5110576137091886
  - 0.510679243992246
  - 0.5216396550405035
  - 0.5117953491133925
  - 0.5250516996007926
  - 0.5189852624628178
  - 0.509970852277068
  - 0.510335968621253
  - 0.5220165339444778
  - 0.5079850008153479
  TL_precision_micro:
  - 0.5887635756056808
  - 0.44099587203302376
  - 0.5538183694530444
  - 0.3959752321981424
  - 0.5295918367346939
  - 0.32421460892049125
  - 0.20736910148674856
  - 0.22782159017453135
  - 0.8055729984301413
  - 0.3427795733678087
  - 0.7538720103425985
  - 0.7063219133807369
  - 0.5808738880167451
  - 0.3544149967679379
  - 0.7502521008403361
  - 0.22590820943762122
  TL_precision_weighted:
  - 0.9798135249448421
  - 0.9776897737791298
  - 0.9752688621103013
  - 0.9781751652698508
  - 0.9803633187095436
  - 0.9768923510379386
  - 0.977907770978677
  - 0.979655646279139
  - 0.9797823618342776
  - 0.9797066759620012
  - 0.9749564246469667
  - 0.9777124784410767
  - 0.979728786565194
  - 0.9771462357479758
  - 0.9731087053414046
  - 0.9784994217781775
  TL_recall_macro:
  - 0.6798272115333651
  - 0.6644693852605537
  - 0.6900421781379411
  - 0.6404586655809796
  - 0.6802298367782522
  - 0.62515864519284
  - 0.5848700478925754
  - 0.5957303270541772
  - 0.7362971422276126
  - 0.643821588824399
  - 0.7487336554624722
  - 0.7354736317098889
  - 0.6692485533427647
  - 0.6273228069811874
  - 0.717658099393604
  - 0.5782082925474333
  TL_recall_micro:
  - 0.5887635756056808
  - 0.44099587203302376
  - 0.5538183694530444
  - 0.3959752321981424
  - 0.5295918367346939
  - 0.32421460892049125
  - 0.20736910148674856
  - 0.22782159017453135
  - 0.8055729984301413
  - 0.3427795733678087
  - 0.7538720103425985
  - 0.7063219133807369
  - 0.5808738880167451
  - 0.3544149967679379
  - 0.7502521008403361
  - 0.22590820943762122
  TL_recall_weighted:
  - 0.5887635756056808
  - 0.44099587203302376
  - 0.5538183694530444
  - 0.3959752321981424
  - 0.529591836734694
  - 0.32421460892049125
  - 0.20736910148674856
  - 0.22782159017453135
  - 0.8055729984301414
  - 0.3427795733678087
  - 0.7538720103425987
  - 0.7063219133807369
  - 0.5808738880167451
  - 0.354414996767938
  - 0.750252100840336
  - 0.22590820943762122
  TL_roc_auc:
  - 0.7936740935393553
  - 0.8212590353528716
  - 0.809206805308817
  - 0.8229673694352149
  - 0.8112578837370806
  - 0.8366899134525737
  - 0.8450489768404348
  - 0.8284009396935953
  - 0.8130007230698634
  - 0.8555343598533118
  - 0.8271151567717933
  - 0.8303344610980093
  - 0.7785220889928555
  - 0.8075388396321177
  - 0.786249036248413
  - 0.8122332570631096
  TT_average_precision:
  - 0.030248956916568405
  - 0.018955381746823735
  - 0.015439489528812373
  - 0.026208198310194497
  - 0.035498809385196235
  - 0.030047384431116896
  - 0.021275081353711197
  - 0.028008833143485495
  - 0.030056956648302578
  - 0.02531931318661553
  - 0.014651391428290646
  - 0.02519832543594798
  - 0.03021796589566598
  - 0.0218362462130645
  - 0.014043513466574661
  - 0.026793120214349972
  TT_balanced_accuracy:
  - 0.5375155183116077
  - 0.5383357887142948
  - 0.5040177580233124
  - 0.5438197767145135
  - 0.5282629998419472
  - 0.5556447892639966
  - 0.5313175012085202
  - 0.5258978115150708
  - 0.5300612909939394
  - 0.5433029227000837
  - 0.543681811337285
  - 0.536094012311136
  - 0.5288004090525099
  - 0.5521155564166317
  - 0.5362698412698412
  - 0.49004033619418236
  TT_f1_macro:
  - 0.33578958183053065
  - 0.348960414487301
  - 0.36553294489307697
  - 0.2662866567674338
  - 0.3248844343472819
  - 0.2716709599721227
  - 0.13178389406295174
  - 0.18972780937312478
  - 0.43283488179067714
  - 0.28269666872845556
  - 0.45932052990132144
  - 0.40976426180471476
  - 0.3428058716779283
  - 0.28532553894758955
  - 0.45466184969378104
  - 0.185196398730731
  TT_f1_micro:
  - 0.45447670901391407
  - 0.5018796992481203
  - 0.5499686716791979
  - 0.33654448621553884
  - 0.42993558165971957
  - 0.34921507064364204
  - 0.14419152276295133
  - 0.21860282574568288
  - 0.6836680560818492
  - 0.36946624803767664
  - 0.7986656200941915
  - 0.6397174254317112
  - 0.46904130352406215
  - 0.37441130298273156
  - 0.7883045525902669
  - 0.21287284144427002
  TT_f1_weighted:
  - 0.6022942008655628
  - 0.6550461063178615
  - 0.6995212903485948
  - 0.4852222164143761
  - 0.576260426619407
  - 0.5022327131354568
  - 0.23282093354909428
  - 0.337284545846613
  - 0.7909188902631001
  - 0.5246958700607404
  - 0.8779122640637343
  - 0.7648151852217496
  - 0.6158612092126488
  - 0.5303212928637092
  - 0.8718407837720764
  - 0.32984942470200507
  TT_matthews_corrcoef:
  - 0.023742180150049072
  - 0.018614306788822275
  - 0.0017464545022586376
  - 0.02473482606366565
  - 0.018891997487413548
  - 0.028451143715249576
  - 0.021115596376065627
  - 0.016855680685451943
  - 0.020425076583957705
  - 0.02188915288575406
  - 0.0233271942703107
  - 0.020094937238506857
  - 0.01837780263334879
  - 0.025860852460841622
  - 0.01867095242413756
  - -0.006653644485699285
  TT_precision_macro:
  - 0.50375638631456
  - 0.5022595884214793
  - 0.5001897888891492
  - 0.5034904994175675
  - 0.5031570212916211
  - 0.5036367627113538
  - 0.5035592591451359
  - 0.502742644597639
  - 0.5034694430916543
  - 0.5027661817273537
  - 0.503114328228763
  - 0.5027969078301593
  - 0.5029317607001218
  - 0.5032081768668788
  - 0.5024028535294024
  - 0.4988887429885882
  TT_precision_micro:
  - 0.45447670901391407
  - 0.5018796992481203
  - 0.5499686716791979
  - 0.33654448621553884
  - 0.42993558165971957
  - 0.34921507064364204
  - 0.14419152276295133
  - 0.21860282574568288
  - 0.6836680560818492
  - 0.36946624803767664
  - 0.7986656200941915
  - 0.6397174254317112
  - 0.46904130352406215
  - 0.37441130298273156
  - 0.7883045525902669
  - 0.21287284144427002
  TT_precision_weighted:
  - 0.9546007809776116
  - 0.9727903185439805
  - 0.9767977403951
  - 0.96957651178568
  - 0.9491096034996078
  - 0.9753748037288819
  - 0.9799250849907806
  - 0.96959804214985
  - 0.9528717972481685
  - 0.9739677207825677
  - 0.9787624129915068
  - 0.9664235253458386
  - 0.9524924487333457
  - 0.975412483312315
  - 0.9792884184957171
  - 0.962192220252563
  TT_recall_macro:
  - 0.5375155183116077
  - 0.5383357887142948
  - 0.5040177580233124
  - 0.5438197767145135
  - 0.5282629998419472
  - 0.5556447892639966
  - 0.5313175012085202
  - 0.5258978115150708
  - 0.5300612909939394
  - 0.5433029227000837
  - 0.543681811337285
  - 0.536094012311136
  - 0.5288004090525099
  - 0.5521155564166317
  - 0.5362698412698412
  - 0.49004033619418236
  TT_recall_micro:
  - 0.45447670901391407
  - 0.5018796992481203
  - 0.5499686716791979
  - 0.33654448621553884
  - 0.42993558165971957
  - 0.34921507064364204
  - 0.14419152276295133
  - 0.21860282574568288
  - 0.6836680560818492
  - 0.36946624803767664
  - 0.7986656200941915
  - 0.6397174254317112
  - 0.46904130352406215
  - 0.37441130298273156
  - 0.7883045525902669
  - 0.21287284144427002
  TT_recall_weighted:
  - 0.45447670901391407
  - 0.5018796992481203
  - 0.5499686716791979
  - 0.33654448621553884
  - 0.42993558165971957
  - 0.34921507064364204
  - 0.14419152276295136
  - 0.21860282574568288
  - 0.6836680560818492
  - 0.36946624803767664
  - 0.7986656200941915
  - 0.6397174254317112
  - 0.46904130352406215
  - 0.37441130298273156
  - 0.7883045525902669
  - 0.21287284144427002
  TT_roc_auc:
  - 0.5408314027814726
  - 0.5595300488259338
  - 0.5245256715028132
  - 0.5777637874590783
  - 0.5432858121279174
  - 0.6064852170266303
  - 0.5681184128587493
  - 0.5737527411550584
  - 0.544640832633776
  - 0.6168886029591227
  - 0.5306900658444101
  - 0.5536457040973789
  - 0.528048294147591
  - 0.5822769005564704
  - 0.5078151927437642
  - 0.5363743351909033
  fit_time:
  - 26.488539695739746
  - 22.52314853668213
  - 26.251654624938965
  - 11.864058256149292
  - 32.511672496795654
  - 13.367077589035034
  - 13.821633577346802
  - 27.04726815223694
  - 38.697168588638306
  - 13.127054452896118
  - 31.40201497077942
  - 20.253528118133545
  - 28.95087456703186
  - 11.638203859329224
  - 31.641560792922974
  - 14.790454626083374
  score_time:
  - 217.30007696151733
  - 195.93871641159058
  - 224.51516675949097
  - 139.12754559516907
  - 268.0549545288086
  - 129.10183238983154
  - 138.72307181358337
  - 210.78774881362915
  - 264.13369512557983
  - 127.5845730304718
  - 241.41494727134705
  - 185.1080093383789
  - 228.3352153301239
  - 135.58420324325562
  - 253.53849530220032
  - 149.7887659072876
start: 2023-10-05 17:25:36.646167
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
