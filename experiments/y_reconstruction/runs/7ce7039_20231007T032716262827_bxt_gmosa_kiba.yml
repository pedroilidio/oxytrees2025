active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-07 04:44:54.408923
estimator:
  call: bipartite_adaptations.estimators.bxt_gmosa
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gmosa
  params: {}
hash: 7ce70399918576cef545f24ce652caa18b3d4d44c46c5e7322128dd40f8d3f4a
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/7ce7039_20231007T032716262827_bxt_gmosa_kiba.yml"
results:
  LL_average_precision:
  - 0.9998897858123101
  - 0.999929313826253
  - 0.9998775715966367
  - 0.9999412477804167
  - 0.9999367044855849
  - 0.999945772670135
  - 0.9999199600745552
  - 0.9999543590876074
  - 0.9996925625734696
  - 0.9996740736950989
  - 0.9998246283140805
  - 0.999885764820174
  - 0.9998046988825198
  - 0.9998175975934626
  - 0.99967535936605
  - 0.9998388849024283
  LL_balanced_accuracy:
  - 0.9647662580128942
  - 0.9799752073996377
  - 0.9649790775739182
  - 0.9746260074296511
  - 0.9821773461231752
  - 0.9808476551121468
  - 0.9762339110165197
  - 0.9804979784489856
  - 0.9674171814103978
  - 0.9655397769820415
  - 0.9754788233510514
  - 0.9806545719755675
  - 0.9691091588836873
  - 0.9716761186062534
  - 0.9624875874650717
  - 0.971279995964617
  LL_f1_macro:
  - 0.9188261167516691
  - 0.9507281212174481
  - 0.9208499177534047
  - 0.9396345406371507
  - 0.9573732112420723
  - 0.9531763173585328
  - 0.9450931196118133
  - 0.9532303913494681
  - 0.9242755349550993
  - 0.9183782337576556
  - 0.9429108621710293
  - 0.9529996149703365
  - 0.9294123694952965
  - 0.9332370048581371
  - 0.9171141393472719
  - 0.9335745526092033
  LL_f1_micro:
  - 0.9433897441012512
  - 0.9676063993888554
  - 0.94405676592869
  - 0.9591590885718903
  - 0.9714325822980276
  - 0.9690901878975745
  - 0.9621046291263277
  - 0.9686788405882266
  - 0.9476196281396269
  - 0.9442257121450293
  - 0.9607934595777814
  - 0.9688257503415652
  - 0.9506431271782149
  - 0.9544280009396289
  - 0.9403776133427296
  - 0.954024254169603
  LL_f1_weighted:
  - 0.9459175837965309
  - 0.9685405628037567
  - 0.9464543913519763
  - 0.9605611923965073
  - 0.9721319333618106
  - 0.9699339442570771
  - 0.963262795556582
  - 0.9695207437547364
  - 0.9498219215956298
  - 0.9467875174367055
  - 0.9620461696338694
  - 0.9696759758981044
  - 0.952553836772106
  - 0.9561421227121268
  - 0.942995717179434
  - 0.9557187461371197
  LL_matthews_corrcoef:
  - 0.8495619206900427
  - 0.9060089999936997
  - 0.8530586456729853
  - 0.8860150024272232
  - 0.9181848192843597
  - 0.9104775514563582
  - 0.895809406034216
  - 0.9105782522907716
  - 0.8589790781487785
  - 0.8487782726816979
  - 0.8918832769747826
  - 0.9101550015866472
  - 0.8679471463226431
  - 0.8746637177092715
  - 0.8466417520939462
  - 0.8752645247572423
  LL_precision_macro:
  - 0.8882357231420028
  - 0.9275493272437529
  - 0.891259030811845
  - 0.9134953480411987
  - 0.9371126978189093
  - 0.9309937684486718
  - 0.9212606837606838
  - 0.9314028314028314
  - 0.8946394602306503
  - 0.886875940465726
  - 0.9182393309028523
  - 0.9308614622702984
  - 0.9014695911087527
  - 0.9054883154449265
  - 0.8874710780442523
  - 0.9063868585863115
  LL_precision_micro:
  - 0.9433897441012512
  - 0.9676063993888554
  - 0.94405676592869
  - 0.9591590885718903
  - 0.9714325822980276
  - 0.9690901878975745
  - 0.9621046291263277
  - 0.9686788405882266
  - 0.9476196281396269
  - 0.9442257121450293
  - 0.9607934595777814
  - 0.9688257503415652
  - 0.9506431271782149
  - 0.9544280009396289
  - 0.9403776133427296
  - 0.954024254169603
  LL_precision_weighted:
  - 0.956043752727791
  - 0.9723002757034046
  - 0.9562234089135582
  - 0.9662249462294281
  - 0.9750256379571425
  - 0.9733561271998705
  - 0.9680723403087842
  - 0.972975926293883
  - 0.9586572766446831
  - 0.9568445398646042
  - 0.9672045655335912
  - 0.9731364344139748
  - 0.9603694328996625
  - 0.9630421737391046
  - 0.9537960991326724
  - 0.9626321221616445
  LL_recall_macro:
  - 0.9647662580128942
  - 0.9799752073996377
  - 0.9649790775739182
  - 0.9746260074296511
  - 0.9821773461231752
  - 0.9808476551121468
  - 0.9762339110165197
  - 0.9804979784489856
  - 0.9674171814103978
  - 0.9655397769820415
  - 0.9754788233510514
  - 0.9806545719755675
  - 0.9691091588836873
  - 0.9716761186062534
  - 0.9624875874650717
  - 0.971279995964617
  LL_recall_micro:
  - 0.9433897441012512
  - 0.9676063993888554
  - 0.94405676592869
  - 0.9591590885718903
  - 0.9714325822980276
  - 0.9690901878975745
  - 0.9621046291263277
  - 0.9686788405882266
  - 0.9476196281396269
  - 0.9442257121450293
  - 0.9607934595777814
  - 0.9688257503415652
  - 0.9506431271782149
  - 0.9544280009396289
  - 0.9403776133427296
  - 0.954024254169603
  LL_recall_weighted:
  - 0.9433897441012512
  - 0.9676063993888554
  - 0.94405676592869
  - 0.9591590885718903
  - 0.9714325822980276
  - 0.9690901878975745
  - 0.9621046291263277
  - 0.9686788405882266
  - 0.9476196281396269
  - 0.9442257121450293
  - 0.9607934595777814
  - 0.9688257503415652
  - 0.9506431271782149
  - 0.9544280009396289
  - 0.9403776133427296
  - 0.954024254169603
  LL_roc_auc:
  - 0.9999721045854811
  - 0.9999829119411531
  - 0.9999679543276071
  - 0.9999855074315154
  - 0.9999840138482416
  - 0.9999868379280382
  - 0.9999792547624599
  - 0.9999886565813805
  - 0.9999220057249105
  - 0.9999200848337003
  - 0.9999550715783916
  - 0.9999720882072405
  - 0.9999489953606735
  - 0.9999542177666629
  - 0.9999116923988558
  - 0.9999586505257034
  LT_average_precision:
  - 0.4600993690654909
  - 0.39961791750041253
  - 0.4176826232452968
  - 0.3895907727332222
  - 0.463697075945295
  - 0.4130134738836975
  - 0.4293267806428816
  - 0.39425372694600275
  - 0.4579173377472352
  - 0.4062836113913987
  - 0.41434973988755663
  - 0.3887325929267821
  - 0.46360850966660094
  - 0.404674281875278
  - 0.42452416811258126
  - 0.3897501337330401
  LT_balanced_accuracy:
  - 0.7356047028843787
  - 0.7079907036656337
  - 0.7218844220300138
  - 0.7078120935646561
  - 0.7365517547420697
  - 0.7143368604282693
  - 0.7249863097068624
  - 0.7069944423999996
  - 0.7361477289887661
  - 0.7119455256023306
  - 0.7217104572344226
  - 0.7069954070544447
  - 0.7347723229680312
  - 0.711434042195494
  - 0.7243921087364081
  - 0.7087567623578421
  LT_f1_macro:
  - 0.6585087514276345
  - 0.6567072684731007
  - 0.6347211317958481
  - 0.6547017169200919
  - 0.6729707492119965
  - 0.6596956943516419
  - 0.6418176515439649
  - 0.6537350003515368
  - 0.6635272976484342
  - 0.6506476444544724
  - 0.6383983777365567
  - 0.6561502084158576
  - 0.6599849413504282
  - 0.6542200644617853
  - 0.6331419898023092
  - 0.651038123709792
  LT_f1_micro:
  - 0.7198466464809289
  - 0.7204397601711163
  - 0.7027518258691581
  - 0.7275548314880694
  - 0.740714923649988
  - 0.7199853708814044
  - 0.7098004011924948
  - 0.7249947357338385
  - 0.7283747576622301
  - 0.7088362092850573
  - 0.7091021932595227
  - 0.730292249891944
  - 0.7193921978404737
  - 0.7107146021619706
  - 0.6939903420166578
  - 0.7172713981924509
  LT_f1_weighted:
  - 0.7469657137737143
  - 0.7422276234140385
  - 0.7354970569686969
  - 0.7502882516180616
  - 0.7635632627552108
  - 0.7421270915227358
  - 0.7407445716188786
  - 0.747852584549455
  - 0.7541596149237755
  - 0.733451591849371
  - 0.7407300962007969
  - 0.7522805791451923
  - 0.7457651708273569
  - 0.7338774400194269
  - 0.7271110014920648
  - 0.7414157714683335
  LT_matthews_corrcoef:
  - 0.3838366240069691
  - 0.3539342374295943
  - 0.3501301690956513
  - 0.34957865808394556
  - 0.3937186487459988
  - 0.3637095226425586
  - 0.35823018285122615
  - 0.34840292378240284
  - 0.3867117310787177
  - 0.355061593988419
  - 0.3513710144317999
  - 0.34973267771110916
  - 0.3849191473267663
  - 0.3577906312009942
  - 0.35507618152025033
  - 0.34938444706257643
  LT_precision_macro:
  - 0.6563323568305094
  - 0.6505709656935579
  - 0.6381249911433245
  - 0.6470141079033866
  - 0.6638271237296455
  - 0.6542952255115595
  - 0.6425963029404148
  - 0.6466036912546196
  - 0.6583182311283338
  - 0.6487041719414938
  - 0.6392148923903618
  - 0.6477242268312883
  - 0.6577728031414292
  - 0.6513641493653641
  - 0.6404673891976144
  - 0.6461862725672759
  LT_precision_micro:
  - 0.7198466464809289
  - 0.7204397601711163
  - 0.7027518258691581
  - 0.7275548314880695
  - 0.740714923649988
  - 0.7199853708814044
  - 0.7098004011924948
  - 0.7249947357338387
  - 0.7283747576622301
  - 0.7088362092850572
  - 0.7091021932595227
  - 0.730292249891944
  - 0.7193921978404737
  - 0.7107146021619706
  - 0.6939903420166578
  - 0.7172713981924508
  LT_precision_weighted:
  - 0.8205191947714959
  - 0.7930255379020913
  - 0.8227004086553438
  - 0.8006185693003448
  - 0.8189742326755752
  - 0.7962407200236453
  - 0.8220927792122426
  - 0.7990352647423735
  - 0.8208620682683879
  - 0.7970121284960547
  - 0.8222352526139999
  - 0.7999146333989985
  - 0.8177800821552917
  - 0.7932021393341443
  - 0.8218564079838522
  - 0.7988276164945298
  LT_recall_macro:
  - 0.7356047028843787
  - 0.7079907036656337
  - 0.7218844220300138
  - 0.7078120935646561
  - 0.7365517547420697
  - 0.7143368604282693
  - 0.7249863097068624
  - 0.7069944423999996
  - 0.7361477289887661
  - 0.7119455256023306
  - 0.7217104572344226
  - 0.7069954070544447
  - 0.7347723229680312
  - 0.711434042195494
  - 0.7243921087364081
  - 0.7087567623578421
  LT_recall_micro:
  - 0.7198466464809289
  - 0.7204397601711163
  - 0.7027518258691581
  - 0.7275548314880695
  - 0.740714923649988
  - 0.7199853708814044
  - 0.7098004011924948
  - 0.7249947357338387
  - 0.7283747576622301
  - 0.7088362092850572
  - 0.7091021932595227
  - 0.730292249891944
  - 0.7193921978404737
  - 0.7107146021619706
  - 0.6939903420166578
  - 0.7172713981924508
  LT_recall_weighted:
  - 0.7198466464809289
  - 0.7204397601711163
  - 0.7027518258691581
  - 0.7275548314880695
  - 0.740714923649988
  - 0.7199853708814044
  - 0.7098004011924948
  - 0.7249947357338387
  - 0.7283747576622301
  - 0.7088362092850572
  - 0.7091021932595227
  - 0.730292249891944
  - 0.7193921978404737
  - 0.7107146021619706
  - 0.6939903420166578
  - 0.7172713981924508
  LT_roc_auc:
  - 0.8095600001631569
  - 0.7631426718618174
  - 0.7785158347155045
  - 0.7644033798123093
  - 0.8151642152325353
  - 0.767313728636485
  - 0.7796506709162427
  - 0.7641756710453286
  - 0.8105860401519929
  - 0.7656714903408954
  - 0.7787055029025179
  - 0.7618803788698004
  - 0.8092670408927896
  - 0.7635031099343695
  - 0.7784692999122524
  - 0.76148357080692
  TL_average_precision:
  - 0.7092991368166215
  - 0.7044325573455111
  - 0.7054115941454986
  - 0.6959401901510635
  - 0.6730381392565523
  - 0.6614650017665513
  - 0.6654350876807962
  - 0.6532836860753136
  - 0.7053027431078833
  - 0.6924113694232624
  - 0.7062879407969613
  - 0.6958004296173228
  - 0.6750185190430236
  - 0.6680087777017252
  - 0.6648579654155611
  - 0.6612066438461102
  TL_balanced_accuracy:
  - 0.8132001137994067
  - 0.8167925787141025
  - 0.8110562233761114
  - 0.809524997534669
  - 0.820427189359731
  - 0.815851009458089
  - 0.8117367724751727
  - 0.813294565896808
  - 0.8252590075139303
  - 0.8225483073993958
  - 0.8243147762777066
  - 0.8224195743918645
  - 0.8172709090709303
  - 0.8167290242170562
  - 0.8087631823195364
  - 0.8123158754074947
  TL_f1_macro:
  - 0.7065605033637634
  - 0.7139119653289412
  - 0.7024012767247578
  - 0.7068864988139636
  - 0.7236140189992852
  - 0.7132483215764427
  - 0.7088222081285345
  - 0.7117110085849945
  - 0.7224508555504492
  - 0.7114095001640841
  - 0.7245298824559783
  - 0.726782924084638
  - 0.707141282773374
  - 0.7026059705151728
  - 0.6929010175915478
  - 0.7000394165769219
  TL_f1_micro:
  - 0.7474193691298955
  - 0.7599652043692742
  - 0.7401889534883721
  - 0.7508038231148695
  - 0.771697235513025
  - 0.7635989252995067
  - 0.7516957364341085
  - 0.7597009337561663
  - 0.7634347864611023
  - 0.7535346194503171
  - 0.7637310606060606
  - 0.7707232205778718
  - 0.7564055616587325
  - 0.7545673183001633
  - 0.7365517850050748
  - 0.7501213538678786
  TL_f1_weighted:
  - 0.7716950485707152
  - 0.7834727432147102
  - 0.7647513520768777
  - 0.7748719610449739
  - 0.7935140102699295
  - 0.7874292951236062
  - 0.7754897572510795
  - 0.7834297389557736
  - 0.7856059177267616
  - 0.7779510898646306
  - 0.7851733349676704
  - 0.7918150454898626
  - 0.781810100376704
  - 0.7811932405268147
  - 0.7637635819553229
  - 0.7766970435788907
  TL_matthews_corrcoef:
  - 0.5093984157426197
  - 0.5139992900781234
  - 0.5071810924641734
  - 0.5033687078434351
  - 0.5233732623403143
  - 0.5095136067838749
  - 0.5077833004430033
  - 0.5075503549980401
  - 0.532556075688257
  - 0.5211387358897818
  - 0.5345895696562326
  - 0.5306400866119929
  - 0.5071410481244578
  - 0.5013357259798132
  - 0.4933532920608588
  - 0.49660324125265914
  TL_precision_macro:
  - 0.7071253605348963
  - 0.7084923132300114
  - 0.7067412908197318
  - 0.7046523366885651
  - 0.7137143638466529
  - 0.7054798842841443
  - 0.7067801290825616
  - 0.7055632230016771
  - 0.7179924054373266
  - 0.7104999280840346
  - 0.7202998667415951
  - 0.7183326664104426
  - 0.7026596477486018
  - 0.6983852843649273
  - 0.6970745580470448
  - 0.6974081359944284
  TL_precision_micro:
  - 0.7474193691298955
  - 0.7599652043692742
  - 0.7401889534883721
  - 0.7508038231148696
  - 0.7716972355130249
  - 0.7635989252995067
  - 0.7516957364341085
  - 0.7597009337561663
  - 0.7634347864611023
  - 0.7535346194503171
  - 0.7637310606060606
  - 0.7707232205778718
  - 0.7564055616587325
  - 0.7545673183001633
  - 0.7365517850050748
  - 0.7501213538678787
  TL_precision_weighted:
  - 0.865389995142196
  - 0.8673028321637744
  - 0.8644290354652127
  - 0.8627258253810774
  - 0.8680178001798828
  - 0.8680473435521202
  - 0.8637240890493931
  - 0.8656006773748934
  - 0.8705436712325761
  - 0.8722060410967324
  - 0.8686095582640786
  - 0.8674484996944624
  - 0.8708569464000421
  - 0.872654813033584
  - 0.8672468655200508
  - 0.8693143570989869
  TL_recall_macro:
  - 0.8132001137994067
  - 0.8167925787141025
  - 0.8110562233761114
  - 0.809524997534669
  - 0.820427189359731
  - 0.815851009458089
  - 0.8117367724751727
  - 0.813294565896808
  - 0.8252590075139303
  - 0.8225483073993958
  - 0.8243147762777066
  - 0.8224195743918645
  - 0.8172709090709303
  - 0.8167290242170562
  - 0.8087631823195364
  - 0.8123158754074947
  TL_recall_micro:
  - 0.7474193691298955
  - 0.7599652043692742
  - 0.7401889534883721
  - 0.7508038231148696
  - 0.7716972355130249
  - 0.7635989252995067
  - 0.7516957364341085
  - 0.7597009337561663
  - 0.7634347864611023
  - 0.7535346194503171
  - 0.7637310606060606
  - 0.7707232205778718
  - 0.7564055616587325
  - 0.7545673183001633
  - 0.7365517850050748
  - 0.7501213538678787
  TL_recall_weighted:
  - 0.7474193691298955
  - 0.7599652043692742
  - 0.7401889534883721
  - 0.7508038231148696
  - 0.7716972355130249
  - 0.7635989252995067
  - 0.7516957364341085
  - 0.7597009337561663
  - 0.7634347864611023
  - 0.7535346194503171
  - 0.7637310606060606
  - 0.7707232205778718
  - 0.7564055616587325
  - 0.7545673183001633
  - 0.7365517850050748
  - 0.7501213538678787
  TL_roc_auc:
  - 0.9053930591839081
  - 0.9051622081984623
  - 0.9033852001069214
  - 0.8999565094737212
  - 0.904607242966281
  - 0.9026110790837925
  - 0.899936569064065
  - 0.8991397017606882
  - 0.9109655259256149
  - 0.9104102828944005
  - 0.910804430864373
  - 0.9080771149215232
  - 0.9002002305066534
  - 0.8993013750238841
  - 0.8944440858331923
  - 0.8960575638610333
  TT_average_precision:
  - 0.3627025503919511
  - 0.32793499847540564
  - 0.32775249682306384
  - 0.3044290300463719
  - 0.32956707670915203
  - 0.31919913151551116
  - 0.3157570837680993
  - 0.29090857301190365
  - 0.3479457194816399
  - 0.3196968429674725
  - 0.3225247057038261
  - 0.2902137672832325
  - 0.3360827558734797
  - 0.30577281631015
  - 0.3075711285559019
  - 0.28366785102710956
  TT_balanced_accuracy:
  - 0.6510725952783488
  - 0.6246875753682621
  - 0.6461622330993586
  - 0.6149105626226504
  - 0.6459973403140244
  - 0.6257568662712935
  - 0.648709456338667
  - 0.6067199923364307
  - 0.6554335472369625
  - 0.627923694166743
  - 0.6525225824380181
  - 0.6057638196935244
  - 0.6494831571001848
  - 0.6273143260151867
  - 0.6553105181774797
  - 0.6211036254247163
  TT_f1_macro:
  - 0.5502628857977339
  - 0.5652901851355939
  - 0.5373110774100345
  - 0.555717655175092
  - 0.5699761856837106
  - 0.5612174966560198
  - 0.5397293592464525
  - 0.5477288726820633
  - 0.5677334950679197
  - 0.5556779522292913
  - 0.5547447469276917
  - 0.5580532713955827
  - 0.5531806501941294
  - 0.5575900835867555
  - 0.5259943310296091
  - 0.552655165558256
  TT_f1_micro:
  - 0.5873824451410659
  - 0.6154970760233918
  - 0.5768872939925571
  - 0.6135034556087188
  - 0.6266653605015674
  - 0.6105462519936204
  - 0.586190855927698
  - 0.6092171717171717
  - 0.6109587251828631
  - 0.5934675704412546
  - 0.601475279106858
  - 0.6266613503455609
  - 0.6022377805404698
  - 0.6098072505742534
  - 0.5672958487299844
  - 0.6140683777755584
  TT_f1_weighted:
  - 0.6282232424181121
  - 0.6494755760943086
  - 0.6217960932684304
  - 0.6503130211327739
  - 0.6653775562378735
  - 0.6462363959555489
  - 0.6333617626189271
  - 0.6479320266652031
  - 0.6492383176514458
  - 0.628510261865109
  - 0.644496125962263
  - 0.661167893005172
  - 0.6459087014727966
  - 0.6479632250173468
  - 0.6176942271576441
  - 0.6545856479742693
  TT_matthews_corrcoef:
  - 0.2410461482140218
  - 0.20617258067143718
  - 0.22852862463579787
  - 0.18710518928105893
  - 0.23269404902533095
  - 0.20615283678757315
  - 0.22846143192849655
  - 0.17222491452868421
  - 0.24972392158186335
  - 0.2116566336913495
  - 0.23888399404768845
  - 0.17381728907653274
  - 0.2332191446945081
  - 0.20560990453213665
  - 0.2351089259537234
  - 0.19252928767342942
  TT_precision_macro:
  - 0.5961512004572402
  - 0.5852272828611358
  - 0.5893276792001864
  - 0.5761643469862366
  - 0.5927183336616609
  - 0.5844864248284489
  - 0.587745976557053
  - 0.5694842187837357
  - 0.6003033742052353
  - 0.5875493216431844
  - 0.5935362516487784
  - 0.5714148989452694
  - 0.5909653811626158
  - 0.5830138959316163
  - 0.5889769213826636
  - 0.5765202661812157
  TT_precision_micro:
  - 0.5873824451410659
  - 0.6154970760233918
  - 0.5768872939925571
  - 0.6135034556087188
  - 0.6266653605015674
  - 0.6105462519936204
  - 0.586190855927698
  - 0.6092171717171717
  - 0.6109587251828631
  - 0.5934675704412546
  - 0.601475279106858
  - 0.6266613503455609
  - 0.6022377805404698
  - 0.6098072505742534
  - 0.5672958487299844
  - 0.6140683777755584
  TT_precision_weighted:
  - 0.7798576185210386
  - 0.7422529793924998
  - 0.7864228208960986
  - 0.7445504591700595
  - 0.7728705645829113
  - 0.7469353545978619
  - 0.793000596609591
  - 0.7443092116908543
  - 0.7759050969953835
  - 0.7444664010603584
  - 0.7856114818554956
  - 0.7384665204003076
  - 0.7850290625381894
  - 0.7552183246009727
  - 0.8075305708006334
  - 0.759680093348444
  TT_recall_macro:
  - 0.6510725952783488
  - 0.6246875753682621
  - 0.6461622330993586
  - 0.6149105626226504
  - 0.6459973403140244
  - 0.6257568662712935
  - 0.648709456338667
  - 0.6067199923364307
  - 0.6554335472369625
  - 0.627923694166743
  - 0.6525225824380181
  - 0.6057638196935244
  - 0.6494831571001848
  - 0.6273143260151867
  - 0.6553105181774797
  - 0.6211036254247163
  TT_recall_micro:
  - 0.5873824451410659
  - 0.6154970760233918
  - 0.5768872939925571
  - 0.6135034556087188
  - 0.6266653605015674
  - 0.6105462519936204
  - 0.586190855927698
  - 0.6092171717171717
  - 0.6109587251828631
  - 0.5934675704412546
  - 0.601475279106858
  - 0.6266613503455609
  - 0.6022377805404698
  - 0.6098072505742534
  - 0.5672958487299844
  - 0.6140683777755584
  TT_recall_weighted:
  - 0.5873824451410659
  - 0.6154970760233918
  - 0.5768872939925571
  - 0.6135034556087188
  - 0.6266653605015674
  - 0.6105462519936204
  - 0.586190855927698
  - 0.6092171717171717
  - 0.6109587251828631
  - 0.5934675704412546
  - 0.601475279106858
  - 0.6266613503455607
  - 0.6022377805404698
  - 0.6098072505742534
  - 0.5672958487299844
  - 0.6140683777755584
  TT_roc_auc:
  - 0.717046724963315
  - 0.6769552311305143
  - 0.6950602679060419
  - 0.6631699722868265
  - 0.707137359010126
  - 0.6791602588876224
  - 0.7038847749261111
  - 0.6604638339383047
  - 0.7169520792407467
  - 0.6758955612275792
  - 0.7059739277969436
  - 0.664060363889664
  - 0.7126664755388643
  - 0.6738804051660974
  - 0.7063594160605995
  - 0.6661392121708748
  fit_time:
  - 3426.748107433319
  - 3404.300750017166
  - 3374.4691274166107
  - 4042.332729578018
  - 4608.940569162369
  - 4404.555571556091
  - 3999.2062175273895
  - 4172.482474803925
  - 4084.4083223342896
  - 3747.8776395320892
  - 3700.2186794281006
  - 4138.976558685303
  - 3886.3472838401794
  - 3953.2730708122253
  - 3680.096256017685
  - 4079.7508792877197
  score_time:
  - 63.094388008117676
  - 54.87606620788574
  - 55.90981149673462
  - 42.086846590042114
  - 48.36956524848938
  - 42.33971619606018
  - 49.55632662773132
  - 46.47009778022766
  - 45.530853271484375
  - 45.32181906700134
  - 46.323397636413574
  - 46.68247890472412
  - 46.52679109573364
  - 43.650388956069946
  - 45.78586935997009
  - 48.069754123687744
start: 2023-10-07 03:27:16.262827
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
