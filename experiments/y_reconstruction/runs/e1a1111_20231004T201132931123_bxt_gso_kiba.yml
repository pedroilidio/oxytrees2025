active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-04 21:03:38.568448
estimator:
  call: bipartite_adaptations.estimators.bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gso
  params: {}
hash: e1a1111115970f6e8b556b553b3893264b386f631c19157d9618352068b87867
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/e1a1111_20231004T201132931123_bxt_gso_kiba.yml"
results:
  LL_average_precision:
  - 0.9999566806684411
  - 0.9999633477328573
  - 0.9998436465462113
  - 0.9999090118804305
  - 0.9999501811186547
  - 0.9998746287178774
  - 0.9997542583797396
  - 0.9999538414080343
  - 0.999642547942181
  - 0.9997066362419875
  - 0.9996141822747218
  - 0.9998395004528967
  - 0.9997180843395241
  - 0.9997447757270056
  - 0.9996886197613906
  - 0.9996834731248034
  LL_balanced_accuracy:
  - 0.9827418123626197
  - 0.9809991508761414
  - 0.962631627350899
  - 0.9720155894889605
  - 0.9820367561986328
  - 0.9725162940576755
  - 0.9623722785778122
  - 0.9809622033991328
  - 0.9606956393852489
  - 0.970112235126463
  - 0.9622247540991138
  - 0.9748381803263744
  - 0.9610173251198062
  - 0.9692078164422686
  - 0.9626515483915664
  - 0.9605472529588988
  LL_f1_macro:
  - 0.9582890721699683
  - 0.9531090934568137
  - 0.9160253039665014
  - 0.9338895445595534
  - 0.957053543155139
  - 0.9343489571211427
  - 0.9160036383987065
  - 0.954285153747471
  - 0.910196888946359
  - 0.9283291105767506
  - 0.914935855761605
  - 0.9398470312980154
  - 0.9126722278700025
  - 0.9278899679905377
  - 0.9174447231015639
  - 0.9111605138419736
  LL_f1_micro:
  - 0.9722711706619677
  - 0.9692628068577472
  - 0.9403068944747242
  - 0.9549574696264085
  - 0.9712072347641054
  - 0.9556442727232661
  - 0.9400020567365467
  - 0.9694244075864197
  - 0.9368140291769643
  - 0.9516262909694575
  - 0.9396017276586993
  - 0.9594529080785673
  - 0.9377141296000945
  - 0.9504566008926474
  - 0.9406382135306554
  - 0.9368429938924125
  LL_f1_weighted:
  - 0.9729408125907022
  - 0.9701087568821664
  - 0.9430023797219401
  - 0.956638473588699
  - 0.9719171098109224
  - 0.9573027615866051
  - 0.9426958105979072
  - 0.9702287773695494
  - 0.939903236459973
  - 0.9536029532102687
  - 0.942368325415765
  - 0.9608453637517184
  - 0.9406268539176496
  - 0.9524551601328167
  - 0.9432357546860521
  - 0.9398597696761195
  LL_matthews_corrcoef:
  - 0.9198734838907467
  - 0.9103537284407114
  - 0.8447674373510713
  - 0.8758152719532657
  - 0.9175958696987899
  - 0.8766244158771153
  - 0.8447338570664128
  - 0.9125092551935373
  - 0.8348286517368982
  - 0.8660347847008018
  - 0.8429030072118647
  - 0.8863933693822295
  - 0.8390455541902176
  - 0.8652746046827708
  - 0.8472086134140983
  - 0.8364726328620095
  LL_precision_macro:
  - 0.9382089994566738
  - 0.9307408388228673
  - 0.8856372873246176
  - 0.906264330918096
  - 0.9366794488496035
  - 0.906584056558531
  - 0.8858229192876513
  - 0.9328163080846393
  - 0.8781991938814749
  - 0.8988495683961539
  - 0.8842748972583461
  - 0.9136636636636637
  - 0.8817630074007625
  - 0.8989171297197718
  - 0.8878526058857792
  - 0.8798125279392043
  LL_precision_micro:
  - 0.9722711706619677
  - 0.9692628068577472
  - 0.9403068944747242
  - 0.9549574696264085
  - 0.9712072347641054
  - 0.9556442727232661
  - 0.9400020567365467
  - 0.9694244075864197
  - 0.9368140291769643
  - 0.9516262909694575
  - 0.9396017276586993
  - 0.9594529080785673
  - 0.9377141296000945
  - 0.9504566008926474
  - 0.9406382135306554
  - 0.9368429938924125
  LL_precision_weighted:
  - 0.9756979548793518
  - 0.9735204712856912
  - 0.9539602254265009
  - 0.9634016530698296
  - 0.974853582291867
  - 0.9639313369444433
  - 0.9537028367576792
  - 0.973532769948107
  - 0.9522062335402189
  - 0.961412334062894
  - 0.9535809202029301
  - 0.9664542828097455
  - 0.9524431175951159
  - 0.9604725788630676
  - 0.9539527528556591
  - 0.9520243557064109
  LL_recall_macro:
  - 0.9827418123626197
  - 0.9809991508761414
  - 0.962631627350899
  - 0.9720155894889605
  - 0.9820367561986328
  - 0.9725162940576755
  - 0.9623722785778122
  - 0.9809622033991328
  - 0.9606956393852489
  - 0.970112235126463
  - 0.9622247540991138
  - 0.9748381803263744
  - 0.9610173251198062
  - 0.9692078164422686
  - 0.9626515483915664
  - 0.9605472529588988
  LL_recall_micro:
  - 0.9722711706619677
  - 0.9692628068577472
  - 0.9403068944747242
  - 0.9549574696264085
  - 0.9712072347641054
  - 0.9556442727232661
  - 0.9400020567365467
  - 0.9694244075864197
  - 0.9368140291769643
  - 0.9516262909694575
  - 0.9396017276586993
  - 0.9594529080785673
  - 0.9377141296000945
  - 0.9504566008926474
  - 0.9406382135306554
  - 0.9368429938924125
  LL_recall_weighted:
  - 0.9722711706619677
  - 0.9692628068577472
  - 0.9403068944747242
  - 0.9549574696264085
  - 0.9712072347641054
  - 0.9556442727232661
  - 0.9400020567365467
  - 0.9694244075864197
  - 0.9368140291769643
  - 0.9516262909694575
  - 0.9396017276586993
  - 0.9594529080785673
  - 0.9377141296000945
  - 0.9504566008926474
  - 0.9406382135306554
  - 0.9368429938924125
  LL_roc_auc:
  - 0.9999892575578032
  - 0.9999912472263982
  - 0.9999587479241648
  - 0.9999773110485584
  - 0.9999874663894674
  - 0.9999689850366035
  - 0.9999338940283717
  - 0.9999885296872966
  - 0.9999086090098774
  - 0.9999283239863094
  - 0.999898417214009
  - 0.9999605858573855
  - 0.999925452389029
  - 0.9999352123259174
  - 0.9999153922143909
  - 0.9999169163337472
  LT_average_precision:
  - 0.4581365557902745
  - 0.40795913552311
  - 0.4191879968533306
  - 0.3923471339142863
  - 0.4663836111121112
  - 0.41120731000565175
  - 0.42914115910012873
  - 0.39475978847639603
  - 0.4707435112510452
  - 0.41361066970592636
  - 0.41762003213406607
  - 0.3928409509693177
  - 0.4685658606291005
  - 0.406814936663632
  - 0.4221933940101023
  - 0.3948180609543955
  LT_balanced_accuracy:
  - 0.7350987054220297
  - 0.7077612753644409
  - 0.7229297596506681
  - 0.7069770946633419
  - 0.7441581658239538
  - 0.7092438309754605
  - 0.7213777671709494
  - 0.7085706350069816
  - 0.7358794356257716
  - 0.7080596827848356
  - 0.7198578195983096
  - 0.7078259886980536
  - 0.7335174860696446
  - 0.7079464248562715
  - 0.7208018011831967
  - 0.7124862387382779
  LT_f1_macro:
  - 0.6664722314603858
  - 0.6539512617834244
  - 0.6311352258091686
  - 0.6551958696963737
  - 0.669145045568692
  - 0.6500546658685622
  - 0.6331676934537678
  - 0.6605537292963386
  - 0.6453886187089206
  - 0.6467545353023554
  - 0.6292816891523485
  - 0.6580302812009554
  - 0.6434709068009249
  - 0.6476647365278827
  - 0.6314329226787521
  - 0.651204152577719
  LT_f1_micro:
  - 0.7325571263641709
  - 0.716006693930024
  - 0.6964125411443961
  - 0.7289734126852191
  - 0.7304223756725555
  - 0.7074841240815242
  - 0.6980306103223948
  - 0.735235118750762
  - 0.7003071427015488
  - 0.704935110992896
  - 0.6955037625649721
  - 0.7328301803149694
  - 0.694379136189481
  - 0.7021863370547581
  - 0.6932482721956407
  - 0.71506734006734
  LT_f1_weighted:
  - 0.7572114216148013
  - 0.7386769838367077
  - 0.7303341135398691
  - 0.7513180847088424
  - 0.7558076568830465
  - 0.7316386528634593
  - 0.7309578319186896
  - 0.7559510300092958
  - 0.7310129996067595
  - 0.7300128631625208
  - 0.7295577032429393
  - 0.7543218574893159
  - 0.7247838840908039
  - 0.7266571210173373
  - 0.7263660262504209
  - 0.7399289215718154
  LT_matthews_corrcoef:
  - 0.3875492739993625
  - 0.35198214679398415
  - 0.35007557711960996
  - 0.3489759931689885
  - 0.4003807495739212
  - 0.35207902847691586
  - 0.34999454457747403
  - 0.35498742379828413
  - 0.3782580006103287
  - 0.34815959132974844
  - 0.345223919039654
  - 0.3520045736559718
  - 0.37676505188831977
  - 0.3500630651564569
  - 0.3497040021156791
  - 0.35402783044395153
  LT_precision_macro:
  - 0.659714235248357
  - 0.6490790709726582
  - 0.6374344433507543
  - 0.6470986970881606
  - 0.66414026547955
  - 0.6481042974067256
  - 0.6383338792321014
  - 0.6510472352096981
  - 0.6516443290680942
  - 0.645649435071296
  - 0.6355188940912406
  - 0.6490516424954255
  - 0.6519713862906098
  - 0.6473265886531038
  - 0.638464551059366
  - 0.6474633198284772
  LT_precision_micro:
  - 0.732557126364171
  - 0.716006693930024
  - 0.6964125411443961
  - 0.7289734126852191
  - 0.7304223756725554
  - 0.7074841240815241
  - 0.6980306103223948
  - 0.735235118750762
  - 0.7003071427015488
  - 0.704935110992896
  - 0.6955037625649721
  - 0.7328301803149694
  - 0.694379136189481
  - 0.7021863370547581
  - 0.6932482721956407
  - 0.7150673400673401
  LT_precision_weighted:
  - 0.8192510269841707
  - 0.793054460113841
  - 0.8240210508772522
  - 0.8001132745171892
  - 0.8241807460276631
  - 0.7936926755049484
  - 0.821130951581443
  - 0.7998700958800226
  - 0.823732900519885
  - 0.7947613753314162
  - 0.8225065432006914
  - 0.8003822847912434
  - 0.8201526001292887
  - 0.7915323984841383
  - 0.8196918834865181
  - 0.8012557324037392
  LT_recall_macro:
  - 0.7350987054220297
  - 0.7077612753644409
  - 0.7229297596506681
  - 0.7069770946633419
  - 0.7441581658239538
  - 0.7092438309754605
  - 0.7213777671709494
  - 0.7085706350069816
  - 0.7358794356257716
  - 0.7080596827848356
  - 0.7198578195983096
  - 0.7078259886980536
  - 0.7335174860696446
  - 0.7079464248562715
  - 0.7208018011831967
  - 0.7124862387382779
  LT_recall_micro:
  - 0.732557126364171
  - 0.716006693930024
  - 0.6964125411443961
  - 0.7289734126852191
  - 0.7304223756725554
  - 0.7074841240815241
  - 0.6980306103223948
  - 0.735235118750762
  - 0.7003071427015488
  - 0.704935110992896
  - 0.6955037625649721
  - 0.7328301803149694
  - 0.694379136189481
  - 0.7021863370547581
  - 0.6932482721956407
  - 0.7150673400673401
  LT_recall_weighted:
  - 0.732557126364171
  - 0.716006693930024
  - 0.6964125411443961
  - 0.7289734126852191
  - 0.7304223756725554
  - 0.7074841240815241
  - 0.6980306103223948
  - 0.735235118750762
  - 0.7003071427015488
  - 0.704935110992896
  - 0.6955037625649721
  - 0.7328301803149694
  - 0.694379136189481
  - 0.7021863370547581
  - 0.6932482721956407
  - 0.7150673400673401
  LT_roc_auc:
  - 0.8107169029153004
  - 0.7647124576164614
  - 0.7787449876315187
  - 0.7632252924363236
  - 0.8141985412617458
  - 0.7634697899385088
  - 0.7774384248384025
  - 0.7673458058471867
  - 0.8116152468604555
  - 0.7641793379852964
  - 0.7760029051566686
  - 0.7653088377377613
  - 0.8079007953980241
  - 0.7602840734013603
  - 0.7764679917436557
  - 0.7609557774128026
  TL_average_precision:
  - 0.7050351284132237
  - 0.701058936368905
  - 0.6925252609395921
  - 0.6868418376968402
  - 0.662764338302989
  - 0.6451812778099977
  - 0.6520173304171535
  - 0.6460431674449217
  - 0.6896137942943537
  - 0.6830379834679933
  - 0.6862830189373335
  - 0.6742931099198323
  - 0.665025992216133
  - 0.6555844145538947
  - 0.6582139493996584
  - 0.6430402392001192
  TL_balanced_accuracy:
  - 0.8131986831053916
  - 0.8120266979059931
  - 0.8018728544173854
  - 0.8034137073472991
  - 0.8163320232160202
  - 0.8094808433804692
  - 0.8017083475062586
  - 0.8057645703029513
  - 0.8151336733199006
  - 0.815264197852692
  - 0.8092047268443088
  - 0.8127692686016309
  - 0.8056895869122478
  - 0.8074800677791281
  - 0.8015576015393295
  - 0.7979768201320165
  TL_f1_macro:
  - 0.7162759306431792
  - 0.7053264357020557
  - 0.6878652566311876
  - 0.691838828629813
  - 0.70872960874326
  - 0.6919375615218586
  - 0.682286661796476
  - 0.6942438685004773
  - 0.7028927382892864
  - 0.7023364721921078
  - 0.6949035052010536
  - 0.7041222987739586
  - 0.6828789204940677
  - 0.6835821266766529
  - 0.6806061310034031
  - 0.6679179278926446
  TL_f1_micro:
  - 0.7606215665426193
  - 0.7501431465821
  - 0.7235949612403101
  - 0.732437015503876
  - 0.7532451710083289
  - 0.7369516384778012
  - 0.7189371916842847
  - 0.7387024312896407
  - 0.7407850434166223
  - 0.7439327871740661
  - 0.7291556553911205
  - 0.7438006518675123
  - 0.7274875994540431
  - 0.7319624023652971
  - 0.722220996425577
  - 0.7109350867128548
  TL_f1_weighted:
  - 0.7829999931977984
  - 0.7749690508302179
  - 0.7499567526706559
  - 0.7588616157945964
  - 0.7777736910098398
  - 0.7646369490664902
  - 0.7466737233481239
  - 0.765333919204697
  - 0.7657222321897916
  - 0.7694904629291301
  - 0.7545602621031261
  - 0.7684318452889399
  - 0.7568166939198133
  - 0.7618008186431937
  - 0.7511678689505092
  - 0.7426705262201135
  TL_matthews_corrcoef:
  - 0.5134630323813689
  - 0.5040901990679642
  - 0.49029757801010504
  - 0.4897684993153389
  - 0.5110277195640086
  - 0.4922854110640046
  - 0.4858904969175694
  - 0.49046694737143187
  - 0.5117157678137669
  - 0.5080625169449486
  - 0.5040763386124113
  - 0.5083670024428255
  - 0.4828929034772471
  - 0.48192294747334763
  - 0.4798640679171723
  - 0.46709360587780113
  TL_precision_macro:
  - 0.7104449187080029
  - 0.703593899577895
  - 0.6990835806241431
  - 0.6976453082976827
  - 0.7063886288746482
  - 0.695767307678332
  - 0.6956273143800779
  - 0.6966854974609276
  - 0.7077317097460885
  - 0.7046914325211826
  - 0.7054407105464752
  - 0.7065716129402333
  - 0.6907045301935856
  - 0.6888331567139425
  - 0.6909001153532391
  - 0.6830481617288764
  TL_precision_micro:
  - 0.7606215665426191
  - 0.7501431465821
  - 0.7235949612403101
  - 0.732437015503876
  - 0.7532451710083289
  - 0.7369516384778013
  - 0.7189371916842847
  - 0.7387024312896406
  - 0.7407850434166223
  - 0.7439327871740662
  - 0.7291556553911205
  - 0.7438006518675123
  - 0.7274875994540431
  - 0.7319624023652972
  - 0.722220996425577
  - 0.7109350867128547
  TL_precision_weighted:
  - 0.8628534359516163
  - 0.8657590064346763
  - 0.8615475428114386
  - 0.8621652181644388
  - 0.8682518454098884
  - 0.8685479639641029
  - 0.8639978330898036
  - 0.8642388385117094
  - 0.8680331821119649
  - 0.868995494080789
  - 0.865344609640179
  - 0.8656835425515713
  - 0.86869747508778
  - 0.8707735492938331
  - 0.8653599386595802
  - 0.8678267441495988
  TL_recall_macro:
  - 0.8131986831053916
  - 0.8120266979059931
  - 0.8018728544173854
  - 0.8034137073472991
  - 0.8163320232160202
  - 0.8094808433804692
  - 0.8017083475062586
  - 0.8057645703029513
  - 0.8151336733199006
  - 0.815264197852692
  - 0.8092047268443088
  - 0.8127692686016309
  - 0.8056895869122478
  - 0.8074800677791281
  - 0.8015576015393295
  - 0.7979768201320165
  TL_recall_micro:
  - 0.7606215665426191
  - 0.7501431465821
  - 0.7235949612403101
  - 0.732437015503876
  - 0.7532451710083289
  - 0.7369516384778013
  - 0.7189371916842847
  - 0.7387024312896406
  - 0.7407850434166223
  - 0.7439327871740662
  - 0.7291556553911205
  - 0.7438006518675123
  - 0.7274875994540431
  - 0.7319624023652972
  - 0.722220996425577
  - 0.7109350867128547
  TL_recall_weighted:
  - 0.7606215665426191
  - 0.7501431465821
  - 0.7235949612403101
  - 0.732437015503876
  - 0.7532451710083289
  - 0.7369516384778013
  - 0.7189371916842847
  - 0.7387024312896406
  - 0.7407850434166223
  - 0.7439327871740662
  - 0.7291556553911205
  - 0.7438006518675123
  - 0.7274875994540431
  - 0.7319624023652972
  - 0.722220996425577
  - 0.7109350867128547
  TL_roc_auc:
  - 0.9010628784552077
  - 0.9033067012331788
  - 0.8964375532677906
  - 0.8954723964365594
  - 0.9014966150292307
  - 0.89902579656023
  - 0.8965255715893732
  - 0.8958122014805345
  - 0.9070419484787007
  - 0.9071423499368736
  - 0.9039606196462817
  - 0.9025335463376987
  - 0.8959580301209739
  - 0.8952780382361357
  - 0.8907862288761156
  - 0.8890338148527589
  TT_average_precision:
  - 0.35510315448741697
  - 0.33021109082173916
  - 0.3236521779738264
  - 0.30125113794991465
  - 0.3281194026135924
  - 0.3117040935991239
  - 0.30916439432519344
  - 0.2903288216800774
  - 0.35189676360663114
  - 0.3220524891137486
  - 0.3212630369200113
  - 0.2878898285511775
  - 0.33454835738363703
  - 0.30269899416182167
  - 0.30464723243024117
  - 0.28134910616175396
  TT_balanced_accuracy:
  - 0.6513390236716637
  - 0.6241143294228035
  - 0.6407350244248509
  - 0.6123554375294136
  - 0.6404662650692942
  - 0.6130382879174673
  - 0.6506367467737728
  - 0.6057536071234702
  - 0.6526266990982502
  - 0.6198661382035672
  - 0.6505430474971867
  - 0.6123080877200304
  - 0.6435241895552425
  - 0.6181535648493073
  - 0.6526851069673247
  - 0.619652367512685
  TT_f1_macro:
  - 0.566020840256316
  - 0.5615289669764943
  - 0.5230266046201338
  - 0.5537016411849076
  - 0.5468932808488544
  - 0.5421641586403116
  - 0.517274944378078
  - 0.549146245284266
  - 0.5415870289078235
  - 0.5524165829583243
  - 0.5315253425402189
  - 0.5578902200988741
  - 0.5222352293346333
  - 0.5437815837596206
  - 0.5259751714754985
  - 0.5404873146667303
  TT_f1_micro:
  - 0.6132445141065831
  - 0.6090510366826156
  - 0.5565855927698034
  - 0.6116427432216905
  - 0.5901580459770115
  - 0.5849282296650717
  - 0.5496079213184476
  - 0.612772461456672
  - 0.570598223615465
  - 0.5927365762892078
  - 0.5649920255183413
  - 0.6205808080808081
  - 0.5549303147287836
  - 0.5910982389560239
  - 0.5683944205865707
  - 0.5927960318252938
  TT_f1_weighted:
  - 0.6523996806250782
  - 0.6437860819805296
  - 0.6020161307797591
  - 0.6486387032459145
  - 0.6324444047078923
  - 0.6230244242700821
  - 0.5972667874440586
  - 0.6509166763175042
  - 0.6103492842766622
  - 0.6279233921230787
  - 0.6094339831976432
  - 0.6564759131204948
  - 0.6005137079221289
  - 0.6311418048122315
  - 0.6189094867714788
  - 0.6358300805345294
  TT_matthews_corrcoef:
  - 0.24175536299560837
  - 0.20478782721644578
  - 0.2208465012643415
  - 0.1829286108175464
  - 0.22239500487982894
  - 0.18460810526750632
  - 0.2331808062312686
  - 0.1710130475526231
  - 0.24612346205937063
  - 0.19842531803877822
  - 0.23661633608105725
  - 0.1833893404597801
  - 0.22497328559264557
  - 0.19023037479074997
  - 0.23102238057557745
  - 0.189042957630869
  TT_precision_macro:
  - 0.5965475627488166
  - 0.5844746419915143
  - 0.5866400835897544
  - 0.5744576261537789
  - 0.5880274316596587
  - 0.5753730288168856
  - 0.590239084352244
  - 0.5691358508440542
  - 0.5992237251640611
  - 0.5821178679585144
  - 0.5929755499028776
  - 0.5748647111642406
  - 0.5881610608413662
  - 0.5765689878658818
  - 0.5873879276552962
  - 0.5746688940902858
  TT_precision_micro:
  - 0.6132445141065831
  - 0.6090510366826156
  - 0.5565855927698034
  - 0.6116427432216905
  - 0.5901580459770115
  - 0.5849282296650717
  - 0.5496079213184476
  - 0.612772461456672
  - 0.570598223615465
  - 0.5927365762892078
  - 0.5649920255183413
  - 0.6205808080808081
  - 0.5549303147287836
  - 0.5910982389560239
  - 0.5683944205865707
  - 0.5927960318252938
  TT_precision_weighted:
  - 0.7752997453611048
  - 0.7425711044642775
  - 0.7866131298032389
  - 0.7430048608636398
  - 0.774326754586327
  - 0.7408949941073775
  - 0.8023091037621187
  - 0.7434124555963909
  - 0.7824992014183961
  - 0.738314450673306
  - 0.7916182631799157
  - 0.7430629521318428
  - 0.7899914553779404
  - 0.7510861053648901
  - 0.8054200988867816
  - 0.7610142560150508
  TT_recall_macro:
  - 0.6513390236716637
  - 0.6241143294228035
  - 0.6407350244248509
  - 0.6123554375294136
  - 0.6404662650692942
  - 0.6130382879174673
  - 0.6506367467737728
  - 0.6057536071234702
  - 0.6526266990982502
  - 0.6198661382035672
  - 0.6505430474971867
  - 0.6123080877200304
  - 0.6435241895552425
  - 0.6181535648493073
  - 0.6526851069673247
  - 0.619652367512685
  TT_recall_micro:
  - 0.6132445141065831
  - 0.6090510366826156
  - 0.5565855927698034
  - 0.6116427432216905
  - 0.5901580459770115
  - 0.5849282296650717
  - 0.5496079213184476
  - 0.612772461456672
  - 0.570598223615465
  - 0.5927365762892078
  - 0.5649920255183413
  - 0.6205808080808081
  - 0.5549303147287836
  - 0.5910982389560239
  - 0.5683944205865707
  - 0.5927960318252938
  TT_recall_weighted:
  - 0.6132445141065831
  - 0.6090510366826156
  - 0.5565855927698034
  - 0.6116427432216905
  - 0.5901580459770115
  - 0.5849282296650717
  - 0.5496079213184476
  - 0.612772461456672
  - 0.570598223615465
  - 0.5927365762892078
  - 0.5649920255183413
  - 0.6205808080808081
  - 0.5549303147287836
  - 0.5910982389560239
  - 0.5683944205865707
  - 0.5927960318252938
  TT_roc_auc:
  - 0.71154596188581
  - 0.6771904191830894
  - 0.6907180754230615
  - 0.6610124288989689
  - 0.7004533434364302
  - 0.6658122029343646
  - 0.7001350671686015
  - 0.6616425707957464
  - 0.7147034756562329
  - 0.671627642417711
  - 0.7047761316421397
  - 0.6623391640421405
  - 0.7053055823936423
  - 0.6662255458438178
  - 0.7012406387311586
  - 0.6598005333164214
  fit_time:
  - 3077.9178590774536
  - 2829.0382375717163
  - 2776.4579169750214
  - 2782.5566663742065
  - 3042.378746509552
  - 2953.748673915863
  - 2685.1463680267334
  - 2970.121099948883
  - 3014.724371433258
  - 3003.7276699543
  - 2988.7144429683685
  - 2630.737265586853
  - 3050.609753370285
  - 2922.014759540558
  - 2737.2657659053802
  - 2764.5587816238403
  score_time:
  - 46.883944034576416
  - 47.45708131790161
  - 47.35864329338074
  - 43.56788682937622
  - 42.30450391769409
  - 42.01836824417114
  - 54.41045045852661
  - 41.83161497116089
  - 46.83211040496826
  - 45.126370906829834
  - 48.2831392288208
  - 53.92665410041809
  - 45.54374575614929
  - 46.47161626815796
  - 42.704280614852905
  - 44.646770000457764
start: 2023-10-04 20:11:32.931123
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
