active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: y_reconstruction/runs
end: 2023-10-06 01:39:58.712178
estimator:
  call: bipartite_adaptations.estimators.brf_gmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiterandomforestregressor
          - call: bipartite_learn.ensemble._forest.BipartiteRandomForestRegressor
            params:
              bipartite_adapter: gmo
              bootstrap: true
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: 0.5
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: 0.5
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 5
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 5
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: square
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: brf_gmo
  params: {}
hash: fdefd247fe87523278988a0ab7adfda8e5ac0dd490e19c14ff670f97345a2cc5
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/fdefd24_20231006T013801500380_brf_gmo_davis.yml"
results:
  LL_average_precision:
  - 0.5965712584605862
  - 0.6237619746549576
  - 0.6664950390455028
  - 0.7069017808782311
  - 0.6550809793776411
  - 0.6215985998221449
  - 0.6555546062937027
  - 0.7105044744316139
  - 0.6621215868747101
  - 0.6360118836772359
  - 0.6703212475449897
  - 0.6830465636156762
  - 0.7083090017947332
  - 0.6589679504910443
  - 0.6902911004389432
  - 0.7484386748239571
  LL_balanced_accuracy:
  - 0.7049008095914961
  - 0.7172317262830482
  - 0.810410992820005
  - 0.8026104169244093
  - 0.684016955491834
  - 0.743463540033858
  - 0.7831471891183628
  - 0.7341744548286604
  - 0.7441809943516852
  - 0.6715328467153285
  - 0.7257011379889311
  - 0.7081263968214552
  - 0.7561790038696792
  - 0.75
  - 0.788026496687914
  - 0.7828367997002061
  LL_f1_macro:
  - 0.354607284318035
  - 0.3781812220727596
  - 0.48409708597363277
  - 0.4738232531505593
  - 0.3400293843058246
  - 0.4202360732514172
  - 0.46484912249421895
  - 0.40461897299214067
  - 0.4068284015098103
  - 0.32507676397210905
  - 0.39187392948813776
  - 0.3684747542549117
  - 0.42890785464897735
  - 0.4288469346325619
  - 0.47309264772638454
  - 0.4660039562784859
  LL_f1_micro:
  - 0.434275220662283
  - 0.461465552988567
  - 0.6381998582565557
  - 0.6230805575242145
  - 0.3994431609501807
  - 0.5152538356732421
  - 0.5894755492558469
  - 0.4960429955114576
  - 0.5116995438658847
  - 0.3762217878087791
  - 0.4789747224190881
  - 0.44466099692889205
  - 0.5371719684852793
  - 0.5278715715893608
  - 0.59933853059296
  - 0.5892983699503898
  LL_f1_weighted:
  - 0.5625552395608784
  - 0.5840194300289693
  - 0.7402134289292577
  - 0.7287093129591966
  - 0.5183645563342837
  - 0.6290276650407857
  - 0.6954941874176479
  - 0.613619662302314
  - 0.6334877696254116
  - 0.49211528920756004
  - 0.5988878302900063
  - 0.5664734845778355
  - 0.652255985002698
  - 0.640153027919662
  - 0.7026749289239024
  - 0.6946805421080126
  LL_matthews_corrcoef:
  - 0.16729151814053617
  - 0.18810154396629808
  - 0.264196419399044
  - 0.25467073850113253
  - 0.1677193098749191
  - 0.22313185901680477
  - 0.25541398753502786
  - 0.20946375615513751
  - 0.20425918929097786
  - 0.16025041103463766
  - 0.19928107550491284
  - 0.18313361085618132
  - 0.22528055710719722
  - 0.22978231051001183
  - 0.2635317074463681
  - 0.2572097865396679
  LL_precision_macro:
  - 0.5341463414634147
  - 0.5407194099221987
  - 0.5562155896841495
  - 0.5535814213766088
  - 0.5382162703835291
  - 0.5511245200219419
  - 0.5575992871690427
  - 0.5468401486988848
  - 0.5427160767779874
  - 0.5374275171323142
  - 0.5439884213790964
  - 0.5402855187249438
  - 0.5495272140221402
  - 0.5527999102233195
  - 0.5602800103707545
  - 0.5584761904761905
  LL_precision_micro:
  - 0.434275220662283
  - 0.461465552988567
  - 0.6381998582565557
  - 0.6230805575242145
  - 0.3994431609501807
  - 0.5152538356732421
  - 0.5894755492558469
  - 0.4960429955114576
  - 0.5116995438658847
  - 0.3762217878087791
  - 0.4789747224190881
  - 0.44466099692889205
  - 0.5371719684852793
  - 0.5278715715893608
  - 0.59933853059296
  - 0.5892983699503898
  LL_precision_weighted:
  - 0.9613651370208388
  - 0.9561423901898338
  - 0.9593223833681668
  - 0.9596082410553369
  - 0.9540979149163891
  - 0.9504351700326343
  - 0.9527081685433479
  - 0.9527891579438242
  - 0.9582834404500977
  - 0.9533070605528976
  - 0.9541618410812204
  - 0.9552557603861745
  - 0.9541548340554491
  - 0.9501433227320827
  - 0.9516962449379638
  - 0.9519674665046741
  LL_recall_macro:
  - 0.7049008095914961
  - 0.7172317262830482
  - 0.810410992820005
  - 0.8026104169244093
  - 0.684016955491834
  - 0.743463540033858
  - 0.7831471891183628
  - 0.7341744548286604
  - 0.7441809943516852
  - 0.6715328467153285
  - 0.7257011379889311
  - 0.7081263968214552
  - 0.7561790038696792
  - 0.75
  - 0.788026496687914
  - 0.7828367997002061
  LL_recall_micro:
  - 0.434275220662283
  - 0.461465552988567
  - 0.6381998582565557
  - 0.6230805575242145
  - 0.3994431609501807
  - 0.5152538356732421
  - 0.5894755492558469
  - 0.4960429955114576
  - 0.5116995438658847
  - 0.3762217878087791
  - 0.4789747224190881
  - 0.44466099692889205
  - 0.5371719684852793
  - 0.5278715715893608
  - 0.59933853059296
  - 0.5892983699503898
  LL_recall_weighted:
  - 0.434275220662283
  - 0.461465552988567
  - 0.6381998582565557
  - 0.6230805575242145
  - 0.3994431609501807
  - 0.5152538356732421
  - 0.5894755492558469
  - 0.4960429955114576
  - 0.5116995438658847
  - 0.3762217878087791
  - 0.4789747224190881
  - 0.44466099692889205
  - 0.5371719684852793
  - 0.5278715715893608
  - 0.59933853059296
  - 0.5892983699503898
  LL_roc_auc:
  - 0.9768476255219968
  - 0.9731510560377266
  - 0.9789072490383708
  - 0.9818642759567916
  - 0.9770417537753623
  - 0.9722757989051476
  - 0.9750839656973883
  - 0.9790162544768686
  - 0.9797629190993972
  - 0.9717545765787773
  - 0.9736413723971278
  - 0.9763785738739238
  - 0.9811741684055204
  - 0.9755429833181551
  - 0.9777524113249285
  - 0.9818981331442125
  LT_average_precision:
  - 0.5542450700609471
  - 0.48316425110355077
  - 0.4506586738949526
  - 0.41248559999534945
  - 0.5772965948977814
  - 0.4909489196422061
  - 0.4300144490697717
  - 0.42339099869779495
  - 0.6035693832035228
  - 0.4634772591084301
  - 0.40141643257800247
  - 0.3586344101135115
  - 0.6149714582223716
  - 0.51623707525262
  - 0.49659000757128596
  - 0.47860724117954234
  LT_balanced_accuracy:
  - 0.6632686409870813
  - 0.682036061535236
  - 0.760300279329609
  - 0.7788917910447761
  - 0.6450347567569326
  - 0.7222235975820204
  - 0.7354734618674826
  - 0.7141834219453648
  - 0.7047593015275095
  - 0.6328711437882593
  - 0.6882369662258907
  - 0.6868228678537958
  - 0.7189619136211505
  - 0.7295183884380929
  - 0.7447249167212694
  - 0.7669853472215158
  LT_f1_macro:
  - 0.32814158056408826
  - 0.3539402576616807
  - 0.45482729325663523
  - 0.468229106238156
  - 0.31123519395688415
  - 0.39984334913404673
  - 0.43650854001931705
  - 0.3986428933031754
  - 0.3881695126065611
  - 0.2875901008878719
  - 0.3533079224111772
  - 0.350615788411064
  - 0.41147940600900546
  - 0.4088274640776534
  - 0.4397623040106107
  - 0.46268862716231135
  LT_f1_micro:
  - 0.37537537537537535
  - 0.4449743861508567
  - 0.6058823529411764
  - 0.6212121212121212
  - 0.3462285815226992
  - 0.5052110934463876
  - 0.558288770053476
  - 0.4857397504456328
  - 0.4626391096979332
  - 0.3310369192722134
  - 0.4297682709447415
  - 0.4174688057040998
  - 0.4905493729023141
  - 0.5115703939233351
  - 0.5593582887700534
  - 0.5918003565062389
  LT_f1_weighted:
  - 0.486395247523424
  - 0.5784625482083967
  - 0.7172426187499289
  - 0.728030770085601
  - 0.44745161718525656
  - 0.6287472220014548
  - 0.6722242613431031
  - 0.6026983871797899
  - 0.5768132565296673
  - 0.4481692930136892
  - 0.5560130662165935
  - 0.5385470481348202
  - 0.5999136162679987
  - 0.6312484931376481
  - 0.6721254904490956
  - 0.698282320925158
  LT_matthews_corrcoef:
  - 0.1605761409030049
  - 0.1397753536819733
  - 0.21274512104448848
  - 0.23326502737723706
  - 0.15386334925130485
  - 0.18449665825690453
  - 0.20554643210484402
  - 0.19562855272815352
  - 0.19502924810553707
  - 0.11956070530467475
  - 0.15880275753011164
  - 0.16710514799279108
  - 0.21530944674416463
  - 0.19817984477427794
  - 0.215747456294867
  - 0.23963491381298824
  LT_precision_macro:
  - 0.5394820108616907
  - 0.5268314274272778
  - 0.5434694947742664
  - 0.5487757032875228
  - 0.5408073395167352
  - 0.5382936570174569
  - 0.5448557296180662
  - 0.5446702764094813
  - 0.5464403904155496
  - 0.5268959117935552
  - 0.5334927781519075
  - 0.5373671205330516
  - 0.5529294765133076
  - 0.5427800699783042
  - 0.5475502918964321
  - 0.5537715763390877
  LT_precision_micro:
  - 0.37537537537537535
  - 0.4449743861508567
  - 0.6058823529411764
  - 0.6212121212121212
  - 0.3462285815226992
  - 0.5052110934463876
  - 0.558288770053476
  - 0.4857397504456328
  - 0.4626391096979332
  - 0.3310369192722134
  - 0.4297682709447415
  - 0.41746880570409983
  - 0.4905493729023141
  - 0.5115703939233351
  - 0.5593582887700534
  - 0.5918003565062389
  LT_precision_weighted:
  - 0.9466316259878277
  - 0.9597403611606011
  - 0.9560699617797416
  - 0.956429993590054
  - 0.9410030707616117
  - 0.955101603427531
  - 0.9484866112725215
  - 0.9473622038291121
  - 0.9445959530273584
  - 0.9537214766850667
  - 0.9558232955543332
  - 0.9529051157621583
  - 0.9409415675276005
  - 0.952677846237526
  - 0.9493413206501986
  - 0.9496811590751135
  LT_recall_macro:
  - 0.6632686409870813
  - 0.682036061535236
  - 0.760300279329609
  - 0.7788917910447761
  - 0.6450347567569326
  - 0.7222235975820204
  - 0.7354734618674826
  - 0.7141834219453648
  - 0.7047593015275095
  - 0.6328711437882593
  - 0.6882369662258907
  - 0.6868228678537958
  - 0.7189619136211505
  - 0.7295183884380929
  - 0.7447249167212694
  - 0.7669853472215158
  LT_recall_micro:
  - 0.37537537537537535
  - 0.4449743861508567
  - 0.6058823529411764
  - 0.6212121212121212
  - 0.3462285815226992
  - 0.5052110934463876
  - 0.558288770053476
  - 0.4857397504456328
  - 0.4626391096979332
  - 0.3310369192722134
  - 0.4297682709447415
  - 0.41746880570409983
  - 0.4905493729023141
  - 0.5115703939233351
  - 0.5593582887700534
  - 0.5918003565062389
  LT_recall_weighted:
  - 0.37537537537537535
  - 0.4449743861508567
  - 0.6058823529411764
  - 0.6212121212121211
  - 0.34622858152269914
  - 0.5052110934463876
  - 0.558288770053476
  - 0.4857397504456328
  - 0.4626391096979332
  - 0.3310369192722134
  - 0.4297682709447415
  - 0.41746880570409983
  - 0.4905493729023141
  - 0.5115703939233351
  - 0.5593582887700534
  - 0.5918003565062389
  LT_roc_auc:
  - 0.9181525381582217
  - 0.8854574521057735
  - 0.8934729981378026
  - 0.9022361940298508
  - 0.9203918961277859
  - 0.9045029846116655
  - 0.8787624820611587
  - 0.9094207525740472
  - 0.9193898968663139
  - 0.8809111629917339
  - 0.8844542238692832
  - 0.8907093805912926
  - 0.927072743687825
  - 0.8995044608614913
  - 0.910990435955727
  - 0.9216720366395752
  TL_average_precision:
  - 0.2657599141127171
  - 0.3162712463594887
  - 0.3267579022782841
  - 0.31455747140967405
  - 0.28430470073382774
  - 0.28071536870804503
  - 0.32364615188448875
  - 0.27678163309089415
  - 0.33482666025961966
  - 0.29473225421246096
  - 0.2853138355355701
  - 0.29194764347307894
  - 0.2499924953155702
  - 0.29309411451415396
  - 0.38110341569943806
  - 0.3943200483745033
  TL_balanced_accuracy:
  - 0.5920680573585807
  - 0.5948437314100277
  - 0.6785719309456492
  - 0.6791302835997893
  - 0.62848837704541
  - 0.6964560629156903
  - 0.6981464318813717
  - 0.6648748841519926
  - 0.6692125044025437
  - 0.5844758146417898
  - 0.6596000921942036
  - 0.633228539743747
  - 0.6612675398005067
  - 0.659552251241083
  - 0.6900994992092778
  - 0.6631368631368632
  TL_f1_macro:
  - 0.2324905920390099
  - 0.24489294052079935
  - 0.39009322627275606
  - 0.40179059263134986
  - 0.30297400085436604
  - 0.3892387512763498
  - 0.42754705142811317
  - 0.36701423266555105
  - 0.3553108782629826
  - 0.25752723393518745
  - 0.3378677277716795
  - 0.313553166226647
  - 0.3208405515206085
  - 0.3480508391184416
  - 0.38480965633943565
  - 0.35902318622099055
  TL_f1_micro:
  - 0.24311355962324507
  - 0.25715301226230675
  - 0.4574769666902906
  - 0.48086463501063076
  - 0.36218233516971743
  - 0.4938688466323085
  - 0.5657335223245925
  - 0.45818568391211906
  - 0.42544872934067884
  - 0.27954505064865826
  - 0.3940467753366407
  - 0.3586109142452162
  - 0.3934601030744624
  - 0.4291807357384041
  - 0.4952161587526577
  - 0.4571226080793763
  TL_f1_weighted:
  - 0.3113605099793661
  - 0.3284221601264668
  - 0.5656645072753728
  - 0.5911521151712066
  - 0.4904550253053536
  - 0.6200179697579127
  - 0.6839868564166752
  - 0.5860470469115076
  - 0.5463382689945315
  - 0.3706156485718688
  - 0.5100271204920412
  - 0.47028931597312207
  - 0.5273721348256725
  - 0.5587433414236844
  - 0.6247394708685456
  - 0.591120731414925
  TL_matthews_corrcoef:
  - 0.11644832320559109
  - 0.11919518764341401
  - 0.18228574720543214
  - 0.17806700923340052
  - 0.10523148805071336
  - 0.16094691159218727
  - 0.16317291657106384
  - 0.13704022954938766
  - 0.1530895794354577
  - 0.0936617879051446
  - 0.1513519552330272
  - 0.13059407666960876
  - 0.12335797894064389
  - 0.130866051284821
  - 0.14885010235170182
  - 0.12479329089364155
  TL_precision_macro:
  - 0.5368211635132595
  - 0.5374497411324081
  - 0.5465192002156769
  - 0.5442525115521075
  - 0.5215460462884004
  - 0.5329639970976361
  - 0.5335930862462461
  - 0.5284761754519812
  - 0.5346257202067819
  - 0.5259616629646817
  - 0.5358825205517209
  - 0.5320029268766119
  - 0.5235899781616693
  - 0.5268343493207818
  - 0.5291378371093451
  - 0.5238654911474543
  TL_precision_micro:
  - 0.24311355962324507
  - 0.25715301226230675
  - 0.4574769666902906
  - 0.48086463501063076
  - 0.36218233516971743
  - 0.4938688466323085
  - 0.5657335223245925
  - 0.45818568391211906
  - 0.42544872934067884
  - 0.27954505064865826
  - 0.3940467753366407
  - 0.3586109142452162
  - 0.3934601030744624
  - 0.4291807357384041
  - 0.4952161587526577
  - 0.4571226080793763
  TL_precision_weighted:
  - 0.9388186219146578
  - 0.9342186546445624
  - 0.9296516275678673
  - 0.9288056292370671
  - 0.9541522939827659
  - 0.9522370408145214
  - 0.947079796394173
  - 0.9480989938558451
  - 0.945563686571749
  - 0.929520557172266
  - 0.9442073687766205
  - 0.9399364271272762
  - 0.9620765437324057
  - 0.9516481704323064
  - 0.9548794814121184
  - 0.9553813589044332
  TL_recall_macro:
  - 0.5920680573585807
  - 0.5948437314100277
  - 0.6785719309456492
  - 0.6791302835997893
  - 0.62848837704541
  - 0.6964560629156903
  - 0.6981464318813717
  - 0.6648748841519926
  - 0.6692125044025437
  - 0.5844758146417898
  - 0.6596000921942036
  - 0.633228539743747
  - 0.6612675398005067
  - 0.659552251241083
  - 0.6900994992092778
  - 0.6631368631368632
  TL_recall_micro:
  - 0.24311355962324507
  - 0.25715301226230675
  - 0.4574769666902906
  - 0.48086463501063076
  - 0.36218233516971743
  - 0.4938688466323085
  - 0.5657335223245925
  - 0.45818568391211906
  - 0.42544872934067884
  - 0.27954505064865826
  - 0.3940467753366407
  - 0.3586109142452162
  - 0.3934601030744624
  - 0.4291807357384041
  - 0.4952161587526577
  - 0.4571226080793763
  TL_recall_weighted:
  - 0.24311355962324507
  - 0.25715301226230675
  - 0.4574769666902906
  - 0.48086463501063076
  - 0.36218233516971743
  - 0.4938688466323085
  - 0.5657335223245925
  - 0.45818568391211906
  - 0.42544872934067884
  - 0.27954505064865826
  - 0.3940467753366407
  - 0.3586109142452162
  - 0.3934601030744624
  - 0.4291807357384041
  - 0.4952161587526577
  - 0.4571226080793763
  TL_roc_auc:
  - 0.7971508828250401
  - 0.8240327060435615
  - 0.82975592650868
  - 0.8224349775668389
  - 0.8146992682947606
  - 0.8405573377623067
  - 0.8127174127464445
  - 0.8125372667686501
  - 0.8671187920860268
  - 0.8336769869135016
  - 0.8594174339733168
  - 0.8322673927147399
  - 0.8053154593300987
  - 0.8097024544988666
  - 0.833145262256194
  - 0.821497362286836
  TT_average_precision:
  - 0.32679318396815976
  - 0.2526020463443577
  - 0.24298841449065375
  - 0.26331047050373063
  - 0.40074326237522984
  - 0.31917587052720436
  - 0.20771924999949698
  - 0.18780285172621725
  - 0.2743945300516703
  - 0.2555201242659838
  - 0.23581771753277816
  - 0.26473492271182797
  - 0.45262559701941735
  - 0.30488240849986975
  - 0.20208092442796585
  - 0.2441006186285807
  TT_balanced_accuracy:
  - 0.5595886795344441
  - 0.5728021978021978
  - 0.6439236957581668
  - 0.6577879656160458
  - 0.60400158909835
  - 0.650916114790287
  - 0.6758214657595378
  - 0.6429354336133533
  - 0.6303665190981159
  - 0.5830991149246673
  - 0.6166967941458315
  - 0.647542372881356
  - 0.6260294295749061
  - 0.6178216497602931
  - 0.5907734924355423
  - 0.6694478015958838
  TT_f1_macro:
  - 0.18631925711429254
  - 0.21387776493098892
  - 0.35064935064935066
  - 0.39977591036414567
  - 0.2739940050645356
  - 0.3775362993298585
  - 0.40683304449330593
  - 0.3574189310689817
  - 0.33890766530248073
  - 0.2005259960350451
  - 0.3093101343101343
  - 0.30294429628705505
  - 0.2951380588094669
  - 0.3147249904082634
  - 0.34044478276467627
  - 0.37261073356267804
  TT_f1_micro:
  - 0.1881293057763646
  - 0.22151563328033916
  - 0.4090909090909091
  - 0.47914438502673795
  - 0.3031266560678325
  - 0.48913619501854794
  - 0.5454545454545454
  - 0.45614973262032094
  - 0.38738738738738737
  - 0.21356650768415475
  - 0.35294117647058826
  - 0.3417112299465241
  - 0.3375728669846317
  - 0.3995760466348702
  - 0.4390374331550802
  - 0.4711229946524064
  TT_f1_weighted:
  - 0.21924587266367093
  - 0.28159198486689513
  - 0.5221195916383082
  - 0.5888596294132626
  - 0.4035495244733776
  - 0.6201508410210393
  - 0.6718086569501885
  - 0.5901703977548126
  - 0.49497252406896103
  - 0.2937575378251527
  - 0.46359692594986723
  - 0.44974878429456816
  - 0.45122116533712486
  - 0.5423149469437853
  - 0.5777217007166857
  - 0.6002126107362474
  TT_matthews_corrcoef:
  - 0.0948217621924491
  - 0.09614704425499383
  - 0.14230695881076183
  - 0.15917829572473868
  - 0.10842284768770255
  - 0.11825374439415935
  - 0.13453423776385887
  - 0.11035906910167763
  - 0.13533299652873496
  - 0.08996058846619209
  - 0.11596915517810316
  - 0.1464105154591632
  - 0.11913229339900852
  - 0.08021215547572925
  - 0.06734534512147657
  - 0.13738069123459226
  TT_precision_macro:
  - 0.5377217898413246
  - 0.5317444198047709
  - 0.5351770957855262
  - 0.5401452191409326
  - 0.5282580151001204
  - 0.5231651008288135
  - 0.5257355679702048
  - 0.5213017930982984
  - 0.5351221695496495
  - 0.5243471530488626
  - 0.5288115133135458
  - 0.5363218352436546
  - 0.5281531531531531
  - 0.5136519686728892
  - 0.512490968970791
  - 0.5278455284552845
  TT_precision_micro:
  - 0.1881293057763646
  - 0.22151563328033916
  - 0.4090909090909091
  - 0.47914438502673795
  - 0.3031266560678325
  - 0.48913619501854794
  - 0.5454545454545454
  - 0.4561497326203209
  - 0.38738738738738737
  - 0.21356650768415475
  - 0.35294117647058826
  - 0.3417112299465241
  - 0.3375728669846317
  - 0.3995760466348702
  - 0.4390374331550802
  - 0.4711229946524064
  TT_precision_weighted:
  - 0.9304978007373482
  - 0.9323452569064059
  - 0.931241720402587
  - 0.9202273393909143
  - 0.9373886254063646
  - 0.948404017321125
  - 0.9516654816319621
  - 0.9510069858690814
  - 0.9252083921129259
  - 0.9558338991918048
  - 0.9336543108661713
  - 0.9487580165205683
  - 0.9458600094530143
  - 0.9621491367737982
  - 0.947215976859692
  - 0.9500584757184469
  TT_recall_macro:
  - 0.5595886795344441
  - 0.5728021978021978
  - 0.6439236957581668
  - 0.6577879656160458
  - 0.60400158909835
  - 0.650916114790287
  - 0.6758214657595378
  - 0.6429354336133533
  - 0.6303665190981159
  - 0.5830991149246673
  - 0.6166967941458315
  - 0.647542372881356
  - 0.6260294295749061
  - 0.6178216497602931
  - 0.5907734924355423
  - 0.6694478015958838
  TT_recall_micro:
  - 0.1881293057763646
  - 0.22151563328033916
  - 0.4090909090909091
  - 0.47914438502673795
  - 0.3031266560678325
  - 0.48913619501854794
  - 0.5454545454545454
  - 0.4561497326203209
  - 0.38738738738738737
  - 0.21356650768415475
  - 0.35294117647058826
  - 0.3417112299465241
  - 0.3375728669846317
  - 0.3995760466348702
  - 0.4390374331550802
  - 0.4711229946524064
  TT_recall_weighted:
  - 0.1881293057763646
  - 0.22151563328033916
  - 0.4090909090909091
  - 0.47914438502673795
  - 0.3031266560678325
  - 0.48913619501854794
  - 0.5454545454545454
  - 0.4561497326203209
  - 0.38738738738738737
  - 0.21356650768415475
  - 0.35294117647058826
  - 0.3417112299465241
  - 0.3375728669846317
  - 0.3995760466348702
  - 0.4390374331550802
  - 0.4711229946524064
  TT_roc_auc:
  - 0.8115171433193417
  - 0.7587527092284877
  - 0.7909150008126118
  - 0.7829547277936963
  - 0.8261950890330446
  - 0.7482634289919058
  - 0.7634601382614754
  - 0.7874640841155884
  - 0.8121145044598148
  - 0.8520302682251202
  - 0.7873508145308824
  - 0.8589124293785311
  - 0.8371775463243308
  - 0.7682557972058188
  - 0.6686469209460899
  - 0.7787743216787171
  fit_time:
  - 60.72666954994202
  - 60.55602264404297
  - 60.755314350128174
  - 62.60564565658569
  - 66.42006826400757
  - 71.31991267204285
  - 66.38534712791443
  - 66.22715425491333
  - 64.88969993591309
  - 60.70713925361633
  - 65.89749503135681
  - 66.1679618358612
  - 65.12474799156189
  - 64.84187030792236
  - 62.54742360115051
  - 63.7326226234436
  score_time:
  - 30.438019037246704
  - 29.178125858306885
  - 31.05914616584778
  - 30.617476224899292
  - 30.13660764694214
  - 45.58418679237366
  - 46.03005814552307
  - 39.6080858707428
  - 50.44879698753357
  - 47.258119106292725
  - 50.86422109603882
  - 47.03514504432678
  - 51.41443490982056
  - 51.952184438705444
  - 49.57968711853027
  - 47.679445028305054
start: 2023-10-06 01:38:01.500380
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
