active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: y_reconstruction/runs
end: 2023-10-05 17:22:34.682372
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: bxt_lmo
  params: {}
hash: 7478691f33b3d83619823c1870b723eede2ccf4e67440d79145765f47e10c988
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/7478691_20231005T171817058114_bxt_lmo_enzymes.yml"
results:
  LL_average_precision:
  - 0.9999900738418627
  - 1.0
  - 0.9999967143735746
  - 0.9999948320573249
  - 0.9999911699546736
  - 1.0
  - 0.99998888462614
  - 0.9999914987443247
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999892739018365
  - 1.0
  - 0.999997339128175
  - 0.9999945204820414
  LL_balanced_accuracy:
  - 0.933788842560185
  - 0.9704363307144983
  - 0.9848796750040989
  - 0.9493927125506073
  - 0.9039304100186206
  - 0.9761582243495903
  - 0.9607464607464608
  - 0.9612051965073451
  - 0.9634020900918447
  - 0.9753778096459194
  - 0.9642121883824735
  - 0.8856872302584056
  - 0.9393643136036645
  - 0.9776394343591552
  - 0.9858232077764277
  - 0.965433170796874
  LL_f1_macro:
  - 0.5268735194477187
  - 0.6173107063248225
  - 0.6918168913428607
  - 0.5531318330406906
  - 0.4902440220574679
  - 0.6392089144933443
  - 0.5791502281060272
  - 0.5763170255485339
  - 0.5826884656292296
  - 0.639088630350893
  - 0.5916932646554368
  - 0.47441780894928687
  - 0.5393719496987192
  - 0.6556530676852352
  - 0.705821597698034
  - 0.5945100992290768
  LL_f1_micro:
  - 0.8688145977302604
  - 0.9414965250222447
  - 0.9700598802395209
  - 0.8997486953803236
  - 0.8095987553818879
  - 0.9528052329076786
  - 0.9222518817786115
  - 0.9231236322535652
  - 0.9274816985660359
  - 0.9512781665584493
  - 0.9291417165668663
  - 0.7735613111127144
  - 0.8799462112715125
  - 0.9557751965947623
  - 0.9719416588509727
  - 0.9315525575355313
  LL_f1_weighted:
  - 0.9215800637011123
  - 0.9621029107780671
  - 0.9788272649547645
  - 0.939203925937241
  - 0.8864211119800532
  - 0.9686799949508104
  - 0.9517955787456244
  - 0.9525920652739406
  - 0.9549895825720466
  - 0.9676325085759677
  - 0.9554436466665153
  - 0.8633477483685305
  - 0.9274969176332556
  - 0.9699923624345042
  - 0.9797923192475617
  - 0.956856579348443
  LL_matthews_corrcoef:
  - 0.2401400847618975
  - 0.37915743728744417
  - 0.491601745142815
  - 0.27915272178883227
  - 0.19140971478285412
  - 0.41222800144268196
  - 0.31923229542600884
  - 0.3138737467503394
  - 0.32389356813047343
  - 0.4123540181203716
  - 0.3391809843391949
  - 0.17681545657958647
  - 0.2604169026971083
  - 0.43776377357854396
  - 0.5128283376045225
  - 0.34335630318033566
  LL_precision_macro:
  - 0.5332346378304154
  - 0.5763973532996691
  - 0.6246042514699232
  - 0.5433508598970315
  - 0.5226757369614512
  - 0.5892203035060178
  - 0.5552957359009628
  - 0.5534017882089969
  - 0.5565961212299978
  - 0.5894214206099909
  - 0.5619564409425407
  - 0.5202649344032607
  - 0.5385881153240011
  - 0.6003042816778961
  - 0.6353336458821691
  - 0.563324639459957
  LL_precision_micro:
  - 0.8688145977302604
  - 0.9414965250222447
  - 0.9700598802395209
  - 0.8997486953803236
  - 0.8095987553818879
  - 0.9528052329076786
  - 0.9222518817786115
  - 0.9231236322535652
  - 0.9274816985660359
  - 0.9512781665584493
  - 0.9291417165668663
  - 0.7735613111127143
  - 0.8799462112715125
  - 0.9557751965947623
  - 0.9719416588509727
  - 0.9315525575355313
  LL_precision_weighted:
  - 0.9912802013338557
  - 0.9910609787057322
  - 0.9925386675766514
  - 0.9913080394778755
  - 0.9913650229198134
  - 0.9915785371122545
  - 0.9914017211760666
  - 0.9917893289826559
  - 0.9917914908412996
  - 0.9912864488778663
  - 0.9912197458943706
  - 0.9908224696466776
  - 0.9907347011109237
  - 0.991128125724183
  - 0.9924055247897929
  - 0.9913311807679628
  LL_recall_macro:
  - 0.933788842560185
  - 0.9704363307144983
  - 0.9848796750040989
  - 0.9493927125506073
  - 0.9039304100186206
  - 0.9761582243495903
  - 0.9607464607464608
  - 0.9612051965073451
  - 0.9634020900918447
  - 0.9753778096459194
  - 0.9642121883824735
  - 0.8856872302584056
  - 0.9393643136036645
  - 0.9776394343591552
  - 0.9858232077764277
  - 0.965433170796874
  LL_recall_micro:
  - 0.8688145977302604
  - 0.9414965250222447
  - 0.9700598802395209
  - 0.8997486953803236
  - 0.8095987553818879
  - 0.9528052329076786
  - 0.9222518817786115
  - 0.9231236322535652
  - 0.9274816985660359
  - 0.9512781665584493
  - 0.9291417165668663
  - 0.7735613111127143
  - 0.8799462112715125
  - 0.9557751965947623
  - 0.9719416588509727
  - 0.9315525575355313
  LL_recall_weighted:
  - 0.8688145977302604
  - 0.9414965250222447
  - 0.9700598802395209
  - 0.8997486953803236
  - 0.8095987553818879
  - 0.9528052329076786
  - 0.9222518817786115
  - 0.9231236322535652
  - 0.9274816985660359
  - 0.9512781665584493
  - 0.9291417165668663
  - 0.7735613111127143
  - 0.8799462112715125
  - 0.9557751965947623
  - 0.9719416588509727
  - 0.9315525575355313
  LL_roc_auc:
  - 0.9999999096187161
  - 1.0
  - 0.999999970611399
  - 0.9999999539873184
  - 0.9999999229212052
  - 1.0
  - 0.999999894290235
  - 0.9999999245983235
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999998939055643
  - 1.0
  - 0.9999999754461091
  - 0.999999948508272
  LT_average_precision:
  - 0.2248268659756883
  - 0.3742789336403678
  - 0.2751982306155286
  - 0.2778586090630421
  - 0.24902466855536598
  - 0.40185741761329835
  - 0.3193513347311337
  - 0.30489451479740703
  - 0.24326190367963027
  - 0.368230347564106
  - 0.325559317846171
  - 0.28088120007774176
  - 0.26332027635542
  - 0.44039985525370356
  - 0.356007720401882
  - 0.3271920086426393
  LT_balanced_accuracy:
  - 0.6838528133365156
  - 0.7573228983132457
  - 0.6883943304892112
  - 0.7298460352823902
  - 0.6898449659734839
  - 0.7676652472229811
  - 0.7681450722492004
  - 0.7292982226666611
  - 0.6859615243947041
  - 0.7541774885486112
  - 0.7714702479292606
  - 0.7082415271395393
  - 0.7103315954133214
  - 0.8210897048716308
  - 0.7102617199629851
  - 0.774303598822359
  LT_f1_macro:
  - 0.4939515996147343
  - 0.5229134155471095
  - 0.5479947369319617
  - 0.5207300094880184
  - 0.47805812093201927
  - 0.5150051327006643
  - 0.5305340187946339
  - 0.5278946777463673
  - 0.523504285104378
  - 0.5119527958964843
  - 0.5277251232445362
  - 0.4583321592989833
  - 0.4938366010135245
  - 0.5336833032882561
  - 0.5394179496229431
  - 0.5410921938689486
  LT_f1_micro:
  - 0.8472819850831897
  - 0.9099099099099099
  - 0.9429972140815515
  - 0.8899924020405948
  - 0.8102051061388411
  - 0.897680813343464
  - 0.9072144433590218
  - 0.9027099388545171
  - 0.9013374928284567
  - 0.8933753030138573
  - 0.9007742682441477
  - 0.7582401678787221
  - 0.8394650028686174
  - 0.9084264987879446
  - 0.9248706537863164
  - 0.9025652158182279
  LT_f1_weighted:
  - 0.9072342806735548
  - 0.9459931005022876
  - 0.9624817097613637
  - 0.9323288479046533
  - 0.885258052362363
  - 0.939438303809924
  - 0.9433572020605344
  - 0.9396481220968722
  - 0.9379059231650916
  - 0.9368344279960447
  - 0.9395834070438996
  - 0.8527069615955141
  - 0.9026064900376317
  - 0.9448768802366369
  - 0.9521356644211401
  - 0.9388451416249592
  LT_matthews_corrcoef:
  - 0.10799990287612934
  - 0.15578591874835393
  - 0.15972114816526203
  - 0.1509947017876753
  - 0.10073142539722454
  - 0.15007948645759478
  - 0.17410418106939285
  - 0.1575543145936793
  - 0.1344433847432571
  - 0.14219096264871506
  - 0.17312452381527244
  - 0.09990511666876178
  - 0.120842566749445
  - 0.19688839370533676
  - 0.1607767044904623
  - 0.1960008077025483
  LT_precision_macro:
  - 0.515860484821497
  - 0.5235785977844898
  - 0.5338529895047591
  - 0.5247985569339249
  - 0.5133619819868885
  - 0.5210373334688194
  - 0.5282610692894566
  - 0.5270644946114242
  - 0.5242994132254734
  - 0.5198859761090738
  - 0.5276016441717721
  - 0.5119825191373942
  - 0.5173570284458427
  - 0.5301824061840955
  - 0.530734492126484
  - 0.5350125889570719
  LT_precision_micro:
  - 0.8472819850831899
  - 0.9099099099099099
  - 0.9429972140815515
  - 0.8899924020405948
  - 0.8102051061388411
  - 0.897680813343464
  - 0.9072144433590217
  - 0.9027099388545171
  - 0.9013374928284567
  - 0.8933753030138573
  - 0.9007742682441477
  - 0.7582401678787221
  - 0.8394650028686174
  - 0.9084264987879446
  - 0.9248706537863164
  - 0.9025652158182279
  LT_precision_weighted:
  - 0.9827350433326844
  - 0.9893601115263463
  - 0.9854557341502012
  - 0.984576570778823
  - 0.9835187397174551
  - 0.9899474448892004
  - 0.9876544165609028
  - 0.9848443076092906
  - 0.9821409724830059
  - 0.9894302024229027
  - 0.9874336022272416
  - 0.9847105041289098
  - 0.9834601791170782
  - 0.9899366041373678
  - 0.9848734223536139
  - 0.984576686484547
  LT_recall_macro:
  - 0.6838528133365156
  - 0.7573228983132457
  - 0.6883943304892112
  - 0.7298460352823902
  - 0.6898449659734839
  - 0.7676652472229811
  - 0.7681450722492004
  - 0.7292982226666611
  - 0.6859615243947041
  - 0.7541774885486112
  - 0.7714702479292606
  - 0.7082415271395393
  - 0.7103315954133214
  - 0.8210897048716308
  - 0.7102617199629851
  - 0.774303598822359
  LT_recall_micro:
  - 0.8472819850831899
  - 0.9099099099099099
  - 0.9429972140815515
  - 0.8899924020405948
  - 0.8102051061388411
  - 0.897680813343464
  - 0.9072144433590217
  - 0.9027099388545171
  - 0.9013374928284567
  - 0.8933753030138573
  - 0.9007742682441477
  - 0.7582401678787221
  - 0.8394650028686174
  - 0.9084264987879446
  - 0.9248706537863164
  - 0.9025652158182279
  LT_recall_weighted:
  - 0.8472819850831899
  - 0.9099099099099099
  - 0.9429972140815515
  - 0.8899924020405948
  - 0.8102051061388411
  - 0.897680813343464
  - 0.9072144433590217
  - 0.9027099388545171
  - 0.9013374928284567
  - 0.8933753030138573
  - 0.9007742682441477
  - 0.7582401678787221
  - 0.8394650028686174
  - 0.9084264987879446
  - 0.9248706537863164
  - 0.9025652158182279
  LT_roc_auc:
  - 0.7464851273095179
  - 0.8070160568192419
  - 0.7671374877542029
  - 0.7495980110865037
  - 0.7434287423705621
  - 0.8282561073115647
  - 0.8581515713432529
  - 0.7248873080368884
  - 0.7416702021310315
  - 0.8214536806710186
  - 0.825933822968755
  - 0.7161292196413338
  - 0.7809758680282048
  - 0.8639437428595502
  - 0.8149123105014526
  - 0.7647137432401965
  TL_average_precision:
  - 0.6370078462668374
  - 0.633164214283167
  - 0.6411491137448934
  - 0.6178066238744765
  - 0.7471450315945363
  - 0.7687732391130544
  - 0.7549868558100056
  - 0.7403598108364434
  - 0.7762558161105915
  - 0.7793847279032164
  - 0.7568510471315804
  - 0.761616561136484
  - 0.7358591397124328
  - 0.7506752253670301
  - 0.7611078428496687
  - 0.7467800590398165
  TL_balanced_accuracy:
  - 0.8156483620594818
  - 0.8264355252618788
  - 0.845687898660911
  - 0.8113298077039275
  - 0.8368254362998804
  - 0.8812406674388004
  - 0.8776183961085651
  - 0.8660989096273104
  - 0.8906129759762924
  - 0.903117184127904
  - 0.8933379658908434
  - 0.8529819314356711
  - 0.866869255713107
  - 0.8850546741461927
  - 0.9046835829319193
  - 0.8823749109954838
  TL_f1_macro:
  - 0.5246313529242793
  - 0.5633650451129322
  - 0.6003144739431029
  - 0.5509126325190036
  - 0.4987500443070732
  - 0.5951374549119345
  - 0.5773548558408907
  - 0.5928739440700265
  - 0.6003303919531892
  - 0.603054214036873
  - 0.5782143494799948
  - 0.48958487043440035
  - 0.5234766670273715
  - 0.5794109216688635
  - 0.6030360599360798
  - 0.5774290302442856
  TL_f1_micro:
  - 0.8846195593183545
  - 0.9215244210374431
  - 0.9484885650385975
  - 0.9195945458480629
  - 0.8265313506277362
  - 0.9330134910901088
  - 0.9241216362455811
  - 0.9394343842435611
  - 0.9443720829262998
  - 0.9405526296803982
  - 0.928811052593608
  - 0.8130005050140683
  - 0.8912587286081262
  - 0.9355024889979078
  - 0.9499494985931751
  - 0.9393622393766683
  TL_f1_weighted:
  - 0.9303140543341998
  - 0.9502328047494049
  - 0.9657263717439128
  - 0.9499633203793881
  - 0.8955398711034248
  - 0.9562945842048538
  - 0.9517339967090995
  - 0.9605177030420916
  - 0.963792222442496
  - 0.9612551379242388
  - 0.9550907200073547
  - 0.8881568640173101
  - 0.9357821464371988
  - 0.9592763614756152
  - 0.967599374878386
  - 0.961919582742847
  TL_matthews_corrcoef:
  - 0.18993304629397828
  - 0.24464032124708737
  - 0.30142896761246013
  - 0.2191006207760652
  - 0.17881374706469136
  - 0.31263629540242144
  - 0.2857626482052949
  - 0.30075222092661236
  - 0.32025771629075256
  - 0.33087806642369094
  - 0.2909679417061684
  - 0.17306416708706196
  - 0.20006756500952555
  - 0.2872005646292229
  - 0.32779952690420244
  - 0.28129015005549474
  TL_precision_macro:
  - 0.5285717957152843
  - 0.5458351513149994
  - 0.5657091431807962
  - 0.538548414604513
  - 0.5237321418555576
  - 0.5640943251539661
  - 0.5540627071872221
  - 0.5617673912798389
  - 0.5656436237092602
  - 0.5678960728734053
  - 0.5538101775333195
  - 0.5212129880187627
  - 0.527276086743108
  - 0.5535535404850247
  - 0.5663805837267532
  - 0.5517320476860322
  TL_precision_micro:
  - 0.8846195593183545
  - 0.9215244210374431
  - 0.9484885650385975
  - 0.9195945458480629
  - 0.8265313506277362
  - 0.9330134910901089
  - 0.9241216362455811
  - 0.9394343842435611
  - 0.9443720829262998
  - 0.9405526296803982
  - 0.928811052593608
  - 0.8130005050140683
  - 0.8912587286081262
  - 0.9355024889979078
  - 0.9499494985931751
  - 0.9393622393766683
  TL_precision_weighted:
  - 0.9881496152524631
  - 0.9869996022728983
  - 0.9883649883622947
  - 0.9880039732022131
  - 0.9880299821808657
  - 0.9876160309169596
  - 0.9881545927296959
  - 0.9883623923241198
  - 0.9896861385319095
  - 0.9892585962614905
  - 0.9895842910710859
  - 0.9896681226009301
  - 0.9915236499615346
  - 0.9901514332799863
  - 0.991071230044277
  - 0.9908915802349073
  TL_recall_macro:
  - 0.8156483620594818
  - 0.8264355252618788
  - 0.845687898660911
  - 0.8113298077039275
  - 0.8368254362998804
  - 0.8812406674388004
  - 0.8776183961085651
  - 0.8660989096273104
  - 0.8906129759762924
  - 0.903117184127904
  - 0.8933379658908434
  - 0.8529819314356711
  - 0.866869255713107
  - 0.8850546741461927
  - 0.9046835829319193
  - 0.8823749109954838
  TL_recall_micro:
  - 0.8846195593183545
  - 0.9215244210374431
  - 0.9484885650385975
  - 0.9195945458480629
  - 0.8265313506277362
  - 0.9330134910901089
  - 0.9241216362455811
  - 0.9394343842435611
  - 0.9443720829262998
  - 0.9405526296803982
  - 0.928811052593608
  - 0.8130005050140683
  - 0.8912587286081262
  - 0.9355024889979078
  - 0.9499494985931751
  - 0.9393622393766683
  TL_recall_weighted:
  - 0.8846195593183545
  - 0.9215244210374431
  - 0.9484885650385975
  - 0.9195945458480629
  - 0.8265313506277362
  - 0.9330134910901089
  - 0.9241216362455811
  - 0.9394343842435611
  - 0.9443720829262998
  - 0.9405526296803982
  - 0.928811052593608
  - 0.8130005050140683
  - 0.8912587286081262
  - 0.9355024889979078
  - 0.9499494985931751
  - 0.9393622393766683
  TL_roc_auc:
  - 0.8865425232926182
  - 0.8467470611134056
  - 0.8493881089018093
  - 0.8134105315796076
  - 0.9000929683821259
  - 0.9167958081516535
  - 0.921735909067936
  - 0.8905534099081094
  - 0.9084434736683467
  - 0.9250180707397401
  - 0.9062002311798397
  - 0.9113176106125861
  - 0.8867663578626412
  - 0.901378687141493
  - 0.9119097438904924
  - 0.8936605726381431
  TT_average_precision:
  - 0.17985080844423054
  - 0.23243958209779028
  - 0.1863097119700318
  - 0.19910653865263586
  - 0.17472091502442216
  - 0.3491904151760065
  - 0.2436284288556276
  - 0.25890639715486047
  - 0.18224052934760926
  - 0.30745912737778003
  - 0.23593103591716993
  - 0.21943829913177323
  - 0.1687293999318275
  - 0.24058914067966666
  - 0.10103800976663577
  - 0.11292086389684988
  TT_balanced_accuracy:
  - 0.6862514628287515
  - 0.6827036155781643
  - 0.6350769224174908
  - 0.6764962474290108
  - 0.6572940603220783
  - 0.7424206859739406
  - 0.7033323274443104
  - 0.7290029313159586
  - 0.6918614130434783
  - 0.7308786519312835
  - 0.7250802109717879
  - 0.6765992098199475
  - 0.6658216371087659
  - 0.7812012027152122
  - 0.6641529038608771
  - 0.7004470077346451
  TT_f1_macro:
  - 0.5090081724357653
  - 0.5215107564130348
  - 0.536995683058884
  - 0.5306542930443254
  - 0.47537249123871694
  - 0.5199410430448597
  - 0.5273768833466678
  - 0.5522498108772519
  - 0.5365177384241561
  - 0.5176857176966031
  - 0.5313737219976951
  - 0.4799013020333388
  - 0.4974153823195385
  - 0.5191381377929214
  - 0.5174258702937947
  - 0.5174015808391395
  TT_f1_micro:
  - 0.8774741824440618
  - 0.9240746770867253
  - 0.9455660479756866
  - 0.9160968197112775
  - 0.8043244406196214
  - 0.9007923586236839
  - 0.907142081840877
  - 0.9240204059481166
  - 0.9256669535283993
  - 0.9048626940193205
  - 0.9115380440681645
  - 0.814718332790622
  - 0.8604776247848537
  - 0.9111581460979051
  - 0.9242917616411592
  - 0.9065450993161837
  TT_f1_weighted:
  - 0.9246477148318123
  - 0.9535387070182888
  - 0.9634818667388648
  - 0.9462434204914332
  - 0.8805629986475827
  - 0.9401027491056805
  - 0.9418375885629067
  - 0.9503698406196076
  - 0.9524386652038025
  - 0.9428791625285654
  - 0.9448906141413509
  - 0.8875519076631478
  - 0.9149300684402644
  - 0.9477988332959727
  - 0.9537984965949516
  - 0.9431875265969304
  TT_matthews_corrcoef:
  - 0.12070956294984454
  - 0.12220103767972113
  - 0.1205485283299735
  - 0.13663738277570214
  - 0.0874352219887785
  - 0.14953369407598385
  - 0.145260289614837
  - 0.18820598123351578
  - 0.14878273693070923
  - 0.13990932409285256
  - 0.15831973167726918
  - 0.09700929734190067
  - 0.10137820064923701
  - 0.15552314164184028
  - 0.10877795730585918
  - 0.12828183829883916
  TT_precision_macro:
  - 0.5195579652989619
  - 0.5204334949294037
  - 0.5268956891792508
  - 0.5264450018679618
  - 0.5121506782083397
  - 0.5230594241310058
  - 0.5259434296604477
  - 0.5386692554201402
  - 0.5288441308461231
  - 0.5211957870556444
  - 0.5278402278571529
  - 0.5133222620027068
  - 0.515494871094741
  - 0.521503684330472
  - 0.5180207655748565
  - 0.5205244146860931
  TT_precision_micro:
  - 0.877474182444062
  - 0.9240746770867253
  - 0.9455660479756866
  - 0.9160968197112775
  - 0.8043244406196214
  - 0.9007923586236839
  - 0.907142081840877
  - 0.9240204059481167
  - 0.9256669535283993
  - 0.9048626940193205
  - 0.9115380440681645
  - 0.814718332790622
  - 0.8604776247848537
  - 0.9111581460979051
  - 0.9242917616411592
  - 0.9065450993161837
  TT_precision_weighted:
  - 0.9825757546105667
  - 0.9878264827977321
  - 0.9839673533927855
  - 0.9822201661384307
  - 0.980610360574934
  - 0.9877443345756606
  - 0.9837983673073306
  - 0.9828111584004618
  - 0.9842998769000114
  - 0.988409719299831
  - 0.985337782562647
  - 0.9822995505731142
  - 0.982218114100751
  - 0.9915072626671079
  - 0.9878266217193332
  - 0.9867986657231336
  TT_recall_macro:
  - 0.6862514628287515
  - 0.6827036155781643
  - 0.6350769224174908
  - 0.6764962474290108
  - 0.6572940603220783
  - 0.7424206859739406
  - 0.7033323274443104
  - 0.7290029313159586
  - 0.6918614130434783
  - 0.7308786519312835
  - 0.7250802109717879
  - 0.6765992098199475
  - 0.6658216371087659
  - 0.7812012027152122
  - 0.6641529038608771
  - 0.7004470077346451
  TT_recall_micro:
  - 0.877474182444062
  - 0.9240746770867253
  - 0.9455660479756866
  - 0.9160968197112775
  - 0.8043244406196214
  - 0.9007923586236839
  - 0.907142081840877
  - 0.9240204059481167
  - 0.9256669535283993
  - 0.9048626940193205
  - 0.9115380440681645
  - 0.814718332790622
  - 0.8604776247848537
  - 0.9111581460979051
  - 0.9242917616411592
  - 0.9065450993161837
  TT_recall_weighted:
  - 0.877474182444062
  - 0.9240746770867253
  - 0.9455660479756866
  - 0.9160968197112775
  - 0.8043244406196214
  - 0.9007923586236839
  - 0.907142081840877
  - 0.9240204059481167
  - 0.9256669535283993
  - 0.9048626940193205
  - 0.9115380440681645
  - 0.814718332790622
  - 0.8604776247848538
  - 0.9111581460979051
  - 0.9242917616411592
  - 0.9065450993161837
  TT_roc_auc:
  - 0.7897786765762621
  - 0.7401580485966768
  - 0.6952850288698257
  - 0.7016250082935137
  - 0.7031038539382996
  - 0.8295371181429979
  - 0.8258682651157687
  - 0.7410797362776401
  - 0.7324960371376812
  - 0.8091114558042012
  - 0.8299424779656217
  - 0.643005344425859
  - 0.7470859173829472
  - 0.848249868240037
  - 0.7799296104748363
  - 0.7017276704418898
  fit_time:
  - 17.56875228881836
  - 15.307606935501099
  - 16.616599559783936
  - 19.061108827590942
  - 15.758297443389893
  - 15.54249095916748
  - 17.03512406349182
  - 20.55953884124756
  - 19.05038595199585
  - 17.774482011795044
  - 17.277077674865723
  - 19.303592920303345
  - 16.933396339416504
  - 18.06726622581482
  - 17.380831718444824
  - 20.293097257614136
  score_time:
  - 215.0890974998474
  - 216.84845113754272
  - 224.07910919189453
  - 238.18442964553833
  - 212.32118678092957
  - 207.2795774936676
  - 210.1557538509369
  - 233.37783575057983
  - 227.11617803573608
  - 212.54212355613708
  - 215.123548746109
  - 228.94934034347534
  - 218.2828938961029
  - 215.52626991271973
  - 217.8438401222229
  - 231.5159137248993
start: 2023-10-05 17:18:17.058114
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
