active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-05 19:31:10.782710
estimator:
  call: bipartite_adaptations.estimators.brf_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: brf_lmo
  params: {}
hash: aee8a7a764b06997e5ecd13c8da17a10aaea3a934627fbc1fcb427c8a1881c41
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/aee8a7a_20231005T190749531830_brf_lmo_kiba.yml"
results:
  LL_average_precision:
  - 0.9914375145310466
  - 0.9919330931225652
  - 0.9763473597883112
  - 0.9817533044497091
  - 0.9913346926686408
  - 0.9812123997387372
  - 0.9751591655076478
  - 0.9917723553025712
  - 0.9742550606337737
  - 0.9796633399454087
  - 0.9755014086557207
  - 0.9860007557759088
  - 0.9726004127314204
  - 0.9755543820945548
  - 0.9729210807360431
  - 0.969626862317263
  LL_balanced_accuracy:
  - 0.9146218649695119
  - 0.905311337846858
  - 0.8678645330390399
  - 0.8927560902145837
  - 0.9079365636392112
  - 0.8913687465978527
  - 0.8660433769129421
  - 0.9067386327883986
  - 0.8684508052062652
  - 0.8876514130370653
  - 0.8683873220348327
  - 0.8939693682195278
  - 0.8719818004328633
  - 0.8859787786023081
  - 0.8711013093781032
  - 0.8676875642482444
  LL_f1_macro:
  - 0.8240283152994771
  - 0.804683045328658
  - 0.751889833224882
  - 0.786652679063359
  - 0.8138535255577704
  - 0.7829379492913751
  - 0.7501514641320031
  - 0.8108489818460735
  - 0.7491593744094831
  - 0.7753192866151744
  - 0.7521703334618123
  - 0.7879793071354524
  - 0.7580475281958664
  - 0.7759952408625554
  - 0.759577876850403
  - 0.7504296113301694
  LL_f1_micro:
  - 0.862822459391266
  - 0.8468245456815878
  - 0.788923739147042
  - 0.8273847125710676
  - 0.8524453901652426
  - 0.8246925913411391
  - 0.7864042368772863
  - 0.8502291792152081
  - 0.7885205749686914
  - 0.8181624528052416
  - 0.789566469317898
  - 0.8291366113796295
  - 0.7954656211235158
  - 0.8165558198261686
  - 0.7951278776133427
  - 0.7882017852948086
  LL_f1_weighted:
  - 0.874156571277845
  - 0.8607213245236974
  - 0.809156792746164
  - 0.8434760039396492
  - 0.8649510417309036
  - 0.8413814411379473
  - 0.8067325645497295
  - 0.8631547340759254
  - 0.8095342120184862
  - 0.8360029618052942
  - 0.8098248604833983
  - 0.8450976666141838
  - 0.8149262331279363
  - 0.8340408849488214
  - 0.8140683099388809
  - 0.8087649408358646
  LL_matthews_corrcoef:
  - 0.6989171337797723
  - 0.6708390727787553
  - 0.599277000224651
  - 0.6456727481007158
  - 0.6841443596284672
  - 0.6404839560675754
  - 0.5970774615697737
  - 0.6797853636518734
  - 0.5955151401573832
  - 0.6300143306313181
  - 0.599612433536283
  - 0.6474781701922453
  - 0.6073181617813554
  - 0.6310892785981034
  - 0.6094969435198977
  - 0.5973009182993947
  LL_precision_macro:
  - 0.7945365411004383
  - 0.7775798624073382
  - 0.744066015301442
  - 0.7653639930905713
  - 0.7868420892674646
  - 0.7620416816276142
  - 0.7434830935346994
  - 0.7840326092626886
  - 0.740627973358706
  - 0.7559761447089556
  - 0.7439925649893211
  - 0.7660282846164679
  - 0.7478853462725076
  - 0.7579634552731682
  - 0.7502595078299776
  - 0.7425757774339818
  LL_precision_micro:
  - 0.8628224593912661
  - 0.8468245456815878
  - 0.788923739147042
  - 0.8273847125710676
  - 0.8524453901652426
  - 0.8246925913411391
  - 0.7864042368772863
  - 0.8502291792152081
  - 0.7885205749686914
  - 0.8181624528052417
  - 0.789566469317898
  - 0.8291366113796295
  - 0.7954656211235158
  - 0.8165558198261686
  - 0.7951278776133427
  - 0.7882017852948086
  LL_precision_weighted:
  - 0.9191924033448772
  - 0.9149631569322273
  - 0.8969669161777816
  - 0.9083882361187635
  - 0.9153454378854603
  - 0.9081187692405519
  - 0.8959860856579536
  - 0.9149155491966092
  - 0.8982242690953036
  - 0.9069078514115061
  - 0.8973115661782299
  - 0.9090910116431318
  - 0.8985915853829449
  - 0.9053504890985714
  - 0.8974576069668644
  - 0.8972393460976839
  LL_recall_macro:
  - 0.9146218649695119
  - 0.905311337846858
  - 0.8678645330390399
  - 0.8927560902145837
  - 0.9079365636392112
  - 0.8913687465978527
  - 0.8660433769129421
  - 0.9067386327883986
  - 0.8684508052062652
  - 0.8876514130370653
  - 0.8683873220348327
  - 0.8939693682195278
  - 0.8719818004328633
  - 0.8859787786023081
  - 0.8711013093781032
  - 0.8676875642482444
  LL_recall_micro:
  - 0.8628224593912661
  - 0.8468245456815878
  - 0.788923739147042
  - 0.8273847125710676
  - 0.8524453901652426
  - 0.8246925913411391
  - 0.7864042368772863
  - 0.8502291792152081
  - 0.7885205749686914
  - 0.8181624528052417
  - 0.789566469317898
  - 0.8291366113796295
  - 0.7954656211235158
  - 0.8165558198261686
  - 0.7951278776133427
  - 0.7882017852948086
  LL_recall_weighted:
  - 0.8628224593912661
  - 0.8468245456815878
  - 0.788923739147042
  - 0.8273847125710676
  - 0.8524453901652426
  - 0.8246925913411391
  - 0.7864042368772863
  - 0.8502291792152081
  - 0.7885205749686914
  - 0.8181624528052417
  - 0.789566469317898
  - 0.8291366113796295
  - 0.7954656211235158
  - 0.8165558198261686
  - 0.7951278776133427
  - 0.7882017852948086
  LL_roc_auc:
  - 0.9984630290878426
  - 0.9985451304594596
  - 0.9956794978666068
  - 0.9968328448182628
  - 0.998424746785379
  - 0.9967644850586537
  - 0.9954443048695484
  - 0.9984434281794794
  - 0.9954680617315201
  - 0.996568010622159
  - 0.9955128982109186
  - 0.9974562762743429
  - 0.9950076403365911
  - 0.9958328329067038
  - 0.9950217908098987
  - 0.9945293516483228
  LT_average_precision:
  - 0.46134839936386834
  - 0.44700861725862595
  - 0.3775796227618712
  - 0.3732136247581854
  - 0.4736579095815849
  - 0.42344350096990546
  - 0.40487676370411574
  - 0.3692118710607329
  - 0.4719937696288675
  - 0.4445454810528091
  - 0.38445868382178855
  - 0.37962590192291534
  - 0.4683841028913165
  - 0.4278622358186792
  - 0.39847386425142794
  - 0.3696456119217466
  LT_balanced_accuracy:
  - 0.73225576469576
  - 0.7216252068623694
  - 0.7061306806246648
  - 0.7112065269860666
  - 0.7424132610022907
  - 0.7170856044481693
  - 0.704466247917348
  - 0.7100915381611985
  - 0.7288894923900561
  - 0.713534411957992
  - 0.7053346192002512
  - 0.7123166166743065
  - 0.7261212279318506
  - 0.7138756917022984
  - 0.7037552154800897
  - 0.7041357447124739
  LT_f1_macro:
  - 0.6210359082254356
  - 0.6239618471375219
  - 0.5685181495218206
  - 0.6015128338415572
  - 0.628775891151397
  - 0.614269410232335
  - 0.5703189980364154
  - 0.6129029165984293
  - 0.5908418965326921
  - 0.6074655007027929
  - 0.5706691176818125
  - 0.6073382688167848
  - 0.593049064010508
  - 0.6116509724517654
  - 0.5703866739776275
  - 0.5888290189432948
  LT_f1_micro:
  - 0.663635175463437
  - 0.6604160432667265
  - 0.6060223204885239
  - 0.6398687812392637
  - 0.6698542705905417
  - 0.646850860568984
  - 0.6072857443672353
  - 0.656692267624209
  - 0.6209619448014464
  - 0.6399574425640855
  - 0.6099012534494797
  - 0.6481032017820926
  - 0.6216692789968652
  - 0.6424220272904484
  - 0.6057061846535531
  - 0.6206361864256601
  LT_f1_weighted:
  - 0.6986924225459269
  - 0.6916552677207238
  - 0.6498410986937754
  - 0.6760201591091101
  - 0.7039360640221417
  - 0.6787850055507906
  - 0.6502180681778001
  - 0.6909108144667145
  - 0.6589556936171929
  - 0.6730539147766496
  - 0.6537288824631395
  - 0.683510489892709
  - 0.6581857788764374
  - 0.6739534292642362
  - 0.6478609374681681
  - 0.6568131662612494
  LT_matthews_corrcoef:
  - 0.36830204619586626
  - 0.3620140342267746
  - 0.31740910477858236
  - 0.3371370457343117
  - 0.38530151435253024
  - 0.3550750908283437
  - 0.3166087273145488
  - 0.3373228774986896
  - 0.3623946359794792
  - 0.3476694589176039
  - 0.3157491288876474
  - 0.33935131382875044
  - 0.36155091046687166
  - 0.35148840008569854
  - 0.31730846097691384
  - 0.3285366539628573
  LT_precision_macro:
  - 0.6460097205872909
  - 0.6478330949269342
  - 0.6221901313902297
  - 0.6345382044158578
  - 0.6531034815799024
  - 0.6451942431273219
  - 0.6225643440332742
  - 0.6354013644241706
  - 0.643442443354823
  - 0.6415158938033823
  - 0.6213841981220892
  - 0.6355985650124047
  - 0.6445232078109231
  - 0.6444110997508423
  - 0.6235362971817724
  - 0.6321869586695107
  LT_precision_micro:
  - 0.663635175463437
  - 0.6604160432667265
  - 0.6060223204885239
  - 0.6398687812392637
  - 0.6698542705905417
  - 0.646850860568984
  - 0.6072857443672353
  - 0.656692267624209
  - 0.6209619448014464
  - 0.6399574425640855
  - 0.6099012534494797
  - 0.6481032017820926
  - 0.6216692789968652
  - 0.6424220272904484
  - 0.6057061846535531
  - 0.6206361864256601
  LT_precision_weighted:
  - 0.8274904592716602
  - 0.8111672158372668
  - 0.8304080006117288
  - 0.8146944735768159
  - 0.8330472707941569
  - 0.8103059012716446
  - 0.8271959845615885
  - 0.8089352253775364
  - 0.837916707099589
  - 0.8105997867492682
  - 0.8289289887352925
  - 0.8133830173843732
  - 0.8330460213693156
  - 0.807394683615417
  - 0.8256322592631012
  - 0.8118901903844196
  LT_recall_macro:
  - 0.73225576469576
  - 0.7216252068623694
  - 0.7061306806246648
  - 0.7112065269860666
  - 0.7424132610022907
  - 0.7170856044481693
  - 0.704466247917348
  - 0.7100915381611985
  - 0.7288894923900561
  - 0.713534411957992
  - 0.7053346192002512
  - 0.7123166166743065
  - 0.7261212279318506
  - 0.7138756917022984
  - 0.7037552154800897
  - 0.7041357447124739
  LT_recall_micro:
  - 0.663635175463437
  - 0.6604160432667265
  - 0.6060223204885239
  - 0.6398687812392637
  - 0.6698542705905417
  - 0.646850860568984
  - 0.6072857443672353
  - 0.656692267624209
  - 0.6209619448014464
  - 0.6399574425640855
  - 0.6099012534494797
  - 0.6481032017820926
  - 0.6216692789968652
  - 0.6424220272904484
  - 0.6057061846535531
  - 0.6206361864256601
  LT_recall_weighted:
  - 0.663635175463437
  - 0.6604160432667265
  - 0.6060223204885238
  - 0.6398687812392637
  - 0.6698542705905417
  - 0.646850860568984
  - 0.6072857443672353
  - 0.656692267624209
  - 0.6209619448014464
  - 0.6399574425640855
  - 0.6099012534494797
  - 0.6481032017820926
  - 0.6216692789968653
  - 0.6424220272904484
  - 0.6057061846535531
  - 0.6206361864256601
  LT_roc_auc:
  - 0.8027741587904909
  - 0.7826144658124325
  - 0.764316728963483
  - 0.7547332091424763
  - 0.8126562370492112
  - 0.7773383880036384
  - 0.7679557303742166
  - 0.7512267059192694
  - 0.8090526539793733
  - 0.7778947310814223
  - 0.7669981254131619
  - 0.7564000020209509
  - 0.8046152325308814
  - 0.7715559716184303
  - 0.7653130956481734
  - 0.7528903236011188
  TL_average_precision:
  - 0.6760683249926345
  - 0.6770029465729558
  - 0.6604868279926811
  - 0.6581708250848893
  - 0.6520626709284194
  - 0.6371915683408345
  - 0.6421056934021319
  - 0.6299094203683812
  - 0.6629379834329108
  - 0.6581157511254186
  - 0.665509169541413
  - 0.6593259763370235
  - 0.6325278574328366
  - 0.6259339037628001
  - 0.6276585167460164
  - 0.6062410019061188
  TL_balanced_accuracy:
  - 0.7953636203763694
  - 0.7901278571981212
  - 0.762503187487665
  - 0.7758679976447141
  - 0.7894304165020204
  - 0.7812418597848672
  - 0.7583772219926816
  - 0.780097951659297
  - 0.7768432479854296
  - 0.7829328776432244
  - 0.7695575298431212
  - 0.7793453504610477
  - 0.7760325283201555
  - 0.7832457427729314
  - 0.7666492906340026
  - 0.7662170503146885
  TL_f1_macro:
  - 0.6794724559815769
  - 0.6613355678528963
  - 0.6222926943857177
  - 0.6422901860403141
  - 0.6628490591905858
  - 0.642905420010899
  - 0.6152257999222324
  - 0.6497463916980162
  - 0.6393902000389584
  - 0.6479855461265538
  - 0.6350597053105944
  - 0.6526325580160542
  - 0.6325454035813052
  - 0.6401932647265735
  - 0.6267142422707703
  - 0.618109659006386
  TL_f1_micro:
  - 0.716728690412901
  - 0.6972229563072586
  - 0.6458994009866103
  - 0.6730752290345313
  - 0.699727538543328
  - 0.6785588442565187
  - 0.6401074700493306
  - 0.6858593199436223
  - 0.6663454722665249
  - 0.6801224453840733
  - 0.6599828224101479
  - 0.6844608879492601
  - 0.6672880810501903
  - 0.6797030139887913
  - 0.6587418913551918
  - 0.6515378844711178
  TL_f1_weighted:
  - 0.7444766090202863
  - 0.728145374400753
  - 0.6778117089056818
  - 0.7051706180521493
  - 0.7304606338413083
  - 0.7125647761495564
  - 0.6736084075626235
  - 0.7183214504639085
  - 0.697771268476253
  - 0.712175020416136
  - 0.6907153476668976
  - 0.7150410934856671
  - 0.7027842897048857
  - 0.7155691901426315
  - 0.693635635661058
  - 0.6887753670400413
  TL_matthews_corrcoef:
  - 0.47665512547570893
  - 0.46203438328205093
  - 0.4263255073278248
  - 0.44174914616189004
  - 0.4610102067511478
  - 0.4425431049691621
  - 0.4163034922491078
  - 0.44424693322788683
  - 0.4466355157778563
  - 0.45119799118067394
  - 0.4386076402644841
  - 0.4496726789356003
  - 0.43244062623100643
  - 0.43913145968137696
  - 0.4218906565978735
  - 0.4156816766977073
  TL_precision_macro:
  - 0.6923054270806542
  - 0.6839497363304274
  - 0.6730964106929824
  - 0.6768439161128065
  - 0.6835764303017307
  - 0.674088949548225
  - 0.6676895086979763
  - 0.6761485013664432
  - 0.6801410052491605
  - 0.6798833251028071
  - 0.6784189280580843
  - 0.6809637406237368
  - 0.6693685309056837
  - 0.6702024159251772
  - 0.6668781170403456
  - 0.6622653922222159
  TL_precision_micro:
  - 0.716728690412901
  - 0.6972229563072586
  - 0.6458994009866103
  - 0.6730752290345313
  - 0.699727538543328
  - 0.6785588442565187
  - 0.6401074700493306
  - 0.6858593199436223
  - 0.6663454722665249
  - 0.6801224453840733
  - 0.6599828224101479
  - 0.6844608879492601
  - 0.6672880810501903
  - 0.6797030139887913
  - 0.6587418913551918
  - 0.6515378844711178
  TL_precision_weighted:
  - 0.8592764844951536
  - 0.8625572998132843
  - 0.8548955506881556
  - 0.8576943688690462
  - 0.8612710789742569
  - 0.8630852668296695
  - 0.8545164474845784
  - 0.8585524592676342
  - 0.8602984003111128
  - 0.8619069969866726
  - 0.8550416191516006
  - 0.8558275951138629
  - 0.8632934582843829
  - 0.8667447521841477
  - 0.856853507848832
  - 0.8612718939974953
  TL_recall_macro:
  - 0.7953636203763694
  - 0.7901278571981212
  - 0.762503187487665
  - 0.7758679976447141
  - 0.7894304165020204
  - 0.7812418597848672
  - 0.7583772219926816
  - 0.780097951659297
  - 0.7768432479854296
  - 0.7829328776432244
  - 0.7695575298431212
  - 0.7793453504610477
  - 0.7760325283201555
  - 0.7832457427729314
  - 0.7666492906340026
  - 0.7662170503146885
  TL_recall_micro:
  - 0.716728690412901
  - 0.6972229563072586
  - 0.6458994009866103
  - 0.6730752290345313
  - 0.699727538543328
  - 0.6785588442565187
  - 0.6401074700493306
  - 0.6858593199436223
  - 0.6663454722665249
  - 0.6801224453840733
  - 0.6599828224101479
  - 0.6844608879492601
  - 0.6672880810501903
  - 0.6797030139887913
  - 0.6587418913551918
  - 0.6515378844711178
  TL_recall_weighted:
  - 0.716728690412901
  - 0.6972229563072586
  - 0.6458994009866103
  - 0.6730752290345313
  - 0.699727538543328
  - 0.6785588442565187
  - 0.6401074700493306
  - 0.6858593199436223
  - 0.6663454722665249
  - 0.6801224453840733
  - 0.6599828224101479
  - 0.6844608879492601
  - 0.6672880810501903
  - 0.6797030139887913
  - 0.6587418913551918
  - 0.6515378844711177
  TL_roc_auc:
  - 0.8893004093835242
  - 0.8917490071292434
  - 0.8832493552050271
  - 0.8809912369841774
  - 0.8900043251118954
  - 0.8885943952072721
  - 0.8841964836783587
  - 0.8842859242674895
  - 0.893428811598274
  - 0.8940266931837119
  - 0.8911271672478939
  - 0.8873007555802208
  - 0.8840370236982602
  - 0.8833277727616128
  - 0.8760649861909083
  - 0.875569348992809
  TT_average_precision:
  - 0.35377061533162246
  - 0.3570313273095722
  - 0.3032979174877042
  - 0.2870063713396006
  - 0.3353300667006732
  - 0.3319040555130073
  - 0.29665609492356126
  - 0.27910068124028714
  - 0.35232659869093397
  - 0.3543017334085454
  - 0.3024251672607976
  - 0.2940046560280837
  - 0.32917064018539105
  - 0.32823152815507745
  - 0.2875111263122213
  - 0.2715898769899975
  TT_balanced_accuracy:
  - 0.6399437570761658
  - 0.6378795108253308
  - 0.6169894255149251
  - 0.6092014927000067
  - 0.6454492013917967
  - 0.6352412721421442
  - 0.6201999865592966
  - 0.6121241771926703
  - 0.6484218868344291
  - 0.6313280295077213
  - 0.6299598487597344
  - 0.6249198030122926
  - 0.6420909599966269
  - 0.6346265365759329
  - 0.6198188794843035
  - 0.623042655532753
  TT_f1_macro:
  - 0.5070281334720432
  - 0.510353488078223
  - 0.44829026110420067
  - 0.4829720460781766
  - 0.5022865452700079
  - 0.4933583806549961
  - 0.4414668873721218
  - 0.49300526839731756
  - 0.4805710222349049
  - 0.49651762623097007
  - 0.46716514946409726
  - 0.4981463994224443
  - 0.48096416533350134
  - 0.5004792697620031
  - 0.45083440253520235
  - 0.4727411635386837
  TT_f1_micro:
  - 0.5263192267502612
  - 0.5232589048378522
  - 0.4576023391812866
  - 0.49820574162679426
  - 0.5201149425287356
  - 0.503056884635832
  - 0.4514221158958001
  - 0.5143208399787347
  - 0.4876893939393939
  - 0.5050505050505051
  - 0.47906698564593303
  - 0.5153176501860712
  - 0.49568147614997055
  - 0.5163953527081461
  - 0.46739238989313897
  - 0.4864010120177103
  TT_f1_weighted:
  - 0.565869470810259
  - 0.5556518706872365
  - 0.4930406311984319
  - 0.5353669942988188
  - 0.5598443384903863
  - 0.5338666374356632
  - 0.48921135069996685
  - 0.5554701519621121
  - 0.5168280563559564
  - 0.5333584067596209
  - 0.5167146791086183
  - 0.5531178438466149
  - 0.5357044408863452
  - 0.5534962704149422
  - 0.5133300116448067
  - 0.5249311078929874
  TT_matthews_corrcoef:
  - 0.22817484933497603
  - 0.23373835320767644
  - 0.19627729728106588
  - 0.18191921433069802
  - 0.23676679523916488
  - 0.23149403081736927
  - 0.19904708539642554
  - 0.1826052631683504
  - 0.2556550052343527
  - 0.2278580713843077
  - 0.21502600889696244
  - 0.20648668693026287
  - 0.23145321220100185
  - 0.22286833857788488
  - 0.19025297506299335
  - 0.2029619957738223
  TT_precision_macro:
  - 0.5930083680701504
  - 0.5990604358711566
  - 0.5823253410690633
  - 0.5757649912204369
  - 0.5963541133113885
  - 0.5990627444108709
  - 0.5824037991578037
  - 0.5743476629475821
  - 0.6100907067942887
  - 0.5988351475492208
  - 0.5889432100441201
  - 0.5853282483067173
  - 0.594254042339206
  - 0.5922371948424361
  - 0.5755227278791689
  - 0.5836977460176964
  TT_precision_micro:
  - 0.5263192267502612
  - 0.5232589048378522
  - 0.45760233918128657
  - 0.49820574162679426
  - 0.5201149425287356
  - 0.503056884635832
  - 0.4514221158958001
  - 0.5143208399787347
  - 0.4876893939393939
  - 0.5050505050505051
  - 0.47906698564593303
  - 0.5153176501860712
  - 0.49568147614997055
  - 0.5163953527081461
  - 0.4673923898931389
  - 0.4864010120177103
  TT_precision_weighted:
  - 0.7867024820765813
  - 0.7752594406449669
  - 0.7959575384684547
  - 0.7610894595878174
  - 0.796717507087372
  - 0.7832787542528257
  - 0.8070804091327733
  - 0.7633976571253313
  - 0.8116279450927897
  - 0.7735555233761234
  - 0.8004069487985344
  - 0.7718905807986658
  - 0.8074826533139771
  - 0.7820383917543816
  - 0.805534825548642
  - 0.7878738867858145
  TT_recall_macro:
  - 0.6399437570761658
  - 0.6378795108253308
  - 0.6169894255149251
  - 0.6092014927000067
  - 0.6454492013917967
  - 0.6352412721421442
  - 0.6201999865592966
  - 0.6121241771926703
  - 0.6484218868344291
  - 0.6313280295077213
  - 0.6299598487597344
  - 0.6249198030122926
  - 0.6420909599966269
  - 0.6346265365759329
  - 0.6198188794843035
  - 0.623042655532753
  TT_recall_micro:
  - 0.5263192267502612
  - 0.5232589048378522
  - 0.45760233918128657
  - 0.49820574162679426
  - 0.5201149425287356
  - 0.503056884635832
  - 0.4514221158958001
  - 0.5143208399787347
  - 0.4876893939393939
  - 0.5050505050505051
  - 0.47906698564593303
  - 0.5153176501860712
  - 0.49568147614997055
  - 0.5163953527081461
  - 0.4673923898931389
  - 0.4864010120177103
  TT_recall_weighted:
  - 0.5263192267502612
  - 0.5232589048378522
  - 0.45760233918128657
  - 0.49820574162679426
  - 0.5201149425287356
  - 0.503056884635832
  - 0.4514221158958001
  - 0.5143208399787347
  - 0.4876893939393939
  - 0.5050505050505051
  - 0.47906698564593303
  - 0.5153176501860712
  - 0.49568147614997055
  - 0.5163953527081461
  - 0.4673923898931389
  - 0.4864010120177103
  TT_roc_auc:
  - 0.7061367961441096
  - 0.6958169101001108
  - 0.6692291844101548
  - 0.6457760065480792
  - 0.7085666489121947
  - 0.6897379410871716
  - 0.6825135775391431
  - 0.6493562822952611
  - 0.7185709758735057
  - 0.6945459958759117
  - 0.6863154459073358
  - 0.6626761214603598
  - 0.709413731141232
  - 0.6889474808434801
  - 0.6828199949945174
  - 0.6552996708234535
  fit_time:
  - 107.85221123695374
  - 103.76579332351685
  - 97.81704211235046
  - 101.1561758518219
  - 104.75609493255615
  - 104.01546335220337
  - 109.90316462516785
  - 107.3789529800415
  - 100.16999578475952
  - 101.33701062202454
  - 98.91298222541809
  - 96.11943078041077
  - 95.2107367515564
  - 98.22406268119812
  - 98.12393951416016
  - 89.59698486328125
  score_time:
  - 1232.2801113128662
  - 1236.9706852436066
  - 1177.2877798080444
  - 1202.329576253891
  - 1232.9408631324768
  - 1227.9098105430603
  - 1259.7383949756622
  - 1293.0370802879333
  - 1181.939331293106
  - 1238.0121862888336
  - 1226.7866969108582
  - 1263.1182413101196
  - 1166.8883366584778
  - 1189.1181485652924
  - 1147.2078828811646
  - 1238.2650692462921
start: 2023-10-05 19:07:49.531830
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
