active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: y_reconstruction/runs
end: 2023-10-10 02:06:33.599483
estimator:
  call: bipartite_adaptations.estimators.bxt_gmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state:
                        call: numpy.random.mtrand.RandomState
                        params: {}
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmo
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 5
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 5
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: square
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gmo
  params: {}
hash: 22de8080220c1ac4e109309d43647778bad8de01d422abf8c511a0564c260445
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/22de808_20231010T013443496374_bxt_gmo_enzymes.yml"
results:
  LL_average_precision:
  - 0.9550093583531105
  - 0.9534336206500633
  - 0.9572283408036831
  - 0.960451734132153
  - 0.9453486795370096
  - 0.9431265059342846
  - 0.9462748334185546
  - 0.9518646895757764
  - 0.9594613560270692
  - 0.9496104292378372
  - 0.9525267252886315
  - 0.9418926046792738
  - 0.9404181741343817
  - 0.9448209630249227
  - 0.9537818759520481
  - 0.9501970764076402
  LL_balanced_accuracy:
  - 0.8752381532093618
  - 0.907286558875177
  - 0.8979833494252455
  - 0.8433101263133616
  - 0.8987884430489126
  - 0.9138932252911126
  - 0.8882524707996406
  - 0.8826204620061529
  - 0.911874083226313
  - 0.9128197026135252
  - 0.8744754501563781
  - 0.7802975579849583
  - 0.8735358076128867
  - 0.8489172330775872
  - 0.8914307411907655
  - 0.8948178599838476
  LL_f1_macro:
  - 0.4638588012044575
  - 0.5004828862555768
  - 0.48798626791909294
  - 0.4359878061322516
  - 0.4850577566102612
  - 0.5065723228778615
  - 0.47726584725261234
  - 0.47013047533569036
  - 0.4996054951216844
  - 0.5070195449520776
  - 0.46554426442723945
  - 0.3802721351691376
  - 0.464734881326382
  - 0.44558760349515897
  - 0.483281967854858
  - 0.48473741105735846
  LL_f1_micro:
  - 0.7528070238913612
  - 0.8165295914195706
  - 0.7979943727003823
  - 0.6896027222663107
  - 0.7994078415765162
  - 0.8295517398937066
  - 0.7786655604453743
  - 0.7673989370656278
  - 0.8253795964639338
  - 0.827489599115023
  - 0.7514669456268187
  - 0.5647981146141452
  - 0.7496110568399725
  - 0.7011879854748335
  - 0.7851225260322727
  - 0.7917237813529567
  LL_f1_weighted:
  - 0.850100950380804
  - 0.8894277986036496
  - 0.8784748968659389
  - 0.806997707832404
  - 0.8801127600091853
  - 0.8975960395705777
  - 0.866519420994313
  - 0.8597135777998215
  - 0.8958829104159903
  - 0.8960579748580924
  - 0.8486217612845952
  - 0.7119683686859506
  - 0.8473860251064841
  - 0.8136731559679694
  - 0.8699832038569596
  - 0.8745587165578483
  LL_matthews_corrcoef:
  - 0.16530471836589708
  - 0.21047022083615774
  - 0.19319053068848852
  - 0.14292031701962662
  - 0.1855072094451493
  - 0.21669842628234232
  - 0.18026835626924462
  - 0.1705660537052523
  - 0.20363449291957883
  - 0.21873069886479612
  - 0.17038444666867303
  - 0.1098008030573898
  - 0.16970970966634882
  - 0.1580833556605459
  - 0.19022043707104014
  - 0.18952631216504953
  LL_precision_macro:
  - 0.5182055380565088
  - 0.5271907535944472
  - 0.5234448132073866
  - 0.5148744644065248
  - 0.521573421544657
  - 0.5283637210540325
  - 0.5209249668167504
  - 0.5190089014868964
  - 0.5251697110812318
  - 0.5289733740437966
  - 0.5193810166023346
  - 0.5107530515416537
  - 0.5192761878299528
  - 0.5179056413439901
  - 0.5231099725135431
  - 0.5227448063040723
  LL_precision_micro:
  - 0.7528070238913612
  - 0.8165295914195705
  - 0.7979943727003823
  - 0.6896027222663107
  - 0.7994078415765162
  - 0.8295517398937066
  - 0.7786655604453743
  - 0.7673989370656278
  - 0.8253795964639338
  - 0.827489599115023
  - 0.7514669456268187
  - 0.5647981146141452
  - 0.7496110568399725
  - 0.7011879854748335
  - 0.7851225260322728
  - 0.7917237813529567
  LL_precision_weighted:
  - 0.990999437732305
  - 0.990022602656834
  - 0.9905280316022389
  - 0.9907660134809361
  - 0.9913450816155551
  - 0.9903309061923998
  - 0.9907371683938307
  - 0.9911570186178662
  - 0.9912097097882182
  - 0.9900035832574285
  - 0.990366353493929
  - 0.9906405033908421
  - 0.9903469114022079
  - 0.9892991584772745
  - 0.9900683749656525
  - 0.9905255954982568
  LL_recall_macro:
  - 0.8752381532093618
  - 0.907286558875177
  - 0.8979833494252455
  - 0.8433101263133616
  - 0.8987884430489126
  - 0.9138932252911126
  - 0.8882524707996406
  - 0.8826204620061529
  - 0.911874083226313
  - 0.9128197026135252
  - 0.8744754501563781
  - 0.7802975579849583
  - 0.8735358076128867
  - 0.8489172330775872
  - 0.8914307411907655
  - 0.8948178599838476
  LL_recall_micro:
  - 0.7528070238913612
  - 0.8165295914195705
  - 0.7979943727003823
  - 0.6896027222663107
  - 0.7994078415765162
  - 0.8295517398937066
  - 0.7786655604453743
  - 0.7673989370656278
  - 0.8253795964639338
  - 0.827489599115023
  - 0.7514669456268187
  - 0.5647981146141452
  - 0.7496110568399725
  - 0.7011879854748335
  - 0.7851225260322728
  - 0.7917237813529567
  LL_recall_weighted:
  - 0.7528070238913612
  - 0.8165295914195705
  - 0.7979943727003823
  - 0.6896027222663107
  - 0.7994078415765162
  - 0.8295517398937066
  - 0.7786655604453743
  - 0.7673989370656278
  - 0.8253795964639338
  - 0.827489599115023
  - 0.7514669456268187
  - 0.5647981146141452
  - 0.7496110568399725
  - 0.7011879854748335
  - 0.7851225260322728
  - 0.7917237813529567
  LL_roc_auc:
  - 0.9996001807075531
  - 0.9995114264009675
  - 0.9995843900785449
  - 0.9996699395320895
  - 0.9995824641685024
  - 0.9994876037818863
  - 0.9995472261999296
  - 0.9996752171995891
  - 0.9996641381934299
  - 0.9995058884977421
  - 0.9995617394906832
  - 0.9995232025848654
  - 0.9994346154352002
  - 0.9994025678126454
  - 0.9995536137715058
  - 0.9995549974522444
  LT_average_precision:
  - 0.20227980840146745
  - 0.32611597711063306
  - 0.29314476470568857
  - 0.2636325751551348
  - 0.2676893559354667
  - 0.32097079987437604
  - 0.3110459336895479
  - 0.28978111404446927
  - 0.2530264907156879
  - 0.3237318490084632
  - 0.3390833660083519
  - 0.28456823438837797
  - 0.24029208877841512
  - 0.3635594795555826
  - 0.36514524449206787
  - 0.29259884544205134
  LT_balanced_accuracy:
  - 0.7541758156963798
  - 0.8042992554431577
  - 0.7912922630545041
  - 0.7239594949933001
  - 0.7567766048170582
  - 0.7762417094710714
  - 0.7804526504266771
  - 0.7465085533375808
  - 0.7690521541950113
  - 0.7728569772663514
  - 0.7942855646924565
  - 0.6797285869342891
  - 0.761731991436655
  - 0.7736363213758475
  - 0.8051234359475405
  - 0.7632017726799192
  LT_f1_macro:
  - 0.44075231070574555
  - 0.46169944341155533
  - 0.4549084804036687
  - 0.4178894971804726
  - 0.46129214815994335
  - 0.46528146046564234
  - 0.4455682644187448
  - 0.4511917600213462
  - 0.47309383652292825
  - 0.46604444559639263
  - 0.43198630467593413
  - 0.36033694717919346
  - 0.44025600634716267
  - 0.4153486771663551
  - 0.45328113620499677
  - 0.4658407807260467
  LT_f1_micro:
  - 0.7028829604130808
  - 0.771464235319657
  - 0.7429176164115923
  - 0.6538224971959912
  - 0.7546435742971886
  - 0.787040052100293
  - 0.7240131697963025
  - 0.7343065957523789
  - 0.7760327022375216
  - 0.7877636672817395
  - 0.6869640725062411
  - 0.5242230181989218
  - 0.7002474182444062
  - 0.6554325409747096
  - 0.7319186656536055
  - 0.7598683020369768
  LT_f1_weighted:
  - 0.8149677362058159
  - 0.8637665050092029
  - 0.8435749494037845
  - 0.7804775959767702
  - 0.8500706314305394
  - 0.8739328807180464
  - 0.8312856084535265
  - 0.8370260176778135
  - 0.8632927339724873
  - 0.8741992780673431
  - 0.8054066018763839
  - 0.6771443027658648
  - 0.8130793000235036
  - 0.7838753409360942
  - 0.8355913424621076
  - 0.8528685216421018
  LT_matthews_corrcoef:
  - 0.11687479655308068
  - 0.12561067893142067
  - 0.12849629982811706
  - 0.09690257221307468
  - 0.12357518177871843
  - 0.11488522213470963
  - 0.11869264631176575
  - 0.11347942431965058
  - 0.1373159472580284
  - 0.11525692281383929
  - 0.12162080860910841
  - 0.07422644436669044
  - 0.12019956581134313
  - 0.10326088446172435
  - 0.13745072036859693
  - 0.131390356416231
  LT_precision_macro:
  - 0.5134353046452312
  - 0.5129626037357818
  - 0.5141707325972025
  - 0.510481927213882
  - 0.514867812395256
  - 0.5119448057737311
  - 0.5125582199589277
  - 0.5130599725339795
  - 0.5175204593954885
  - 0.512171356574426
  - 0.5125657039126192
  - 0.5076637294284961
  - 0.5138003149155843
  - 0.5097417716754531
  - 0.5154795554061393
  - 0.5163975204112496
  LT_precision_micro:
  - 0.7028829604130808
  - 0.771464235319657
  - 0.7429176164115923
  - 0.6538224971959912
  - 0.7546435742971888
  - 0.787040052100293
  - 0.7240131697963024
  - 0.7343065957523789
  - 0.7760327022375215
  - 0.7877636672817395
  - 0.6869640725062411
  - 0.5242230181989218
  - 0.7002474182444062
  - 0.6554325409747096
  - 0.7319186656536054
  - 0.7598683020369768
  LT_precision_weighted:
  - 0.985919040875836
  - 0.9909069886752191
  - 0.9887124354035179
  - 0.9860912147545197
  - 0.9858540659144001
  - 0.9905929564109376
  - 0.9890474778226837
  - 0.9862678264790011
  - 0.9852121205239145
  - 0.9902511215732571
  - 0.9895406692473336
  - 0.986113948987674
  - 0.9861572401086537
  - 0.9906663643100925
  - 0.9884138598233829
  - 0.9851395559063727
  LT_recall_macro:
  - 0.7541758156963798
  - 0.8042992554431577
  - 0.7912922630545041
  - 0.7239594949933001
  - 0.7567766048170582
  - 0.7762417094710714
  - 0.7804526504266771
  - 0.7465085533375808
  - 0.7690521541950113
  - 0.7728569772663514
  - 0.7942855646924565
  - 0.6797285869342891
  - 0.761731991436655
  - 0.7736363213758475
  - 0.8051234359475405
  - 0.7632017726799192
  LT_recall_micro:
  - 0.7028829604130808
  - 0.771464235319657
  - 0.7429176164115923
  - 0.6538224971959912
  - 0.7546435742971888
  - 0.787040052100293
  - 0.7240131697963024
  - 0.7343065957523789
  - 0.7760327022375215
  - 0.7877636672817395
  - 0.6869640725062411
  - 0.5242230181989218
  - 0.7002474182444062
  - 0.6554325409747096
  - 0.7319186656536054
  - 0.7598683020369768
  LT_recall_weighted:
  - 0.7028829604130808
  - 0.771464235319657
  - 0.7429176164115923
  - 0.6538224971959912
  - 0.7546435742971888
  - 0.787040052100293
  - 0.7240131697963024
  - 0.7343065957523789
  - 0.7760327022375215
  - 0.7877636672817395
  - 0.6869640725062411
  - 0.5242230181989218
  - 0.7002474182444062
  - 0.6554325409747096
  - 0.7319186656536054
  - 0.7598683020369768
  LT_roc_auc:
  - 0.8502218398720907
  - 0.8811904759351464
  - 0.8940046566520563
  - 0.8298963897718079
  - 0.8309403324551777
  - 0.8718961691418737
  - 0.8963764339356914
  - 0.8084614650134918
  - 0.8529703543475763
  - 0.8594723737991722
  - 0.906659346449274
  - 0.819013359966081
  - 0.8629418173097498
  - 0.886686448745815
  - 0.9106448892420678
  - 0.8261539545757277
  TL_average_precision:
  - 0.5490629645976682
  - 0.5658386899215113
  - 0.5588538930029369
  - 0.522573507111609
  - 0.6502386139588937
  - 0.660643540281045
  - 0.6627596275569266
  - 0.6364789874266745
  - 0.7098706646355235
  - 0.7085867565000223
  - 0.693049531457806
  - 0.6777275919331014
  - 0.6646048127945833
  - 0.6739594786645604
  - 0.6846282233999598
  - 0.6576739422315093
  TL_balanced_accuracy:
  - 0.75768438837687
  - 0.7902988542985643
  - 0.786436182324563
  - 0.7216409886672307
  - 0.8038289362952546
  - 0.8235608485229584
  - 0.8104417820041157
  - 0.7982468056315779
  - 0.8293685924665345
  - 0.8278984998452839
  - 0.7887123364624345
  - 0.6928286361004543
  - 0.7728041103321721
  - 0.7573447861036053
  - 0.8131942215471334
  - 0.8083488797086607
  TL_f1_macro:
  - 0.4359270805417219
  - 0.4735895800136047
  - 0.45944187847734125
  - 0.40357793325577523
  - 0.4529794673854134
  - 0.4752879103060786
  - 0.44792748087250456
  - 0.4429405899888993
  - 0.4759555516540137
  - 0.47391884620834107
  - 0.4306480461146051
  - 0.32974842110043334
  - 0.4212871651128142
  - 0.40754539571856163
  - 0.45230083251932834
  - 0.4498313061618992
  TL_f1_micro:
  - 0.7000253265313506
  - 0.778533294856071
  - 0.75
  - 0.6246302575571748
  - 0.7293317413799342
  - 0.7695873313613736
  - 0.712953610850588
  - 0.7054685809104683
  - 0.7837476030247115
  - 0.77353726282375
  - 0.6808852175167737
  - 0.4622321621816608
  - 0.6739209088606679
  - 0.6324940480484813
  - 0.738384676430272
  - 0.7357153163552412
  TL_f1_weighted:
  - 0.8144371777048399
  - 0.8655454816476569
  - 0.8476485152924068
  - 0.7596690359862457
  - 0.8335845641120997
  - 0.8590118863177751
  - 0.8219927357836511
  - 0.8172336895461969
  - 0.8696102803710174
  - 0.8624589562784164
  - 0.8005745205181483
  - 0.6220725865125208
  - 0.7978686692915687
  - 0.7658803552402479
  - 0.8411709582996002
  - 0.8397414168942303
  TL_matthews_corrcoef:
  - 0.10937771311491581
  - 0.1434095847866895
  - 0.1319592181297592
  - 0.0892061524041777
  - 0.13845125980461412
  - 0.16350148184894514
  - 0.1420932457511425
  - 0.13308436669412665
  - 0.15660700486536602
  - 0.15904897629065257
  - 0.1223063607521706
  - 0.07515771306367554
  - 0.10038723243539223
  - 0.10161467912168963
  - 0.13202104496661338
  - 0.12684040792321313
  TL_precision_macro:
  - 0.5116067218910755
  - 0.5177113246436884
  - 0.5151981805406888
  - 0.508975931837573
  - 0.5157726511957842
  - 0.5206551060556575
  - 0.5162594821787124
  - 0.5148463020591875
  - 0.5186157351777497
  - 0.5192868958466115
  - 0.512953071267866
  - 0.5073234478384464
  - 0.5092351948287791
  - 0.5100308453586144
  - 0.513912737779753
  - 0.5130440631869071
  TL_precision_micro:
  - 0.7000253265313506
  - 0.778533294856071
  - 0.75
  - 0.6246302575571748
  - 0.7293317413799342
  - 0.7695873313613736
  - 0.712953610850588
  - 0.7054685809104683
  - 0.7837476030247115
  - 0.7735372628237501
  - 0.6808852175167737
  - 0.4622321621816608
  - 0.6739209088606679
  - 0.6324940480484813
  - 0.738384676430272
  - 0.7357153163552413
  TL_precision_weighted:
  - 0.9880584691412535
  - 0.9868068768792355
  - 0.9877076964305359
  - 0.9877781479695686
  - 0.9880674643413098
  - 0.9868970861999691
  - 0.9879426160393535
  - 0.9880967634071424
  - 0.9889023476207564
  - 0.988143098680337
  - 0.9888133634494026
  - 0.9891535120570263
  - 0.9911648681960166
  - 0.9892982419347639
  - 0.9901352802124267
  - 0.990459497823703
  TL_recall_macro:
  - 0.75768438837687
  - 0.7902988542985643
  - 0.786436182324563
  - 0.7216409886672307
  - 0.8038289362952546
  - 0.8235608485229584
  - 0.8104417820041157
  - 0.7982468056315779
  - 0.8293685924665345
  - 0.8278984998452839
  - 0.7887123364624345
  - 0.6928286361004543
  - 0.7728041103321721
  - 0.7573447861036053
  - 0.8131942215471334
  - 0.8083488797086607
  TL_recall_micro:
  - 0.7000253265313506
  - 0.778533294856071
  - 0.75
  - 0.6246302575571748
  - 0.7293317413799342
  - 0.7695873313613736
  - 0.712953610850588
  - 0.7054685809104683
  - 0.7837476030247115
  - 0.7735372628237501
  - 0.6808852175167737
  - 0.4622321621816608
  - 0.6739209088606679
  - 0.6324940480484813
  - 0.738384676430272
  - 0.7357153163552413
  TL_recall_weighted:
  - 0.7000253265313506
  - 0.778533294856071
  - 0.75
  - 0.6246302575571748
  - 0.7293317413799342
  - 0.7695873313613736
  - 0.712953610850588
  - 0.7054685809104683
  - 0.7837476030247115
  - 0.7735372628237501
  - 0.6808852175167737
  - 0.4622321621816608
  - 0.6739209088606679
  - 0.6324940480484813
  - 0.738384676430272
  - 0.7357153163552413
  TL_roc_auc:
  - 0.8691080540490541
  - 0.870083535656221
  - 0.8841800738345131
  - 0.8437097028677696
  - 0.9141079088668379
  - 0.9225114700368242
  - 0.9287083206981849
  - 0.9151895590148995
  - 0.9112740247078892
  - 0.9133730680198905
  - 0.9105311552340636
  - 0.9157967523112938
  - 0.8985823418287874
  - 0.9009017318125625
  - 0.9113504290764951
  - 0.904788878230137
  TT_average_precision:
  - 0.12711768497154163
  - 0.18910348489044895
  - 0.22164137443240048
  - 0.1956058463597707
  - 0.18733270721319462
  - 0.25829721179137105
  - 0.24481133054580656
  - 0.22234333822183525
  - 0.18015319479762917
  - 0.2814526211865096
  - 0.2630033831580692
  - 0.24525353012936849
  - 0.12392632710512236
  - 0.18915602379771837
  - 0.10554877045778562
  - 0.14411328923346273
  TT_balanced_accuracy:
  - 0.6942764900322336
  - 0.6519971830215512
  - 0.7468135115499204
  - 0.6604904816482431
  - 0.7174170958451433
  - 0.739479428993759
  - 0.7322939756391967
  - 0.7256529439167495
  - 0.755919384057971
  - 0.7313300142247511
  - 0.7362418722529409
  - 0.6054532322137957
  - 0.732015014688282
  - 0.7206621095692045
  - 0.7374060561553726
  - 0.7151348419490149
  TT_f1_macro:
  - 0.4154429789255699
  - 0.4412999883102548
  - 0.4337340211665272
  - 0.3826204612778069
  - 0.4278457466702721
  - 0.4416333004961627
  - 0.4114090017003259
  - 0.42279316664513683
  - 0.4478591163119865
  - 0.44598095643872804
  - 0.39858872267773915
  - 0.2925471563681559
  - 0.4126449102342416
  - 0.3788299574904973
  - 0.4178580534404365
  - 0.4353256254592673
  TT_f1_micro:
  - 0.6490425989672978
  - 0.740095517203951
  - 0.6957559969608162
  - 0.5741886464778031
  - 0.6717943201376936
  - 0.7230001085422773
  - 0.6367089981547813
  - 0.6592315206773038
  - 0.7260111876075731
  - 0.7395528058178661
  - 0.6088136329100184
  - 0.3897210463475524
  - 0.6376398450946644
  - 0.5798871160316943
  - 0.6687289699337892
  - 0.709866492999023
  TT_f1_weighted:
  - 0.7765454971692619
  - 0.8434931833435655
  - 0.8114436955443168
  - 0.7186486770163818
  - 0.7922414164609002
  - 0.8311155196462354
  - 0.7676596803045377
  - 0.7832749444369085
  - 0.8316566999850725
  - 0.8427943187919503
  - 0.7469437878065354
  - 0.5486798287402654
  - 0.7679597582644496
  - 0.7277407490751063
  - 0.7942059081600444
  - 0.8221786660834688
  TT_matthews_corrcoef:
  - 0.08613429262003705
  - 0.060960562009080656
  - 0.10468032026296271
  - 0.06895205259436345
  - 0.10163564532851022
  - 0.09881427278465145
  - 0.09968194118170938
  - 0.1036062466882669
  - 0.11525670709704836
  - 0.09368496397416311
  - 0.0967214522917294
  - 0.046395406368435234
  - 0.1015798456451707
  - 0.07091859944882227
  - 0.08729313806187729
  - 0.08789459090938624
  TT_precision_macro:
  - 0.5095471103630749
  - 0.5061122680805474
  - 0.5110994424307885
  - 0.5074060241893291
  - 0.5118778658609949
  - 0.5101932142428547
  - 0.5106938733241055
  - 0.5118924377481091
  - 0.5129768487249932
  - 0.5094852288236936
  - 0.5098998531083907
  - 0.5051030530001399
  - 0.5111183160442868
  - 0.5056981324949732
  - 0.5080243234693462
  - 0.5089774615784449
  TT_precision_micro:
  - 0.6490425989672978
  - 0.740095517203951
  - 0.6957559969608162
  - 0.5741886464778031
  - 0.6717943201376936
  - 0.7230001085422773
  - 0.6367089981547813
  - 0.6592315206773038
  - 0.7260111876075731
  - 0.7395528058178661
  - 0.6088136329100184
  - 0.3897210463475524
  - 0.6376398450946644
  - 0.5798871160316943
  - 0.6687289699337892
  - 0.7098664929990232
  TT_precision_weighted:
  - 0.9843230633345101
  - 0.9877269040996457
  - 0.9877243891805799
  - 0.9837746183579845
  - 0.9837172706533241
  - 0.9885991775139429
  - 0.9865105134995894
  - 0.984449824666932
  - 0.9869418099143892
  - 0.9891454370693636
  - 0.98784191761026
  - 0.9834255126377668
  - 0.985952935189983
  - 0.9922323749246889
  - 0.9903509054646789
  - 0.9880205365044393
  TT_recall_macro:
  - 0.6942764900322336
  - 0.6519971830215512
  - 0.7468135115499204
  - 0.6604904816482431
  - 0.7174170958451433
  - 0.739479428993759
  - 0.7322939756391967
  - 0.7256529439167495
  - 0.755919384057971
  - 0.7313300142247511
  - 0.7362418722529409
  - 0.6054532322137957
  - 0.732015014688282
  - 0.7206621095692045
  - 0.7374060561553726
  - 0.7151348419490149
  TT_recall_micro:
  - 0.6490425989672978
  - 0.740095517203951
  - 0.6957559969608162
  - 0.5741886464778031
  - 0.6717943201376936
  - 0.7230001085422773
  - 0.6367089981547813
  - 0.6592315206773038
  - 0.7260111876075731
  - 0.7395528058178661
  - 0.6088136329100184
  - 0.3897210463475524
  - 0.6376398450946644
  - 0.5798871160316943
  - 0.6687289699337892
  - 0.7098664929990232
  TT_recall_weighted:
  - 0.6490425989672978
  - 0.740095517203951
  - 0.6957559969608164
  - 0.5741886464778031
  - 0.6717943201376936
  - 0.7230001085422773
  - 0.6367089981547813
  - 0.6592315206773038
  - 0.7260111876075731
  - 0.7395528058178661
  - 0.6088136329100184
  - 0.3897210463475524
  - 0.6376398450946644
  - 0.5798871160316943
  - 0.6687289699337892
  - 0.7098664929990232
  TT_roc_auc:
  - 0.7777308703061161
  - 0.7617917289623066
  - 0.8185461266610597
  - 0.776359258098047
  - 0.8134848245962606
  - 0.8299504543961458
  - 0.8457711511028201
  - 0.8344623132884271
  - 0.8452824954710146
  - 0.8105232105943343
  - 0.8541821266235337
  - 0.7583150764982656
  - 0.8154185512742795
  - 0.818867746608202
  - 0.8064483367447385
  - 0.7911795461230708
  fit_time:
  - 406.3114025592804
  - 432.22298216819763
  - 421.5324065685272
  - 404.9421417713165
  - 409.4322874546051
  - 431.29295682907104
  - 427.81181955337524
  - 447.336510181427
  - 456.1067864894867
  - 473.96964979171753
  - 443.0684506893158
  - 449.66209268569946
  - 460.37667655944824
  - 442.77910709381104
  - 447.7895841598511
  - 452.665935754776
  score_time:
  - 1449.262003660202
  - 1419.8972380161285
  - 1444.7518866062164
  - 1398.1663000583649
  - 1466.5999279022217
  - 1464.9181380271912
  - 1453.1456198692322
  - 1447.1983103752136
  - 1441.9555377960205
  - 1421.8519983291626
  - 1440.7629735469818
  - 1447.2456929683685
  - 1449.28378033638
  - 1435.0431916713715
  - 1456.6107292175293
  - 1416.3642537593842
start: 2023-10-10 01:34:43.496374
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
