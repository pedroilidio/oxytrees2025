active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: y_reconstruction/runs
end: 2023-10-05 17:18:01.438340
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: bxt_lmo
  params: {}
hash: b2081db3154f280709326bfedcd8c726ab78014da9efab64d799f935e1fdb6b9
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/b2081db_20231005T171746002804_bxt_lmo_davis.yml"
results:
  LL_average_precision:
  - 0.9901362617350733
  - 0.981304134490447
  - 0.9851975567410802
  - 0.988723900805917
  - 0.987345379691922
  - 0.981852999550394
  - 0.9871278525139165
  - 0.9874694573492125
  - 0.9915199953379843
  - 0.9832892080219131
  - 0.9853321257123454
  - 0.9895499522954786
  - 0.9914674606582599
  - 0.9825065413249612
  - 0.9858066363313485
  - 0.9884916756718023
  LL_balanced_accuracy:
  - 0.871577776404425
  - 0.8743701399688958
  - 0.9236816043575142
  - 0.9700606210565383
  - 0.8825582845031792
  - 0.9018433757602358
  - 0.9425656704311474
  - 0.9482554517133956
  - 0.9165477003289677
  - 0.8865805727119596
  - 0.8982028480815869
  - 0.8945865408492675
  - 0.9371489202346773
  - 0.9287954830614806
  - 0.8877952755905512
  - 0.9628380488414215
  LL_f1_macro:
  - 0.5523176524946287
  - 0.5707894181735662
  - 0.6518188422820353
  - 0.7909682948603495
  - 0.587523202935529
  - 0.6321665914532741
  - 0.7174102763830651
  - 0.7302341718257623
  - 0.6365507964018144
  - 0.5955860272822366
  - 0.6143537721022136
  - 0.6044449923256879
  - 0.6966383562846585
  - 0.6883061202179391
  - 0.6074179924267846
  - 0.7844617626479975
  LL_f1_micro:
  - 0.7538060541437118
  - 0.7607369231680587
  - 0.8543586109142453
  - 0.9428301441058351
  - 0.7767904744979561
  - 0.8145252058527337
  - 0.8912709662178124
  - 0.9019017245452398
  - 0.8407084888335999
  - 0.7846099164741426
  - 0.8066383179777935
  - 0.7994330262225372
  - 0.8806942716663705
  - 0.8655292932883123
  - 0.7879163713678242
  - 0.929718875502008
  LL_f1_weighted:
  - 0.8277474048945805
  - 0.8290537506545018
  - 0.8930347042584477
  - 0.9530159998479104
  - 0.839156812866756
  - 0.8625619567937324
  - 0.9153713750714959
  - 0.9230122453912494
  - 0.8840992598539186
  - 0.8441620229728662
  - 0.8592930188139134
  - 0.8551345204279291
  - 0.9088856636793575
  - 0.8971340228719203
  - 0.8443722270230174
  - 0.9421545563866319
  LL_matthews_corrcoef:
  - 0.3273026673141081
  - 0.35292809256291136
  - 0.4503593225647648
  - 0.644438934759201
  - 0.373280821958145
  - 0.4293662950361715
  - 0.5401046078577046
  - 0.5576207168590502
  - 0.4306430572526784
  - 0.3831143185566815
  - 0.40534048461639904
  - 0.3925486715738647
  - 0.5112796082256669
  - 0.50131968450621
  - 0.39942981164415786
  - 0.6354995148172573
  LL_precision_macro:
  - 0.5720757825370676
  - 0.5831785345717234
  - 0.6196792103639729
  - 0.720876585928489
  - 0.5910570870414587
  - 0.61469357617524
  - 0.6647851420247632
  - 0.6734172237514746
  - 0.6113038450419196
  - 0.5949197860962567
  - 0.6031515151515151
  - 0.5976303317535545
  - 0.6494953010790114
  - 0.6465275615073186
  - 0.6028533510285335
  - 0.7181430601610611
  LL_precision_micro:
  - 0.7538060541437118
  - 0.7607369231680587
  - 0.8543586109142453
  - 0.9428301441058351
  - 0.7767904744979562
  - 0.8145252058527338
  - 0.8912709662178124
  - 0.9019017245452398
  - 0.8407084888335999
  - 0.7846099164741426
  - 0.8066383179777935
  - 0.7994330262225372
  - 0.8806942716663705
  - 0.8655292932883123
  - 0.7879163713678242
  - 0.929718875502008
  LL_precision_weighted:
  - 0.9645107573930392
  - 0.9601968957839949
  - 0.9651395071158095
  - 0.9747450348241463
  - 0.9593503816157554
  - 0.9574544651377671
  - 0.9641661414519739
  - 0.9659761388316561
  - 0.9645404846492835
  - 0.9591104386889415
  - 0.9601088990543277
  - 0.9608371596225996
  - 0.9643287084446266
  - 0.9605926705027411
  - 0.9563729761937794
  - 0.9693373208608951
  LL_recall_macro:
  - 0.871577776404425
  - 0.8743701399688958
  - 0.9236816043575142
  - 0.9700606210565383
  - 0.8825582845031792
  - 0.9018433757602358
  - 0.9425656704311474
  - 0.9482554517133956
  - 0.9165477003289677
  - 0.8865805727119596
  - 0.8982028480815869
  - 0.8945865408492675
  - 0.9371489202346773
  - 0.9287954830614806
  - 0.8877952755905512
  - 0.9628380488414215
  LL_recall_micro:
  - 0.7538060541437118
  - 0.7607369231680587
  - 0.8543586109142453
  - 0.9428301441058351
  - 0.7767904744979562
  - 0.8145252058527338
  - 0.8912709662178124
  - 0.9019017245452398
  - 0.8407084888335999
  - 0.7846099164741426
  - 0.8066383179777935
  - 0.7994330262225372
  - 0.8806942716663705
  - 0.8655292932883123
  - 0.7879163713678242
  - 0.929718875502008
  LL_recall_weighted:
  - 0.7538060541437118
  - 0.7607369231680587
  - 0.8543586109142453
  - 0.9428301441058351
  - 0.7767904744979562
  - 0.8145252058527338
  - 0.8912709662178124
  - 0.9019017245452398
  - 0.8407084888335999
  - 0.7846099164741426
  - 0.8066383179777935
  - 0.7994330262225372
  - 0.8806942716663705
  - 0.8655292932883123
  - 0.7879163713678242
  - 0.929718875502008
  LL_roc_auc:
  - 0.9995317259219366
  - 0.9989264806331981
  - 0.9992391355673931
  - 0.9994299110824414
  - 0.9991444166452812
  - 0.9987582804847103
  - 0.999206380669085
  - 0.9991824019327357
  - 0.9995550753014597
  - 0.9990038228832306
  - 0.9990547997647923
  - 0.9993570402212251
  - 0.9994836116637644
  - 0.9988628317935083
  - 0.998934944959837
  - 0.9992432252229415
  LT_average_precision:
  - 0.6838380283152183
  - 0.6333788408815448
  - 0.5885337272828188
  - 0.5151481363593687
  - 0.6730196228910466
  - 0.6137844901860957
  - 0.5704940633010847
  - 0.5073362556639395
  - 0.6924407313541462
  - 0.6131942224711755
  - 0.5561107609919629
  - 0.48200617790554734
  - 0.6588088058610627
  - 0.6016358133396802
  - 0.605577965624714
  - 0.5305365781107033
  LT_balanced_accuracy:
  - 0.7854708647618145
  - 0.7932319102654821
  - 0.8293528864059591
  - 0.8690820895522389
  - 0.8026777182560558
  - 0.8198078023675929
  - 0.8546427958481391
  - 0.8549426418949748
  - 0.8416072483166384
  - 0.8004121119484797
  - 0.8189619905908965
  - 0.8148453608247423
  - 0.851816774946615
  - 0.8414799564006297
  - 0.8300505138112759
  - 0.8713005675980836
  LT_f1_macro:
  - 0.4838967298979556
  - 0.491182553757034
  - 0.539720371773904
  - 0.6256565656565657
  - 0.5158580472755577
  - 0.5252830188679246
  - 0.5944728022402046
  - 0.6063237247177549
  - 0.5711927739371395
  - 0.5138992248949543
  - 0.5154067897937092
  - 0.5208608415526568
  - 0.5987613707671136
  - 0.5765235492133383
  - 0.5288540566563514
  - 0.6338789457717963
  LT_f1_micro:
  - 0.6173820879703232
  - 0.6855679208620385
  - 0.7418894830659537
  - 0.8445632798573975
  - 0.6548313018901254
  - 0.7131248895954779
  - 0.794295900178253
  - 0.7989304812834225
  - 0.7419183889772124
  - 0.703232644409115
  - 0.6980392156862745
  - 0.6937611408199643
  - 0.766295707472178
  - 0.7768945416004239
  - 0.6962566844919786
  - 0.8317290552584671
  LT_f1_weighted:
  - 0.7170672285940088
  - 0.7823439452967107
  - 0.8186680697104867
  - 0.886405588865482
  - 0.7434479436390783
  - 0.7971024965031626
  - 0.8506198307803947
  - 0.8518433466192505
  - 0.8103137851480818
  - 0.7907986810595928
  - 0.7865979123298819
  - 0.780467819087546
  - 0.8252395815398156
  - 0.8394139960817566
  - 0.7809592102987613
  - 0.8746189674507764
  LT_matthews_corrcoef:
  - 0.26434872191078895
  - 0.23319575493575084
  - 0.29244305818708477
  - 0.38769084915163154
  - 0.2960499326969369
  - 0.2824561104051691
  - 0.35828516814504086
  - 0.3729813160041149
  - 0.34534707583113483
  - 0.2605641957051717
  - 0.2764413634654761
  - 0.28499077951243257
  - 0.3771977230925403
  - 0.3339148692152033
  - 0.30436420023074207
  - 0.40609498285256374
  LT_precision_macro:
  - 0.5611973544429595
  - 0.5463628430401902
  - 0.5649174075981829
  - 0.6018094610729137
  - 0.5723918192218196
  - 0.5623667197255516
  - 0.5904912373912203
  - 0.5979841850963941
  - 0.5872819615017129
  - 0.5565004683425736
  - 0.5598972837587004
  - 0.564491774782982
  - 0.601102429189019
  - 0.5816293444117945
  - 0.5701692335760684
  - 0.6110374919198449
  LT_precision_micro:
  - 0.6173820879703232
  - 0.6855679208620385
  - 0.7418894830659537
  - 0.8445632798573975
  - 0.6548313018901254
  - 0.7131248895954778
  - 0.7942959001782531
  - 0.7989304812834225
  - 0.7419183889772125
  - 0.703232644409115
  - 0.6980392156862745
  - 0.6937611408199643
  - 0.766295707472178
  - 0.7768945416004239
  - 0.6962566844919786
  - 0.8317290552584671
  LT_precision_weighted:
  - 0.9487872377202057
  - 0.9616012112042807
  - 0.9586150429623044
  - 0.9592941913290268
  - 0.9449822745571018
  - 0.9569105741388221
  - 0.9542840018003228
  - 0.9511582446633359
  - 0.9486299515343728
  - 0.955744888424627
  - 0.9581260548283812
  - 0.9538387939181787
  - 0.9456324844864554
  - 0.9540107898902221
  - 0.9545375161502354
  - 0.9538951590508683
  LT_recall_macro:
  - 0.7854708647618145
  - 0.7932319102654821
  - 0.8293528864059591
  - 0.8690820895522389
  - 0.8026777182560558
  - 0.8198078023675929
  - 0.8546427958481391
  - 0.8549426418949748
  - 0.8416072483166384
  - 0.8004121119484797
  - 0.8189619905908965
  - 0.8148453608247423
  - 0.851816774946615
  - 0.8414799564006297
  - 0.8300505138112759
  - 0.8713005675980836
  LT_recall_micro:
  - 0.6173820879703232
  - 0.6855679208620385
  - 0.7418894830659537
  - 0.8445632798573975
  - 0.6548313018901254
  - 0.7131248895954778
  - 0.7942959001782531
  - 0.7989304812834225
  - 0.7419183889772125
  - 0.703232644409115
  - 0.6980392156862745
  - 0.6937611408199643
  - 0.766295707472178
  - 0.7768945416004239
  - 0.6962566844919786
  - 0.8317290552584671
  LT_recall_weighted:
  - 0.6173820879703232
  - 0.6855679208620385
  - 0.7418894830659537
  - 0.8445632798573975
  - 0.6548313018901255
  - 0.7131248895954777
  - 0.7942959001782531
  - 0.7989304812834225
  - 0.7419183889772125
  - 0.703232644409115
  - 0.6980392156862745
  - 0.6937611408199644
  - 0.766295707472178
  - 0.7768945416004239
  - 0.6962566844919786
  - 0.8317290552584671
  LT_roc_auc:
  - 0.9508925293957442
  - 0.9150090415913201
  - 0.9355695220360025
  - 0.9361044776119403
  - 0.9473089951072637
  - 0.9302220510303791
  - 0.9382533228176719
  - 0.9368329299502053
  - 0.9503659159470719
  - 0.9061721821817481
  - 0.9326209827820626
  - 0.9317461020703757
  - 0.9523843887248391
  - 0.9201351042213342
  - 0.955910220651816
  - 0.9409432249336277
  TL_average_precision:
  - 0.30745559350477775
  - 0.35348875382509953
  - 0.32014960345797405
  - 0.3470160598236892
  - 0.28225531830558653
  - 0.22672631090897422
  - 0.3261773142248187
  - 0.2716568557476903
  - 0.4023426005708836
  - 0.4014650485205976
  - 0.3310334334780675
  - 0.3047919785937839
  - 0.14239205444450226
  - 0.14795748932001107
  - 0.20529551338926486
  - 0.1843412318772027
  TL_balanced_accuracy:
  - 0.6848944510881034
  - 0.7507115472190427
  - 0.7167172055132556
  - 0.7367989474968017
  - 0.7411058204213055
  - 0.7502112104596577
  - 0.7555761507568737
  - 0.7705591597157861
  - 0.7606921256986787
  - 0.7618686707483389
  - 0.7390925668114461
  - 0.7479946095691135
  - 0.7195609090314197
  - 0.7306543548726848
  - 0.7108295993674223
  - 0.7499921131500079
  TL_f1_macro:
  - 0.4990539514825612
  - 0.5033772704009692
  - 0.5228264595345649
  - 0.5958592227732293
  - 0.4787167984386706
  - 0.48595169142132344
  - 0.5130340260643943
  - 0.5488194912507807
  - 0.5655584878785964
  - 0.5375044202207307
  - 0.5185325520664031
  - 0.5342847579630952
  - 0.5329928895477619
  - 0.5381119038004217
  - 0.47271325411826426
  - 0.5689034370965438
  TL_f1_micro:
  - 0.6648302825661987
  - 0.6395948107339613
  - 0.6867469879518072
  - 0.8058114812189937
  - 0.6722942953616492
  - 0.6674960014217167
  - 0.7158043940467753
  - 0.7737420269312544
  - 0.7844322018837746
  - 0.7172560867247202
  - 0.7035790219702339
  - 0.7266123316796598
  - 0.7986493691132042
  - 0.7789230495823707
  - 0.6665485471296952
  - 0.8359319631467045
  TL_f1_weighted:
  - 0.7507656188523721
  - 0.7291739058019416
  - 0.7650403479576243
  - 0.8494741190373606
  - 0.7718774696317381
  - 0.7648371939548224
  - 0.799540427392602
  - 0.839271528543558
  - 0.8425756697254108
  - 0.7925283780857123
  - 0.7849698528310499
  - 0.801008688427479
  - 0.8605565930270173
  - 0.8436451197753041
  - 0.7670347568907352
  - 0.8829414875436487
  TL_matthews_corrcoef:
  - 0.18737916421812767
  - 0.25296987636949037
  - 0.22762801216484266
  - 0.2837338097225869
  - 0.19440866581807678
  - 0.21247254967780643
  - 0.22684235388364782
  - 0.25668627760860324
  - 0.26837776520971746
  - 0.262176917249112
  - 0.22986762260427357
  - 0.2447793588397285
  - 0.19789522379538538
  - 0.21777075746266553
  - 0.17213895313823366
  - 0.24862802410409163
  TL_precision_macro:
  - 0.5474743170717891
  - 0.5638121369560263
  - 0.5597720330965468
  - 0.5849928553639163
  - 0.539188943343552
  - 0.5451064765280238
  - 0.5503347567477305
  - 0.5608811813854075
  - 0.5690724975542742
  - 0.5656213816469717
  - 0.5552496514492344
  - 0.5604014484610101
  - 0.5445918626564592
  - 0.5514016989100856
  - 0.5351371667882914
  - 0.5618178445621723
  TL_precision_micro:
  - 0.6648302825661987
  - 0.6395948107339613
  - 0.6867469879518072
  - 0.8058114812189936
  - 0.6722942953616492
  - 0.6674960014217167
  - 0.7158043940467753
  - 0.7737420269312544
  - 0.7844322018837746
  - 0.7172560867247201
  - 0.7035790219702339
  - 0.7266123316796598
  - 0.7986493691132042
  - 0.7789230495823707
  - 0.6665485471296952
  - 0.8359319631467045
  TL_precision_weighted:
  - 0.9174580055932922
  - 0.9307084317084666
  - 0.9189465581732326
  - 0.9217721003831125
  - 0.9543337439621578
  - 0.9504675270624536
  - 0.9486073262242902
  - 0.9487642944091071
  - 0.9402430755923323
  - 0.93574689767049
  - 0.9365166762884157
  - 0.9363190485463554
  - 0.9530351595191769
  - 0.9461753652566457
  - 0.9494657664569413
  - 0.9530670673724445
  TL_recall_macro:
  - 0.6848944510881034
  - 0.7507115472190427
  - 0.7167172055132556
  - 0.7367989474968017
  - 0.7411058204213055
  - 0.7502112104596577
  - 0.7555761507568737
  - 0.7705591597157861
  - 0.7606921256986787
  - 0.7618686707483389
  - 0.7390925668114461
  - 0.7479946095691135
  - 0.7195609090314197
  - 0.7306543548726848
  - 0.7108295993674223
  - 0.7499921131500079
  TL_recall_micro:
  - 0.6648302825661987
  - 0.6395948107339613
  - 0.6867469879518072
  - 0.8058114812189936
  - 0.6722942953616492
  - 0.6674960014217167
  - 0.7158043940467753
  - 0.7737420269312544
  - 0.7844322018837746
  - 0.7172560867247201
  - 0.7035790219702339
  - 0.7266123316796598
  - 0.7986493691132042
  - 0.7789230495823707
  - 0.6665485471296952
  - 0.8359319631467045
  TL_recall_weighted:
  - 0.6648302825661987
  - 0.6395948107339613
  - 0.6867469879518072
  - 0.8058114812189936
  - 0.6722942953616493
  - 0.6674960014217167
  - 0.7158043940467753
  - 0.7737420269312544
  - 0.7844322018837746
  - 0.7172560867247201
  - 0.7035790219702338
  - 0.7266123316796598
  - 0.7986493691132042
  - 0.7789230495823707
  - 0.6665485471296952
  - 0.8359319631467045
  TL_roc_auc:
  - 0.7870924008620415
  - 0.8553077063512576
  - 0.8130723298307801
  - 0.8126072030038898
  - 0.8129811664693307
  - 0.8358883352672173
  - 0.8238176059195075
  - 0.8058216182617403
  - 0.835003463116176
  - 0.8309497141862288
  - 0.8339015140982363
  - 0.8043454245727235
  - 0.7611296519617466
  - 0.7394114956188751
  - 0.7742352233790195
  - 0.7776425329056907
  TT_average_precision:
  - 0.31485803419113145
  - 0.2962933332183341
  - 0.2611196181929698
  - 0.2927958734755713
  - 0.3162686263490915
  - 0.29705450507636755
  - 0.1817264413669748
  - 0.2521392693200322
  - 0.33299894022119425
  - 0.3254083399059388
  - 0.28399197549077926
  - 0.25820615328658586
  - 0.26346857256355355
  - 0.16654291029139273
  - 0.10130251971544102
  - 0.2416654112043434
  TT_balanced_accuracy:
  - 0.6689789784676163
  - 0.7080235940530057
  - 0.7112536567528036
  - 0.728
  - 0.6943815577517524
  - 0.6736975717439293
  - 0.6683016386255275
  - 0.7166657532745109
  - 0.7756310661437811
  - 0.7631072224849672
  - 0.7328600052269362
  - 0.7887853107344633
  - 0.7605153203342618
  - 0.69512458591387
  - 0.633177072235244
  - 0.6500540678073914
  TT_f1_macro:
  - 0.4209048179891637
  - 0.46216517755577113
  - 0.47027860869618765
  - 0.5859242254437657
  - 0.4415584793778313
  - 0.4556820203119877
  - 0.47245221110013214
  - 0.5075616608885087
  - 0.5812400635930046
  - 0.5123097539963626
  - 0.5183958793230317
  - 0.5258833831718899
  - 0.5528592269691582
  - 0.513439099011942
  - 0.4454367437490803
  - 0.5308480065765823
  TT_f1_micro:
  - 0.5066242713301536
  - 0.5850556438791733
  - 0.6064171122994653
  - 0.7903743315508021
  - 0.5691573926868044
  - 0.6433492315845257
  - 0.6871657754010695
  - 0.7411764705882353
  - 0.7673555908850026
  - 0.7138314785373608
  - 0.7005347593582888
  - 0.6983957219251337
  - 0.7700052994170641
  - 0.7991520932697403
  - 0.6497326203208557
  - 0.8048128342245989
  TT_f1_weighted:
  - 0.6120615603570188
  - 0.6868285688720573
  - 0.7066541117879545
  - 0.8379860000962764
  - 0.6793564541809175
  - 0.7498859426769683
  - 0.7834539203306601
  - 0.8209827720384525
  - 0.8246105265463723
  - 0.7985603157310204
  - 0.7816261563826815
  - 0.7812872889501851
  - 0.8340757755461801
  - 0.8653442461579577
  - 0.7586304223701278
  - 0.8590689897350179
  TT_matthews_corrcoef:
  - 0.17428964519734746
  - 0.20294828473097454
  - 0.20232858092559677
  - 0.2704260550575938
  - 0.17700427998518645
  - 0.1403313713606091
  - 0.13745269109707645
  - 0.1858424166740323
  - 0.30446137624363523
  - 0.23121316430631328
  - 0.22708988662043458
  - 0.27366863761353616
  - 0.25764501065382495
  - 0.1595375474221387
  - 0.10174819552168403
  - 0.15278620768629905
  TT_precision_macro:
  - 0.5449418038540794
  - 0.5494992003944872
  - 0.548445143256464
  - 0.5801866790065929
  - 0.5402951230243341
  - 0.5283436515407669
  - 0.5280645548732088
  - 0.5398510185773181
  - 0.584076815905626
  - 0.550796332046332
  - 0.5553656869446343
  - 0.5648358143829848
  - 0.5637015813788202
  - 0.5326102281245917
  - 0.5194340796019901
  - 0.5388920233890705
  TT_precision_micro:
  - 0.5066242713301536
  - 0.5850556438791733
  - 0.6064171122994653
  - 0.7903743315508022
  - 0.5691573926868044
  - 0.6433492315845257
  - 0.6871657754010695
  - 0.7411764705882353
  - 0.7673555908850026
  - 0.7138314785373608
  - 0.7005347593582888
  - 0.6983957219251337
  - 0.7700052994170641
  - 0.7991520932697403
  - 0.6497326203208557
  - 0.8048128342245989
  TT_precision_weighted:
  - 0.9164153676638742
  - 0.9277738797896321
  - 0.9301325874355841
  - 0.9179882634526435
  - 0.9347461417447621
  - 0.9453889386723097
  - 0.9458866051348248
  - 0.950099109467489
  - 0.93022329677942
  - 0.9503831846836617
  - 0.9335333959595148
  - 0.9454587590850133
  - 0.9427039889506965
  - 0.9598929120341415
  - 0.9472066472450581
  - 0.9361489414958983
  TT_recall_macro:
  - 0.6689789784676163
  - 0.7080235940530057
  - 0.7112536567528036
  - 0.728
  - 0.6943815577517524
  - 0.6736975717439293
  - 0.6683016386255275
  - 0.7166657532745109
  - 0.7756310661437811
  - 0.7631072224849672
  - 0.7328600052269362
  - 0.7887853107344633
  - 0.7605153203342618
  - 0.69512458591387
  - 0.633177072235244
  - 0.6500540678073914
  TT_recall_micro:
  - 0.5066242713301536
  - 0.5850556438791733
  - 0.6064171122994653
  - 0.7903743315508022
  - 0.5691573926868044
  - 0.6433492315845257
  - 0.6871657754010695
  - 0.7411764705882353
  - 0.7673555908850026
  - 0.7138314785373608
  - 0.7005347593582888
  - 0.6983957219251337
  - 0.7700052994170641
  - 0.7991520932697403
  - 0.6497326203208557
  - 0.8048128342245989
  TT_recall_weighted:
  - 0.5066242713301536
  - 0.5850556438791733
  - 0.6064171122994653
  - 0.7903743315508022
  - 0.5691573926868044
  - 0.6433492315845257
  - 0.6871657754010695
  - 0.7411764705882353
  - 0.7673555908850026
  - 0.7138314785373608
  - 0.7005347593582888
  - 0.6983957219251337
  - 0.7700052994170641
  - 0.7991520932697403
  - 0.6497326203208557
  - 0.8048128342245989
  TT_roc_auc:
  - 0.8086308332836671
  - 0.7824846001749116
  - 0.8038660003250446
  - 0.8106223495702005
  - 0.8099503678871524
  - 0.7509565857247976
  - 0.7556858661697814
  - 0.8039599464491228
  - 0.825564145521934
  - 0.834382811972164
  - 0.801033408833522
  - 0.8546299435028247
  - 0.8073483105244037
  - 0.712300158432954
  - 0.6571745152354571
  - 0.6760384199478404
  fit_time:
  - 1.0731534957885742
  - 0.8952994346618652
  - 1.45570969581604
  - 1.3835713863372803
  - 1.3210618495941162
  - 1.3150036334991455
  - 1.4125337600708008
  - 1.3338522911071777
  - 1.3287880420684814
  - 1.3481311798095703
  - 1.3904914855957031
  - 1.222827672958374
  - 1.0778307914733887
  - 1.0976154804229736
  - 1.3597288131713867
  - 0.9012782573699951
  score_time:
  - 11.376933574676514
  - 10.887593507766724
  - 13.654209613800049
  - 13.531639575958252
  - 13.000081539154053
  - 13.307209491729736
  - 11.251898050308228
  - 13.026689291000366
  - 13.099047899246216
  - 13.344668865203857
  - 13.647131443023682
  - 12.789595365524292
  - 12.734678268432617
  - 12.619256019592285
  - 10.924339771270752
  - 10.736436128616333
start: 2023-10-05 17:17:46.002804
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
