active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: y_reconstruction/runs
end: 2023-10-17 04:50:53.632762
estimator:
  call: bipartite_adaptations.estimators.bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state:
                        call: numpy.random.mtrand.RandomState
                        params: {}
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gso
  params: {}
hash: 0b1d6e7eb368bffe93fbfc0fa8903ce273dba3854c69572c2c6b7bba2d647b38
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/0b1d6e7_20231017T043606702278_bxt_gso_davis.yml"
results:
  LL_average_precision:
  - 0.9896242521946005
  - 0.9816945027745407
  - 0.9858881705691774
  - 0.9886900270343291
  - 0.9901078228639322
  - 0.9813117061175526
  - 0.985786345238654
  - 0.9880146941274071
  - 0.9907409397815385
  - 0.9840337331308515
  - 0.9844118530632462
  - 0.9897983061687554
  - 0.9926983799513568
  - 0.9829563411007854
  - 0.9858259991842695
  - 0.9897314983673058
  LL_balanced_accuracy:
  - 0.8716395772819974
  - 0.8976360808709176
  - 0.9326875464223818
  - 0.9691946059631324
  - 0.9502555791048497
  - 0.9030346730202521
  - 0.9358270418668497
  - 0.962367601246106
  - 0.9143132021600149
  - 0.9251044980971987
  - 0.8680430321497419
  - 0.8990563695058356
  - 0.9312819872675071
  - 0.938456712672522
  - 0.9036057992750905
  - 0.9616513646867779
  LL_f1_macro:
  - 0.5524036960070885
  - 0.6073705417869409
  - 0.6721251459850209
  - 0.7871140646257955
  - 0.730087221394135
  - 0.6343283500033985
  - 0.6997447869948619
  - 0.7772178643819505
  - 0.6321695742197128
  - 0.667072284060425
  - 0.5671131161179898
  - 0.6120246104242001
  - 0.6822383430283849
  - 0.7120074613934348
  - 0.6347301208203618
  - 0.7800610508540624
  LL_f1_micro:
  - 0.7539245305372905
  - 0.8050470943664475
  - 0.8715450035435861
  - 0.9411764705882353
  - 0.9054558379242937
  - 0.8167762573307268
  - 0.8785140562248996
  - 0.9286557996692654
  - 0.8364433386647709
  - 0.8577690895089154
  - 0.7493503425466572
  - 0.8079376328844791
  - 0.869557490669984
  - 0.8837746578994135
  - 0.8178006142215922
  - 0.9274746042995511
  LL_f1_weighted:
  - 0.8278291431124172
  - 0.8593594615846104
  - 0.9043915154852656
  - 0.9518294944939969
  - 0.9260252736545892
  - 0.86410193473457
  - 0.9066601248667815
  - 0.9417601711468495
  - 0.8812763961872517
  - 0.893606834490273
  - 0.8197503779520154
  - 0.860888858702367
  - 0.9013819458128589
  - 0.9096247184612553
  - 0.8649160285990675
  - 0.9405336032629806
  LL_matthews_corrcoef:
  - 0.32739731283589124
  - 0.3955418396680386
  - 0.47703303070625747
  - 0.6387088531211584
  - 0.5570267438117626
  - 0.43202732559935847
  - 0.5160643360861903
  - 0.6246976105224087
  - 0.4250851052865239
  - 0.4718898257122165
  - 0.3506363878584959
  - 0.40167854903890776
  - 0.4919948705737535
  - 0.5331502943760588
  - 0.4324066817175006
  - 0.6290478278569316
  LL_precision_macro:
  - 0.5721054800164812
  - 0.5983646570661459
  - 0.6314808539478143
  - 0.717366628830874
  - 0.6722792607802874
  - 0.6157763975155279
  - 0.6527683997299122
  - 0.7110047846889952
  - 0.6090342679127726
  - 0.6309560405779281
  - 0.5835132482826301
  - 0.6010794896957802
  - 0.64031362299902
  - 0.6620737168446434
  - 0.6158156911581569
  - 0.7142857142857143
  LL_precision_micro:
  - 0.7539245305372905
  - 0.8050470943664475
  - 0.8715450035435861
  - 0.9411764705882353
  - 0.9054558379242936
  - 0.8167762573307269
  - 0.8785140562248996
  - 0.9286557996692653
  - 0.836443338664771
  - 0.8577690895089154
  - 0.7493503425466572
  - 0.8079376328844791
  - 0.869557490669984
  - 0.8837746578994136
  - 0.8178006142215922
  - 0.9274746042995512
  LL_precision_weighted:
  - 0.9645132203082207
  - 0.9616470485866138
  - 0.9662212547440945
  - 0.9744274554316619
  - 0.9674240032930111
  - 0.9575740302688789
  - 0.9628815735595996
  - 0.9698920647408095
  - 0.9643334383381121
  - 0.9627480062285877
  - 0.9581348658502857
  - 0.9611728678843992
  - 0.963394277845644
  - 0.9623258536284354
  - 0.9577969044149641
  - 0.9689176875569505
  LL_recall_macro:
  - 0.8716395772819974
  - 0.8976360808709176
  - 0.9326875464223818
  - 0.9691946059631324
  - 0.9502555791048497
  - 0.9030346730202521
  - 0.9358270418668497
  - 0.962367601246106
  - 0.9143132021600149
  - 0.9251044980971987
  - 0.8680430321497419
  - 0.8990563695058356
  - 0.9312819872675071
  - 0.938456712672522
  - 0.9036057992750905
  - 0.9616513646867779
  LL_recall_micro:
  - 0.7539245305372905
  - 0.8050470943664475
  - 0.8715450035435861
  - 0.9411764705882353
  - 0.9054558379242936
  - 0.8167762573307269
  - 0.8785140562248996
  - 0.9286557996692653
  - 0.836443338664771
  - 0.8577690895089154
  - 0.7493503425466572
  - 0.8079376328844791
  - 0.869557490669984
  - 0.8837746578994136
  - 0.8178006142215922
  - 0.9274746042995512
  LL_recall_weighted:
  - 0.7539245305372905
  - 0.8050470943664475
  - 0.8715450035435861
  - 0.9411764705882353
  - 0.9054558379242936
  - 0.8167762573307269
  - 0.8785140562248996
  - 0.9286557996692653
  - 0.836443338664771
  - 0.8577690895089154
  - 0.7493503425466572
  - 0.8079376328844791
  - 0.869557490669984
  - 0.8837746578994136
  - 0.8178006142215922
  - 0.9274746042995512
  LL_roc_auc:
  - 0.999481667211103
  - 0.9989912360253002
  - 0.9992871532200223
  - 0.9994261963589897
  - 0.9994141941765202
  - 0.9986929569225081
  - 0.9990471190363499
  - 0.9992514181165716
  - 0.9994975200455928
  - 0.9990525901264053
  - 0.9989568087701721
  - 0.999405032414696
  - 0.999579013082855
  - 0.9989141667011122
  - 0.9989741873663642
  - 0.9993598659878988
  LT_average_precision:
  - 0.7016550179540783
  - 0.6079342607256288
  - 0.5879514786098881
  - 0.5068054196239092
  - 0.6847256204552933
  - 0.6181945043589225
  - 0.5687038458427379
  - 0.5088539264170848
  - 0.6855294980237526
  - 0.6103852409465674
  - 0.5554753432156098
  - 0.4807923726315112
  - 0.6724703742040339
  - 0.6109994092107339
  - 0.5978656964123663
  - 0.5308469995750161
  LT_balanced_accuracy:
  - 0.82400356419699
  - 0.8204104096233981
  - 0.8527583798882682
  - 0.854589552238806
  - 0.8795826694534257
  - 0.828445992290542
  - 0.854009385294591
  - 0.859835315531573
  - 0.8624605809507089
  - 0.8359878946321503
  - 0.8015372513866997
  - 0.8252108716026242
  - 0.8656531508990906
  - 0.851266602075007
  - 0.84851976924804
  - 0.8768741925968121
  LT_f1_macro:
  - 0.5303372132657916
  - 0.5418607433291508
  - 0.5918344514274123
  - 0.6640113731080319
  - 0.665459384833522
  - 0.5559714780073148
  - 0.6102874684904598
  - 0.6672242482475488
  - 0.6086066204371376
  - 0.5999618074181923
  - 0.5001786547383914
  - 0.5558176000946742
  - 0.6285749838005883
  - 0.6141925642997951
  - 0.5692684420851131
  - 0.6592466252660427
  LT_f1_micro:
  - 0.6873343932167462
  - 0.7687687687687689
  - 0.8133689839572192
  - 0.886096256684492
  - 0.8447270800211977
  - 0.7618795265854089
  - 0.8155080213903744
  - 0.8668449197860962
  - 0.7892598480833775
  - 0.8267090620031796
  - 0.6757575757575758
  - 0.749554367201426
  - 0.8019784490372726
  - 0.8249425896484721
  - 0.7563279857397505
  - 0.8573975044563279
  LT_f1_weighted:
  - 0.7715650831018288
  - 0.8403609846266
  - 0.866809566810405
  - 0.9128282455210359
  - 0.8803297135007964
  - 0.8312099149263601
  - 0.8647589376721765
  - 0.8970292192569422
  - 0.843606125875031
  - 0.8748569422001327
  - 0.7702269561194767
  - 0.8204081646183353
  - 0.850260644502606
  - 0.8715352697267527
  - 0.8240782505364936
  - 0.8916732526098603
  LT_matthews_corrcoef:
  - 0.3088272219224689
  - 0.2764108466691731
  - 0.34437015829640977
  - 0.4187137877919276
  - 0.4497254089527328
  - 0.30484219257783
  - 0.3702849218655885
  - 0.43242692528128246
  - 0.385474942730026
  - 0.3409532787919944
  - 0.2577793890608794
  - 0.3093095090048539
  - 0.4091767474618127
  - 0.37006270338628056
  - 0.33849843056177126
  - 0.4342652390445373
  LT_precision_macro:
  - 0.5735904350595072
  - 0.5596133535784396
  - 0.584045349938006
  - 0.623608574322143
  - 0.6332074405220698
  - 0.5707336704944891
  - 0.5968271810413355
  - 0.6299157125753382
  - 0.6024876491968956
  - 0.5864980109225992
  - 0.5550928725381451
  - 0.5735464130468293
  - 0.6144702365149539
  - 0.5974661436844483
  - 0.582191311370945
  - 0.6250989730438791
  LT_precision_micro:
  - 0.6873343932167462
  - 0.7687687687687688
  - 0.8133689839572192
  - 0.886096256684492
  - 0.8447270800211977
  - 0.7618795265854089
  - 0.8155080213903744
  - 0.8668449197860962
  - 0.7892598480833775
  - 0.8267090620031796
  - 0.6757575757575758
  - 0.749554367201426
  - 0.8019784490372726
  - 0.824942589648472
  - 0.7563279857397505
  - 0.857397504456328
  LT_precision_weighted:
  - 0.9506625283836697
  - 0.9615875123655738
  - 0.9591825446186705
  - 0.957933613422742
  - 0.9495633722872514
  - 0.9559407868169413
  - 0.953614796452437
  - 0.9512605863465453
  - 0.9499853476085984
  - 0.9562241059280681
  - 0.9568372034392965
  - 0.9525252419924718
  - 0.9466909856811545
  - 0.9540715939545301
  - 0.9540964394970282
  - 0.9545715650810948
  LT_recall_macro:
  - 0.82400356419699
  - 0.8204104096233981
  - 0.8527583798882682
  - 0.854589552238806
  - 0.8795826694534257
  - 0.828445992290542
  - 0.854009385294591
  - 0.859835315531573
  - 0.8624605809507089
  - 0.8359878946321503
  - 0.8015372513866997
  - 0.8252108716026242
  - 0.8656531508990906
  - 0.851266602075007
  - 0.84851976924804
  - 0.8768741925968121
  LT_recall_micro:
  - 0.6873343932167462
  - 0.7687687687687688
  - 0.8133689839572192
  - 0.886096256684492
  - 0.8447270800211977
  - 0.7618795265854089
  - 0.8155080213903744
  - 0.8668449197860962
  - 0.7892598480833775
  - 0.8267090620031796
  - 0.6757575757575758
  - 0.749554367201426
  - 0.8019784490372726
  - 0.824942589648472
  - 0.7563279857397505
  - 0.857397504456328
  LT_recall_weighted:
  - 0.6873343932167462
  - 0.7687687687687688
  - 0.8133689839572192
  - 0.886096256684492
  - 0.8447270800211977
  - 0.7618795265854089
  - 0.8155080213903744
  - 0.8668449197860962
  - 0.7892598480833775
  - 0.8267090620031796
  - 0.6757575757575758
  - 0.749554367201426
  - 0.8019784490372726
  - 0.824942589648472
  - 0.7563279857397505
  - 0.857397504456328
  LT_roc_auc:
  - 0.9582553788587466
  - 0.905761284517476
  - 0.9313493171942894
  - 0.9207313432835821
  - 0.9483323372875088
  - 0.9278643607222484
  - 0.9235636739548391
  - 0.933452323090047
  - 0.9458243170215046
  - 0.9037642698716329
  - 0.9223906883565354
  - 0.9225757859759735
  - 0.954150017329708
  - 0.9226723453500734
  - 0.9478877083932
  - 0.9407753867906296
  TL_average_precision:
  - 0.37555872949867514
  - 0.34988491992891657
  - 0.3471446016751818
  - 0.36098286165428023
  - 0.24973611118025002
  - 0.24204171081269626
  - 0.2677656921021037
  - 0.2292872980533751
  - 0.38403484417188827
  - 0.3833923949667686
  - 0.36047081790413266
  - 0.3331841623814228
  - 0.14647443288032347
  - 0.16402401884953438
  - 0.18330396386071202
  - 0.19429245455450425
  TL_balanced_accuracy:
  - 0.7208208365041706
  - 0.7584952327618392
  - 0.7537668019058068
  - 0.7643978337532793
  - 0.7582838573387736
  - 0.758518948270501
  - 0.7812789620018535
  - 0.7522088353413654
  - 0.7803628219748796
  - 0.7748379421408467
  - 0.7426388304436136
  - 0.7467770020488764
  - 0.7000733843752045
  - 0.746699615492236
  - 0.7344688982604112
  - 0.7492095623674571
  TL_f1_macro:
  - 0.5143521480529402
  - 0.5461613528880852
  - 0.5764948973327467
  - 0.6401370370429058
  - 0.5634340761784202
  - 0.5212293783501327
  - 0.5549097931641656
  - 0.58607321849381
  - 0.5644813404848779
  - 0.603150879267833
  - 0.5181659161869296
  - 0.5543632545044787
  - 0.5336049571343688
  - 0.5607313363460429
  - 0.5294790550293081
  - 0.5804951996407353
  TL_f1_micro:
  - 0.6781588768437888
  - 0.7126355073751556
  - 0.7627569099929127
  - 0.8502834868887313
  - 0.8201528345477164
  - 0.7318286831348855
  - 0.7795889440113395
  - 0.8375265768958186
  - 0.7746578994135419
  - 0.815176826017416
  - 0.7014528703047485
  - 0.7620481927710845
  - 0.8082459569930691
  - 0.8096676737160122
  - 0.7694897236002834
  - 0.8520552799433027
  TL_f1_weighted:
  - 0.7607138591933997
  - 0.7847840772628912
  - 0.8197352707986542
  - 0.8795665882931694
  - 0.872389003689835
  - 0.8111137911795204
  - 0.8432386984658007
  - 0.880226203794273
  - 0.8362752789306175
  - 0.8597161933871316
  - 0.783434423755321
  - 0.8254910093658923
  - 0.8664433898024047
  - 0.8636744003550586
  - 0.838855248007425
  - 0.8928999253620767
  TL_matthews_corrcoef:
  - 0.22454685893605061
  - 0.27318555857209237
  - 0.28582477517697
  - 0.34529594605208713
  - 0.25124865683161945
  - 0.23177014762020465
  - 0.26846269012500384
  - 0.2717208481070272
  - 0.28275300707760737
  - 0.3141113647102532
  - 0.23269704425762233
  - 0.2542663290244995
  - 0.18470177589564257
  - 0.24487657713914932
  - 0.21253868330804088
  - 0.25849129241125385
  TL_precision_macro:
  - 0.5570839381104943
  - 0.5721776844924503
  - 0.5804831458364768
  - 0.6127366369340829
  - 0.5611012707202361
  - 0.5519472573357411
  - 0.5640575955949728
  - 0.5731855995410212
  - 0.5712908923232632
  - 0.5897492069977497
  - 0.5557906522085067
  - 0.565495736574746
  - 0.542627791454544
  - 0.5607667526272178
  - 0.5481649082644482
  - 0.567029679376747
  TL_precision_micro:
  - 0.6781588768437888
  - 0.7126355073751555
  - 0.7627569099929128
  - 0.8502834868887313
  - 0.8201528345477164
  - 0.7318286831348854
  - 0.7795889440113395
  - 0.8375265768958186
  - 0.7746578994135419
  - 0.815176826017416
  - 0.7014528703047485
  - 0.7620481927710844
  - 0.8082459569930691
  - 0.8096676737160121
  - 0.7694897236002834
  - 0.8520552799433027
  TL_precision_weighted:
  - 0.9241927128632043
  - 0.927504698879822
  - 0.9234216212778392
  - 0.9272046381940892
  - 0.9525050446382185
  - 0.9490469068115486
  - 0.9499741992660315
  - 0.9456660676318721
  - 0.9433575665329478
  - 0.9350718477674876
  - 0.9372076245415971
  - 0.9349497181396123
  - 0.951084994000269
  - 0.9475874485008188
  - 0.9494223194594937
  - 0.9529741421449396
  TL_recall_macro:
  - 0.7208208365041706
  - 0.7584952327618392
  - 0.7537668019058068
  - 0.7643978337532793
  - 0.7582838573387736
  - 0.758518948270501
  - 0.7812789620018535
  - 0.7522088353413654
  - 0.7803628219748796
  - 0.7748379421408467
  - 0.7426388304436136
  - 0.7467770020488764
  - 0.7000733843752045
  - 0.746699615492236
  - 0.7344688982604112
  - 0.7492095623674571
  TL_recall_micro:
  - 0.6781588768437888
  - 0.7126355073751555
  - 0.7627569099929128
  - 0.8502834868887313
  - 0.8201528345477164
  - 0.7318286831348854
  - 0.7795889440113395
  - 0.8375265768958186
  - 0.7746578994135419
  - 0.815176826017416
  - 0.7014528703047485
  - 0.7620481927710844
  - 0.8082459569930691
  - 0.8096676737160121
  - 0.7694897236002834
  - 0.8520552799433027
  TL_recall_weighted:
  - 0.6781588768437888
  - 0.7126355073751556
  - 0.7627569099929128
  - 0.8502834868887313
  - 0.8201528345477164
  - 0.7318286831348854
  - 0.7795889440113395
  - 0.8375265768958186
  - 0.7746578994135419
  - 0.815176826017416
  - 0.7014528703047485
  - 0.7620481927710844
  - 0.8082459569930691
  - 0.8096676737160121
  - 0.7694897236002834
  - 0.8520552799433027
  TL_roc_auc:
  - 0.8141862725662359
  - 0.8466842668832847
  - 0.8350082489847017
  - 0.8316812285431809
  - 0.8025507466119237
  - 0.8251545211172541
  - 0.8179081478834709
  - 0.8042684175069136
  - 0.8429807414080022
  - 0.8389005600208919
  - 0.83792914022726
  - 0.8239406661991542
  - 0.7454300698320105
  - 0.7780072877268769
  - 0.7865330126515551
  - 0.7886267241530399
  TT_average_precision:
  - 0.34125196659428225
  - 0.2896386844640997
  - 0.2592472311747789
  - 0.29964358420766524
  - 0.31366644048738535
  - 0.29667126092616175
  - 0.16065255003180717
  - 0.1820795000407425
  - 0.2975436189354028
  - 0.29968420557151065
  - 0.27623648854953364
  - 0.2960597566020737
  - 0.24817674369431542
  - 0.15111823159068988
  - 0.09650161883245735
  - 0.17952812754936373
  TT_balanced_accuracy:
  - 0.7222927007858597
  - 0.7077811893988364
  - 0.7162207459775719
  - 0.7500859598853868
  - 0.7589658888066524
  - 0.6656181015452538
  - 0.6945172983425847
  - 0.7048908235404645
  - 0.7565540091536179
  - 0.7583507871089792
  - 0.7450235212126493
  - 0.7978531073446327
  - 0.7588379556739736
  - 0.7193884899487665
  - 0.6216918815256766
  - 0.6685749422216568
  TT_f1_macro:
  - 0.48868603411513867
  - 0.547672010124763
  - 0.551786981348831
  - 0.6342660925152556
  - 0.5569060245370216
  - 0.4925121035555608
  - 0.5141715158996062
  - 0.5415151515151515
  - 0.5715586007353974
  - 0.605011759368695
  - 0.5243231672312442
  - 0.5759797051609671
  - 0.5625182293419488
  - 0.5456953004622496
  - 0.5017629904559915
  - 0.5432496593334076
  TT_f1_micro:
  - 0.6120826709062003
  - 0.7461579226285109
  - 0.7572192513368984
  - 0.8454545454545455
  - 0.7604663487016429
  - 0.7260201377848436
  - 0.7636363636363637
  - 0.8096256684491978
  - 0.7604663487016429
  - 0.8606253312135665
  - 0.7064171122994652
  - 0.7780748663101604
  - 0.7864334923158453
  - 0.8463169051404346
  - 0.7850267379679146
  - 0.8171122994652407
  TT_f1_weighted:
  - 0.7041975281439725
  - 0.809514625899707
  - 0.8188813860884511
  - 0.8750298460421025
  - 0.8244469978917739
  - 0.8093898031307671
  - 0.8358694688019322
  - 0.8654976502997892
  - 0.8195659793503005
  - 0.8951449505997319
  - 0.7858963190924225
  - 0.8374041196606982
  - 0.8449831870045753
  - 0.8944946997663846
  - 0.8513225086621943
  - 0.8670430570583372
  TT_matthews_corrcoef:
  - 0.2301711246254778
  - 0.22635194503453535
  - 0.23304438505950267
  - 0.33006143122532094
  - 0.26575955303322923
  - 0.14382091994081636
  - 0.17276793048873015
  - 0.1967857881640981
  - 0.2825171309875737
  - 0.29334883939687556
  - 0.2396534040500823
  - 0.3070346870300817
  - 0.26261616872709487
  - 0.19852746258638304
  - 0.10921752359435691
  - 0.17523375816063946
  TT_precision_macro:
  - 0.559582193234488
  - 0.5616456224564332
  - 0.5627942582038302
  - 0.6089031031894334
  - 0.5681828602541875
  - 0.5312231223815997
  - 0.5383626007297162
  - 0.5472503425900348
  - 0.5777769265473242
  - 0.5832719947735192
  - 0.5586002455892253
  - 0.5791248242129167
  - 0.5666123829263352
  - 0.5449125127418852
  - 0.5245054709289853
  - 0.5455389003763167
  TT_precision_micro:
  - 0.6120826709062003
  - 0.7461579226285109
  - 0.7572192513368984
  - 0.8454545454545455
  - 0.7604663487016429
  - 0.7260201377848436
  - 0.7636363636363637
  - 0.8096256684491978
  - 0.7604663487016429
  - 0.8606253312135665
  - 0.7064171122994652
  - 0.7780748663101604
  - 0.7864334923158453
  - 0.8463169051404346
  - 0.7850267379679144
  - 0.8171122994652407
  TT_precision_weighted:
  - 0.9212769734493912
  - 0.9191788574549715
  - 0.923994640480388
  - 0.9224983048829534
  - 0.936744484062822
  - 0.9423560698365628
  - 0.9472628762577484
  - 0.9477667410746936
  - 0.9268176924519168
  - 0.9472322374895905
  - 0.9353972279088859
  - 0.943430274105896
  - 0.9420941776006939
  - 0.9613603194616807
  - 0.944234178936149
  - 0.9382193558157067
  TT_recall_macro:
  - 0.7222927007858597
  - 0.7077811893988364
  - 0.7162207459775719
  - 0.7500859598853868
  - 0.7589658888066524
  - 0.6656181015452538
  - 0.6945172983425847
  - 0.7048908235404645
  - 0.7565540091536179
  - 0.7583507871089792
  - 0.7450235212126493
  - 0.7978531073446327
  - 0.7588379556739736
  - 0.7193884899487665
  - 0.6216918815256766
  - 0.6685749422216568
  TT_recall_micro:
  - 0.6120826709062003
  - 0.7461579226285109
  - 0.7572192513368984
  - 0.8454545454545455
  - 0.7604663487016429
  - 0.7260201377848436
  - 0.7636363636363637
  - 0.8096256684491978
  - 0.7604663487016429
  - 0.8606253312135665
  - 0.7064171122994652
  - 0.7780748663101604
  - 0.7864334923158453
  - 0.8463169051404346
  - 0.7850267379679144
  - 0.8171122994652407
  TT_recall_weighted:
  - 0.6120826709062003
  - 0.7461579226285109
  - 0.7572192513368984
  - 0.8454545454545455
  - 0.7604663487016429
  - 0.7260201377848436
  - 0.7636363636363637
  - 0.8096256684491978
  - 0.7604663487016429
  - 0.8606253312135665
  - 0.7064171122994652
  - 0.7780748663101604
  - 0.7864334923158453
  - 0.8463169051404346
  - 0.7850267379679144
  - 0.8171122994652407
  TT_roc_auc:
  - 0.817396190751888
  - 0.7637243811551769
  - 0.7927382983910288
  - 0.813941547277937
  - 0.8046878401323523
  - 0.7425312729948492
  - 0.733881890565181
  - 0.7583947263346617
  - 0.8167708694065123
  - 0.8309033173434228
  - 0.7964489502569911
  - 0.8734774011299435
  - 0.8058344435024828
  - 0.7335137137095946
  - 0.6476965693586193
  - 0.6711899865007175
  fit_time:
  - 875.9802052974701
  - 844.8650615215302
  - 829.3418340682983
  - 824.9835650920868
  - 871.8475682735443
  - 827.3158831596375
  - 834.6504831314087
  - 840.1240742206573
  - 868.5953929424286
  - 813.7083222866058
  - 836.451361656189
  - 885.668571472168
  - 849.0267226696014
  - 876.4638798236847
  - 812.8929853439331
  - 812.5484302043915
  score_time:
  - 1.1522836685180664
  - 1.2508208751678467
  - 1.250335931777954
  - 1.2620396614074707
  - 1.2476086616516113
  - 1.2022054195404053
  - 1.3789699077606201
  - 1.333209753036499
  - 1.226595401763916
  - 1.3620226383209229
  - 1.2961595058441162
  - 1.0718507766723633
  - 1.095632553100586
  - 1.138737440109253
  - 1.3463337421417236
  - 1.2842800617218018
start: 2023-10-17 04:36:06.702278
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
