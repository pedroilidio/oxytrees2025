active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/lncRNA/normalized_lncrna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/lncRNA/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: lncrna
  pairwise: true
  y:
    force_download: false
    path: datasets/lncRNA/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-10 03:41:13.469406
estimator:
  call: bipartite_adaptations.estimators.bxt_gmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state:
                        call: numpy.random.mtrand.RandomState
                        params: {}
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmo
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 5
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 5
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: square
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gmo
  params: {}
hash: 424e15c510de8cfbd59da9d6c9f0e189ecc8599ccc81a75697c61b2115b86b2e
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/424e15c_20231010T031505154329_bxt_gmo_lncrna.yml"
results:
  LL_average_precision:
  - 0.8206078354351215
  - 0.8166889131183441
  - 0.897638349280143
  - 0.8502952195695956
  - 0.8221519444923773
  - 0.8358693172097285
  - 0.8966016321373603
  - 0.8449661140821049
  - 0.832382926921791
  - 0.8310262558609691
  - 0.8222026232966011
  - 0.8295502518841975
  - 0.8485403725693486
  - 0.828648693024496
  - 0.8207523858529673
  - 0.8463904452217804
  LL_balanced_accuracy:
  - 0.8774924181666224
  - 0.8723974105860469
  - 0.8967898567660211
  - 0.8794573848108058
  - 0.878952376011717
  - 0.8818409294886385
  - 0.9068864268532767
  - 0.8713189382307398
  - 0.8825182316396836
  - 0.8772407703880494
  - 0.8718009147907475
  - 0.8664881522054162
  - 0.8875377994471506
  - 0.8746379181890425
  - 0.8719659458171592
  - 0.8797361979197302
  LL_f1_macro:
  - 0.7436708761380788
  - 0.7496037237330072
  - 0.7845046364992435
  - 0.7637460956154087
  - 0.7449180987223399
  - 0.763958343878361
  - 0.8012962333375676
  - 0.7504036399630007
  - 0.7485637814206563
  - 0.7543217987146038
  - 0.7408617272273816
  - 0.7407175260261185
  - 0.7569418861578374
  - 0.749983540227378
  - 0.7408229504916468
  - 0.7613202388086707
  LL_f1_micro:
  - 0.7968777706545906
  - 0.7930380696465837
  - 0.8317342671607793
  - 0.8056573623907796
  - 0.7989783530888109
  - 0.8081786313477828
  - 0.8481759766089825
  - 0.7922347261415021
  - 0.8043004899292324
  - 0.7999523679912901
  - 0.7894165535956581
  - 0.7834803256445048
  - 0.8127381600435493
  - 0.7956110506260207
  - 0.7896472184531885
  - 0.8052170963364993
  LL_f1_weighted:
  - 0.8205943956267953
  - 0.8146101485022657
  - 0.8486754421788228
  - 0.8249728661303507
  - 0.8225795091594698
  - 0.8277678340755548
  - 0.8627951744743114
  - 0.8134448641305915
  - 0.8274628976708153
  - 0.8211231942042124
  - 0.8130318970202137
  - 0.8062722456228648
  - 0.8345377892913469
  - 0.8174323978444347
  - 0.8132992397215407
  - 0.8251270326182826
  LL_matthews_corrcoef:
  - 0.5870930633452367
  - 0.5956274572275985
  - 0.6419601225839582
  - 0.6142948745064988
  - 0.5886384049010167
  - 0.6145397245318418
  - 0.6654519248032172
  - 0.5967305713801402
  - 0.5932527896611858
  - 0.6016371328276299
  - 0.5838684240093086
  - 0.5842077495189119
  - 0.6042714950970226
  - 0.5959595271279167
  - 0.5837496612340103
  - 0.6108650102688015
  LL_precision_macro:
  - 0.728268336290105
  - 0.7381676521629843
  - 0.7596543182497637
  - 0.7486169777886276
  - 0.7285875440148315
  - 0.7472620428180874
  - 0.7720822292162561
  - 0.7397449592231637
  - 0.7300209789557824
  - 0.7398781282473214
  - 0.7292237074961047
  - 0.7328170041405965
  - 0.7355538223030722
  - 0.7370073481158629
  - 0.7290288068187329
  - 0.7456679550270198
  LL_precision_micro:
  - 0.7968777706545906
  - 0.7930380696465839
  - 0.8317342671607793
  - 0.8056573623907796
  - 0.7989783530888109
  - 0.8081786313477828
  - 0.8481759766089825
  - 0.792234726141502
  - 0.8043004899292324
  - 0.7999523679912901
  - 0.7894165535956581
  - 0.7834803256445048
  - 0.8127381600435493
  - 0.7956110506260207
  - 0.7896472184531886
  - 0.8052170963364993
  LL_precision_weighted:
  - 0.9072317450007954
  - 0.9013222626505252
  - 0.9123669045039468
  - 0.9031768628691526
  - 0.9080626375125123
  - 0.9050730568031637
  - 0.9171413047177104
  - 0.9002137762925256
  - 0.9099354401508348
  - 0.9039453891916743
  - 0.9034104752459291
  - 0.899120136245606
  - 0.9117238078567292
  - 0.9030464009659579
  - 0.9035621962227162
  - 0.9040726015466255
  LL_recall_macro:
  - 0.8774924181666224
  - 0.8723974105860469
  - 0.8967898567660211
  - 0.8794573848108058
  - 0.878952376011717
  - 0.8818409294886385
  - 0.9068864268532767
  - 0.8713189382307398
  - 0.8825182316396836
  - 0.8772407703880494
  - 0.8718009147907475
  - 0.8664881522054162
  - 0.8875377994471506
  - 0.8746379181890425
  - 0.8719659458171592
  - 0.8797361979197302
  LL_recall_micro:
  - 0.7968777706545906
  - 0.7930380696465839
  - 0.8317342671607793
  - 0.8056573623907796
  - 0.7989783530888109
  - 0.8081786313477828
  - 0.8481759766089825
  - 0.792234726141502
  - 0.8043004899292324
  - 0.7999523679912901
  - 0.7894165535956581
  - 0.7834803256445048
  - 0.8127381600435493
  - 0.7956110506260207
  - 0.7896472184531886
  - 0.8052170963364993
  LL_recall_weighted:
  - 0.7968777706545906
  - 0.7930380696465839
  - 0.8317342671607793
  - 0.8056573623907796
  - 0.7989783530888109
  - 0.8081786313477828
  - 0.8481759766089825
  - 0.792234726141502
  - 0.8043004899292324
  - 0.7999523679912901
  - 0.7894165535956581
  - 0.7834803256445048
  - 0.8127381600435493
  - 0.7956110506260207
  - 0.7896472184531886
  - 0.8052170963364993
  LL_roc_auc:
  - 0.9693965214412386
  - 0.9650721327500771
  - 0.9802728099712182
  - 0.9700994196075524
  - 0.9696148041027071
  - 0.9682277382893937
  - 0.9806498408526996
  - 0.9687679773646561
  - 0.9723095149978308
  - 0.9684686723399142
  - 0.9684126386112792
  - 0.9667646593163234
  - 0.9742816678846067
  - 0.9673560878212821
  - 0.9677393091953511
  - 0.9696582610104197
  LT_average_precision:
  - 0.35681395322271636
  - 0.3196464751671223
  - 0.46298968449890987
  - 0.21874888725032463
  - 0.35156569732746756
  - 0.3267528743219592
  - 0.4470038284221507
  - 0.20608059908374776
  - 0.3502306545879224
  - 0.34573885000689514
  - 0.4550098660910644
  - 0.19134513988057797
  - 0.3682605021464129
  - 0.3235746705108889
  - 0.458268590803376
  - 0.19679562869926168
  LT_balanced_accuracy:
  - 0.6421984755130747
  - 0.6535825570096384
  - 0.6830467338726166
  - 0.5548930695004212
  - 0.6250152337799455
  - 0.6673219201160454
  - 0.6800661855374788
  - 0.5430063893871723
  - 0.6362234138226522
  - 0.6758380557569039
  - 0.6559363357930935
  - 0.5313281553919004
  - 0.6469587316220801
  - 0.6584592004540188
  - 0.6562787656456126
  - 0.5421223653968054
  LT_f1_macro:
  - 0.5067791406268396
  - 0.489150719643312
  - 0.5424529193178466
  - 0.40545816939848933
  - 0.4892242443948265
  - 0.5177231897973814
  - 0.5523530640037708
  - 0.39597495658783965
  - 0.5047713036384887
  - 0.5174870901491574
  - 0.46928853885157906
  - 0.3679338620094762
  - 0.5209695693288018
  - 0.5009346775911427
  - 0.46704761319905014
  - 0.38951764594264815
  LT_f1_micro:
  - 0.5151724698991214
  - 0.5148267165636186
  - 0.5702559051078413
  - 0.4288616634858093
  - 0.4961153595834689
  - 0.5540595509274325
  - 0.5874325350407354
  - 0.4187444848037103
  - 0.5150974025974026
  - 0.5523741883116883
  - 0.4790950040950041
  - 0.3836199836199836
  - 0.5345779220779221
  - 0.5334618506493507
  - 0.47608517608517614
  - 0.4113636363636364
  LT_f1_weighted:
  - 0.542666053935704
  - 0.5651002393369994
  - 0.6129533475710476
  - 0.48658850704190326
  - 0.522237886762408
  - 0.6059040211349209
  - 0.6310986458982725
  - 0.4768319314814669
  - 0.5451266735158631
  - 0.6044639352851752
  - 0.5149604631363661
  - 0.43723088222537787
  - 0.5667425237117686
  - 0.5863931608807068
  - 0.5109451592176352
  - 0.4698552766974371
  LT_matthews_corrcoef:
  - 0.24719309326986513
  - 0.23540097761320136
  - 0.2882860882694685
  - 0.0832998779672995
  - 0.21960152740469666
  - 0.25132153156600145
  - 0.2808053186499159
  - 0.0653337005438857
  - 0.23397542686843523
  - 0.26327654721580585
  - 0.2588948914876619
  - 0.048660898720975954
  - 0.2487800985440539
  - 0.23812987640083197
  - 0.260816648708427
  - 0.06381725482109175
  LT_precision_macro:
  - 0.6074280598646535
  - 0.5902016826327702
  - 0.613507718673019
  - 0.5316017565264489
  - 0.5964379087659072
  - 0.5943727399626938
  - 0.6094758945810911
  - 0.5248131294418273
  - 0.6004682287024787
  - 0.5985488323553005
  - 0.6074582208462039
  - 0.5188958066211686
  - 0.6052872747819262
  - 0.5894644139819609
  - 0.6088204849239619
  - 0.5241714940182884
  LT_precision_micro:
  - 0.5151724698991214
  - 0.5148267165636186
  - 0.5702559051078413
  - 0.4288616634858093
  - 0.4961153595834689
  - 0.5540595509274325
  - 0.5874325350407354
  - 0.4187444848037103
  - 0.5150974025974026
  - 0.5523741883116883
  - 0.4790950040950041
  - 0.3836199836199836
  - 0.5345779220779221
  - 0.5334618506493507
  - 0.4760851760851761
  - 0.4113636363636364
  LT_precision_weighted:
  - 0.7807644053849846
  - 0.8229361659330311
  - 0.8182329695481937
  - 0.7744492223743251
  - 0.7686568161339277
  - 0.8235980120604156
  - 0.8116291477961934
  - 0.7676470820078795
  - 0.7753218650246296
  - 0.8320085110551434
  - 0.8324321842260418
  - 0.7660748854196998
  - 0.7797070077719022
  - 0.824019498674827
  - 0.8344675881953558
  - 0.7714782285436761
  LT_recall_macro:
  - 0.6421984755130747
  - 0.6535825570096384
  - 0.6830467338726166
  - 0.5548930695004212
  - 0.6250152337799455
  - 0.6673219201160454
  - 0.6800661855374788
  - 0.5430063893871723
  - 0.6362234138226522
  - 0.6758380557569039
  - 0.6559363357930935
  - 0.5313281553919004
  - 0.6469587316220801
  - 0.6584592004540188
  - 0.6562787656456126
  - 0.5421223653968054
  LT_recall_micro:
  - 0.5151724698991214
  - 0.5148267165636186
  - 0.5702559051078413
  - 0.4288616634858093
  - 0.4961153595834689
  - 0.5540595509274325
  - 0.5874325350407354
  - 0.4187444848037103
  - 0.5150974025974026
  - 0.5523741883116883
  - 0.4790950040950041
  - 0.3836199836199836
  - 0.5345779220779221
  - 0.5334618506493507
  - 0.4760851760851761
  - 0.4113636363636364
  LT_recall_weighted:
  - 0.5151724698991214
  - 0.5148267165636186
  - 0.5702559051078413
  - 0.4288616634858093
  - 0.4961153595834689
  - 0.5540595509274325
  - 0.5874325350407354
  - 0.4187444848037103
  - 0.5150974025974026
  - 0.5523741883116883
  - 0.4790950040950041
  - 0.3836199836199836
  - 0.5345779220779221
  - 0.5334618506493507
  - 0.4760851760851761
  - 0.4113636363636364
  LT_roc_auc:
  - 0.6845786694187855
  - 0.7270683621959464
  - 0.7757349328857028
  - 0.6021204177724772
  - 0.6827693648666122
  - 0.7339187681558768
  - 0.7610598232352019
  - 0.5926712906566198
  - 0.6888335973722305
  - 0.7415880082017133
  - 0.7818876635486818
  - 0.5906050598138006
  - 0.6952889681218977
  - 0.7227433178254548
  - 0.7755142670893783
  - 0.5875598665926034
  TL_average_precision:
  - 0.696983374210673
  - 0.7099208012773375
  - 0.7371928921448707
  - 0.7479434817810301
  - 0.7021315693335297
  - 0.7124566338625558
  - 0.7205446851592788
  - 0.7315284464963032
  - 0.7244738557070144
  - 0.7284404318622129
  - 0.7254208317739184
  - 0.7464791472768553
  - 0.7339971333659712
  - 0.733561567846885
  - 0.7338120519404586
  - 0.7552948361755851
  TL_balanced_accuracy:
  - 0.8644508088418539
  - 0.8612335134947952
  - 0.8753002759695295
  - 0.8628685403636975
  - 0.8713688872575467
  - 0.8692839964459811
  - 0.8815244165866734
  - 0.8620307719439881
  - 0.8643360890590545
  - 0.8596226309921583
  - 0.8557775485926217
  - 0.8502277051689446
  - 0.8824811561893685
  - 0.8699248923475479
  - 0.8700858149365526
  - 0.8715267319108548
  TL_f1_macro:
  - 0.7194550486053259
  - 0.7298632415373785
  - 0.7524235540268402
  - 0.7388381926219731
  - 0.7351750661247646
  - 0.748239168555376
  - 0.7736435982972862
  - 0.7385109243870401
  - 0.7408619866816886
  - 0.746788789396196
  - 0.7343736762592319
  - 0.733309604920438
  - 0.762182402664336
  - 0.7551027095055157
  - 0.7489099189120543
  - 0.7634318871653474
  TL_f1_micro:
  - 0.7781783372031448
  - 0.7777506212065665
  - 0.8059701492537313
  - 0.7856635191389989
  - 0.7923336999470447
  - 0.7969163713389548
  - 0.8279825362981014
  - 0.783754695908214
  - 0.795566401443688
  - 0.7916085636945287
  - 0.7817828664894705
  - 0.7751380085872009
  - 0.8158682634730539
  - 0.7981092609301944
  - 0.7945001022285831
  - 0.8053976691883051
  TL_f1_weighted:
  - 0.8063152180818487
  - 0.8026857873617106
  - 0.8275716248148721
  - 0.8087550610809984
  - 0.8174574378997926
  - 0.8187127731782645
  - 0.8456593567709294
  - 0.8067410232964615
  - 0.8186518842187249
  - 0.8125765980928227
  - 0.8051559207833986
  - 0.797786242849308
  - 0.8360621551795573
  - 0.8182982429618527
  - 0.8161062747067442
  - 0.8240174384936366
  TL_matthews_corrcoef:
  - 0.5525596123550686
  - 0.5666199834892692
  - 0.5919219685852968
  - 0.5756921937373859
  - 0.5719200918628056
  - 0.5871493295447849
  - 0.6148608827522377
  - 0.5760777288316435
  - 0.5721907563649357
  - 0.5804471674359636
  - 0.5652754830792412
  - 0.5641698615788963
  - 0.6060274920193088
  - 0.5979053599182056
  - 0.5910216973526773
  - 0.6067977810827936
  TL_precision_macro:
  - 0.7094398735018805
  - 0.7221957499065254
  - 0.7333941908174479
  - 0.7283344138885566
  - 0.7201938575763881
  - 0.7333869992355055
  - 0.7477258916487826
  - 0.7291694348755314
  - 0.7246567602697802
  - 0.7342169854931767
  - 0.7245338224927949
  - 0.7272004955750244
  - 0.7400571342796928
  - 0.7415968935952633
  - 0.7359632770588118
  - 0.7477638319813752
  TL_precision_micro:
  - 0.7781783372031448
  - 0.7777506212065665
  - 0.8059701492537313
  - 0.7856635191389989
  - 0.7923336999470447
  - 0.7969163713389548
  - 0.8279825362981014
  - 0.783754695908214
  - 0.795566401443688
  - 0.7916085636945287
  - 0.7817828664894705
  - 0.7751380085872009
  - 0.8158682634730539
  - 0.7981092609301944
  - 0.7945001022285831
  - 0.805397669188305
  TL_precision_weighted:
  - 0.9046453602487357
  - 0.898459671403103
  - 0.9041227189665063
  - 0.8972190474369073
  - 0.9054867130271766
  - 0.8999424475214817
  - 0.9053748090240061
  - 0.8965003169396973
  - 0.8991109045014946
  - 0.8925142914059369
  - 0.8931223111618903
  - 0.8883486900714856
  - 0.9072884919108763
  - 0.8981135294865483
  - 0.8999667607841889
  - 0.8973301774031983
  TL_recall_macro:
  - 0.8644508088418539
  - 0.8612335134947952
  - 0.8753002759695295
  - 0.8628685403636975
  - 0.8713688872575467
  - 0.8692839964459811
  - 0.8815244165866734
  - 0.8620307719439881
  - 0.8643360890590545
  - 0.8596226309921583
  - 0.8557775485926217
  - 0.8502277051689446
  - 0.8824811561893685
  - 0.8699248923475479
  - 0.8700858149365526
  - 0.8715267319108548
  TL_recall_micro:
  - 0.7781783372031448
  - 0.7777506212065665
  - 0.8059701492537313
  - 0.7856635191389989
  - 0.7923336999470447
  - 0.7969163713389548
  - 0.8279825362981014
  - 0.783754695908214
  - 0.795566401443688
  - 0.7916085636945287
  - 0.7817828664894705
  - 0.7751380085872009
  - 0.8158682634730539
  - 0.7981092609301944
  - 0.7945001022285831
  - 0.805397669188305
  TL_recall_weighted:
  - 0.7781783372031448
  - 0.7777506212065665
  - 0.8059701492537313
  - 0.7856635191389989
  - 0.7923336999470447
  - 0.7969163713389548
  - 0.8279825362981014
  - 0.783754695908214
  - 0.795566401443688
  - 0.7916085636945287
  - 0.7817828664894705
  - 0.7751380085872009
  - 0.8158682634730539
  - 0.7981092609301944
  - 0.7945001022285831
  - 0.805397669188305
  TL_roc_auc:
  - 0.9471095154511442
  - 0.9420453261030012
  - 0.9470680487449236
  - 0.9453704291693417
  - 0.9458613447288506
  - 0.9396078222043669
  - 0.9425682161777551
  - 0.9412888331745154
  - 0.937128280974889
  - 0.9330938585239757
  - 0.9350696163795928
  - 0.9352862552764601
  - 0.9498065109814295
  - 0.9429398569336348
  - 0.9461054507019646
  - 0.9452115799977515
  TT_average_precision:
  - 0.34544742353588814
  - 0.29031510763476653
  - 0.41262693979110177
  - 0.19276867537359837
  - 0.32899303034827054
  - 0.30383164580692723
  - 0.408097735560536
  - 0.17810553011266456
  - 0.34395120703357746
  - 0.3452380505032746
  - 0.432538553843664
  - 0.18836666408255567
  - 0.3626889559036808
  - 0.3157742354081997
  - 0.432748538911183
  - 0.18934181891655433
  TT_balanced_accuracy:
  - 0.6390508617006236
  - 0.6476067034098318
  - 0.6726519631884808
  - 0.5467563185087205
  - 0.6166109825999806
  - 0.6588490103006233
  - 0.6699687392554533
  - 0.5282383341141283
  - 0.6226999053714233
  - 0.6606497399277087
  - 0.6370592479250707
  - 0.5266030649851314
  - 0.6418350854475926
  - 0.6495347873940586
  - 0.6554435527748463
  - 0.5399714980088227
  TT_f1_macro:
  - 0.4951521425815561
  - 0.47350668753895714
  - 0.5217741246488627
  - 0.3888072492334044
  - 0.47754147675729924
  - 0.5129589444775421
  - 0.5431160632809362
  - 0.38502955830209606
  - 0.4971746759358535
  - 0.5096833238199139
  - 0.45869921735565045
  - 0.36891762000674216
  - 0.5257396071164833
  - 0.5007147617363112
  - 0.47060577358551725
  - 0.3938431020609713
  TT_f1_micro:
  - 0.5035228377065112
  - 0.49993926141885325
  - 0.549855978427407
  - 0.4119629833915548
  - 0.486212342079689
  - 0.5522959183673469
  - 0.5793957222528651
  - 0.40987926702212424
  - 0.5060543052837574
  - 0.5415239726027398
  - 0.4664321856102678
  - 0.382574355177095
  - 0.5376100782778865
  - 0.5314334637964775
  - 0.4785881772183142
  - 0.4143527088732568
  TT_f1_weighted:
  - 0.5323464577122528
  - 0.5538290386350905
  - 0.5963820846750658
  - 0.47273220386012693
  - 0.5163130405090882
  - 0.6059754606384313
  - 0.6247255701853862
  - 0.4716171561561208
  - 0.5340907235791867
  - 0.5920548606278963
  - 0.49879727267283
  - 0.4321373051325865
  - 0.566604862687978
  - 0.5822223237608452
  - 0.5110071652385482
  - 0.46986831349195246
  TT_matthews_corrcoef:
  - 0.24028615503101014
  - 0.22231859726452938
  - 0.2676339171163154
  - 0.06986076041249821
  - 0.20110555869050714
  - 0.23654158471486597
  - 0.2635706688324208
  - 0.042232380646352506
  - 0.2135113372796146
  - 0.2443427995007036
  - 0.2326442311939894
  - 0.04225097665600514
  - 0.24435424149815385
  - 0.2281830046900288
  - 0.2628308376987886
  - 0.06159223663324804
  TT_precision_macro:
  - 0.6038063259613149
  - 0.583711575334823
  - 0.6037172011661808
  - 0.5260955417421402
  - 0.5867059106151202
  - 0.5880583410521895
  - 0.602179815201725
  - 0.5157903611439143
  - 0.5928833054290736
  - 0.5929092753195666
  - 0.5987225216962945
  - 0.5167757458528182
  - 0.6052436975479532
  - 0.5870491150199049
  - 0.6111015027839505
  - 0.5237269292024574
  TT_precision_micro:
  - 0.5035228377065112
  - 0.49993926141885325
  - 0.549855978427407
  - 0.4119629833915548
  - 0.486212342079689
  - 0.5522959183673469
  - 0.5793957222528651
  - 0.4098792670221242
  - 0.5060543052837574
  - 0.5415239726027398
  - 0.4664321856102678
  - 0.3825743551770949
  - 0.5376100782778865
  - 0.5314334637964775
  - 0.4785881772183142
  - 0.4143527088732568
  TT_precision_weighted:
  - 0.7861751405096259
  - 0.828776199290465
  - 0.8215886470155525
  - 0.7807533977556289
  - 0.7685222028680826
  - 0.8199900201759275
  - 0.8076339332227004
  - 0.7643953918931317
  - 0.7602069375350436
  - 0.8193743461647808
  - 0.8140748937624294
  - 0.7530626870617019
  - 0.766643754680647
  - 0.8129116201016126
  - 0.8301878808366571
  - 0.7612633157271562
  TT_recall_macro:
  - 0.6390508617006236
  - 0.6476067034098318
  - 0.6726519631884808
  - 0.5467563185087205
  - 0.6166109825999806
  - 0.6588490103006233
  - 0.6699687392554533
  - 0.5282383341141283
  - 0.6226999053714233
  - 0.6606497399277087
  - 0.6370592479250707
  - 0.5266030649851314
  - 0.6418350854475926
  - 0.6495347873940586
  - 0.6554435527748463
  - 0.5399714980088227
  TT_recall_micro:
  - 0.5035228377065112
  - 0.49993926141885325
  - 0.549855978427407
  - 0.4119629833915548
  - 0.486212342079689
  - 0.5522959183673469
  - 0.5793957222528651
  - 0.4098792670221242
  - 0.5060543052837574
  - 0.5415239726027398
  - 0.4664321856102678
  - 0.3825743551770949
  - 0.5376100782778865
  - 0.5314334637964775
  - 0.4785881772183142
  - 0.4143527088732568
  TT_recall_weighted:
  - 0.5035228377065112
  - 0.49993926141885325
  - 0.549855978427407
  - 0.4119629833915548
  - 0.486212342079689
  - 0.5522959183673469
  - 0.5793957222528651
  - 0.4098792670221242
  - 0.5060543052837574
  - 0.5415239726027398
  - 0.4664321856102678
  - 0.3825743551770949
  - 0.5376100782778865
  - 0.5314334637964775
  - 0.4785881772183142
  - 0.4143527088732568
  TT_roc_auc:
  - 0.6765778977556882
  - 0.7105807105013153
  - 0.7517989798207275
  - 0.581224830898993
  - 0.6669207049761855
  - 0.7160386192644257
  - 0.7365674863643932
  - 0.5589475571182729
  - 0.6707473719732889
  - 0.7240260822657547
  - 0.7589036583669495
  - 0.5722809684727062
  - 0.6747380410473344
  - 0.6952530777425152
  - 0.7588385607745112
  - 0.5636184219364914
  fit_time:
  - 361.06070590019226
  - 363.4005470275879
  - 343.3672745227814
  - 352.4106957912445
  - 348.6441738605499
  - 366.7614631652832
  - 350.16028332710266
  - 344.5757966041565
  - 367.901971578598
  - 347.5953369140625
  - 354.299898147583
  - 339.11248302459717
  - 372.2199158668518
  - 375.32556533813477
  - 372.3608064651489
  - 386.86419463157654
  score_time:
  - 1193.7967736721039
  - 1185.2470030784607
  - 1205.3966734409332
  - 1144.916002035141
  - 1197.9371242523193
  - 1182.9195804595947
  - 1180.4904191493988
  - 1185.3666307926178
  - 1195.687169790268
  - 1190.804233789444
  - 1197.8794167041779
  - 1191.1386122703552
  - 1181.8915739059448
  - 1185.2693781852722
  - 1189.5635690689087
  - 1179.2844588756561
start: 2023-10-10 03:15:05.154329
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
