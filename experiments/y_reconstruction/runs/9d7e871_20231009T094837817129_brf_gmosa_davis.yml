active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: y_reconstruction/runs
end: 2023-10-09 09:51:04.866738
estimator:
  call: bipartite_adaptations.estimators.brf_gmosa
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiterandomforestregressor
          - call: bipartite_learn.ensemble._forest.BipartiteRandomForestRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: true
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: 0.5
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: 0.5
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: brf_gmosa
  params: {}
hash: 9d7e87168121604924235e1a0ca4230ad4978b8e225a4a2fa3aa81e141159460
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/9d7e871_20231009T094837817129_brf_gmosa_davis.yml"
results:
  LL_average_precision:
  - 0.8330218084541523
  - 0.8229001682184354
  - 0.8482880024827477
  - 0.8996029072009069
  - 0.8918849522948749
  - 0.8347040570530012
  - 0.8383323957731965
  - 0.8990420286919112
  - 0.8748203373582001
  - 0.8112789601217465
  - 0.8518766886122681
  - 0.8800785487887183
  - 0.8977559700427569
  - 0.8034249587241528
  - 0.8408191808429019
  - 0.9015775096035025
  LL_balanced_accuracy:
  - 0.8361967739941907
  - 0.8556143079315708
  - 0.8832631839564249
  - 0.914357293084251
  - 0.9127290861488593
  - 0.8781741801993855
  - 0.8656017969676171
  - 0.8907788161993769
  - 0.8529576066041835
  - 0.8419739222658931
  - 0.8326907530626204
  - 0.8212999751676187
  - 0.9148982648857821
  - 0.8412484316185697
  - 0.8596737907761529
  - 0.9154643682468303
  LL_f1_macro:
  - 0.5065166379399373
  - 0.5445020639749699
  - 0.57967238041485
  - 0.631265927832288
  - 0.6395527522159207
  - 0.5927238264346336
  - 0.5702913462847854
  - 0.6060558610310758
  - 0.5364549209296391
  - 0.5320067152672404
  - 0.5196838156151372
  - 0.5024852051556765
  - 0.6467419921249483
  - 0.5411774421964664
  - 0.5648176691360451
  - 0.656291177309466
  LL_f1_micro:
  - 0.6859783188199752
  - 0.7250162905041171
  - 0.7772265532719113
  - 0.8364635010630759
  - 0.8341330489899887
  - 0.76980036727682
  - 0.7455705173635719
  - 0.7929364516891094
  - 0.7193294236123452
  - 0.6998992950654582
  - 0.6821993857784078
  - 0.6599929128277817
  - 0.8384574373556068
  - 0.7001954860494046
  - 0.7347625797306874
  - 0.8401252067091897
  LL_f1_weighted:
  - 0.7794288463587847
  - 0.8038670517300792
  - 0.8414214481734303
  - 0.8814474358486076
  - 0.8780599078924631
  - 0.8316204587073058
  - 0.8153969154593195
  - 0.8491192120087
  - 0.801047748021537
  - 0.7840199368672357
  - 0.7709897485612852
  - 0.7551720744808005
  - 0.8804973231021498
  - 0.7811766009557963
  - 0.8068940033655555
  - 0.8803124567766251
  LL_matthews_corrcoef:
  - 0.2800586399161419
  - 0.3243796362013221
  - 0.3616464297785692
  - 0.42376215374127424
  - 0.4362520576530057
  - 0.38250357030694787
  - 0.35628667960607274
  - 0.39635239555489177
  - 0.3141410330239379
  - 0.31379340341033213
  - 0.30142996324105303
  - 0.2836534069810139
  - 0.44583816897520423
  - 0.3271125043786175
  - 0.3512943497033351
  - 0.4592805619607697
  LL_precision_macro:
  - 0.5583236127312114
  - 0.5739720998531571
  - 0.5853122251539138
  - 0.6083451202263084
  - 0.6152789227809838
  - 0.5967206309672063
  - 0.5868022252062153
  - 0.6005013673655424
  - 0.5698983297022513
  - 0.5719837783034809
  - 0.5682766367137355
  - 0.5626044674061693
  - 0.619771332961517
  - 0.5783905364878374
  - 0.5857775318206973
  - 0.6269294377067255
  LL_precision_micro:
  - 0.6859783188199752
  - 0.7250162905041171
  - 0.7772265532719111
  - 0.8364635010630759
  - 0.8341330489899887
  - 0.7698003672768201
  - 0.7455705173635719
  - 0.7929364516891094
  - 0.7193294236123452
  - 0.6998992950654582
  - 0.6821993857784078
  - 0.6599929128277817
  - 0.8384574373556068
  - 0.7001954860494046
  - 0.7347625797306875
  - 0.8401252067091897
  LL_precision_weighted:
  - 0.9633702421553045
  - 0.959317755166358
  - 0.9619894031088397
  - 0.9645632367225788
  - 0.9617580731251995
  - 0.9554698925491898
  - 0.9558299094981839
  - 0.9583796605263889
  - 0.9607631910278696
  - 0.9567952347745472
  - 0.9566032858307807
  - 0.9574280747865206
  - 0.9613036638841234
  - 0.952996326619875
  - 0.9544971774856188
  - 0.959414364768237
  LL_recall_macro:
  - 0.8361967739941907
  - 0.8556143079315708
  - 0.8832631839564249
  - 0.914357293084251
  - 0.9127290861488593
  - 0.8781741801993855
  - 0.8656017969676171
  - 0.8907788161993769
  - 0.8529576066041835
  - 0.8419739222658931
  - 0.8326907530626204
  - 0.8212999751676187
  - 0.9148982648857821
  - 0.8412484316185697
  - 0.8596737907761529
  - 0.9154643682468303
  LL_recall_micro:
  - 0.6859783188199752
  - 0.7250162905041171
  - 0.7772265532719111
  - 0.8364635010630759
  - 0.8341330489899887
  - 0.7698003672768201
  - 0.7455705173635719
  - 0.7929364516891094
  - 0.7193294236123452
  - 0.6998992950654582
  - 0.6821993857784078
  - 0.6599929128277817
  - 0.8384574373556068
  - 0.7001954860494046
  - 0.7347625797306875
  - 0.8401252067091897
  LL_recall_weighted:
  - 0.6859783188199752
  - 0.7250162905041171
  - 0.7772265532719111
  - 0.8364635010630759
  - 0.8341330489899887
  - 0.7698003672768201
  - 0.7455705173635719
  - 0.7929364516891094
  - 0.7193294236123452
  - 0.6998992950654582
  - 0.6821993857784078
  - 0.6599929128277817
  - 0.8384574373556068
  - 0.7001954860494046
  - 0.7347625797306875
  - 0.8401252067091897
  LL_roc_auc:
  - 0.9958667573079538
  - 0.9944146737725226
  - 0.9952876496683113
  - 0.9967980295168696
  - 0.9966429377354052
  - 0.9933894371463546
  - 0.9935936835871235
  - 0.9962840047753265
  - 0.9962150970499304
  - 0.9937175562368326
  - 0.9944678566519627
  - 0.9955406437372976
  - 0.9968867748638404
  - 0.9925465714281905
  - 0.9939218619177979
  - 0.996554180889889
  LT_average_precision:
  - 0.6533457011766712
  - 0.5672462680156097
  - 0.5129753725015821
  - 0.4529174904044645
  - 0.606731669715254
  - 0.5497443650856083
  - 0.5176002486436817
  - 0.4451865423498349
  - 0.6492781976374531
  - 0.5560085408354482
  - 0.4985235629125224
  - 0.4271799817711233
  - 0.5853818815169827
  - 0.5640431647184729
  - 0.548566168007989
  - 0.5001789275940867
  LT_balanced_accuracy:
  - 0.7908429148263489
  - 0.8090284875645359
  - 0.8177141527001863
  - 0.8206529850746269
  - 0.8354056871143486
  - 0.8267676488191888
  - 0.8091504284953945
  - 0.8169587061320849
  - 0.7938734303636699
  - 0.784187868010511
  - 0.7943443106207362
  - 0.7667104029990628
  - 0.8422051078919174
  - 0.8027178959266885
  - 0.8163171327373615
  - 0.8507213225645669
  LT_f1_macro:
  - 0.4982068125526835
  - 0.5219448349024574
  - 0.5422860035964315
  - 0.5807167798172118
  - 0.6023840086480107
  - 0.5626651604643536
  - 0.5370792570894246
  - 0.5660267843433969
  - 0.5155180671934758
  - 0.5022017416228813
  - 0.4857427772861978
  - 0.46995427722001015
  - 0.6026003830038578
  - 0.5178983292171735
  - 0.5383426897323773
  - 0.6114679238334282
  LT_f1_micro:
  - 0.641582759229818
  - 0.7380321497968557
  - 0.7500891265597148
  - 0.803030303030303
  - 0.7820173114290762
  - 0.7730083024200672
  - 0.7206773618538325
  - 0.753475935828877
  - 0.6654301360183713
  - 0.6869810987458046
  - 0.6509803921568628
  - 0.6153297682709448
  - 0.7751280692457163
  - 0.6933403992227521
  - 0.7171122994652407
  - 0.810873440285205
  LT_f1_weighted:
  - 0.736487591085172
  - 0.8195049025224105
  - 0.8243045276180303
  - 0.8588127660152279
  - 0.8368751032376432
  - 0.8387472314011318
  - 0.7994068067216723
  - 0.820331274641843
  - 0.7536921162029874
  - 0.7790225413486409
  - 0.7514739604461288
  - 0.7203286763751254
  - 0.8313267659706113
  - 0.7803678857789601
  - 0.7962297577973156
  - 0.8604395290971794
  LT_matthews_corrcoef:
  - 0.271551548171829
  - 0.2572743248744668
  - 0.2853301940421298
  - 0.3157679436001118
  - 0.36391724662247926
  - 0.3078211255703326
  - 0.2890895266428034
  - 0.3167297130884003
  - 0.28251511018477377
  - 0.2438910555578049
  - 0.2482144764096986
  - 0.2328167006063371
  - 0.3718767316519477
  - 0.27372240738578996
  - 0.29722010343031985
  - 0.3721547034702956
  LT_precision_macro:
  - 0.5633849404226888
  - 0.5535469065985299
  - 0.5640617666385056
  - 0.5777393310265283
  - 0.5987131162926105
  - 0.572493288189475
  - 0.5675825962956778
  - 0.5791252213713096
  - 0.5678989483533299
  - 0.5523270463633059
  - 0.5523285350491504
  - 0.5508075570653793
  - 0.601030274208979
  - 0.5618760546644535
  - 0.5698190049955962
  - 0.598724481806753
  LT_precision_micro:
  - 0.641582759229818
  - 0.7380321497968557
  - 0.7500891265597148
  - 0.803030303030303
  - 0.7820173114290762
  - 0.7730083024200671
  - 0.7206773618538325
  - 0.753475935828877
  - 0.6654301360183713
  - 0.6869810987458046
  - 0.6509803921568628
  - 0.6153297682709448
  - 0.7751280692457163
  - 0.6933403992227521
  - 0.7171122994652407
  - 0.810873440285205
  LT_precision_weighted:
  - 0.9478002197785567
  - 0.9613441059247321
  - 0.9567861931388361
  - 0.9539605293727011
  - 0.9431973906939819
  - 0.9553216943881565
  - 0.9505471039951648
  - 0.9467905981490298
  - 0.9446931814716327
  - 0.9542666700839131
  - 0.9572286933548012
  - 0.9509085236096941
  - 0.9433418433766393
  - 0.9521441176210766
  - 0.9509952798923739
  - 0.951228943278565
  LT_recall_macro:
  - 0.7908429148263489
  - 0.8090284875645359
  - 0.8177141527001863
  - 0.8206529850746269
  - 0.8354056871143486
  - 0.8267676488191888
  - 0.8091504284953945
  - 0.8169587061320849
  - 0.7938734303636699
  - 0.784187868010511
  - 0.7943443106207362
  - 0.7667104029990628
  - 0.8422051078919174
  - 0.8027178959266885
  - 0.8163171327373615
  - 0.8507213225645669
  LT_recall_micro:
  - 0.641582759229818
  - 0.7380321497968557
  - 0.7500891265597148
  - 0.803030303030303
  - 0.7820173114290762
  - 0.7730083024200671
  - 0.7206773618538325
  - 0.753475935828877
  - 0.6654301360183713
  - 0.6869810987458046
  - 0.6509803921568628
  - 0.6153297682709448
  - 0.7751280692457163
  - 0.6933403992227521
  - 0.7171122994652407
  - 0.810873440285205
  LT_recall_weighted:
  - 0.641582759229818
  - 0.7380321497968557
  - 0.7500891265597148
  - 0.803030303030303
  - 0.7820173114290762
  - 0.7730083024200671
  - 0.7206773618538325
  - 0.753475935828877
  - 0.6654301360183712
  - 0.6869810987458046
  - 0.6509803921568628
  - 0.6153297682709448
  - 0.7751280692457163
  - 0.6933403992227521
  - 0.7171122994652406
  - 0.810873440285205
  LT_roc_auc:
  - 0.9349528128737374
  - 0.8991963029937713
  - 0.9104508069522036
  - 0.8995212686567164
  - 0.9280683182588756
  - 0.9119153648886178
  - 0.9118360625303432
  - 0.9120022392723232
  - 0.9266996650378401
  - 0.8985988492871233
  - 0.9139291128731455
  - 0.9041908494504558
  - 0.9317696739591904
  - 0.9134360744418877
  - 0.9305747656118574
  - 0.9233262595489731
  TL_average_precision:
  - 0.33042974260452385
  - 0.3577210377909784
  - 0.3693814272299057
  - 0.38384912039535596
  - 0.27846990235916425
  - 0.2695383750749842
  - 0.3095410524178361
  - 0.2678181986079778
  - 0.2904452892693344
  - 0.30117008038030374
  - 0.2779714385366576
  - 0.2668444709799765
  - 0.24157955423227093
  - 0.24566164253118425
  - 0.324899236266502
  - 0.3451336321990608
  TL_balanced_accuracy:
  - 0.7024939301115496
  - 0.7342382675479082
  - 0.7503853210271745
  - 0.7591360962407263
  - 0.7327308193565423
  - 0.7700922955581341
  - 0.735032437442076
  - 0.7418597466790238
  - 0.7576584621145565
  - 0.7497681571540493
  - 0.744115976847638
  - 0.7296246045827207
  - 0.6821722709893336
  - 0.6447016999456093
  - 0.6714318661043753
  - 0.6966042729200623
  TL_f1_macro:
  - 0.45084627094012264
  - 0.48452677138347844
  - 0.5211803191396498
  - 0.5607542403617718
  - 0.5119397045752943
  - 0.5093635918987632
  - 0.479538075578793
  - 0.5080569290789361
  - 0.5043750749298244
  - 0.5235223261139205
  - 0.49797185058812965
  - 0.4839275233475461
  - 0.4384588120663368
  - 0.35677974424636655
  - 0.3898236837883394
  - 0.44387006286954234
  TL_f1_micro:
  - 0.565310111960192
  - 0.6111604762751022
  - 0.6693834160170092
  - 0.7402551381998583
  - 0.7412475564243826
  - 0.7055269237604407
  - 0.6582211197732105
  - 0.7115520907158045
  - 0.6781588768437888
  - 0.6971743380131509
  - 0.6630049610205528
  - 0.6396172927002126
  - 0.6179136307090812
  - 0.44730762395592677
  - 0.508681785967399
  - 0.618532955350815
  TL_f1_weighted:
  - 0.6698380103771178
  - 0.7063287249136262
  - 0.7518862865079725
  - 0.8052296871401414
  - 0.82067594379031
  - 0.7925819830661152
  - 0.7575855341286788
  - 0.7965379488539566
  - 0.7680236699703678
  - 0.7779427156406999
  - 0.7549053519350233
  - 0.7365467297488082
  - 0.7336763744547308
  - 0.5778461676962874
  - 0.6377509013404845
  - 0.7323426997086725
  TL_matthews_corrcoef:
  - 0.1973367196900403
  - 0.23430111751217922
  - 0.2583423702560768
  - 0.27921108961711316
  - 0.20050082015050782
  - 0.23551658796178673
  - 0.19994340092200852
  - 0.21426771722069027
  - 0.2362351195688661
  - 0.2462594657657707
  - 0.22755819037890945
  - 0.21293504677064823
  - 0.13671644138961206
  - 0.11765241051415586
  - 0.13396785318758186
  - 0.15176641476640573
  TL_precision_macro:
  - 0.5480777138808227
  - 0.5585909960850313
  - 0.5666380720680152
  - 0.5752103177597798
  - 0.5431835575023685
  - 0.5513417673489536
  - 0.542523240629404
  - 0.5474558657169754
  - 0.5541482620633903
  - 0.5607000159370191
  - 0.5530308694633735
  - 0.5493646295282832
  - 0.5256507003573195
  - 0.523914870566473
  - 0.5261727677816362
  - 0.5292885860375142
  TL_precision_micro:
  - 0.565310111960192
  - 0.6111604762751022
  - 0.6693834160170092
  - 0.7402551381998582
  - 0.7412475564243824
  - 0.7055269237604407
  - 0.6582211197732105
  - 0.7115520907158044
  - 0.6781588768437888
  - 0.6971743380131509
  - 0.6630049610205528
  - 0.6396172927002126
  - 0.6179136307090812
  - 0.44730762395592677
  - 0.508681785967399
  - 0.618532955350815
  TL_precision_weighted:
  - 0.9278859495763375
  - 0.9291565238317794
  - 0.9274277568544251
  - 0.9275258032691395
  - 0.951174968213205
  - 0.9515687246434507
  - 0.9480963237860988
  - 0.9469067521143143
  - 0.9437527727625294
  - 0.9345209851020755
  - 0.9393973082814134
  - 0.9373739421392275
  - 0.9532963288168137
  - 0.9471842770802628
  - 0.9508603449161063
  - 0.9523490082631798
  TL_recall_macro:
  - 0.7024939301115496
  - 0.7342382675479082
  - 0.7503853210271745
  - 0.7591360962407263
  - 0.7327308193565423
  - 0.7700922955581341
  - 0.735032437442076
  - 0.7418597466790238
  - 0.7576584621145565
  - 0.7497681571540493
  - 0.744115976847638
  - 0.7296246045827207
  - 0.6821722709893336
  - 0.6447016999456093
  - 0.6714318661043753
  - 0.6966042729200623
  TL_recall_micro:
  - 0.565310111960192
  - 0.6111604762751022
  - 0.6693834160170092
  - 0.7402551381998582
  - 0.7412475564243824
  - 0.7055269237604407
  - 0.6582211197732105
  - 0.7115520907158044
  - 0.6781588768437888
  - 0.6971743380131509
  - 0.6630049610205528
  - 0.6396172927002126
  - 0.6179136307090812
  - 0.44730762395592677
  - 0.508681785967399
  - 0.618532955350815
  TL_recall_weighted:
  - 0.565310111960192
  - 0.6111604762751022
  - 0.6693834160170092
  - 0.7402551381998582
  - 0.7412475564243824
  - 0.7055269237604407
  - 0.6582211197732105
  - 0.7115520907158044
  - 0.6781588768437888
  - 0.6971743380131509
  - 0.6630049610205528
  - 0.6396172927002126
  - 0.6179136307090812
  - 0.44730762395592677
  - 0.508681785967399
  - 0.618532955350815
  TL_roc_auc:
  - 0.8222881614259921
  - 0.8518068940335675
  - 0.8417317743656522
  - 0.8379355263943202
  - 0.7825783452728775
  - 0.8357423459907932
  - 0.8149119182941218
  - 0.8017783832270695
  - 0.8423205235131842
  - 0.8321437483678148
  - 0.8271198024127446
  - 0.820293946934284
  - 0.7665488777332173
  - 0.7705678642055654
  - 0.7955571296784397
  - 0.7913494400336505
  TT_average_precision:
  - 0.3403273500721587
  - 0.28056675722256236
  - 0.2593809263411457
  - 0.29712937464009853
  - 0.3505073264667871
  - 0.3026501965383935
  - 0.16174476819036096
  - 0.20132516680995768
  - 0.24596016522945272
  - 0.228479412800434
  - 0.19307599404781997
  - 0.24523674195754158
  - 0.3629155564773645
  - 0.27312603533902313
  - 0.16611977440736686
  - 0.27687968952125774
  TT_balanced_accuracy:
  - 0.6935551847153281
  - 0.682975113122172
  - 0.7427372826263612
  - 0.7070257879656161
  - 0.7342124167356001
  - 0.672560706401766
  - 0.677387280883746
  - 0.7216724471341669
  - 0.7276073303819623
  - 0.7445375312478887
  - 0.6790987890931266
  - 0.7671468926553673
  - 0.6557981106939567
  - 0.6188555791033107
  - 0.5751757937353505
  - 0.6163836057926764
  TT_f1_macro:
  - 0.4434011865804197
  - 0.47126187650158546
  - 0.5036364601581993
  - 0.5362936429512517
  - 0.5289439985365073
  - 0.49447530624973657
  - 0.45202394368156706
  - 0.4938512210934075
  - 0.5011823724239891
  - 0.5075527309569864
  - 0.4809691224627336
  - 0.48945681620801845
  - 0.39966175149305005
  - 0.33524776358632913
  - 0.3457947753005146
  - 0.4196637705511902
  TT_f1_micro:
  - 0.539480657127716
  - 0.611552729199788
  - 0.6577540106951871
  - 0.7165775401069518
  - 0.7223105458399576
  - 0.7270800211976682
  - 0.6395721925133689
  - 0.711764705882353
  - 0.6486486486486487
  - 0.7117117117117117
  - 0.6502673796791444
  - 0.6395721925133689
  - 0.5119236883942766
  - 0.43720190779014306
  - 0.4518716577540106
  - 0.5780748663101605
  TT_f1_weighted:
  - 0.6418101952743901
  - 0.7092655967683921
  - 0.7470889440198903
  - 0.7867738431161183
  - 0.7978018695183932
  - 0.8101271733314218
  - 0.748261031415894
  - 0.800741605539453
  - 0.7376170940512455
  - 0.7970720098379674
  - 0.7444276463332156
  - 0.7366882545018403
  - 0.6339535144131344
  - 0.5809586307405817
  - 0.5909126710097884
  - 0.6972480038565708
  TT_matthews_corrcoef:
  - 0.19892754956133865
  - 0.18012239870425592
  - 0.23698753986551788
  - 0.22366846698167178
  - 0.2311825812881225
  - 0.1498498008900182
  - 0.13990708470106042
  - 0.18388703349682584
  - 0.22840557840243583
  - 0.21509239459958054
  - 0.1697239565429508
  - 0.2449420017282035
  - 0.13430248622903052
  - 0.07958248904742764
  - 0.055516078042660906
  - 0.09443630389325863
  TT_precision_macro:
  - 0.5511122577686045
  - 0.5443285400420986
  - 0.5578434979619105
  - 0.5604122602473081
  - 0.5570479851537646
  - 0.5325319756956968
  - 0.5275865217788329
  - 0.538135593220339
  - 0.5573016564952049
  - 0.5472981979274205
  - 0.540209961176252
  - 0.5561456878781834
  - 0.5289431587568003
  - 0.5133215718832157
  - 0.5102494259391821
  - 0.5191569410319411
  TT_precision_micro:
  - 0.539480657127716
  - 0.611552729199788
  - 0.6577540106951871
  - 0.7165775401069518
  - 0.7223105458399576
  - 0.7270800211976682
  - 0.6395721925133689
  - 0.711764705882353
  - 0.6486486486486487
  - 0.7117117117117117
  - 0.6502673796791444
  - 0.6395721925133689
  - 0.5119236883942766
  - 0.43720190779014306
  - 0.45187165775401067
  - 0.5780748663101605
  TT_precision_weighted:
  - 0.9203585604666161
  - 0.9201003635032164
  - 0.9333062923887904
  - 0.9157321385796438
  - 0.9339901351042266
  - 0.9431394544768928
  - 0.9482631283642204
  - 0.9514015803828185
  - 0.9265051014397134
  - 0.9479834656082321
  - 0.926107491876267
  - 0.9453140195562837
  - 0.9371707366071919
  - 0.9607444159418372
  - 0.944340522700713
  - 0.9359647430001709
  TT_recall_macro:
  - 0.6935551847153281
  - 0.682975113122172
  - 0.7427372826263612
  - 0.7070257879656161
  - 0.7342124167356001
  - 0.672560706401766
  - 0.677387280883746
  - 0.7216724471341669
  - 0.7276073303819623
  - 0.7445375312478887
  - 0.6790987890931266
  - 0.7671468926553673
  - 0.6557981106939567
  - 0.6188555791033107
  - 0.5751757937353505
  - 0.6163836057926764
  TT_recall_micro:
  - 0.539480657127716
  - 0.611552729199788
  - 0.6577540106951871
  - 0.7165775401069518
  - 0.7223105458399576
  - 0.7270800211976682
  - 0.6395721925133689
  - 0.711764705882353
  - 0.6486486486486487
  - 0.7117117117117117
  - 0.6502673796791444
  - 0.6395721925133689
  - 0.5119236883942766
  - 0.43720190779014306
  - 0.45187165775401067
  - 0.5780748663101605
  TT_recall_weighted:
  - 0.539480657127716
  - 0.611552729199788
  - 0.6577540106951871
  - 0.7165775401069518
  - 0.7223105458399576
  - 0.7270800211976682
  - 0.6395721925133689
  - 0.711764705882353
  - 0.6486486486486487
  - 0.7117117117117117
  - 0.6502673796791444
  - 0.6395721925133689
  - 0.5119236883942766
  - 0.43720190779014306
  - 0.45187165775401067
  - 0.5780748663101605
  TT_roc_auc:
  - 0.8186946045584966
  - 0.7593610973801286
  - 0.801783682756379
  - 0.7941593123209169
  - 0.7921927380382254
  - 0.7394554819720383
  - 0.7457429401310589
  - 0.7683454814490053
  - 0.8007941559110096
  - 0.8170934396324573
  - 0.743232206638209
  - 0.8386864406779662
  - 0.7788331112995035
  - 0.7389971399765437
  - 0.6587769017685916
  - 0.7042879658489352
  fit_time:
  - 131.12072610855103
  - 125.29661321640015
  - 137.01532459259033
  - 133.85026597976685
  - 143.02759647369385
  - 118.68615293502808
  - 116.81137108802795
  - 123.98251962661743
  - 135.7528636455536
  - 123.1056866645813
  - 116.78945875167847
  - 120.37103843688965
  - 145.8102571964264
  - 118.15179491043091
  - 117.00125551223755
  - 135.96095776557922
  score_time:
  - 1.0267021656036377
  - 1.037667989730835
  - 0.8729562759399414
  - 0.9277098178863525
  - 0.9042942523956299
  - 1.0670790672302246
  - 1.156144618988037
  - 0.9694116115570068
  - 0.9560811519622803
  - 0.9883742332458496
  - 1.1715526580810547
  - 0.9738478660583496
  - 0.8729763031005859
  - 1.0080509185791016
  - 1.0241737365722656
  - 0.9704654216766357
start: 2023-10-09 09:48:37.817129
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
