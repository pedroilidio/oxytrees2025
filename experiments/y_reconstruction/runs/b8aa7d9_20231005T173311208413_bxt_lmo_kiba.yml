active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-05 17:43:48.159376
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: bxt_lmo
  params: {}
hash: b8aa7d9d62ffe85f3bbf06e5458e6ad20a8bdb948a5de75ff9469e281f65675f
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/b8aa7d9_20231005T173311208413_bxt_lmo_kiba.yml"
results:
  LL_average_precision:
  - 0.9999566806684411
  - 0.9999633477328573
  - 0.9998436465462113
  - 0.9999090118804305
  - 0.9999501811186547
  - 0.9998746287178774
  - 0.9997542583797396
  - 0.9999538414080343
  - 0.999642547942181
  - 0.9997066362419875
  - 0.9996141822747218
  - 0.9998395004528967
  - 0.9997180843395241
  - 0.9997447757270056
  - 0.9996886197613906
  - 0.9996834731248034
  LL_balanced_accuracy:
  - 0.9827418123626197
  - 0.9809991508761414
  - 0.962631627350899
  - 0.9720155894889605
  - 0.9820367561986328
  - 0.9725162940576755
  - 0.9623722785778122
  - 0.9809622033991328
  - 0.9606956393852489
  - 0.970112235126463
  - 0.9622247540991138
  - 0.9748381803263744
  - 0.9610173251198062
  - 0.9692078164422686
  - 0.9626515483915664
  - 0.9605472529588988
  LL_f1_macro:
  - 0.9582890721699683
  - 0.9531090934568137
  - 0.9160253039665014
  - 0.9338895445595534
  - 0.957053543155139
  - 0.9343489571211427
  - 0.9160036383987065
  - 0.954285153747471
  - 0.910196888946359
  - 0.9283291105767506
  - 0.914935855761605
  - 0.9398470312980154
  - 0.9126722278700025
  - 0.9278899679905377
  - 0.9174447231015639
  - 0.9111605138419736
  LL_f1_micro:
  - 0.9722711706619677
  - 0.9692628068577472
  - 0.9403068944747242
  - 0.9549574696264085
  - 0.9712072347641054
  - 0.9556442727232661
  - 0.9400020567365467
  - 0.9694244075864197
  - 0.9368140291769643
  - 0.9516262909694575
  - 0.9396017276586993
  - 0.9594529080785673
  - 0.9377141296000945
  - 0.9504566008926474
  - 0.9406382135306554
  - 0.9368429938924125
  LL_f1_weighted:
  - 0.9729408125907022
  - 0.9701087568821664
  - 0.9430023797219401
  - 0.956638473588699
  - 0.9719171098109224
  - 0.9573027615866051
  - 0.9426958105979072
  - 0.9702287773695494
  - 0.939903236459973
  - 0.9536029532102687
  - 0.942368325415765
  - 0.9608453637517184
  - 0.9406268539176496
  - 0.9524551601328167
  - 0.9432357546860521
  - 0.9398597696761195
  LL_matthews_corrcoef:
  - 0.9198734838907467
  - 0.9103537284407114
  - 0.8447674373510713
  - 0.8758152719532657
  - 0.9175958696987899
  - 0.8766244158771153
  - 0.8447338570664128
  - 0.9125092551935373
  - 0.8348286517368982
  - 0.8660347847008018
  - 0.8429030072118647
  - 0.8863933693822295
  - 0.8390455541902176
  - 0.8652746046827708
  - 0.8472086134140983
  - 0.8364726328620095
  LL_precision_macro:
  - 0.9382089994566738
  - 0.9307408388228673
  - 0.8856372873246176
  - 0.906264330918096
  - 0.9366794488496035
  - 0.906584056558531
  - 0.8858229192876513
  - 0.9328163080846393
  - 0.8781991938814749
  - 0.8988495683961539
  - 0.8842748972583461
  - 0.9136636636636637
  - 0.8817630074007625
  - 0.8989171297197718
  - 0.8878526058857792
  - 0.8798125279392043
  LL_precision_micro:
  - 0.9722711706619677
  - 0.9692628068577472
  - 0.9403068944747242
  - 0.9549574696264085
  - 0.9712072347641054
  - 0.9556442727232661
  - 0.9400020567365467
  - 0.9694244075864197
  - 0.9368140291769643
  - 0.9516262909694575
  - 0.9396017276586993
  - 0.9594529080785673
  - 0.9377141296000945
  - 0.9504566008926474
  - 0.9406382135306554
  - 0.9368429938924125
  LL_precision_weighted:
  - 0.9756979548793518
  - 0.9735204712856912
  - 0.9539602254265009
  - 0.9634016530698296
  - 0.974853582291867
  - 0.9639313369444433
  - 0.9537028367576792
  - 0.973532769948107
  - 0.9522062335402189
  - 0.961412334062894
  - 0.9535809202029301
  - 0.9664542828097455
  - 0.9524431175951159
  - 0.9604725788630676
  - 0.9539527528556591
  - 0.9520243557064109
  LL_recall_macro:
  - 0.9827418123626197
  - 0.9809991508761414
  - 0.962631627350899
  - 0.9720155894889605
  - 0.9820367561986328
  - 0.9725162940576755
  - 0.9623722785778122
  - 0.9809622033991328
  - 0.9606956393852489
  - 0.970112235126463
  - 0.9622247540991138
  - 0.9748381803263744
  - 0.9610173251198062
  - 0.9692078164422686
  - 0.9626515483915664
  - 0.9605472529588988
  LL_recall_micro:
  - 0.9722711706619677
  - 0.9692628068577472
  - 0.9403068944747242
  - 0.9549574696264085
  - 0.9712072347641054
  - 0.9556442727232661
  - 0.9400020567365467
  - 0.9694244075864197
  - 0.9368140291769643
  - 0.9516262909694575
  - 0.9396017276586993
  - 0.9594529080785673
  - 0.9377141296000945
  - 0.9504566008926474
  - 0.9406382135306554
  - 0.9368429938924125
  LL_recall_weighted:
  - 0.9722711706619677
  - 0.9692628068577472
  - 0.9403068944747242
  - 0.9549574696264085
  - 0.9712072347641054
  - 0.9556442727232661
  - 0.9400020567365467
  - 0.9694244075864197
  - 0.9368140291769643
  - 0.9516262909694575
  - 0.9396017276586993
  - 0.9594529080785673
  - 0.9377141296000945
  - 0.9504566008926474
  - 0.9406382135306554
  - 0.9368429938924125
  LL_roc_auc:
  - 0.9999892575578032
  - 0.9999912472263982
  - 0.9999587479241648
  - 0.9999773110485584
  - 0.9999874663894674
  - 0.9999689850366035
  - 0.9999338940283717
  - 0.9999885296872966
  - 0.9999086090098774
  - 0.9999283239863094
  - 0.999898417214009
  - 0.9999605858573855
  - 0.999925452389029
  - 0.9999352123259174
  - 0.9999153922143909
  - 0.9999169163337472
  LT_average_precision:
  - 0.43956442235729803
  - 0.4001605298455043
  - 0.42488447601680657
  - 0.3939466704071097
  - 0.4236640150092617
  - 0.4055356658386836
  - 0.42658635712392706
  - 0.40055165595207587
  - 0.4550826587737269
  - 0.4114363430946726
  - 0.4290267333695243
  - 0.39837948982229404
  - 0.47711353744407115
  - 0.3986810933024262
  - 0.41750648152628894
  - 0.38449671976208083
  LT_balanced_accuracy:
  - 0.7334228109768883
  - 0.6945037941495809
  - 0.719924043896321
  - 0.7072970683408651
  - 0.7261586271184997
  - 0.7092005357553199
  - 0.7233104354817923
  - 0.7075719125726212
  - 0.7316517945322906
  - 0.7128080697875396
  - 0.7257450279540401
  - 0.7053312228215944
  - 0.7193650600690726
  - 0.7014552743648026
  - 0.723088580840333
  - 0.7047391253073908
  LT_f1_macro:
  - 0.6507176520596432
  - 0.6302200791941359
  - 0.6073824784186662
  - 0.6306437968189937
  - 0.6401353624979134
  - 0.6375539817823705
  - 0.6136491294245265
  - 0.6379513627247183
  - 0.6235643257872692
  - 0.6342620927184601
  - 0.6103272551801854
  - 0.6278435587633838
  - 0.6190614524580581
  - 0.6282295282523767
  - 0.6134686475931856
  - 0.618429670410058
  LT_f1_micro:
  - 0.7089006033938179
  - 0.6851193048952134
  - 0.6602165552858773
  - 0.6881005419423479
  - 0.6951663145054131
  - 0.6871031020381022
  - 0.6660238720617083
  - 0.6984185036184903
  - 0.6687215457337661
  - 0.6818277532112024
  - 0.6623665924128072
  - 0.6844321796278441
  - 0.6635318704284221
  - 0.6743531809321283
  - 0.6636319333687755
  - 0.6663454722665249
  LT_f1_weighted:
  - 0.7378469050436199
  - 0.7125981303805917
  - 0.6994558335827552
  - 0.7184385687382611
  - 0.7257870909984454
  - 0.714675772068306
  - 0.7038301059784577
  - 0.7266031603691928
  - 0.7035607669339974
  - 0.7108626860436345
  - 0.7014631685413854
  - 0.7152153600554629
  - 0.6976178295353658
  - 0.7028610268875147
  - 0.7010469648179488
  - 0.6988120035509864
  LT_matthews_corrcoef:
  - 0.3775248960742964
  - 0.32344343631572575
  - 0.3397481600715543
  - 0.33672992626178333
  - 0.3644124263449178
  - 0.34686812151475654
  - 0.34722649130516225
  - 0.3405810785175552
  - 0.3669954654954021
  - 0.3499529341645017
  - 0.3483589769508852
  - 0.3332022965103177
  - 0.3509269131753167
  - 0.33410533614092686
  - 0.3483440128009015
  - 0.33143758864991374
  LT_precision_macro:
  - 0.6526468713141537
  - 0.6344648017704883
  - 0.6312144072869349
  - 0.6367446295162025
  - 0.6467956564011698
  - 0.6437824875648248
  - 0.6349760435556585
  - 0.6397051624260566
  - 0.6453535811864957
  - 0.6438703149892424
  - 0.634392746013186
  - 0.635176434535987
  - 0.6403478958225839
  - 0.6385250100671285
  - 0.635981356371039
  - 0.6341351769051735
  LT_precision_micro:
  - 0.7089006033938179
  - 0.6851193048952134
  - 0.6602165552858773
  - 0.6881005419423479
  - 0.6951663145054131
  - 0.6871031020381022
  - 0.6660238720617083
  - 0.6984185036184903
  - 0.6687215457337661
  - 0.6818277532112024
  - 0.6623665924128072
  - 0.6844321796278441
  - 0.6635318704284221
  - 0.6743531809321283
  - 0.6636319333687755
  - 0.6663454722665249
  LT_precision_weighted:
  - 0.8202907602882609
  - 0.7866441725458287
  - 0.8276369625320914
  - 0.8030054595347396
  - 0.8165212068332511
  - 0.7958071917449878
  - 0.8271661673552001
  - 0.8009394472275267
  - 0.8265276680026163
  - 0.800775232173542
  - 0.8313694205698164
  - 0.8019460420221282
  - 0.8157300775270492
  - 0.7903153950803968
  - 0.8259360703068562
  - 0.80172488156058
  LT_recall_macro:
  - 0.7334228109768883
  - 0.6945037941495809
  - 0.719924043896321
  - 0.7072970683408651
  - 0.7261586271184997
  - 0.7092005357553199
  - 0.7233104354817923
  - 0.7075719125726212
  - 0.7316517945322906
  - 0.7128080697875396
  - 0.7257450279540401
  - 0.7053312228215944
  - 0.7193650600690726
  - 0.7014552743648026
  - 0.723088580840333
  - 0.7047391253073908
  LT_recall_micro:
  - 0.7089006033938179
  - 0.6851193048952134
  - 0.6602165552858773
  - 0.6881005419423479
  - 0.6951663145054131
  - 0.6871031020381022
  - 0.6660238720617083
  - 0.6984185036184903
  - 0.6687215457337661
  - 0.6818277532112024
  - 0.6623665924128072
  - 0.6844321796278441
  - 0.6635318704284221
  - 0.6743531809321283
  - 0.6636319333687755
  - 0.6663454722665249
  LT_recall_weighted:
  - 0.708900603393818
  - 0.6851193048952133
  - 0.6602165552858773
  - 0.6881005419423479
  - 0.6951663145054131
  - 0.6871031020381022
  - 0.6660238720617083
  - 0.6984185036184903
  - 0.6687215457337661
  - 0.6818277532112025
  - 0.6623665924128072
  - 0.6844321796278441
  - 0.6635318704284221
  - 0.6743531809321283
  - 0.6636319333687755
  - 0.6663454722665249
  LT_roc_auc:
  - 0.7995442634340414
  - 0.7591363411205491
  - 0.7829246373493897
  - 0.756928085275517
  - 0.789871680939525
  - 0.7641394025489401
  - 0.7835413989057711
  - 0.7600951444132928
  - 0.8005633660650572
  - 0.7677983246692919
  - 0.7828406145644087
  - 0.7595128730253842
  - 0.7985852385245353
  - 0.7589531868183115
  - 0.7792822940125745
  - 0.7469615989283396
  TL_average_precision:
  - 0.7071953552701598
  - 0.7037508781878421
  - 0.7025281419315372
  - 0.6926424866900582
  - 0.6723454971297778
  - 0.6544641494378423
  - 0.6549151732801408
  - 0.6507000289724092
  - 0.6974354308460379
  - 0.691956776899441
  - 0.6900714258169887
  - 0.6937025148267575
  - 0.6680671120953197
  - 0.6587464891934856
  - 0.659903031501408
  - 0.6542896575938408
  TL_balanced_accuracy:
  - 0.8172711794390862
  - 0.8168396443498465
  - 0.8050762511684983
  - 0.8078190345151443
  - 0.8143337243215285
  - 0.8095757300995984
  - 0.798234965712815
  - 0.8066008585801263
  - 0.8212781929561336
  - 0.8233690519651471
  - 0.8126516723620444
  - 0.8197507437913811
  - 0.8073594314782748
  - 0.811128310472223
  - 0.8041602789110359
  - 0.8033972417044716
  TL_f1_macro:
  - 0.7190032239494479
  - 0.7114007108706619
  - 0.6931810484475993
  - 0.6976791537158326
  - 0.709796450574266
  - 0.6936714713681663
  - 0.6826921988679766
  - 0.6961997619439262
  - 0.7061332754540894
  - 0.7111901236620541
  - 0.700462996752401
  - 0.710448598390039
  - 0.6832615856133473
  - 0.688778518728713
  - 0.6857265897514149
  - 0.6758318298197179
  TL_f1_micro:
  - 0.7627259436469963
  - 0.7565517089499648
  - 0.729750264270613
  - 0.7388235553206484
  - 0.7554603048024101
  - 0.7393080514446794
  - 0.7207870859760396
  - 0.741080866807611
  - 0.7429780258727628
  - 0.7529400105708245
  - 0.7355091613812543
  - 0.7498128083157154
  - 0.7273877292852625
  - 0.7377653236838622
  - 0.7283659150081638
  - 0.7200035302943383
  TL_f1_weighted:
  - 0.7849377972897799
  - 0.7805783598863493
  - 0.7554605702823726
  - 0.7645088718464734
  - 0.7795971866785234
  - 0.7666655231916845
  - 0.7482938050780289
  - 0.7673980172788738
  - 0.7677494073397307
  - 0.7774598621918665
  - 0.760254930598653
  - 0.7738145725102064
  - 0.756753995372069
  - 0.7668370213467506
  - 0.7565767301190293
  - 0.7506728950709783
  TL_matthews_corrcoef:
  - 0.5199527857031946
  - 0.5129206027225979
  - 0.4961611607095147
  - 0.49767817297360595
  - 0.5088927768536067
  - 0.4930026010091111
  - 0.48089042139776683
  - 0.49228642526294303
  - 0.5213109848706406
  - 0.5221500793542245
  - 0.510368767563007
  - 0.5200911265493061
  - 0.48530469137289195
  - 0.4885303851120065
  - 0.48485590521382377
  - 0.47651019091979574
  TL_precision_macro:
  - 0.7130282522339991
  - 0.7075872995921703
  - 0.7017330884112691
  - 0.7011600454179847
  - 0.7059688782143492
  - 0.696277954770189
  - 0.6938535248871598
  - 0.6976070171659623
  - 0.7114718248118879
  - 0.710781384081715
  - 0.7082799341323819
  - 0.7114887808453454
  - 0.6915677699686802
  - 0.6917713119833503
  - 0.6932248103387925
  - 0.6870995602784625
  TL_precision_micro:
  - 0.7627259436469963
  - 0.7565517089499648
  - 0.7297502642706131
  - 0.7388235553206484
  - 0.7554603048024101
  - 0.7393080514446794
  - 0.7207870859760395
  - 0.741080866807611
  - 0.7429780258727627
  - 0.7529400105708245
  - 0.7355091613812544
  - 0.7498128083157153
  - 0.7273877292852625
  - 0.7377653236838622
  - 0.7283659150081638
  - 0.7200035302943383
  TL_precision_weighted:
  - 0.8653603838633366
  - 0.8679351059360698
  - 0.8624210714601985
  - 0.8639796261204911
  - 0.8664437443592189
  - 0.8681102482283072
  - 0.8607270451574791
  - 0.8643420878167902
  - 0.8722629219404308
  - 0.8729308578090913
  - 0.866340677367403
  - 0.8695651298434995
  - 0.8699225776190452
  - 0.8720477036718682
  - 0.8657826263104145
  - 0.869480462521328
  TL_recall_macro:
  - 0.8172711794390862
  - 0.8168396443498465
  - 0.8050762511684983
  - 0.8078190345151443
  - 0.8143337243215285
  - 0.8095757300995984
  - 0.798234965712815
  - 0.8066008585801263
  - 0.8212781929561336
  - 0.8233690519651471
  - 0.8126516723620444
  - 0.8197507437913811
  - 0.8073594314782748
  - 0.811128310472223
  - 0.8041602789110359
  - 0.8033972417044716
  TL_recall_micro:
  - 0.7627259436469963
  - 0.7565517089499648
  - 0.7297502642706131
  - 0.7388235553206484
  - 0.7554603048024101
  - 0.7393080514446794
  - 0.7207870859760395
  - 0.741080866807611
  - 0.7429780258727627
  - 0.7529400105708245
  - 0.7355091613812544
  - 0.7498128083157153
  - 0.7273877292852625
  - 0.7377653236838622
  - 0.7283659150081638
  - 0.7200035302943383
  TL_recall_weighted:
  - 0.7627259436469963
  - 0.7565517089499648
  - 0.7297502642706131
  - 0.7388235553206484
  - 0.7554603048024101
  - 0.7393080514446794
  - 0.7207870859760396
  - 0.741080866807611
  - 0.7429780258727627
  - 0.7529400105708245
  - 0.7355091613812544
  - 0.7498128083157153
  - 0.7273877292852625
  - 0.7377653236838622
  - 0.7283659150081638
  - 0.7200035302943383
  TL_roc_auc:
  - 0.902622118505175
  - 0.9043639764265887
  - 0.899455023553942
  - 0.8983695882555203
  - 0.9028901837788796
  - 0.8999686122046384
  - 0.895407497948933
  - 0.8960292422586651
  - 0.9109796367532917
  - 0.9115424537648142
  - 0.9066684761827857
  - 0.9081734489566484
  - 0.8972960074366175
  - 0.8961572808319348
  - 0.8913434890436364
  - 0.892339590300616
  TT_average_precision:
  - 0.34540179323453196
  - 0.3270666251176866
  - 0.3321864781754606
  - 0.3026711275610815
  - 0.3097391615758528
  - 0.3173849164590486
  - 0.3129931204115339
  - 0.2961592575325035
  - 0.3382727912358051
  - 0.3221905858592633
  - 0.331445868913276
  - 0.3021083114573978
  - 0.3430756331455051
  - 0.30767943605640535
  - 0.3120890070568314
  - 0.28660101679905053
  TT_balanced_accuracy:
  - 0.65003385050404
  - 0.619280094360876
  - 0.6348875048227345
  - 0.612710664750646
  - 0.6377610585295355
  - 0.629324465159858
  - 0.6416521028484898
  - 0.6164620767360494
  - 0.6444134141657453
  - 0.6333423926761604
  - 0.6553306832455501
  - 0.6260546751887932
  - 0.6393706083271065
  - 0.6308632528420632
  - 0.6426960974890468
  - 0.6215161226814834
  TT_f1_macro:
  - 0.5518145104837014
  - 0.5363618422354106
  - 0.4873541254266238
  - 0.5197319850461838
  - 0.5256506611055856
  - 0.5349203053057258
  - 0.4802298686314087
  - 0.5221760944661165
  - 0.5084873056753343
  - 0.5394903571319459
  - 0.5054315653088478
  - 0.5287781115384145
  - 0.4950497101686981
  - 0.5281022589019887
  - 0.48725571377210636
  - 0.4966700663730267
  TT_f1_micro:
  - 0.5903866248693835
  - 0.5687134502923976
  - 0.5057814992025519
  - 0.5518673577884105
  - 0.5571773772204807
  - 0.5642278043593834
  - 0.4984383306751728
  - 0.5576820839978734
  - 0.5251763322884012
  - 0.5646597554492291
  - 0.5248205741626795
  - 0.5607389686337054
  - 0.5159327357194268
  - 0.5583408235959919
  - 0.5127334465195246
  - 0.5206231898531909
  TT_f1_weighted:
  - 0.631148385107325
  - 0.606151789175955
  - 0.5480359258559417
  - 0.5930757619098809
  - 0.6003723725611799
  - 0.6023876810226301
  - 0.5425194236790446
  - 0.6004416130780492
  - 0.5624907836045572
  - 0.6000027991352379
  - 0.5663610131686987
  - 0.6014505273526881
  - 0.559365128628021
  - 0.5991294819424399
  - 0.5621631397874026
  - 0.5641942614056946
  TT_matthews_corrcoef:
  - 0.2393226464789279
  - 0.19620696933865234
  - 0.21736938928094926
  - 0.18243088257470305
  - 0.21910628891717518
  - 0.21169769740639763
  - 0.22574648532029587
  - 0.18647528159346824
  - 0.23812360719089085
  - 0.22156406310201784
  - 0.2496734984827524
  - 0.20367112462601294
  - 0.22273437176404734
  - 0.21126054774251296
  - 0.2204511853975208
  - 0.1947778072778434
  TT_precision_macro:
  - 0.5954373445146894
  - 0.5806865031071059
  - 0.5875719575702487
  - 0.573819604805397
  - 0.5871210746264046
  - 0.5866346422383687
  - 0.5899412620950899
  - 0.5746445358435716
  - 0.598160639420454
  - 0.5920386852842404
  - 0.6003292693724804
  - 0.5822697114254133
  - 0.5889904280404077
  - 0.5852627037445168
  - 0.5851437530499082
  - 0.5780521822347154
  TT_precision_micro:
  - 0.5903866248693835
  - 0.5687134502923976
  - 0.5057814992025519
  - 0.5518673577884105
  - 0.5571773772204807
  - 0.5642278043593834
  - 0.4984383306751728
  - 0.5576820839978734
  - 0.5251763322884012
  - 0.5646597554492291
  - 0.5248205741626795
  - 0.5607389686337054
  - 0.5159327357194268
  - 0.5583408235959919
  - 0.5127334465195246
  - 0.5206231898531909
  TT_precision_weighted:
  - 0.7784318496244234
  - 0.7449567877249026
  - 0.7958726776473731
  - 0.751275257670646
  - 0.7788755119500355
  - 0.7574057747498999
  - 0.8102387993841705
  - 0.7576689864268679
  - 0.78925519752646
  - 0.7548874817290544
  - 0.8080225458852206
  - 0.7610772128391209
  - 0.7973659438021563
  - 0.7665109892073155
  - 0.8115999412411172
  - 0.7757204841284928
  TT_recall_macro:
  - 0.65003385050404
  - 0.619280094360876
  - 0.6348875048227345
  - 0.612710664750646
  - 0.6377610585295355
  - 0.629324465159858
  - 0.6416521028484898
  - 0.6164620767360494
  - 0.6444134141657453
  - 0.6333423926761604
  - 0.6553306832455501
  - 0.6260546751887932
  - 0.6393706083271065
  - 0.6308632528420632
  - 0.6426960974890468
  - 0.6215161226814834
  TT_recall_micro:
  - 0.5903866248693835
  - 0.5687134502923976
  - 0.5057814992025519
  - 0.5518673577884105
  - 0.5571773772204807
  - 0.5642278043593834
  - 0.4984383306751728
  - 0.5576820839978734
  - 0.5251763322884012
  - 0.5646597554492291
  - 0.5248205741626795
  - 0.5607389686337054
  - 0.5159327357194268
  - 0.5583408235959919
  - 0.5127334465195246
  - 0.5206231898531909
  TT_recall_weighted:
  - 0.5903866248693835
  - 0.5687134502923976
  - 0.5057814992025519
  - 0.5518673577884105
  - 0.5571773772204807
  - 0.5642278043593834
  - 0.4984383306751728
  - 0.5576820839978734
  - 0.5251763322884012
  - 0.5646597554492291
  - 0.5248205741626795
  - 0.5607389686337054
  - 0.5159327357194268
  - 0.5583408235959919
  - 0.5127334465195246
  - 0.5206231898531909
  TT_roc_auc:
  - 0.7050417797400577
  - 0.6692115976308127
  - 0.7002379076947064
  - 0.6548927075773745
  - 0.691023440041304
  - 0.6777444829493183
  - 0.7055916574351957
  - 0.6593314738395685
  - 0.7103123303860047
  - 0.677676019050184
  - 0.7158819572775756
  - 0.6699113443235338
  - 0.7069673375407516
  - 0.6752516722204489
  - 0.7077372369984735
  - 0.6577467087478219
  fit_time:
  - 47.93913173675537
  - 49.0437798500061
  - 47.771658420562744
  - 47.04052543640137
  - 54.542890310287476
  - 48.99240207672119
  - 48.06659388542175
  - 44.654542207717896
  - 43.88473343849182
  - 48.982473611831665
  - 48.19132661819458
  - 44.05862784385681
  - 48.3812141418457
  - 57.36502695083618
  - 48.072497844696045
  - 47.75395369529724
  score_time:
  - 550.9773573875427
  - 575.3102331161499
  - 553.0422642230988
  - 543.3902723789215
  - 580.9566175937653
  - 552.1894397735596
  - 569.9117012023926
  - 557.2105484008789
  - 551.9950497150421
  - 558.8216171264648
  - 578.0946190357208
  - 565.6895909309387
  - 563.0313107967377
  - 573.9175081253052
  - 568.4708285331726
  - 543.7167706489563
start: 2023-10-05 17:33:11.208413
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
