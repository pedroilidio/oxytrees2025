active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: y_reconstruction/runs
end: 2023-10-07 07:04:32.057030
estimator:
  call: bipartite_adaptations.estimators.bxt_gmosa
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 1000
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gmosa_1k
  params:
    n_estimators: 1000
hash: f952f9f517f356fc25f125d8b50ff6bdd66f23eeac17cb65448d9e8d7e193dde
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/f952f9f_20231007T065457556510_bxt_gmosa_1k_davis.yml"
results:
  LL_average_precision:
  - 0.9892008545075249
  - 0.9794642862610066
  - 0.9852670820305024
  - 0.9880613718421603
  - 0.9873860790005202
  - 0.9801801289867093
  - 0.9853518970523804
  - 0.9877233208410214
  - 0.9911033986901004
  - 0.9832083287426718
  - 0.9840549214093993
  - 0.9891051854536146
  - 0.9911480922663215
  - 0.9823117405536413
  - 0.9844690510874526
  - 0.9902053227376035
  LL_balanced_accuracy:
  - 0.8693529448118164
  - 0.7855365474339036
  - 0.9506065857885615
  - 0.963287145861685
  - 0.8826206208702156
  - 0.9378330929838861
  - 0.9297747551007675
  - 0.9497507788161994
  - 0.9256408664887343
  - 0.8746646702851082
  - 0.8453143461227536
  - 0.8661224236404271
  - 0.9384596180252154
  - 0.9609786700125471
  - 0.900824896887889
  - 0.9785772281556431
  LL_f1_macro:
  - 0.5492377099361372
  - 0.45823788144981376
  - 0.7205257726107589
  - 0.7626651927822095
  - 0.5876198126463287
  - 0.7091227935871157
  - 0.6850868598403422
  - 0.7347246624699106
  - 0.6554637834398863
  - 0.5772513401487166
  - 0.5359565131470725
  - 0.5609462437644135
  - 0.7000033523878734
  - 0.7807207608175646
  - 0.6296969163279709
  - 0.8533737433065217
  LL_f1_micro:
  - 0.7495409039748829
  - 0.5915526331378473
  - 0.9057406094968108
  - 0.9298960548074652
  - 0.7769089508915349
  - 0.8825306557668384
  - 0.8670564611386723
  - 0.9047365934325537
  - 0.8580652804928618
  - 0.7619809253006339
  - 0.706177651783605
  - 0.7452752185211434
  - 0.8831822759315207
  - 0.9263076831941236
  - 0.8125442948263644
  - 0.9594849988188047
  LL_f1_weighted:
  - 0.8247992265907026
  - 0.7013215861936142
  - 0.927185972212288
  - 0.9438623556041992
  - 0.839238486139541
  - 0.9089130242417802
  - 0.8988809947819434
  - 0.9249674488101077
  - 0.8955649473093106
  - 0.828496157233639
  - 0.7887568974897726
  - 0.8177399772601622
  - 0.910566768178361
  - 0.9394745411684193
  - 0.8613220372497885
  - 0.9645386173470902
  LL_matthews_corrcoef:
  - 0.3239287172619823
  - 0.24447801403395739
  - 0.5429843138333516
  - 0.602841839448548
  - 0.37339229073988484
  - 0.529124616190411
  - 0.49646797688252947
  - 0.5638972510592818
  - 0.4550158912320941
  - 0.3620692861887017
  - 0.3176156171284624
  - 0.34271805554215107
  - 0.5158298207890873
  - 0.6301217988991319
  - 0.42621638457980143
  - 0.7406497652985338
  LL_precision_macro:
  - 0.5710227272727273
  - 0.5523308661212829
  - 0.663575042158516
  - 0.6961085509472607
  - 0.5910966340933768
  - 0.6598627787307032
  - 0.6433776932826363
  - 0.676753507014028
  - 0.6216045483259633
  - 0.5874743326488706
  - 0.5730346721592859
  - 0.5802024527934593
  - 0.6517131755563406
  - 0.7153318077803204
  - 0.6133040935672515
  - 0.7865588052271313
  LL_precision_micro:
  - 0.749540903974883
  - 0.5915526331378473
  - 0.9057406094968108
  - 0.9298960548074652
  - 0.7769089508915349
  - 0.8825306557668384
  - 0.8670564611386723
  - 0.9047365934325537
  - 0.8580652804928618
  - 0.7619809253006339
  - 0.706177651783605
  - 0.7452752185211434
  - 0.8831822759315207
  - 0.9263076831941236
  - 0.8125442948263643
  - 0.9594849988188047
  LL_precision_weighted:
  - 0.9644234238600686
  - 0.9572511910542922
  - 0.9691630324492095
  - 0.9725040337852116
  - 0.9593543126597173
  - 0.9624420484304266
  - 0.9618777241224646
  - 0.9663237175982015
  - 0.9654801850851243
  - 0.9583588805659425
  - 0.9570815622498882
  - 0.9591408954762356
  - 0.9645544242406132
  - 0.9682634004053411
  - 0.9575210024825825
  - 0.9767801393354818
  LL_recall_macro:
  - 0.8693529448118164
  - 0.7855365474339036
  - 0.9506065857885615
  - 0.963287145861685
  - 0.8826206208702156
  - 0.9378330929838861
  - 0.9297747551007675
  - 0.9497507788161994
  - 0.9256408664887343
  - 0.8746646702851082
  - 0.8453143461227536
  - 0.8661224236404271
  - 0.9384596180252154
  - 0.9609786700125471
  - 0.900824896887889
  - 0.9785772281556431
  LL_recall_micro:
  - 0.749540903974883
  - 0.5915526331378473
  - 0.9057406094968108
  - 0.9298960548074652
  - 0.7769089508915349
  - 0.8825306557668384
  - 0.8670564611386723
  - 0.9047365934325537
  - 0.8580652804928618
  - 0.7619809253006339
  - 0.706177651783605
  - 0.7452752185211434
  - 0.8831822759315207
  - 0.9263076831941236
  - 0.8125442948263643
  - 0.9594849988188047
  LL_recall_weighted:
  - 0.749540903974883
  - 0.5915526331378473
  - 0.9057406094968108
  - 0.9298960548074652
  - 0.7769089508915349
  - 0.8825306557668384
  - 0.8670564611386723
  - 0.9047365934325537
  - 0.8580652804928618
  - 0.7619809253006339
  - 0.706177651783605
  - 0.7452752185211434
  - 0.8831822759315207
  - 0.9263076831941236
  - 0.8125442948263643
  - 0.9594849988188047
  LL_roc_auc:
  - 0.9994721322185633
  - 0.9987213318463004
  - 0.9992295639422843
  - 0.9993702332426402
  - 0.9991495432356572
  - 0.9985775138403877
  - 0.9990195412644477
  - 0.9992081858704022
  - 0.999524363043077
  - 0.9989489780406816
  - 0.9988631290870227
  - 0.9993128904168705
  - 0.9994580356549907
  - 0.9988210305116024
  - 0.9988521596090811
  - 0.9994097773849968
  LT_average_precision:
  - 0.7089397471456139
  - 0.6056696116913415
  - 0.5817278026072333
  - 0.5122571740374178
  - 0.682565111257769
  - 0.608681108832042
  - 0.5665128921357295
  - 0.5098446406092987
  - 0.6973160802683835
  - 0.6103732903734987
  - 0.5547507223969
  - 0.4772304997210254
  - 0.6587706644114592
  - 0.6068557693458517
  - 0.6031339921711545
  - 0.5358520117868777
  LT_balanced_accuracy:
  - 0.838425536701756
  - 0.7362580915690438
  - 0.8638966480446928
  - 0.8575634328358208
  - 0.8392791484404742
  - 0.8564502999174299
  - 0.8530844790039595
  - 0.8627131400400738
  - 0.8662633933559378
  - 0.8052668221091217
  - 0.7974215206170062
  - 0.8077413308341144
  - 0.8712452738357228
  - 0.861746598845424
  - 0.8619608810886423
  - 0.8803911645932723
  LT_f1_macro:
  - 0.5528683961626268
  - 0.4213671298601965
  - 0.6431152845777698
  - 0.6630192117092314
  - 0.5643636716958492
  - 0.6324523052464229
  - 0.6189300093778237
  - 0.6446257263734361
  - 0.6297008693459618
  - 0.5345979509176129
  - 0.48936652511207407
  - 0.5156348626220063
  - 0.6529636323198896
  - 0.6744747052788587
  - 0.5851278795340761
  - 0.6946113352383497
  LT_f1_micro:
  - 0.7201907790143084
  - 0.5626214449743862
  - 0.8689839572192514
  - 0.8844919786096257
  - 0.7235470764882529
  - 0.8547959724430313
  - 0.8265597147950089
  - 0.8429590017825312
  - 0.81522699169758
  - 0.7383854442677973
  - 0.6568627450980392
  - 0.6868092691622103
  - 0.8295354177707119
  - 0.8841194135311783
  - 0.7755793226381462
  - 0.888235294117647
  LT_f1_weighted:
  - 0.7958554776991866
  - 0.6860485261824946
  - 0.9027402656781061
  - 0.9118595456716356
  - 0.7954168486695107
  - 0.8926696382157899
  - 0.872036687220362
  - 0.8813384545042626
  - 0.8613422943834325
  - 0.8156897763688682
  - 0.7559633719867164
  - 0.7753477553036953
  - 0.8691962918182344
  - 0.9102384768969746
  - 0.8374597573220521
  - 0.9121186165583214
  LT_matthews_corrcoef:
  - 0.3298467904491838
  - 0.17895640726080897
  - 0.400045769106729
  - 0.4193989670925629
  - 0.3450555703418403
  - 0.3863705782166246
  - 0.3770223129718626
  - 0.41153939771313086
  - 0.4047752538756867
  - 0.2735706645333496
  - 0.25152005724610865
  - 0.277447479160457
  - 0.43382957108053133
  - 0.43787216466981016
  - 0.3587137664638046
  - 0.47504532804060157
  LT_precision_macro:
  - 0.5803713766918754
  - 0.5338881469487549
  - 0.6099464767263665
  - 0.6229820204231238
  - 0.5877325847839586
  - 0.6047005878140861
  - 0.6006457610935223
  - 0.6167345880076018
  - 0.6118341398036622
  - 0.5612913876261876
  - 0.5531756571160746
  - 0.5625339335180055
  - 0.6267410725524821
  - 0.6325043782060225
  - 0.588873945344343
  - 0.6483131607003116
  LT_precision_micro:
  - 0.7201907790143084
  - 0.5626214449743862
  - 0.8689839572192514
  - 0.8844919786096257
  - 0.723547076488253
  - 0.8547959724430313
  - 0.8265597147950089
  - 0.8429590017825312
  - 0.81522699169758
  - 0.7383854442677972
  - 0.6568627450980392
  - 0.6868092691622103
  - 0.8295354177707119
  - 0.8841194135311783
  - 0.7755793226381462
  - 0.888235294117647
  LT_precision_weighted:
  - 0.9510365186420682
  - 0.9604921553123064
  - 0.960015569173284
  - 0.9582343752482678
  - 0.9471308694377838
  - 0.9574904911792529
  - 0.9532783023072218
  - 0.9515199482745238
  - 0.9497864606357016
  - 0.9548591255475626
  - 0.9573340168262627
  - 0.9531135598283634
  - 0.9470278937291498
  - 0.9557382769931034
  - 0.9552996195655404
  - 0.9557516861058757
  LT_recall_macro:
  - 0.838425536701756
  - 0.7362580915690438
  - 0.8638966480446928
  - 0.8575634328358208
  - 0.8392791484404742
  - 0.8564502999174299
  - 0.8530844790039595
  - 0.8627131400400738
  - 0.8662633933559378
  - 0.8052668221091217
  - 0.7974215206170062
  - 0.8077413308341144
  - 0.8712452738357228
  - 0.861746598845424
  - 0.8619608810886423
  - 0.8803911645932723
  LT_recall_micro:
  - 0.7201907790143084
  - 0.5626214449743862
  - 0.8689839572192514
  - 0.8844919786096257
  - 0.723547076488253
  - 0.8547959724430313
  - 0.8265597147950089
  - 0.8429590017825312
  - 0.81522699169758
  - 0.7383854442677972
  - 0.6568627450980392
  - 0.6868092691622103
  - 0.8295354177707119
  - 0.8841194135311783
  - 0.7755793226381462
  - 0.888235294117647
  LT_recall_weighted:
  - 0.7201907790143084
  - 0.5626214449743862
  - 0.8689839572192514
  - 0.8844919786096257
  - 0.7235470764882529
  - 0.8547959724430313
  - 0.8265597147950089
  - 0.8429590017825312
  - 0.81522699169758
  - 0.7383854442677972
  - 0.6568627450980393
  - 0.6868092691622103
  - 0.8295354177707119
  - 0.8841194135311783
  - 0.7755793226381462
  - 0.888235294117647
  LT_roc_auc:
  - 0.9590209115344993
  - 0.908414358221733
  - 0.9306680633147113
  - 0.9233324626865671
  - 0.9517912013180343
  - 0.9248113046808671
  - 0.9255296841495102
  - 0.9314858303410241
  - 0.9503368433293733
  - 0.9012995248486082
  - 0.9221846386158271
  - 0.9268494504558235
  - 0.9511460257027486
  - 0.9164231022835843
  - 0.9511154342374587
  - 0.9414143160849974
  TL_average_precision:
  - 0.35749648139376367
  - 0.3674167949234062
  - 0.36238061648886505
  - 0.366374229560084
  - 0.24462589927835032
  - 0.26213589749514155
  - 0.2996711551208781
  - 0.2479163369134572
  - 0.4024081997608289
  - 0.39311108013414325
  - 0.35741367101485705
  - 0.358858808494998
  - 0.15890824443879278
  - 0.1828196655171363
  - 0.23015231732744526
  - 0.20065676792890805
  TL_balanced_accuracy:
  - 0.7369012446735264
  - 0.735808286871223
  - 0.7647476976189471
  - 0.7502975086086769
  - 0.7652980910926174
  - 0.7628713246725669
  - 0.7632684584491813
  - 0.7544640098856966
  - 0.795074846516524
  - 0.7966001218698314
  - 0.7567160573012928
  - 0.7823772215233948
  - 0.7130736367800619
  - 0.7493436958647337
  - 0.7404124934106484
  - 0.7570298122929702
  TL_f1_macro:
  - 0.5526958929254968
  - 0.47489580908677775
  - 0.6338046285555629
  - 0.6477222076584108
  - 0.531868668892778
  - 0.5876569563103891
  - 0.5681484351875413
  - 0.6017228671939114
  - 0.6443137390860967
  - 0.6161467421758864
  - 0.5376924835189882
  - 0.5826278556471542
  - 0.5679681632088587
  - 0.6130597977954146
  - 0.5570119084932207
  - 0.6306359497140849
  TL_f1_micro:
  - 0.7401812688821753
  - 0.5930335880575796
  - 0.8382352941176471
  - 0.8644578313253012
  - 0.7655944553047805
  - 0.837035720632664
  - 0.8074060949681077
  - 0.8564847625797307
  - 0.8716900657543984
  - 0.8235294117647058
  - 0.7310418143160878
  - 0.7916371367824239
  - 0.8569397547538653
  - 0.8768437888750666
  - 0.8137845499645642
  - 0.9023742026931253
  TL_f1_weighted:
  - 0.8056441835725116
  - 0.6911202565473874
  - 0.8707638633830391
  - 0.888300218658885
  - 0.8371347676949733
  - 0.8804034627828584
  - 0.8612262540951336
  - 0.8921536854605099
  - 0.8997899185278092
  - 0.8656978897927999
  - 0.8045675324383823
  - 0.845851862685313
  - 0.8965618917084284
  - 0.9057430681388513
  - 0.8675054260834233
  - 0.9238730151060509
  TL_matthews_corrcoef:
  - 0.25437003100255096
  - 0.23483816909735883
  - 0.34026557471577956
  - 0.3438987391891576
  - 0.23445290236571575
  - 0.2800019936610029
  - 0.26475371042369966
  - 0.2879542649512683
  - 0.3633787062114481
  - 0.3414266965992335
  - 0.25262738235952464
  - 0.30078399119706595
  - 0.22110685065854185
  - 0.29494567461380294
  - 0.23512756655375794
  - 0.3172977030410453
  TL_precision_macro:
  - 0.5682817356673321
  - 0.5584680105995565
  - 0.609331131467764
  - 0.618125769083057
  - 0.5517984912757232
  - 0.5745622564117567
  - 0.5665618353941995
  - 0.5814630512394181
  - 0.611873382030643
  - 0.5982570307252141
  - 0.5621509567698398
  - 0.5800976517089049
  - 0.5573607323586939
  - 0.5872219274199979
  - 0.557489704225832
  - 0.5979242752591359
  TL_precision_micro:
  - 0.7401812688821753
  - 0.5930335880575796
  - 0.8382352941176471
  - 0.8644578313253012
  - 0.7655944553047805
  - 0.837035720632664
  - 0.8074060949681078
  - 0.8564847625797307
  - 0.8716900657543984
  - 0.8235294117647058
  - 0.7310418143160878
  - 0.7916371367824239
  - 0.8569397547538653
  - 0.8768437888750666
  - 0.8137845499645642
  - 0.9023742026931254
  TL_precision_weighted:
  - 0.9246234504505265
  - 0.9312115997440215
  - 0.924865126682831
  - 0.9253531177780794
  - 0.9542060451731117
  - 0.9475432206448965
  - 0.9472081989591048
  - 0.946033305375752
  - 0.9449632466574711
  - 0.9385242964106619
  - 0.9383101699961872
  - 0.939814896441765
  - 0.95214719022672
  - 0.9481116290880859
  - 0.9493990681041287
  - 0.9546865948901726
  TL_recall_macro:
  - 0.7369012446735264
  - 0.735808286871223
  - 0.7647476976189471
  - 0.7502975086086769
  - 0.7652980910926174
  - 0.7628713246725669
  - 0.7632684584491813
  - 0.7544640098856966
  - 0.795074846516524
  - 0.7966001218698314
  - 0.7567160573012928
  - 0.7823772215233948
  - 0.7130736367800619
  - 0.7493436958647337
  - 0.7404124934106484
  - 0.7570298122929702
  TL_recall_micro:
  - 0.7401812688821753
  - 0.5930335880575796
  - 0.8382352941176471
  - 0.8644578313253012
  - 0.7655944553047805
  - 0.837035720632664
  - 0.8074060949681078
  - 0.8564847625797307
  - 0.8716900657543984
  - 0.8235294117647058
  - 0.7310418143160878
  - 0.7916371367824239
  - 0.8569397547538653
  - 0.8768437888750666
  - 0.8137845499645642
  - 0.9023742026931254
  TL_recall_weighted:
  - 0.7401812688821753
  - 0.5930335880575796
  - 0.8382352941176471
  - 0.8644578313253012
  - 0.7655944553047805
  - 0.837035720632664
  - 0.8074060949681078
  - 0.8564847625797307
  - 0.8716900657543984
  - 0.8235294117647058
  - 0.7310418143160878
  - 0.7916371367824239
  - 0.8569397547538653
  - 0.8768437888750666
  - 0.8137845499645642
  - 0.9023742026931254
  TL_roc_auc:
  - 0.8274835382919898
  - 0.8591203173782651
  - 0.8434458752062245
  - 0.8367356312294514
  - 0.79980706491648
  - 0.828247977005741
  - 0.8117787182092596
  - 0.7968973205146815
  - 0.8542538719471877
  - 0.8551167919217711
  - 0.8335610381858258
  - 0.8462030481080088
  - 0.7562928270278861
  - 0.7897083651660488
  - 0.8027708223510807
  - 0.7992196400091138
  TT_average_precision:
  - 0.3497563515797904
  - 0.30404253462192665
  - 0.2710431550615878
  - 0.3113728198173556
  - 0.3256095779405321
  - 0.27341841361616764
  - 0.15301931475208336
  - 0.20393484027404668
  - 0.3292687747569046
  - 0.3334899644588953
  - 0.2774618175983742
  - 0.2817081625400083
  - 0.2731130162774514
  - 0.18663366075108773
  - 0.11717402773895856
  - 0.19561968769834978
  TT_balanced_accuracy:
  - 0.7426181982273459
  - 0.695822559793148
  - 0.7278055420120266
  - 0.7480802292263611
  - 0.7549305585789543
  - 0.6731788079470199
  - 0.6778335381941454
  - 0.7275912283036742
  - 0.7964209166721263
  - 0.7902236335382744
  - 0.7648477654847983
  - 0.7987005649717513
  - 0.7819516773646603
  - 0.6944095800497931
  - 0.6370551885787343
  - 0.6719214921301303
  TT_f1_macro:
  - 0.546161809455093
  - 0.4710582637561386
  - 0.6175760579483586
  - 0.6303716050174155
  - 0.5267040149393091
  - 0.5692726101666125
  - 0.5341540149581262
  - 0.5585428940834763
  - 0.6497662965054269
  - 0.6200303236512541
  - 0.5552821829855538
  - 0.5772536521983425
  - 0.6152844225855184
  - 0.5833006183138679
  - 0.5346326688868674
  - 0.5701854131051166
  TT_f1_micro:
  - 0.7074721780604134
  - 0.606253312135665
  - 0.8497326203208556
  - 0.841711229946524
  - 0.7095919448860626
  - 0.863275039745628
  - 0.8096256684491978
  - 0.8272727272727273
  - 0.8494965553789083
  - 0.8659247482776895
  - 0.7524064171122996
  - 0.7796791443850268
  - 0.8500264970853206
  - 0.904610492845787
  - 0.8433155080213902
  - 0.8582887700534759
  TT_f1_weighted:
  - 0.7783053532524384
  - 0.7047444637329091
  - 0.8798476445407609
  - 0.872500453946097
  - 0.7887966067896863
  - 0.8968429887289922
  - 0.8651797571226406
  - 0.8768192146804781
  - 0.8803321041172703
  - 0.8991318346073464
  - 0.8184311605908962
  - 0.8384982982197974
  - 0.886495923856321
  - 0.9286554080189662
  - 0.8872972388764078
  - 0.8923493236835562
  TT_matthews_corrcoef:
  - 0.26448682252594563
  - 0.19221853663805727
  - 0.29418329507746327
  - 0.324669554829931
  - 0.24752666373808963
  - 0.19858579656103187
  - 0.1722226233254101
  - 0.22555117686575518
  - 0.37743740890849403
  - 0.32953941041443013
  - 0.27077807197515963
  - 0.3085445002842899
  - 0.3232082392649479
  - 0.22034366554077472
  - 0.14030429162695612
  - 0.19990418861435946
  TT_precision_macro:
  - 0.5720816490693756
  - 0.5471702109633144
  - 0.5949755330119064
  - 0.6062260384092154
  - 0.5600844496662545
  - 0.5569300583935249
  - 0.5416971853091974
  - 0.5558823529411765
  - 0.6201492452379236
  - 0.5935452961672474
  - 0.5692102915502918
  - 0.579678212748514
  - 0.5926254162638307
  - 0.5624343344236297
  - 0.5359076049091591
  - 0.5581103678929766
  TT_precision_micro:
  - 0.7074721780604134
  - 0.606253312135665
  - 0.8497326203208556
  - 0.841711229946524
  - 0.7095919448860626
  - 0.863275039745628
  - 0.8096256684491978
  - 0.8272727272727273
  - 0.8494965553789083
  - 0.8659247482776895
  - 0.7524064171122995
  - 0.7796791443850267
  - 0.8500264970853206
  - 0.904610492845787
  - 0.8433155080213903
  - 0.8582887700534759
  TT_precision_weighted:
  - 0.9194624199671411
  - 0.9233402257633384
  - 0.9256775564429242
  - 0.9220257158019637
  - 0.9380124187857994
  - 0.9422459400796965
  - 0.9449902331018113
  - 0.9499685435671595
  - 0.9332416312810106
  - 0.9509784995079112
  - 0.9369300508305536
  - 0.9435143302136296
  - 0.9447170151706559
  - 0.9599658009271275
  - 0.9454709674017184
  - 0.938781052706884
  TT_recall_macro:
  - 0.7426181982273459
  - 0.695822559793148
  - 0.7278055420120266
  - 0.7480802292263611
  - 0.7549305585789543
  - 0.6731788079470199
  - 0.6778335381941454
  - 0.7275912283036742
  - 0.7964209166721263
  - 0.7902236335382744
  - 0.7648477654847983
  - 0.7987005649717513
  - 0.7819516773646603
  - 0.6944095800497931
  - 0.6370551885787343
  - 0.6719214921301303
  TT_recall_micro:
  - 0.7074721780604134
  - 0.606253312135665
  - 0.8497326203208556
  - 0.841711229946524
  - 0.7095919448860626
  - 0.863275039745628
  - 0.8096256684491978
  - 0.8272727272727273
  - 0.8494965553789083
  - 0.8659247482776895
  - 0.7524064171122995
  - 0.7796791443850267
  - 0.8500264970853206
  - 0.904610492845787
  - 0.8433155080213903
  - 0.8582887700534759
  TT_recall_weighted:
  - 0.7074721780604134
  - 0.606253312135665
  - 0.8497326203208556
  - 0.841711229946524
  - 0.7095919448860626
  - 0.863275039745628
  - 0.8096256684491978
  - 0.8272727272727273
  - 0.8494965553789083
  - 0.8659247482776895
  - 0.7524064171122995
  - 0.7796791443850267
  - 0.8500264970853206
  - 0.904610492845787
  - 0.8433155080213903
  - 0.8582887700534759
  TT_roc_auc:
  - 0.8472682224927842
  - 0.790802406935625
  - 0.8019715992198926
  - 0.820552435530086
  - 0.7975151290870304
  - 0.7415526122148638
  - 0.7224514401584605
  - 0.7713753337143484
  - 0.8295700233052236
  - 0.8586784676711033
  - 0.7994489938147923
  - 0.8768615819209038
  - 0.805561947438537
  - 0.7350980432501389
  - 0.6729938205838484
  - 0.6897002593841217
  fit_time:
  - 544.1580653190613
  - 461.29721689224243
  - 530.1096251010895
  - 552.2403199672699
  - 504.7746150493622
  - 552.0446207523346
  - 512.047779083252
  - 557.5971293449402
  - 561.6969459056854
  - 505.06008100509644
  - 537.461457490921
  - 525.871529340744
  - 567.745611667633
  - 501.27175641059875
  - 510.9458351135254
  - 494.371036529541
  score_time:
  - 6.160037517547607
  - 7.910933256149292
  - 7.110289812088013
  - 7.285330533981323
  - 7.906178951263428
  - 7.294624328613281
  - 7.7482264041900635
  - 6.538290500640869
  - 6.218008041381836
  - 8.426401138305664
  - 6.565429449081421
  - 6.58360743522644
  - 6.568127870559692
  - 8.17630386352539
  - 8.042989253997803
  - 8.13665509223938
start: 2023-10-07 06:54:57.556510
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
