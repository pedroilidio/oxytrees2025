active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: y_reconstruction/runs
end: 2023-10-05 18:25:28.320788
estimator:
  call: bipartite_adaptations.estimators.brf_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 0.5
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: brf_lmo
  params: {}
hash: e27ecdfb2c9b4bf5cadf18fcdb7f02f0e6b61b61891c5001ed56cf711a48d891
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/e27ecdf_20231005T180634639217_brf_lmo_enzymes.yml"
results:
  LL_average_precision:
  - 0.9855385882982497
  - 0.9914752011589305
  - 0.9937999181838666
  - 0.9903837198825951
  - 0.983974761856039
  - 0.9851525605831232
  - 0.9840679239354673
  - 0.9918082418121086
  - 0.9916233883466244
  - 0.9861295163171389
  - 0.9905106099338129
  - 0.9855653745980948
  - 0.9813633426183632
  - 0.9921555423849109
  - 0.9921934568333446
  - 0.990977275733006
  LL_balanced_accuracy:
  - 0.90093739537998
  - 0.9338455555758095
  - 0.9476618148033447
  - 0.9153348427001075
  - 0.8690563121447783
  - 0.9355573508598225
  - 0.9220271484422428
  - 0.9248982118043967
  - 0.9284170932263739
  - 0.9333554114737462
  - 0.9208635714936386
  - 0.8425680310305267
  - 0.903023713368541
  - 0.9341007745340029
  - 0.9436938031591737
  - 0.927663179115988
  LL_f1_macro:
  - 0.4884763485987251
  - 0.5339882984949682
  - 0.5528470695131635
  - 0.5047127614944902
  - 0.4572457773476288
  - 0.5347893649017857
  - 0.513349056799762
  - 0.5143762403698345
  - 0.5191730779826278
  - 0.5336092051588385
  - 0.5137398002663535
  - 0.4354755324866545
  - 0.49364482254645364
  - 0.5374860860362866
  - 0.5488943986253491
  - 0.5218731406200263
  LL_f1_micro:
  - 0.8037254121591471
  - 0.8690871269509173
  - 0.8963638987086069
  - 0.8322812206911478
  - 0.7404814453007225
  - 0.8724358511891879
  - 0.8455618882716495
  - 0.8511771637447995
  - 0.8581593641834605
  - 0.8681251953923478
  - 0.843313373253493
  - 0.6881478007839742
  - 0.8079947417296816
  - 0.869664285886059
  - 0.888560228939711
  - 0.8567623788567443
  LL_f1_weighted:
  - 0.8825431264457362
  - 0.9208200740510208
  - 0.9369813919293868
  - 0.8998368121881588
  - 0.842233688192425
  - 0.9229932323925845
  - 0.9076590097814571
  - 0.9113646461099735
  - 0.9154239497540211
  - 0.9202141036943067
  - 0.9060386351217441
  - 0.8059271053144811
  - 0.8845980324601344
  - 0.9207514035607581
  - 0.9321821965609384
  - 0.9140788265489236
  LL_matthews_corrcoef:
  - 0.19085983140647053
  - 0.25439593711516084
  - 0.2798974720726916
  - 0.21119853366859165
  - 0.15766905560782865
  - 0.2545447453224801
  - 0.22298657143772987
  - 0.22234313491919794
  - 0.22910683529847645
  - 0.2540594138377709
  - 0.22495018881635123
  - 0.14279102220711715
  - 0.20013641899703027
  - 0.26101250246556873
  - 0.27537542185080977
  - 0.2354365278978386
  LL_precision_macro:
  - 0.522713942166696
  - 0.537292817679558
  - 0.5437509925361284
  - 0.526848710990502
  - 0.5168399308440174
  - 0.5371897221131614
  - 0.5294548651817116
  - 0.5290872427044097
  - 0.5306301632278405
  - 0.5372362869198313
  - 0.5300587832233402
  - 0.5148797276570274
  - 0.5248462961857577
  - 0.5392348565356004
  - 0.5427274521413065
  - 0.5324030460040823
  LL_precision_micro:
  - 0.8037254121591471
  - 0.8690871269509174
  - 0.8963638987086069
  - 0.8322812206911478
  - 0.7404814453007225
  - 0.8724358511891879
  - 0.8455618882716495
  - 0.8511771637447996
  - 0.8581593641834606
  - 0.8681251953923478
  - 0.843313373253493
  - 0.6881478007839742
  - 0.8079947417296814
  - 0.8696642858860592
  - 0.888560228939711
  - 0.8567623788567443
  LL_precision_weighted:
  - 0.9910836607259816
  - 0.9902357801869469
  - 0.9909316354118537
  - 0.9909939339333136
  - 0.9912594509722497
  - 0.9905118495082478
  - 0.9909020924802467
  - 0.9913423080837728
  - 0.9913107963451975
  - 0.9901789438762656
  - 0.9905803813052607
  - 0.990719448412841
  - 0.9904587609675854
  - 0.989772593910549
  - 0.9904769250307666
  - 0.9907173295451597
  LL_recall_macro:
  - 0.90093739537998
  - 0.9338455555758095
  - 0.9476618148033447
  - 0.9153348427001075
  - 0.8690563121447783
  - 0.9355573508598225
  - 0.9220271484422428
  - 0.9248982118043967
  - 0.9284170932263739
  - 0.9333554114737462
  - 0.9208635714936386
  - 0.8425680310305267
  - 0.903023713368541
  - 0.9341007745340029
  - 0.9436938031591737
  - 0.927663179115988
  LL_recall_micro:
  - 0.8037254121591471
  - 0.8690871269509174
  - 0.8963638987086069
  - 0.8322812206911478
  - 0.7404814453007225
  - 0.8724358511891879
  - 0.8455618882716495
  - 0.8511771637447996
  - 0.8581593641834606
  - 0.8681251953923478
  - 0.843313373253493
  - 0.6881478007839742
  - 0.8079947417296814
  - 0.8696642858860592
  - 0.888560228939711
  - 0.8567623788567443
  LL_recall_weighted:
  - 0.8037254121591471
  - 0.8690871269509174
  - 0.8963638987086069
  - 0.8322812206911478
  - 0.7404814453007225
  - 0.8724358511891879
  - 0.8455618882716495
  - 0.8511771637447996
  - 0.8581593641834606
  - 0.8681251953923478
  - 0.843313373253493
  - 0.6881478007839742
  - 0.8079947417296814
  - 0.8696642858860592
  - 0.888560228939711
  - 0.8567623788567443
  LL_roc_auc:
  - 0.9999152066372557
  - 0.9999481360546393
  - 0.9999607992798706
  - 0.9999380861025877
  - 0.9999102356582732
  - 0.9999068470914797
  - 0.9999105242346583
  - 0.9999439805228422
  - 0.9999558404214705
  - 0.9999268162750593
  - 0.999945460153407
  - 0.9999115423856134
  - 0.9998957420955483
  - 0.9999446484784165
  - 0.9999478159664832
  - 0.9999289929070182
  LT_average_precision:
  - 0.18052006253599284
  - 0.19109446300687785
  - 0.3344367308431469
  - 0.2294066420365569
  - 0.2202441415883824
  - 0.22327083499885167
  - 0.3641791990393909
  - 0.24578882373440955
  - 0.24307996489928427
  - 0.2311515715577824
  - 0.3478614582172386
  - 0.24836372108998178
  - 0.22952612121870072
  - 0.24365177908176716
  - 0.4063608639144009
  - 0.27308102086150415
  LT_balanced_accuracy:
  - 0.6776358222286469
  - 0.7659596504454151
  - 0.8021438753061687
  - 0.7436186988232065
  - 0.6764793884568839
  - 0.752888821077774
  - 0.7996885544069284
  - 0.7508872602175218
  - 0.6908799648891815
  - 0.7993268137407746
  - 0.8112422092939667
  - 0.7034317733823225
  - 0.6983664531674776
  - 0.7765717544385795
  - 0.825814693270822
  - 0.7685444741716216
  LT_f1_macro:
  - 0.4634520360556416
  - 0.4869653960978579
  - 0.5148640282448629
  - 0.4895717473259761
  - 0.44101729019819147
  - 0.48094954073720625
  - 0.4923406252999946
  - 0.49872947747093793
  - 0.48761432447961095
  - 0.4828095050386324
  - 0.48737643745587816
  - 0.4270541932636916
  - 0.463351183827388
  - 0.48617061488061264
  - 0.5145260768740744
  - 0.5007393965121469
  LT_f1_micro:
  - 0.7745804647160067
  - 0.8390137125076885
  - 0.8723723723723724
  - 0.8254640182351026
  - 0.718463138267355
  - 0.8298057093237816
  - 0.8319765548681212
  - 0.8450378088932307
  - 0.8285463281698221
  - 0.8239263359745288
  - 0.8169796302326423
  - 0.6796555591736315
  - 0.7694886689615605
  - 0.8309996743731684
  - 0.8611382466804154
  - 0.8368428669633488
  LT_f1_weighted:
  - 0.862784674672908
  - 0.9054163092806723
  - 0.9233847213932429
  - 0.8946918931680257
  - 0.8261583035708023
  - 0.900180463135037
  - 0.8999728488135956
  - 0.906557170776066
  - 0.8958155238778254
  - 0.8964382625025232
  - 0.8907081278385445
  - 0.7992943490869489
  - 0.8594760993130325
  - 0.9002182979662106
  - 0.9163343869351804
  - 0.9007881176859466
  LT_matthews_corrcoef:
  - 0.08966994992482975
  - 0.12549666949277383
  - 0.1734654851143644
  - 0.13166069456397833
  - 0.08162916228493057
  - 0.11464999145794598
  - 0.15094477581351146
  - 0.1406862501692575
  - 0.10849523250526488
  - 0.13539406685817285
  - 0.15341305914994294
  - 0.08961940773340293
  - 0.09935452592703659
  - 0.13181095994248962
  - 0.18641697527257817
  - 0.1545785412736114
  LT_precision_macro:
  - 0.5113162703032552
  - 0.5148043265467169
  - 0.5248973063705749
  - 0.5177885960486646
  - 0.5094392328101356
  - 0.5129944657945799
  - 0.5190066695994451
  - 0.519722624585966
  - 0.5154170390318406
  - 0.5153106508495686
  - 0.5189045428407131
  - 0.5098701865851009
  - 0.5124407651401772
  - 0.515704901966787
  - 0.5266649182706526
  - 0.5222444769120506
  LT_precision_micro:
  - 0.7745804647160068
  - 0.8390137125076884
  - 0.8723723723723724
  - 0.8254640182351026
  - 0.7184631382673551
  - 0.8298057093237816
  - 0.8319765548681212
  - 0.8450378088932305
  - 0.8285463281698221
  - 0.8239263359745288
  - 0.8169796302326423
  - 0.6796555591736315
  - 0.7694886689615605
  - 0.8309996743731684
  - 0.8611382466804154
  - 0.8368428669633489
  LT_precision_weighted:
  - 0.9829114429575908
  - 0.9897483018679138
  - 0.988037957736817
  - 0.9852132458669598
  - 0.9836858011023082
  - 0.9899278006740669
  - 0.9886605547272028
  - 0.9855852646584167
  - 0.9824872716852472
  - 0.9905526150776403
  - 0.988756119130694
  - 0.9851989253308795
  - 0.9835166539682973
  - 0.9893700938445729
  - 0.9878412065333215
  - 0.9846765274628672
  LT_recall_macro:
  - 0.6776358222286469
  - 0.7659596504454151
  - 0.8021438753061687
  - 0.7436186988232065
  - 0.6764793884568839
  - 0.752888821077774
  - 0.7996885544069284
  - 0.7508872602175218
  - 0.6908799648891815
  - 0.7993268137407746
  - 0.8112422092939667
  - 0.7034317733823225
  - 0.6983664531674776
  - 0.7765717544385795
  - 0.825814693270822
  - 0.7685444741716216
  LT_recall_micro:
  - 0.7745804647160068
  - 0.8390137125076884
  - 0.8723723723723724
  - 0.8254640182351026
  - 0.7184631382673551
  - 0.8298057093237816
  - 0.8319765548681212
  - 0.8450378088932305
  - 0.8285463281698221
  - 0.8239263359745288
  - 0.8169796302326423
  - 0.6796555591736315
  - 0.7694886689615605
  - 0.8309996743731684
  - 0.8611382466804154
  - 0.8368428669633489
  LT_recall_weighted:
  - 0.7745804647160068
  - 0.8390137125076884
  - 0.8723723723723724
  - 0.8254640182351026
  - 0.7184631382673551
  - 0.8298057093237816
  - 0.8319765548681212
  - 0.8450378088932305
  - 0.8285463281698221
  - 0.8239263359745288
  - 0.8169796302326423
  - 0.6796555591736315
  - 0.7694886689615605
  - 0.8309996743731684
  - 0.8611382466804154
  - 0.8368428669633489
  LT_roc_auc:
  - 0.7480900015935513
  - 0.8298401395816197
  - 0.8974868697432575
  - 0.7773884938919526
  - 0.7574470611702553
  - 0.8501507992742527
  - 0.8965664057888265
  - 0.7647013375826934
  - 0.7550416836473453
  - 0.8695374979914308
  - 0.8902300608084027
  - 0.7637626306671745
  - 0.7910975911860816
  - 0.8518871367470184
  - 0.9044908204193678
  - 0.7778156538611711
  TL_average_precision:
  - 0.5707023977625191
  - 0.5958520325803182
  - 0.5993127013501696
  - 0.5593574815631527
  - 0.6825303799325074
  - 0.7011127616339651
  - 0.7020546938258028
  - 0.6859812698145339
  - 0.7360450024981684
  - 0.7412435514043891
  - 0.7346264429521611
  - 0.7081964595491415
  - 0.6900987931453095
  - 0.7260848585463763
  - 0.7050904338883984
  - 0.7010307142709963
  TL_balanced_accuracy:
  - 0.7811674400313944
  - 0.8102918065682133
  - 0.8155034801413672
  - 0.7693958891712592
  - 0.7838006083007953
  - 0.8404625255399785
  - 0.8390997885877433
  - 0.8258678575203434
  - 0.8543140780020299
  - 0.868073683780039
  - 0.8455614633676611
  - 0.8066508785951572
  - 0.8300571528745637
  - 0.8508448808463097
  - 0.8555352478704275
  - 0.8459844547022759
  TL_f1_macro:
  - 0.4734960928698223
  - 0.5104115631066469
  - 0.525641453141453
  - 0.4908521652379064
  - 0.439512814881686
  - 0.5096670123265742
  - 0.49569084623965565
  - 0.5004560864551022
  - 0.5125976849659459
  - 0.5207218930210326
  - 0.5011267905416597
  - 0.4385680170394388
  - 0.4783098223794511
  - 0.5087711421743947
  - 0.5213205275178573
  - 0.5103370830794584
  TL_f1_micro:
  - 0.7887767285357645
  - 0.8522112401702618
  - 0.8818267080297238
  - 0.8310367217372484
  - 0.6997720612178443
  - 0.8374395786739773
  - 0.815976480773393
  - 0.8315778082389438
  - 0.8546076196678606
  - 0.8596421614602121
  - 0.8342110958805281
  - 0.700743092128995
  - 0.8087665979232245
  - 0.8542673688767044
  - 0.8786884063198903
  - 0.8650890989106124
  TL_f1_weighted:
  - 0.873051059660797
  - 0.9106018338818159
  - 0.9282811416141442
  - 0.8989985702488338
  - 0.8133884742674299
  - 0.9011343689268787
  - 0.8887175997627796
  - 0.8985210256292703
  - 0.912787346601172
  - 0.9151499507919206
  - 0.9006309178483749
  - 0.8149326267871416
  - 0.8872364680017742
  - 0.9131454303070692
  - 0.9276394358506158
  - 0.9201000171139602
  TL_matthews_corrcoef:
  - 0.13354543045914533
  - 0.1783698069383439
  - 0.1931291690515233
  - 0.1392642389053863
  - 0.1255917013236405
  - 0.19512571809682516
  - 0.17989213530412354
  - 0.17575999169130063
  - 0.1953294605906281
  - 0.21282866106908396
  - 0.18160351649857245
  - 0.1289994704242333
  - 0.14390148212647047
  - 0.18669779929437083
  - 0.19936081885757187
  - 0.18202614414909218
  TL_precision_macro:
  - 0.5158574388934642
  - 0.5256337642130327
  - 0.5295550431977956
  - 0.5179981664693917
  - 0.5138946807899798
  - 0.527957589313549
  - 0.5238581543201873
  - 0.5236994643429949
  - 0.5269207466929998
  - 0.5307656054809993
  - 0.5238596029221857
  - 0.5135666196734611
  - 0.515684886979305
  - 0.5248372358870401
  - 0.5279471137767796
  - 0.52394147822501
  TL_precision_micro:
  - 0.7887767285357646
  - 0.8522112401702618
  - 0.8818267080297237
  - 0.8310367217372484
  - 0.6997720612178443
  - 0.8374395786739773
  - 0.815976480773393
  - 0.8315778082389438
  - 0.8546076196678606
  - 0.8596421614602121
  - 0.8342110958805281
  - 0.700743092128995
  - 0.8087665979232245
  - 0.8542673688767044
  - 0.8786884063198903
  - 0.8650890989106125
  TL_precision_weighted:
  - 0.9879062772416587
  - 0.9867803406974675
  - 0.9874964026937506
  - 0.9873402059591186
  - 0.9878014283263824
  - 0.9867318871059368
  - 0.9876548061589225
  - 0.9876114488450652
  - 0.9889466171916963
  - 0.9884664859424768
  - 0.9888135434893325
  - 0.989603668998089
  - 0.9913005572788418
  - 0.9896126467224088
  - 0.9900256916172923
  - 0.9903094574488699
  TL_recall_macro:
  - 0.7811674400313944
  - 0.8102918065682133
  - 0.8155034801413672
  - 0.7693958891712592
  - 0.7838006083007953
  - 0.8404625255399785
  - 0.8390997885877433
  - 0.8258678575203434
  - 0.8543140780020299
  - 0.868073683780039
  - 0.8455614633676611
  - 0.8066508785951572
  - 0.8300571528745637
  - 0.8508448808463097
  - 0.8555352478704275
  - 0.8459844547022759
  TL_recall_micro:
  - 0.7887767285357646
  - 0.8522112401702618
  - 0.8818267080297237
  - 0.8310367217372484
  - 0.6997720612178443
  - 0.8374395786739773
  - 0.815976480773393
  - 0.8315778082389438
  - 0.8546076196678606
  - 0.8596421614602121
  - 0.8342110958805281
  - 0.700743092128995
  - 0.8087665979232245
  - 0.8542673688767044
  - 0.8786884063198903
  - 0.8650890989106125
  TL_recall_weighted:
  - 0.7887767285357646
  - 0.8522112401702618
  - 0.8818267080297237
  - 0.8310367217372484
  - 0.6997720612178443
  - 0.8374395786739773
  - 0.815976480773393
  - 0.8315778082389438
  - 0.8546076196678606
  - 0.8596421614602121
  - 0.8342110958805281
  - 0.700743092128995
  - 0.8087665979232245
  - 0.8542673688767044
  - 0.8786884063198903
  - 0.8650890989106125
  TL_roc_auc:
  - 0.8272208511828429
  - 0.8627273686619648
  - 0.8613147009317839
  - 0.8239258395751816
  - 0.9105667684369129
  - 0.9209726891302031
  - 0.9268069692617831
  - 0.8960831913863359
  - 0.9129976820516377
  - 0.9266021860298279
  - 0.9141877525945468
  - 0.9271194801857101
  - 0.8943390047218933
  - 0.9101120265238248
  - 0.9095664758334239
  - 0.8885433850301191
  TT_average_precision:
  - 0.11794389050246534
  - 0.10625495252357012
  - 0.24045210452847693
  - 0.15123574862473
  - 0.1238262252104629
  - 0.17100363505795024
  - 0.2836659656613306
  - 0.1541830788399039
  - 0.15223742651168365
  - 0.17241545397228508
  - 0.27936034564331513
  - 0.19455292650846678
  - 0.12185770864644438
  - 0.07752267473325516
  - 0.11960546337018377
  - 0.11378117923727406
  TT_balanced_accuracy:
  - 0.6196547724146426
  - 0.6353653867191773
  - 0.729756448829271
  - 0.6808117365902016
  - 0.6672140936528195
  - 0.7160639986860835
  - 0.7543983869197849
  - 0.7502758501592282
  - 0.669651268115942
  - 0.7450760477076267
  - 0.7418382422575118
  - 0.6753004161243749
  - 0.6784880136365286
  - 0.6717937514267188
  - 0.7453364009937344
  - 0.6958638607253802
  TT_f1_macro:
  - 0.4528964232366109
  - 0.4803969564269331
  - 0.5142248001956505
  - 0.48929336957428543
  - 0.418977350893276
  - 0.47225944243801005
  - 0.48081248220291717
  - 0.4967882143192071
  - 0.4867239008312149
  - 0.48682408257140014
  - 0.48675813898550696
  - 0.4302536266168567
  - 0.4705031987029025
  - 0.47445686174821367
  - 0.49753596701763125
  - 0.488213087560372
  TT_f1_micro:
  - 0.7596277969018933
  - 0.850645826549441
  - 0.8865733203082602
  - 0.8366438727884511
  - 0.6578098106712564
  - 0.8055465103657875
  - 0.8027244111581462
  - 0.8304026918484748
  - 0.8408993115318415
  - 0.8399544122435688
  - 0.8242157820471073
  - 0.6883208509714533
  - 0.7924376075731497
  - 0.837186584174536
  - 0.8673613372408553
  - 0.8486377944209269
  TT_f1_weighted:
  - 0.8532049927898651
  - 0.9121556041241201
  - 0.9312588357395775
  - 0.9008291987311582
  - 0.7823152557266567
  - 0.8843673200519101
  - 0.8807562709786397
  - 0.8966008055327137
  - 0.9042857939960045
  - 0.9056826286594877
  - 0.8944808732434557
  - 0.8048371310425271
  - 0.8740482133949169
  - 0.905524219363817
  - 0.9220584346334347
  - 0.9101964603213812
  TT_matthews_corrcoef:
  - 0.059506552341168854
  - 0.0671253212186649
  - 0.14139188275291237
  - 0.10394936260040859
  - 0.07751363461334435
  - 0.10087535738265208
  - 0.13137634496873846
  - 0.1444790758824921
  - 0.09380620919961374
  - 0.11861715988667683
  - 0.12646204622161744
  - 0.08064998149037746
  - 0.09278708315795191
  - 0.07391235128771032
  - 0.12488537916045192
  - 0.10152591262495406
  TT_precision_macro:
  - 0.5073984298747012
  - 0.508321567384978
  - 0.521753104875055
  - 0.5149402220630195
  - 0.508983039975455
  - 0.5117741014108765
  - 0.5169613339792787
  - 0.5208511961447524
  - 0.51296719585731
  - 0.5143527190347533
  - 0.5165323823325773
  - 0.5092761039280468
  - 0.5120588528965493
  - 0.5079499918179623
  - 0.5158928290552042
  - 0.513156473705966
  TT_precision_micro:
  - 0.7596277969018933
  - 0.850645826549441
  - 0.8865733203082601
  - 0.8366438727884511
  - 0.6578098106712564
  - 0.8055465103657875
  - 0.8027244111581461
  - 0.8304026918484749
  - 0.8408993115318416
  - 0.8399544122435688
  - 0.8242157820471073
  - 0.6883208509714533
  - 0.7924376075731497
  - 0.837186584174536
  - 0.8673613372408553
  - 0.8486377944209269
  TT_precision_weighted:
  - 0.9810911257760893
  - 0.9870476593452733
  - 0.986079087718613
  - 0.9824856311412137
  - 0.9819631766382069
  - 0.987538254947336
  - 0.9855899028681309
  - 0.9836597686337706
  - 0.9838653001319057
  - 0.9888831609861861
  - 0.9860421652274798
  - 0.9830787276830186
  - 0.9828630231038293
  - 0.9900388591836083
  - 0.9893707466154732
  - 0.9868387253222234
  TT_recall_macro:
  - 0.6196547724146426
  - 0.6353653867191773
  - 0.729756448829271
  - 0.6808117365902016
  - 0.6672140936528195
  - 0.7160639986860835
  - 0.7543983869197849
  - 0.7502758501592282
  - 0.669651268115942
  - 0.7450760477076267
  - 0.7418382422575118
  - 0.6753004161243749
  - 0.6784880136365286
  - 0.6717937514267188
  - 0.7453364009937344
  - 0.6958638607253802
  TT_recall_micro:
  - 0.7596277969018933
  - 0.850645826549441
  - 0.8865733203082601
  - 0.8366438727884511
  - 0.6578098106712564
  - 0.8055465103657875
  - 0.8027244111581461
  - 0.8304026918484749
  - 0.8408993115318416
  - 0.8399544122435688
  - 0.8242157820471073
  - 0.6883208509714533
  - 0.7924376075731497
  - 0.837186584174536
  - 0.8673613372408553
  - 0.8486377944209269
  TT_recall_weighted:
  - 0.7596277969018933
  - 0.850645826549441
  - 0.8865733203082601
  - 0.836643872788451
  - 0.6578098106712564
  - 0.8055465103657875
  - 0.8027244111581461
  - 0.8304026918484749
  - 0.8408993115318416
  - 0.8399544122435689
  - 0.8242157820471073
  - 0.6883208509714533
  - 0.7924376075731497
  - 0.837186584174536
  - 0.8673613372408553
  - 0.8486377944209269
  TT_roc_auc:
  - 0.6433312973494569
  - 0.7448423768369618
  - 0.7906336788200892
  - 0.7271947889414614
  - 0.7332656064846554
  - 0.8338952835869923
  - 0.8318838472511796
  - 0.7731690114648722
  - 0.7466335484601448
  - 0.818846242566015
  - 0.843434457454834
  - 0.7276732375806477
  - 0.7374066763034232
  - 0.7887373124141925
  - 0.7963207606131154
  - 0.7065966371552013
  fit_time:
  - 64.97283411026001
  - 64.3183913230896
  - 72.85997343063354
  - 78.96887493133545
  - 67.59520506858826
  - 64.70992493629456
  - 67.97313809394836
  - 86.78457164764404
  - 84.99304389953613
  - 67.64385032653809
  - 73.21515250205994
  - 83.4384491443634
  - 68.70651054382324
  - 67.03856301307678
  - 71.6385600566864
  - 88.34445548057556
  score_time:
  - 897.2210125923157
  - 860.8008584976196
  - 931.4381854534149
  - 1005.8911588191986
  - 869.3977313041687
  - 804.80597448349
  - 897.8970568180084
  - 1015.7182006835938
  - 1011.7174682617188
  - 871.7530972957611
  - 925.0413858890533
  - 1028.0560977458954
  - 844.5908856391907
  - 851.5439088344574
  - 899.9768426418304
  - 1045.078512430191
start: 2023-10-05 18:06:34.639217
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
