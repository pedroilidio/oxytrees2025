active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 1
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-24 03:51:01.385080
estimator:
  call: bipartite_adaptations.estimators.bxt_gmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state:
                        call: numpy.random.mtrand.RandomState
                        params: {}
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 75
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmo
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 5
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 5
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 25
              oob_score: false
              prediction_weights: square
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gmo__25
  params: {}
hash: b0ed587c38c66cbba4ccda8e632852ec494a7e06f795ef24f245ccf7cb672190
modify_params:
  n_jobs: 25
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/b0ed587_20231024T012203903698_bxt_gmo__25_kiba.yml"
results:
  LL_average_precision:
  - 0.937119247945253
  - 0.9463912031263264
  - 0.9426673917776094
  - 0.9343609887071339
  - 0.9186891991394026
  - 0.9444895802293295
  - 0.9404461414659763
  - 0.9387834377607747
  - 0.9183887411341503
  - 0.9197666031991626
  - 0.9241187432776606
  - 0.931951898163447
  - 0.9358180433676393
  - 0.9310325051671993
  - 0.9244897623171159
  - 0.9155353413468149
  LL_balanced_accuracy:
  - 0.8850884359724134
  - 0.9007118251331785
  - 0.8894091697963094
  - 0.8917085971948325
  - 0.8632538753025791
  - 0.9002976791232129
  - 0.890258790057202
  - 0.9002725890271428
  - 0.8613459375483152
  - 0.8688048573242417
  - 0.8671735471533115
  - 0.8897287075860878
  - 0.8872720624859021
  - 0.890887843383108
  - 0.8704391334765633
  - 0.8713876241200018
  LL_f1_macro:
  - 0.7759984558544111
  - 0.7977374240611572
  - 0.7860933711343968
  - 0.7856856860561835
  - 0.7432770031360331
  - 0.7982716598945142
  - 0.7883263019303448
  - 0.8009460773252001
  - 0.7386396696008695
  - 0.7459161047814096
  - 0.7507028248423966
  - 0.7815643736450809
  - 0.7822874501559932
  - 0.7843662208789525
  - 0.7588514621241871
  - 0.7562878368491874
  LL_f1_micro:
  - 0.8161459660944317
  - 0.8402503342196889
  - 0.8242334983619563
  - 0.826547326977038
  - 0.7811949330052863
  - 0.8399087690431768
  - 0.8258237964418458
  - 0.8408049185385418
  - 0.7774305209222255
  - 0.7879210800805065
  - 0.7880973717845128
  - 0.8228231647299066
  - 0.8204338708724673
  - 0.8250601949729857
  - 0.7944231559783884
  - 0.79439012215175
  LL_f1_weighted:
  - 0.8335335630912005
  - 0.8550141264407639
  - 0.8400550280334733
  - 0.8427281779633606
  - 0.8027581313384424
  - 0.8545337114873376
  - 0.841292273688715
  - 0.8549286863936917
  - 0.799819372061243
  - 0.8098140856516398
  - 0.8085265703709342
  - 0.8396118208911247
  - 0.8367643609830356
  - 0.8414105383782008
  - 0.8134408001577633
  - 0.8141857954693689
  LL_matthews_corrcoef:
  - 0.630666966432379
  - 0.660535309017583
  - 0.6445411629732877
  - 0.64384332686724
  - 0.5877673417915534
  - 0.6613609693295653
  - 0.6477151791606471
  - 0.6651430446679207
  - 0.5817596390436006
  - 0.5909010008132566
  - 0.5973851933602013
  - 0.6383398433490692
  - 0.6395139944445002
  - 0.6421682350283656
  - 0.6083052060007792
  - 0.6047726560528173
  LL_precision_macro:
  - 0.7582139486639327
  - 0.7722073988669695
  - 0.76670745259046
  - 0.7645679929672885
  - 0.7377610202980923
  - 0.7731706643357215
  - 0.7687543266185088
  - 0.776321238324985
  - 0.734155308287427
  - 0.7366861402635582
  - 0.7429839186488265
  - 0.7613855148949388
  - 0.764012169161601
  - 0.7637457579329692
  - 0.7497274114743749
  - 0.7462050037180284
  LL_precision_micro:
  - 0.8161459660944317
  - 0.8402503342196889
  - 0.8242334983619563
  - 0.826547326977038
  - 0.7811949330052864
  - 0.8399087690431768
  - 0.8258237964418458
  - 0.8408049185385418
  - 0.7774305209222255
  - 0.7879210800805065
  - 0.7880973717845128
  - 0.8228231647299065
  - 0.8204338708724673
  - 0.8250601949729857
  - 0.7944231559783885
  - 0.7943901221517501
  LL_precision_weighted:
  - 0.9046611165280528
  - 0.9126542039155672
  - 0.9057932861374541
  - 0.9078152580686687
  - 0.8957274243547244
  - 0.9121755331910703
  - 0.9059706123300411
  - 0.9115840080018395
  - 0.8955724893308218
  - 0.8994652836588908
  - 0.8967460919528538
  - 0.9071263842791791
  - 0.9049037070170043
  - 0.907423595413678
  - 0.8971179988725907
  - 0.89859912205509
  LL_recall_macro:
  - 0.8850884359724134
  - 0.9007118251331785
  - 0.8894091697963094
  - 0.8917085971948325
  - 0.8632538753025791
  - 0.9002976791232129
  - 0.890258790057202
  - 0.9002725890271428
  - 0.8613459375483152
  - 0.8688048573242417
  - 0.8671735471533115
  - 0.8897287075860878
  - 0.8872720624859021
  - 0.890887843383108
  - 0.8704391334765633
  - 0.8713876241200018
  LL_recall_micro:
  - 0.8161459660944317
  - 0.8402503342196889
  - 0.8242334983619563
  - 0.826547326977038
  - 0.7811949330052864
  - 0.8399087690431768
  - 0.8258237964418458
  - 0.8408049185385418
  - 0.7774305209222255
  - 0.7879210800805065
  - 0.7880973717845128
  - 0.8228231647299065
  - 0.8204338708724673
  - 0.8250601949729857
  - 0.7944231559783885
  - 0.7943901221517501
  LL_recall_weighted:
  - 0.8161459660944317
  - 0.8402503342196889
  - 0.8242334983619563
  - 0.826547326977038
  - 0.7811949330052864
  - 0.8399087690431768
  - 0.8258237964418458
  - 0.8408049185385418
  - 0.7774305209222255
  - 0.7879210800805065
  - 0.7880973717845128
  - 0.8228231647299065
  - 0.8204338708724673
  - 0.8250601949729857
  - 0.7944231559783885
  - 0.7943901221517501
  LL_roc_auc:
  - 0.9857319034611643
  - 0.9876753409691202
  - 0.9861058331132205
  - 0.9847780089819732
  - 0.9821053762166013
  - 0.9870814952070247
  - 0.9855880263190111
  - 0.9854360747273557
  - 0.9821030625611944
  - 0.9827521575434337
  - 0.9824013529548289
  - 0.9843316877416376
  - 0.9849371231021402
  - 0.9845960156319511
  - 0.9822140895963823
  - 0.980690370556033
  LT_average_precision:
  - 0.46694922591000315
  - 0.4144627918590533
  - 0.42404416360640107
  - 0.3982035244639426
  - 0.4806017460476024
  - 0.4291556703035135
  - 0.42704036665198003
  - 0.40057276841900935
  - 0.4776649421191761
  - 0.4095747555252019
  - 0.4164749626836025
  - 0.39513645602731484
  - 0.4775085281447211
  - 0.4145413731717308
  - 0.4304799556160126
  - 0.39563346980678343
  LT_balanced_accuracy:
  - 0.7464128078015013
  - 0.7228407147947258
  - 0.7271716501297636
  - 0.731306775768715
  - 0.7440113525321539
  - 0.7258968307563884
  - 0.7298241893985405
  - 0.7325707125324725
  - 0.7413634675754179
  - 0.7188161298028942
  - 0.7204729456309571
  - 0.729605574841973
  - 0.7474466751793714
  - 0.7151272381284177
  - 0.7241701019656968
  - 0.7287958049829412
  LT_f1_macro:
  - 0.6258003928378947
  - 0.634871722219634
  - 0.6106787189140026
  - 0.6326398909962865
  - 0.6132844309786349
  - 0.6384902088691344
  - 0.6172599195823036
  - 0.640335620678013
  - 0.6091230517288858
  - 0.6161510028861668
  - 0.5959686718557525
  - 0.6329002506002019
  - 0.6281852093269154
  - 0.626879652996664
  - 0.6014725534705212
  - 0.6225143545336809
  LT_f1_micro:
  - 0.6647352255647286
  - 0.6765524043843025
  - 0.6619232857886979
  - 0.6784032095399586
  - 0.6463393382272856
  - 0.6796333854218617
  - 0.6685285544879255
  - 0.6882335339295808
  - 0.643060971093733
  - 0.650763041526748
  - 0.6424510423247
  - 0.6793895667786016
  - 0.6649468826192965
  - 0.6649942406521354
  - 0.6445928584086479
  - 0.6609626971469077
  LT_f1_weighted:
  - 0.6995735922334587
  - 0.7061975605666981
  - 0.7009750395100758
  - 0.7107811130607302
  - 0.6820984356304659
  - 0.7086755481875795
  - 0.7060656282337778
  - 0.7189770469450049
  - 0.6797912985500323
  - 0.6830923079565627
  - 0.6836738653689138
  - 0.7115527607649967
  - 0.698748584571395
  - 0.6948458466957749
  - 0.683920771801659
  - 0.694132481947262
  LT_matthews_corrcoef:
  - 0.3902875432790354
  - 0.3653812786981237
  - 0.3506867153113887
  - 0.3711462678970513
  - 0.38732937944688944
  - 0.3713133267468016
  - 0.35719601950362123
  - 0.37562714844899
  - 0.38129402811709395
  - 0.35633375652956883
  - 0.3390649859718175
  - 0.36888030082123224
  - 0.39471477214470796
  - 0.354388405270052
  - 0.3487087003690897
  - 0.36830941520040816
  LT_precision_macro:
  - 0.6545418517383748
  - 0.649774558641646
  - 0.6353394803286881
  - 0.6488818817738032
  - 0.6537060126771597
  - 0.6525846845196144
  - 0.6387897817491895
  - 0.6516697363949246
  - 0.6505873458587216
  - 0.6450689971493986
  - 0.6303618731802418
  - 0.6481591599285159
  - 0.6574074002371533
  - 0.6459498375037014
  - 0.6356088040363506
  - 0.6482236806476639
  LT_precision_micro:
  - 0.6647352255647286
  - 0.6765524043843025
  - 0.6619232857886979
  - 0.6784032095399586
  - 0.6463393382272856
  - 0.6796333854218617
  - 0.6685285544879255
  - 0.6882335339295808
  - 0.643060971093733
  - 0.650763041526748
  - 0.6424510423247
  - 0.6793895667786016
  - 0.6649468826192965
  - 0.6649942406521354
  - 0.6445928584086479
  - 0.6609626971469077
  LT_precision_weighted:
  - 0.8381141770399405
  - 0.8084674399944399
  - 0.832211177638965
  - 0.8212211499000253
  - 0.8411670789831069
  - 0.8094659412772366
  - 0.8311184439282635
  - 0.8192902389062545
  - 0.8410594015689059
  - 0.8120443790779036
  - 0.8319539178192883
  - 0.8196186699973285
  - 0.8371426960625344
  - 0.8025973594365844
  - 0.8309259983645587
  - 0.8210634105719331
  LT_recall_macro:
  - 0.7464128078015013
  - 0.7228407147947258
  - 0.7271716501297636
  - 0.731306775768715
  - 0.7440113525321539
  - 0.7258968307563884
  - 0.7298241893985405
  - 0.7325707125324725
  - 0.7413634675754179
  - 0.7188161298028942
  - 0.7204729456309571
  - 0.729605574841973
  - 0.7474466751793714
  - 0.7151272381284177
  - 0.7241701019656968
  - 0.7287958049829412
  LT_recall_micro:
  - 0.6647352255647286
  - 0.6765524043843025
  - 0.6619232857886979
  - 0.6784032095399586
  - 0.6463393382272856
  - 0.6796333854218617
  - 0.6685285544879255
  - 0.6882335339295808
  - 0.643060971093733
  - 0.650763041526748
  - 0.6424510423247
  - 0.6793895667786016
  - 0.6649468826192965
  - 0.6649942406521354
  - 0.6445928584086479
  - 0.6609626971469077
  LT_recall_weighted:
  - 0.6647352255647286
  - 0.6765524043843026
  - 0.6619232857886979
  - 0.6784032095399586
  - 0.6463393382272856
  - 0.6796333854218617
  - 0.6685285544879255
  - 0.6882335339295808
  - 0.643060971093733
  - 0.650763041526748
  - 0.6424510423247
  - 0.6793895667786016
  - 0.6649468826192965
  - 0.6649942406521354
  - 0.6445928584086479
  - 0.6609626971469077
  LT_roc_auc:
  - 0.8145664742327532
  - 0.7727350172013847
  - 0.7828848758458935
  - 0.7685624998693235
  - 0.8184369294831786
  - 0.7766745588142285
  - 0.7793425001878939
  - 0.7699808777200798
  - 0.8175744050884975
  - 0.7712782673716212
  - 0.7779944551041659
  - 0.7672390724909612
  - 0.8172459853419765
  - 0.7676594311045777
  - 0.7809500489255198
  - 0.7626820053424952
  TL_average_precision:
  - 0.6800473589159882
  - 0.6825288320650843
  - 0.685748399041015
  - 0.6740300090048594
  - 0.6421867620723289
  - 0.6425943129526192
  - 0.6490713366495339
  - 0.6356067467668188
  - 0.6650370692919747
  - 0.6546692022610769
  - 0.6642664852815466
  - 0.655442278595179
  - 0.6450116482144389
  - 0.6323638800153127
  - 0.6322946941134123
  - 0.6158783761397895
  TL_balanced_accuracy:
  - 0.7878454023030317
  - 0.7937931039293152
  - 0.7851762280968767
  - 0.7866698755387493
  - 0.7682908682690395
  - 0.7874411327489526
  - 0.7787086912654395
  - 0.7869718662850812
  - 0.7842063464793272
  - 0.7859394702194826
  - 0.7831136524002025
  - 0.796179061751304
  - 0.7934498807427568
  - 0.7932116034413362
  - 0.7786942897183042
  - 0.7786291191952359
  TL_f1_macro:
  - 0.6654193401423195
  - 0.6716673725276138
  - 0.6644785633159095
  - 0.6615696942681287
  - 0.6286994373441069
  - 0.6599961180211444
  - 0.6540081081011313
  - 0.661695367237404
  - 0.6492094474903889
  - 0.6462901745291862
  - 0.650878771501624
  - 0.6726710615247258
  - 0.663413773209067
  - 0.6584219389701416
  - 0.6398790372804225
  - 0.6321794631099706
  TL_f1_micro:
  - 0.6998272195640617
  - 0.710392441860465
  - 0.697112843551797
  - 0.6963750880902043
  - 0.658980152401205
  - 0.7005593727977449
  - 0.6877202255109232
  - 0.7002620683579986
  - 0.6775540492645756
  - 0.6767309725158562
  - 0.677468727977449
  - 0.7064944503171248
  - 0.7047948777700102
  - 0.701999029169057
  - 0.6732160981421826
  - 0.667291822955739
  TL_f1_weighted:
  - 0.7292439719024537
  - 0.7400014940384928
  - 0.7260024141606451
  - 0.7266033407799305
  - 0.6929931088658215
  - 0.7324973754269363
  - 0.7184497695305726
  - 0.7313425807472305
  - 0.7082554552540793
  - 0.7089130728121008
  - 0.7071056602741481
  - 0.735122618496873
  - 0.7367795197312708
  - 0.7355513427494424
  - 0.7069399699643024
  - 0.7032567288521793
  TL_matthews_corrcoef:
  - 0.46326204485479194
  - 0.46893159260994477
  - 0.46164890891781196
  - 0.4594192102113121
  - 0.4269538115909305
  - 0.4534743646639086
  - 0.44748698107080875
  - 0.4558895421533169
  - 0.458170901227115
  - 0.4560567326205711
  - 0.46003998266234863
  - 0.4773191155722141
  - 0.4611810052799451
  - 0.4559114272612551
  - 0.44079940541929513
  - 0.4348272723898499
  TL_precision_macro:
  - 0.6863949541020539
  - 0.6871187883639067
  - 0.68683159228178
  - 0.684067134988043
  - 0.6698618726832938
  - 0.6788531424162405
  - 0.6796181860338499
  - 0.6810589286462448
  - 0.6846550730936405
  - 0.6818459543281161
  - 0.6868832391636217
  - 0.6923106386584715
  - 0.6811961203499914
  - 0.6772228887498487
  - 0.6742986158905524
  - 0.6696473410246038
  TL_precision_micro:
  - 0.6998272195640617
  - 0.7103924418604651
  - 0.697112843551797
  - 0.6963750880902043
  - 0.658980152401205
  - 0.7005593727977449
  - 0.6877202255109232
  - 0.7002620683579986
  - 0.6775540492645756
  - 0.6767309725158562
  - 0.677468727977449
  - 0.7064944503171248
  - 0.7047948777700102
  - 0.701999029169057
  - 0.6732160981421826
  - 0.667291822955739
  TL_precision_weighted:
  - 0.8581616477766998
  - 0.8615792615097235
  - 0.855747805455266
  - 0.8589429031116514
  - 0.8573164537289927
  - 0.8613091413022115
  - 0.8546713420081882
  - 0.8597139451782767
  - 0.8625600112366246
  - 0.8657973474818833
  - 0.8606124396666816
  - 0.8628137198415051
  - 0.8654506136499031
  - 0.8678474793221248
  - 0.861973364778237
  - 0.866028268024729
  TL_recall_macro:
  - 0.7878454023030317
  - 0.7937931039293152
  - 0.7851762280968767
  - 0.7866698755387493
  - 0.7682908682690395
  - 0.7874411327489526
  - 0.7787086912654395
  - 0.7869718662850812
  - 0.7842063464793272
  - 0.7859394702194826
  - 0.7831136524002025
  - 0.796179061751304
  - 0.7934498807427568
  - 0.7932116034413362
  - 0.7786942897183042
  - 0.7786291191952359
  TL_recall_micro:
  - 0.6998272195640617
  - 0.7103924418604651
  - 0.697112843551797
  - 0.6963750880902043
  - 0.658980152401205
  - 0.7005593727977449
  - 0.6877202255109232
  - 0.7002620683579986
  - 0.6775540492645756
  - 0.6767309725158562
  - 0.677468727977449
  - 0.7064944503171248
  - 0.7047948777700102
  - 0.701999029169057
  - 0.6732160981421826
  - 0.667291822955739
  TL_recall_weighted:
  - 0.6998272195640617
  - 0.7103924418604651
  - 0.6971128435517969
  - 0.6963750880902043
  - 0.658980152401205
  - 0.7005593727977449
  - 0.6877202255109232
  - 0.7002620683579986
  - 0.6775540492645756
  - 0.6767309725158562
  - 0.677468727977449
  - 0.7064944503171248
  - 0.7047948777700102
  - 0.701999029169057
  - 0.6732160981421826
  - 0.667291822955739
  TL_roc_auc:
  - 0.8909695281007669
  - 0.8932389460026303
  - 0.8903607975122676
  - 0.8883547987510121
  - 0.8859293196013212
  - 0.8876663651799384
  - 0.8854302244461475
  - 0.8847587075620464
  - 0.8963409497174311
  - 0.8966897748054863
  - 0.8957220002373438
  - 0.8932406353476448
  - 0.888225758921684
  - 0.8881162740604609
  - 0.8836072903651674
  - 0.8815131068012962
  TT_average_precision:
  - 0.3667797566508286
  - 0.33580227383517836
  - 0.33618943668566
  - 0.3171782022593118
  - 0.3366268067898061
  - 0.3280619004774193
  - 0.31917097231547836
  - 0.30732451874765415
  - 0.35925966038580437
  - 0.326565276510665
  - 0.32878476326212136
  - 0.3070860875866368
  - 0.3484140376697363
  - 0.31330769540729797
  - 0.3153384362219056
  - 0.29540157156160546
  TT_balanced_accuracy:
  - 0.653726624226769
  - 0.6413833144818193
  - 0.6358430089147212
  - 0.6309305090358222
  - 0.6399717870513162
  - 0.6399376727070278
  - 0.6438772847165574
  - 0.6325849949137621
  - 0.6554355856161481
  - 0.6416125569980067
  - 0.6470735920881725
  - 0.6430199966221966
  - 0.654373711071756
  - 0.6421519794584917
  - 0.6439550133495077
  - 0.6351887506803902
  TT_f1_macro:
  - 0.5093772249538193
  - 0.5316125456606625
  - 0.4999158016268811
  - 0.5192245709152119
  - 0.4793118440559855
  - 0.524833702114763
  - 0.496645647792807
  - 0.5211095307709666
  - 0.4984313094515732
  - 0.5116215734776073
  - 0.4898740873532321
  - 0.5300020080737925
  - 0.5079055059136243
  - 0.5233302078552025
  - 0.4789159404432603
  - 0.49785284310228245
  TT_f1_micro:
  - 0.525666144200627
  - 0.5520002658160553
  - 0.5234582668793195
  - 0.54339447102605
  - 0.4904649947753396
  - 0.5448564593301436
  - 0.5211323763955343
  - 0.5488769271664008
  - 0.5090125391849529
  - 0.5223950026581605
  - 0.5055156831472621
  - 0.5555223285486444
  - 0.5298043577831577
  - 0.5466560138486634
  - 0.5003828356469923
  - 0.517926695296115
  TT_f1_weighted:
  - 0.5633174847822261
  - 0.5872980689390485
  - 0.5676589749949235
  - 0.5828657661092502
  - 0.5258753773582067
  - 0.5812007777848665
  - 0.5677302003951803
  - 0.5903996641247731
  - 0.5418695412257447
  - 0.552391892944775
  - 0.5454536932050358
  - 0.5948563003171706
  - 0.5729228167371895
  - 0.5860273065533524
  - 0.5482317951055319
  - 0.559595146062101
  TT_matthews_corrcoef:
  - 0.25249415815284354
  - 0.23511736095355648
  - 0.21618360257165975
  - 0.2135171546746468
  - 0.2337658337296825
  - 0.23167803145974303
  - 0.22555384117481403
  - 0.213485612879207
  - 0.262117998771111
  - 0.24293966144296905
  - 0.23929532418105626
  - 0.2323500054856851
  - 0.24588150834762215
  - 0.23128125143434838
  - 0.22455621482725177
  - 0.2183166306779545
  TT_precision_macro:
  - 0.6036796654808276
  - 0.5977487577377342
  - 0.5860098550419341
  - 0.5870491829522405
  - 0.5976026422369303
  - 0.5958903868106956
  - 0.588399178801813
  - 0.5859375281042454
  - 0.6105053341025826
  - 0.6041921711484513
  - 0.5973360536074133
  - 0.5943688405891405
  - 0.597908050094099
  - 0.5940736412338486
  - 0.5875716177649107
  - 0.5881400097839058
  TT_precision_micro:
  - 0.525666144200627
  - 0.5520002658160553
  - 0.5234582668793195
  - 0.54339447102605
  - 0.4904649947753396
  - 0.5448564593301436
  - 0.5211323763955343
  - 0.5488769271664008
  - 0.5090125391849529
  - 0.5223950026581605
  - 0.5055156831472621
  - 0.5555223285486444
  - 0.5298043577831577
  - 0.5466560138486634
  - 0.5003828356469923
  - 0.517926695296115
  TT_precision_weighted:
  - 0.800664339738213
  - 0.7686082168964435
  - 0.7911310315821659
  - 0.7686168143905724
  - 0.8032612039215099
  - 0.7721378186498066
  - 0.8046539806651748
  - 0.7726238532741565
  - 0.8084184519150471
  - 0.7776727255844789
  - 0.807381039832284
  - 0.776750963240806
  - 0.8065791585449085
  - 0.7793561270633814
  - 0.8166501648829492
  - 0.7888907540236456
  TT_recall_macro:
  - 0.653726624226769
  - 0.6413833144818193
  - 0.6358430089147212
  - 0.6309305090358222
  - 0.6399717870513162
  - 0.6399376727070278
  - 0.6438772847165574
  - 0.6325849949137621
  - 0.6554355856161481
  - 0.6416125569980067
  - 0.6470735920881725
  - 0.6430199966221966
  - 0.654373711071756
  - 0.6421519794584917
  - 0.6439550133495077
  - 0.6351887506803902
  TT_recall_micro:
  - 0.525666144200627
  - 0.5520002658160553
  - 0.5234582668793195
  - 0.54339447102605
  - 0.4904649947753396
  - 0.5448564593301436
  - 0.5211323763955343
  - 0.5488769271664008
  - 0.5090125391849529
  - 0.5223950026581605
  - 0.5055156831472621
  - 0.5555223285486444
  - 0.5298043577831577
  - 0.5466560138486634
  - 0.5003828356469923
  - 0.517926695296115
  TT_recall_weighted:
  - 0.525666144200627
  - 0.5520002658160553
  - 0.5234582668793195
  - 0.54339447102605
  - 0.4904649947753396
  - 0.5448564593301436
  - 0.5211323763955343
  - 0.5488769271664008
  - 0.5090125391849529
  - 0.5223950026581605
  - 0.5055156831472621
  - 0.5555223285486444
  - 0.5298043577831577
  - 0.5466560138486634
  - 0.5003828356469923
  - 0.517926695296115
  TT_roc_auc:
  - 0.7230055954456278
  - 0.6873115231440236
  - 0.697799848120096
  - 0.6754329851190964
  - 0.7071389312664529
  - 0.6838267500006365
  - 0.7054346546315164
  - 0.6762939219352668
  - 0.7245633275571315
  - 0.6811333031297856
  - 0.7097621690871587
  - 0.6788217784165705
  - 0.7217130482697034
  - 0.6827386597756109
  - 0.7117292601166914
  - 0.6739295018220541
  fit_time:
  - 106.07107186317444
  - 104.05414342880249
  - 103.45974898338318
  - 104.45505905151367
  - 106.461758852005
  - 108.0050413608551
  - 102.6994206905365
  - 108.85213375091553
  - 106.00433135032654
  - 104.83455324172974
  - 105.14156317710876
  - 107.2406497001648
  - 107.0372097492218
  - 106.2716076374054
  - 105.11892700195312
  - 108.08430767059326
  score_time:
  - 498.9627799987793
  - 457.29717993736267
  - 443.9430058002472
  - 445.72237277030945
  - 449.2126007080078
  - 450.58223843574524
  - 446.88915729522705
  - 447.6469647884369
  - 449.16839718818665
  - 449.0178949832916
  - 451.9968116283417
  - 449.2779858112335
  - 443.6232635974884
  - 446.48929238319397
  - 451.5027298927307
  - 448.1302442550659
start: 2023-10-24 01:22:03.903698
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
  params:
    estimator__classifierassampler__estimator__n_jobs: 75
