active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-04 22:14:34.935886
estimator:
  call: bipartite_adaptations.estimators.bxt_gso
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error_gso
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gso
  params: {}
hash: b862a9436496319f49eff2321e3d6e3dd848da6afe33066c61debc11dae844bb
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/b862a94_20231004T210339236542_bxt_gso_mirna.yml"
results:
  LL_average_precision:
  - 0.999999421601104
  - 0.9999958815103839
  - 0.9999998379861031
  - 0.9999995683645378
  - 0.9999977225936819
  - 0.999988694453379
  - 0.9999976497107994
  - 0.9999919741669052
  - 0.9999990472904356
  - 0.9999970546890226
  - 0.9999946786166096
  - 0.9999978841835747
  - 0.9999919696702596
  - 0.9999722949195431
  - 0.9999970687843819
  - 0.9999836341752334
  LL_balanced_accuracy:
  - 0.7256860468269641
  - 0.7279896787689515
  - 0.7847447610135685
  - 0.8735960441008046
  - 0.8106759646080479
  - 0.7255755768093078
  - 0.7220686058411399
  - 0.7257449400069742
  - 0.7219167862832043
  - 0.7269674437398062
  - 0.72427604112883
  - 0.8732154429236298
  - 0.7232721595050928
  - 0.7240595205833805
  - 0.7844411816064476
  - 0.7577989803457594
  LL_f1_macro:
  - 0.4200097113232597
  - 0.4236318813374228
  - 0.4923524770695523
  - 0.6162987502466348
  - 0.5268932785867922
  - 0.4205491061946074
  - 0.4137205563019543
  - 0.4200871111715281
  - 0.4145218824098678
  - 0.4217065403785518
  - 0.4158285653932086
  - 0.6148506723725029
  - 0.41653516346009367
  - 0.41795852895788227
  - 0.49122851965224845
  - 0.459630845068427
  LL_f1_micro:
  - 0.4903514075539799
  - 0.4949340881816766
  - 0.5996143311255852
  - 0.7651764190225727
  - 0.6482040484718106
  - 0.4904349418132302
  - 0.4828849652710233
  - 0.4904621772059494
  - 0.483031433442803
  - 0.49276698973578514
  - 0.48670686912839994
  - 0.7643489369468018
  - 0.485681591925942
  - 0.4873293588584637
  - 0.5988328317561304
  - 0.549817501596861
  LL_f1_weighted:
  - 0.5932922239965287
  - 0.5973221964015432
  - 0.6930434621962842
  - 0.8213009976378631
  - 0.7324831846811694
  - 0.5929771203021439
  - 0.5870161557149501
  - 0.5933981599998908
  - 0.5865683034840271
  - 0.5955912572187845
  - 0.5911529788079143
  - 0.820894958046605
  - 0.5889872928815402
  - 0.5903451631245862
  - 0.6926973812100458
  - 0.6491988822485901
  LL_matthews_corrcoef:
  - 0.2350014761058768
  - 0.23794735964117525
  - 0.291070258351153
  - 0.41680629147300846
  - 0.3228628603186563
  - 0.23572246755987092
  - 0.22969137503201018
  - 0.2350581338171418
  - 0.23075676795343858
  - 0.23625243881246716
  - 0.2308271856343398
  - 0.414961945182054
  - 0.2323250493640826
  - 0.23354587705754487
  - 0.28978190416332633
  - 0.2644500458272527
  LL_precision_macro:
  - 0.5611753523848587
  - 0.5620849880857823
  - 0.5743840685558477
  - 0.6162535627415576
  - 0.5838819529414312
  - 0.5615814470015594
  - 0.5593939512119026
  - 0.5611888867496768
  - 0.5599872218413015
  - 0.5614793182726514
  - 0.5593924225696314
  - 0.615344514284012
  - 0.5604362504058553
  - 0.5608584680407278
  - 0.5738057262895822
  - 0.5678181762435996
  LL_precision_micro:
  - 0.4903514075539799
  - 0.4949340881816766
  - 0.5996143311255852
  - 0.7651764190225728
  - 0.6482040484718106
  - 0.4904349418132302
  - 0.4828849652710233
  - 0.4904621772059494
  - 0.483031433442803
  - 0.49276698973578514
  - 0.48670686912839994
  - 0.7643489369468017
  - 0.485681591925942
  - 0.4873293588584637
  - 0.5988328317561304
  - 0.549817501596861
  LL_precision_weighted:
  - 0.9376441355293349
  - 0.9372859777644492
  - 0.9404353699153332
  - 0.9454018441912869
  - 0.9409813370978527
  - 0.9372404927508498
  - 0.9385729897127317
  - 0.937643895732756
  - 0.9379769838259077
  - 0.9376313206471425
  - 0.9390285549383697
  - 0.9456378851832355
  - 0.9378330478025908
  - 0.9375993003413368
  - 0.9407831315684524
  - 0.9389388879630237
  LL_recall_macro:
  - 0.7256860468269641
  - 0.7279896787689515
  - 0.7847447610135685
  - 0.8735960441008046
  - 0.8106759646080479
  - 0.7255755768093078
  - 0.7220686058411399
  - 0.7257449400069742
  - 0.7219167862832043
  - 0.7269674437398062
  - 0.72427604112883
  - 0.8732154429236298
  - 0.7232721595050928
  - 0.7240595205833805
  - 0.7844411816064476
  - 0.7577989803457594
  LL_recall_micro:
  - 0.4903514075539799
  - 0.4949340881816766
  - 0.5996143311255852
  - 0.7651764190225728
  - 0.6482040484718106
  - 0.4904349418132302
  - 0.4828849652710233
  - 0.4904621772059494
  - 0.483031433442803
  - 0.49276698973578514
  - 0.48670686912839994
  - 0.7643489369468017
  - 0.485681591925942
  - 0.4873293588584637
  - 0.5988328317561304
  - 0.549817501596861
  LL_recall_weighted:
  - 0.4903514075539799
  - 0.4949340881816766
  - 0.5996143311255852
  - 0.7651764190225728
  - 0.6482040484718106
  - 0.4904349418132302
  - 0.4828849652710233
  - 0.4904621772059494
  - 0.483031433442803
  - 0.49276698973578514
  - 0.48670686912839994
  - 0.7643489369468017
  - 0.485681591925942
  - 0.4873293588584637
  - 0.5988328317561306
  - 0.549817501596861
  LL_roc_auc:
  - 0.9999999560141083
  - 0.9999996687850471
  - 0.9999999877898145
  - 0.9999999673091311
  - 0.9999998226114609
  - 0.9999990460402335
  - 0.999999818963216
  - 0.9999993097106539
  - 0.9999999274468552
  - 0.9999997706147666
  - 0.99999957634032
  - 0.9999998365180067
  - 0.9999993521018095
  - 0.9999975915122863
  - 0.9999997780067791
  - 0.9999986496233032
  LT_average_precision:
  - 0.1781575129100804
  - 0.15577677652492955
  - 0.16126617422657158
  - 0.1815876999318043
  - 0.17593383642427576
  - 0.14924641724994314
  - 0.15951011616774025
  - 0.17762191550148382
  - 0.17688944627775527
  - 0.14965349054114405
  - 0.15621345752935806
  - 0.17587341624354264
  - 0.16937474811670172
  - 0.15009032276061518
  - 0.1523259065332711
  - 0.17082044772344618
  LT_balanced_accuracy:
  - 0.5766005452153039
  - 0.5702695290919761
  - 0.5921324111428783
  - 0.6304714330112616
  - 0.6109974964240847
  - 0.5686330549805765
  - 0.5682553233514245
  - 0.5770926498624876
  - 0.5744057729690084
  - 0.573111535679354
  - 0.558463313864803
  - 0.6246125238360974
  - 0.5708299067514907
  - 0.5681112324151698
  - 0.5848538120105953
  - 0.5847416729763872
  LT_f1_macro:
  - 0.3055858564391454
  - 0.2903306020129262
  - 0.3842469905227375
  - 0.5040105224027592
  - 0.42010031095410083
  - 0.2941007596324994
  - 0.3084045673546366
  - 0.2992950938229045
  - 0.3005758739328196
  - 0.30001748138478285
  - 0.29225058458663217
  - 0.4892762356421941
  - 0.2897921765760218
  - 0.290808547392532
  - 0.37809881894512526
  - 0.33552858972538063
  LT_f1_micro:
  - 0.3385861823361823
  - 0.31864316239316237
  - 0.45905928117466577
  - 0.6873011921555611
  - 0.5243224746783466
  - 0.32461675335340817
  - 0.3410552970161511
  - 0.3297723110942197
  - 0.3320626882014782
  - 0.332993430057487
  - 0.3192376129208869
  - 0.6614863697612549
  - 0.31721188064604433
  - 0.3197714207500684
  - 0.45070490008212427
  - 0.38367135404070074
  LT_f1_weighted:
  - 0.4355841871507556
  - 0.41252941824962647
  - 0.5671825615066082
  - 0.7631027572736689
  - 0.6312769664607103
  - 0.4207530317847272
  - 0.43639945896294213
  - 0.4249453263484165
  - 0.4281968487094425
  - 0.43124959192480145
  - 0.4100370979773754
  - 0.7446516936556743
  - 0.4098769381574588
  - 0.41442427616753413
  - 0.5593762527595239
  - 0.489364700348239
  LT_matthews_corrcoef:
  - 0.08661947989253456
  - 0.08033313286370741
  - 0.09755300774266105
  - 0.142847899004588
  - 0.11366578979791188
  - 0.07754487530956933
  - 0.07869727498407848
  - 0.08779912819442466
  - 0.08436938738581107
  - 0.08159604912431266
  - 0.06895462896121136
  - 0.13284155981496368
  - 0.08163476693563936
  - 0.07755731275168405
  - 0.08984993207382203
  - 0.09131066267341385
  LT_precision_macro:
  - 0.5244872091829257
  - 0.5229594972354631
  - 0.5258231310827235
  - 0.5390995978565355
  - 0.5290995567166226
  - 0.521903467973553
  - 0.5226841687425337
  - 0.5249981253902001
  - 0.5239168052552251
  - 0.5227662952598101
  - 0.5203321559318965
  - 0.5354035041399279
  - 0.5235219679026893
  - 0.5220783582530024
  - 0.5237850548560575
  - 0.5245972165317683
  LT_precision_micro:
  - 0.3385861823361823
  - 0.31864316239316237
  - 0.45905928117466577
  - 0.6873011921555611
  - 0.5243224746783466
  - 0.32461675335340817
  - 0.3410552970161511
  - 0.3297723110942197
  - 0.3320626882014782
  - 0.332993430057487
  - 0.3192376129208869
  - 0.6614863697612549
  - 0.31721188064604433
  - 0.3197714207500684
  - 0.45070490008212427
  - 0.3836713540407007
  LT_precision_weighted:
  - 0.9021075163004834
  - 0.9037099502063745
  - 0.8924733903915847
  - 0.8963254060801984
  - 0.8983115204581608
  - 0.9026822284187285
  - 0.8934976160550495
  - 0.9041598287169446
  - 0.9026579424810683
  - 0.9042646452955835
  - 0.8915171298355703
  - 0.8970020012838753
  - 0.90323786081013
  - 0.9027805404038339
  - 0.8911130231298432
  - 0.9013003847938894
  LT_recall_macro:
  - 0.5766005452153039
  - 0.5702695290919761
  - 0.5921324111428783
  - 0.6304714330112616
  - 0.6109974964240847
  - 0.5686330549805765
  - 0.5682553233514245
  - 0.5770926498624876
  - 0.5744057729690084
  - 0.573111535679354
  - 0.558463313864803
  - 0.6246125238360974
  - 0.5708299067514907
  - 0.5681112324151698
  - 0.5848538120105953
  - 0.5847416729763872
  LT_recall_micro:
  - 0.3385861823361823
  - 0.31864316239316237
  - 0.45905928117466577
  - 0.6873011921555611
  - 0.5243224746783466
  - 0.32461675335340817
  - 0.3410552970161511
  - 0.3297723110942197
  - 0.3320626882014782
  - 0.332993430057487
  - 0.3192376129208869
  - 0.6614863697612549
  - 0.31721188064604433
  - 0.3197714207500684
  - 0.45070490008212427
  - 0.3836713540407007
  LT_recall_weighted:
  - 0.3385861823361823
  - 0.31864316239316237
  - 0.45905928117466577
  - 0.6873011921555611
  - 0.5243224746783466
  - 0.32461675335340817
  - 0.3410552970161511
  - 0.3297723110942197
  - 0.3320626882014782
  - 0.332993430057487
  - 0.3192376129208869
  - 0.6614863697612549
  - 0.31721188064604433
  - 0.3197714207500684
  - 0.45070490008212427
  - 0.38367135404070063
  LT_roc_auc:
  - 0.674871507778281
  - 0.6712684262373012
  - 0.660238098348261
  - 0.6798951908930113
  - 0.6738737799184418
  - 0.6648660377961559
  - 0.659874465146414
  - 0.6815876389735395
  - 0.6750256964206933
  - 0.6659461914910868
  - 0.6535071281482496
  - 0.670738776322228
  - 0.6678229634155489
  - 0.66469171349639
  - 0.647444361716289
  - 0.6706341237278182
  TL_average_precision:
  - 0.26255606065045956
  - 0.27313560113922974
  - 0.27018128388917223
  - 0.2836279994678068
  - 0.24007374384973462
  - 0.24166432215357003
  - 0.23476150978458799
  - 0.2502991793939985
  - 0.28494837700338815
  - 0.2867563782133814
  - 0.27256960827267585
  - 0.29779447965618755
  - 0.26860577080352177
  - 0.28190798545846213
  - 0.28212019552061024
  - 0.2790156257664336
  TL_balanced_accuracy:
  - 0.5140518519314858
  - 0.5153866927882487
  - 0.5268741794040764
  - 0.566388975762834
  - 0.5387265959417099
  - 0.5182126050810748
  - 0.5157239378492988
  - 0.5161101715071168
  - 0.5143340656080395
  - 0.5191337803949246
  - 0.5155025966660415
  - 0.579323581485584
  - 0.5136877228984476
  - 0.5160054044244331
  - 0.532268058927104
  - 0.5213935393463252
  TL_f1_macro:
  - 0.10081129723812872
  - 0.1036004009775024
  - 0.132934333243171
  - 0.24625868781941782
  - 0.16708288231952262
  - 0.1097851821764171
  - 0.10194374013827973
  - 0.10352740440658884
  - 0.10168771382514624
  - 0.11313846301447673
  - 0.10332426423308061
  - 0.27349557076463893
  - 0.09846822639542349
  - 0.1048679492985431
  - 0.14502884104018654
  - 0.11828221128827592
  TL_f1_micro:
  - 0.10204375458490735
  - 0.10472442564394381
  - 0.13293660315784422
  - 0.25887048275107977
  - 0.16789650149778768
  - 0.11056833484486217
  - 0.10302443180256685
  - 0.10464606618452772
  - 0.10309313765905406
  - 0.11388682771319428
  - 0.1045016077170418
  - 0.2925158886697348
  - 0.1000151152884272
  - 0.10612993651578861
  - 0.14507928655838623
  - 0.11875410913872453
  TL_f1_weighted:
  - 0.07218291070235518
  - 0.07633545802781928
  - 0.13172340109298364
  - 0.33009167676235107
  - 0.1894492717414618
  - 0.08711021846682979
  - 0.07510346021784423
  - 0.07631473129198939
  - 0.07125273217267349
  - 0.09108613068623198
  - 0.0754318943151786
  - 0.3742357917388315
  - 0.06642820360512193
  - 0.07611080526596857
  - 0.15067765616939555
  - 0.10080383015839732
  TL_matthews_corrcoef:
  - 0.0401494244715748
  - 0.04280364151104052
  - 0.05434818161172029
  - 0.0848306765146468
  - 0.06556898036130769
  - 0.04708418638531802
  - 0.04371765036325923
  - 0.0448229492548357
  - 0.041922982922287765
  - 0.048787532012950205
  - 0.04354245373768608
  - 0.09665317169937652
  - 0.04149322978628613
  - 0.045299928966382026
  - 0.06151379921903736
  - 0.05137539184876572
  TL_precision_macro:
  - 0.528679071862883
  - 0.5297684458872954
  - 0.5274773491693341
  - 0.5270987901050029
  - 0.5277541253050793
  - 0.5304311299467948
  - 0.5303873141003512
  - 0.531177457965206
  - 0.5306531403085787
  - 0.5310997517320991
  - 0.5305746404673549
  - 0.5294421766661119
  - 0.5314458462315309
  - 0.5320529789492017
  - 0.529316510042549
  - 0.5308437847156366
  TL_precision_micro:
  - 0.10204375458490735
  - 0.10472442564394381
  - 0.13293660315784422
  - 0.25887048275107977
  - 0.16789650149778768
  - 0.11056833484486217
  - 0.10302443180256685
  - 0.10464606618452772
  - 0.10309313765905406
  - 0.11388682771319428
  - 0.1045016077170418
  - 0.2925158886697348
  - 0.10001511528842719
  - 0.1061299365157886
  - 0.14507928655838623
  - 0.11875410913872453
  TL_precision_weighted:
  - 0.9214929671376868
  - 0.9224362191880977
  - 0.9205444720226832
  - 0.9107638861084579
  - 0.9158469515322849
  - 0.9231652571778783
  - 0.9259004710524203
  - 0.9253051540568831
  - 0.9220640661905929
  - 0.9217954898162466
  - 0.9234785413782488
  - 0.9101146571126675
  - 0.92488607259789
  - 0.9236096392695706
  - 0.9205412284981699
  - 0.9218214892282012
  TL_recall_macro:
  - 0.5140518519314858
  - 0.5153866927882487
  - 0.5268741794040764
  - 0.566388975762834
  - 0.5387265959417099
  - 0.5182126050810748
  - 0.5157239378492988
  - 0.5161101715071168
  - 0.5143340656080395
  - 0.5191337803949246
  - 0.5155025966660415
  - 0.579323581485584
  - 0.5136877228984476
  - 0.5160054044244331
  - 0.532268058927104
  - 0.5213935393463252
  TL_recall_micro:
  - 0.10204375458490735
  - 0.10472442564394381
  - 0.13293660315784422
  - 0.25887048275107977
  - 0.16789650149778768
  - 0.11056833484486217
  - 0.10302443180256685
  - 0.10464606618452772
  - 0.10309313765905406
  - 0.11388682771319428
  - 0.1045016077170418
  - 0.2925158886697348
  - 0.10001511528842719
  - 0.1061299365157886
  - 0.14507928655838623
  - 0.11875410913872453
  TL_recall_weighted:
  - 0.10204375458490735
  - 0.10472442564394381
  - 0.13293660315784422
  - 0.25887048275107977
  - 0.16789650149778768
  - 0.11056833484486217
  - 0.10302443180256685
  - 0.10464606618452772
  - 0.10309313765905406
  - 0.11388682771319428
  - 0.1045016077170418
  - 0.2925158886697348
  - 0.10001511528842719
  - 0.1061299365157886
  - 0.14507928655838623
  - 0.11875410913872453
  TL_roc_auc:
  - 0.7000710657447085
  - 0.7105040426359533
  - 0.7080263371922275
  - 0.7073454631715432
  - 0.7008090216294435
  - 0.7066481959721846
  - 0.7006267656750993
  - 0.7104767310723046
  - 0.7230202450859906
  - 0.7258163159178854
  - 0.7132121845185521
  - 0.7249543273661758
  - 0.7122409123245652
  - 0.718022989945485
  - 0.7149975040569507
  - 0.7139369188771345
  TT_average_precision:
  - 0.11902622705831864
  - 0.10228579248457449
  - 0.11097893757192055
  - 0.10864891915586744
  - 0.11270882910377841
  - 0.09761809866940575
  - 0.10598971638484929
  - 0.10477626793096356
  - 0.12368025349408746
  - 0.11087302281324142
  - 0.11756947302047015
  - 0.11126925223490014
  - 0.13027199449550858
  - 0.11139283382347367
  - 0.12175248459992617
  - 0.12508605873260173
  TT_balanced_accuracy:
  - 0.5058796313197391
  - 0.504679174889014
  - 0.5178693944385658
  - 0.5574281762883398
  - 0.5280061974650995
  - 0.5071797592305924
  - 0.5031722814782451
  - 0.5046741105584562
  - 0.506636339327454
  - 0.5053082828833276
  - 0.5034922723998325
  - 0.5620578190569536
  - 0.5054103953335759
  - 0.5045457961787573
  - 0.5201893102586989
  - 0.5142156147818386
  TT_f1_macro:
  - 0.09190353558757151
  - 0.08875953576090677
  - 0.18206679750521088
  - 0.4264919432193322
  - 0.23516457427326787
  - 0.09548182717908642
  - 0.0994188385671029
  - 0.09506054422011118
  - 0.09140557049369676
  - 0.09749330951106774
  - 0.09473217682038909
  - 0.42621564781220767
  - 0.08978699013439959
  - 0.08980732555260035
  - 0.1860919889762071
  - 0.12696696259782975
  TT_f1_micro:
  - 0.09352960472363457
  - 0.0903928161390848
  - 0.1841069378382811
  - 0.5619268429006148
  - 0.2480276134122288
  - 0.09681130834976989
  - 0.10094099276791585
  - 0.0964857688158659
  - 0.0933801775147929
  - 0.0988042406311637
  - 0.09679076265614728
  - 0.5545597875694963
  - 0.09202416173570022
  - 0.09144888231426691
  - 0.18828073635765946
  - 0.12702265372168284
  TT_f1_weighted:
  - 0.058780255182224884
  - 0.05538683247914215
  - 0.2168898825007207
  - 0.6668477837144084
  - 0.32059210923924425
  - 0.06557206322126655
  - 0.06779363179818876
  - 0.06414367528407872
  - 0.05504982659184008
  - 0.06791220178870816
  - 0.05792420086865962
  - 0.6587866234088874
  - 0.05112925822895792
  - 0.05642026882281659
  - 0.22197565246451814
  - 0.12097025810314166
  TT_matthews_corrcoef:
  - 0.01849181296954321
  - 0.014996047877367821
  - 0.028372907232750467
  - 0.05849084900281686
  - 0.0356414220050551
  - 0.021159796788933986
  - 0.00940041749390911
  - 0.013969946611389549
  - 0.02214904422276991
  - 0.015417106916524344
  - 0.011468261940772126
  - 0.06420787465221124
  - 0.018990900084109558
  - 0.014487346847723986
  - 0.031948040619369
  - 0.030077956399776205
  TT_precision_macro:
  - 0.514539480806925
  - 0.5120150163904056
  - 0.5112625789811442
  - 0.5148932964538739
  - 0.511339552291287
  - 0.5155902512106953
  - 0.5069640611706275
  - 0.5104383179368746
  - 0.5184808271464031
  - 0.511194165368526
  - 0.5094151469934353
  - 0.5166081052718373
  - 0.5166648767681763
  - 0.5115427094854721
  - 0.51263883320354
  - 0.5159100305380853
  TT_precision_micro:
  - 0.09352960472363457
  - 0.0903928161390848
  - 0.1841069378382811
  - 0.5619268429006148
  - 0.2480276134122288
  - 0.09681130834976989
  - 0.10094099276791585
  - 0.0964857688158659
  - 0.0933801775147929
  - 0.0988042406311637
  - 0.09679076265614728
  - 0.5545597875694963
  - 0.0920241617357002
  - 0.09144888231426693
  - 0.18828073635765943
  - 0.12702265372168284
  TT_precision_weighted:
  - 0.8979090387651218
  - 0.8960476370061603
  - 0.8818393349667673
  - 0.8853725134169427
  - 0.8881157837839865
  - 0.9001794186350401
  - 0.8773344983694676
  - 0.8894472951547637
  - 0.9019286990428089
  - 0.8900086288002437
  - 0.8805284916685133
  - 0.8825884738714845
  - 0.8972551191050087
  - 0.8940251561930883
  - 0.882063528994648
  - 0.8977059641643056
  TT_recall_macro:
  - 0.5058796313197391
  - 0.504679174889014
  - 0.5178693944385658
  - 0.5574281762883398
  - 0.5280061974650995
  - 0.5071797592305924
  - 0.5031722814782451
  - 0.5046741105584562
  - 0.506636339327454
  - 0.5053082828833276
  - 0.5034922723998325
  - 0.5620578190569536
  - 0.5054103953335759
  - 0.5045457961787573
  - 0.5201893102586989
  - 0.5142156147818386
  TT_recall_micro:
  - 0.09352960472363457
  - 0.0903928161390848
  - 0.1841069378382811
  - 0.5619268429006148
  - 0.2480276134122288
  - 0.09681130834976989
  - 0.10094099276791585
  - 0.0964857688158659
  - 0.0933801775147929
  - 0.0988042406311637
  - 0.09679076265614728
  - 0.5545597875694963
  - 0.0920241617357002
  - 0.09144888231426693
  - 0.18828073635765943
  - 0.12702265372168284
  TT_recall_weighted:
  - 0.09352960472363457
  - 0.0903928161390848
  - 0.1841069378382811
  - 0.5619268429006148
  - 0.2480276134122288
  - 0.09681130834976989
  - 0.10094099276791585
  - 0.0964857688158659
  - 0.0933801775147929
  - 0.0988042406311637
  - 0.09679076265614728
  - 0.5545597875694963
  - 0.0920241617357002
  - 0.09144888231426693
  - 0.18828073635765943
  - 0.12702265372168284
  TT_roc_auc:
  - 0.5963411528919256
  - 0.580194404965932
  - 0.5834411747285047
  - 0.5854189424170291
  - 0.5841651991387666
  - 0.5780441176109876
  - 0.5792073626224383
  - 0.5853980522298431
  - 0.6067204642690185
  - 0.597213078861718
  - 0.5986553453932089
  - 0.5921669955953492
  - 0.596331810744893
  - 0.5865862304071126
  - 0.5887793385373561
  - 0.6064352508144779
  fit_time:
  - 3903.98100733757
  - 4053.5110766887665
  - 3742.0466918945312
  - 4083.607526540756
  - 4024.6307079792023
  - 3719.1572806835175
  - 3951.205063343048
  - 3943.2798528671265
  - 3657.1239285469055
  - 4112.49690079689
  - 3781.998207807541
  - 4166.690556764603
  - 3731.5349082946777
  - 4163.244517326355
  - 4124.6338901519775
  - 3718.7011086940765
  score_time:
  - 78.8212685585022
  - 91.7733223438263
  - 95.4609923362732
  - 84.39651107788086
  - 79.64708542823792
  - 98.9337797164917
  - 76.52072668075562
  - 81.65387654304504
  - 86.67988896369934
  - 88.03267288208008
  - 84.27627778053284
  - 86.6443133354187
  - 96.68385004997253
  - 79.08279967308044
  - 82.25258994102478
  - 99.67572474479675
start: 2023-10-04 21:03:39.236542
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
