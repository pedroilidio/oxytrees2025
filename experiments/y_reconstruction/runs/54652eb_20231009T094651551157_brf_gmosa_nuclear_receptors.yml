active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: y_reconstruction/runs
end: 2023-10-09 09:47:36.648442
estimator:
  call: bipartite_adaptations.estimators.brf_gmosa
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiterandomforestregressor
          - call: bipartite_learn.ensemble._forest.BipartiteRandomForestRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: true
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: 0.5
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: 0.5
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: brf_gmosa
  params: {}
hash: 54652eb3fa68089f85d152710bf24cb672c752c95a785896a25b3309d843dca7
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/54652eb_20231009T094651551157_brf_gmosa_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.8307565264362734
  - 0.9918691289184893
  - 0.8293426119174225
  - 0.8334563540532164
  - 0.8935579611960993
  - 0.9299341049307925
  - 0.9920111624219454
  - 0.9446239725896957
  - 0.8666975832524833
  - 0.9552489058035312
  - 0.9992307692307691
  - 0.8409242652683587
  - 0.9040595682397032
  - 0.971268657187816
  - 0.9079529423902558
  - 0.9047666993197696
  LL_balanced_accuracy:
  - 0.6260623229461757
  - 0.7870111731843575
  - 0.6420689655172414
  - 0.7230662983425414
  - 0.7378303198887344
  - 0.5515818431911967
  - 0.7249322493224932
  - 0.5802721088435374
  - 0.7105263157894737
  - 0.6951058201058201
  - 0.7279220779220779
  - 0.7552631578947369
  - 0.8672086720867209
  - 0.6693333333333333
  - 0.7063074901445466
  - 0.8611842105263158
  LL_f1_macro:
  - 0.2862631264407069
  - 0.47664429196836383
  - 0.30739185626403676
  - 0.4161325714883826
  - 0.4116620362670149
  - 0.13947721226182452
  - 0.39429676727439866
  - 0.20074663473930143
  - 0.4041573566253639
  - 0.3608307813358429
  - 0.40945240538399
  - 0.45993031358885017
  - 0.6171875
  - 0.33688066525842936
  - 0.3965178020168759
  - 0.6006730074617048
  LL_f1_micro:
  - 0.30526315789473685
  - 0.5986842105263158
  - 0.3337612323491656
  - 0.4852374839537869
  - 0.5039473684210526
  - 0.14210526315789473
  - 0.47881899871630296
  - 0.2079589216944801
  - 0.46375
  - 0.42375
  - 0.48902439024390243
  - 0.5463414634146342
  - 0.755
  - 0.38
  - 0.4548780487804878
  - 0.7426829268292683
  LL_f1_weighted:
  - 0.3861665176344772
  - 0.7001070311262487
  - 0.42379877306088853
  - 0.588636998500903
  - 0.6195339804545151
  - 0.18290262468736526
  - 0.5967434865699563
  - 0.26809380076671313
  - 0.5647983952874263
  - 0.5393107960325755
  - 0.5997907080389301
  - 0.644344352851194
  - 0.8112734374999999
  - 0.4848391668226424
  - 0.5571801284014076
  - 0.8039591906054563
  LL_matthews_corrcoef:
  - 0.15294773088138494
  - 0.26901594652525895
  - 0.1636380048827079
  - 0.23196950806161984
  - 0.21599932566169447
  - 0.07049772632476893
  - 0.2031323195587458
  - 0.10337676620776705
  - 0.22562347707654548
  - 0.18438719575673904
  - 0.22044831135465995
  - 0.266282618187027
  - 0.42010461662530785
  - 0.1761063060013213
  - 0.2193427292607583
  - 0.3999174511830288
  LL_precision_macro:
  - 0.5463917525773196
  - 0.5630372492836676
  - 0.5471204188481675
  - 0.5603070175438597
  - 0.5490430622009569
  - 0.5240875912408759
  - 0.5458612975391499
  - 0.5332829046898638
  - 0.5604508196721312
  - 0.5435643564356436
  - 0.5533049040511727
  - 0.5694444444444444
  - 0.6201550387596899
  - 0.5457875457875457
  - 0.558300395256917
  - 0.6107011070110702
  LL_precision_micro:
  - 0.30526315789473685
  - 0.5986842105263158
  - 0.3337612323491656
  - 0.4852374839537869
  - 0.5039473684210526
  - 0.14210526315789473
  - 0.47881899871630296
  - 0.2079589216944801
  - 0.46375
  - 0.42375
  - 0.48902439024390243
  - 0.5463414634146342
  - 0.755
  - 0.38
  - 0.4548780487804878
  - 0.7426829268292683
  LL_precision_weighted:
  - 0.9355398806294086
  - 0.9494043130749509
  - 0.9372131004308115
  - 0.9379124158277594
  - 0.9513441198690507
  - 0.9586707645024971
  - 0.9521959260567526
  - 0.9472771445606009
  - 0.9351664959016394
  - 0.9497920792079207
  - 0.9455249882989235
  - 0.9369918699186992
  - 0.941124031007752
  - 0.9432234432234432
  - 0.9364383495613613
  - 0.943029430294303
  LL_recall_macro:
  - 0.6260623229461757
  - 0.7870111731843575
  - 0.6420689655172414
  - 0.7230662983425414
  - 0.7378303198887344
  - 0.5515818431911967
  - 0.7249322493224932
  - 0.5802721088435374
  - 0.7105263157894737
  - 0.6951058201058201
  - 0.7279220779220779
  - 0.7552631578947369
  - 0.8672086720867209
  - 0.6693333333333333
  - 0.7063074901445466
  - 0.8611842105263158
  LL_recall_micro:
  - 0.30526315789473685
  - 0.5986842105263158
  - 0.3337612323491656
  - 0.4852374839537869
  - 0.5039473684210526
  - 0.14210526315789473
  - 0.47881899871630296
  - 0.2079589216944801
  - 0.46375
  - 0.42375
  - 0.48902439024390243
  - 0.5463414634146342
  - 0.755
  - 0.38
  - 0.4548780487804878
  - 0.7426829268292683
  LL_recall_weighted:
  - 0.30526315789473685
  - 0.5986842105263158
  - 0.3337612323491656
  - 0.4852374839537869
  - 0.5039473684210526
  - 0.14210526315789473
  - 0.47881899871630296
  - 0.2079589216944801
  - 0.46375
  - 0.42375
  - 0.48902439024390243
  - 0.5463414634146342
  - 0.755
  - 0.38
  - 0.4548780487804878
  - 0.7426829268292683
  LL_roc_auc:
  - 0.9855078165984681
  - 0.9994921279837481
  - 0.9878416347381864
  - 0.9891637368156705
  - 0.9949116320092268
  - 0.9967070984952691
  - 0.9995373124462953
  - 0.996413110698825
  - 0.992977881470299
  - 0.99750481000481
  - 0.999948051948052
  - 0.9927850877192983
  - 0.9951372497595943
  - 0.9978133333333333
  - 0.9920933651083542
  - 0.9958881578947368
  LT_average_precision:
  - 0.2894127661532529
  - 0.34476893964305516
  - 0.23455724992707477
  - 0.3045531167099191
  - 0.27199539747068013
  - 0.23780788215671725
  - 0.13762093082206242
  - 0.18865334790101113
  - 0.3341546377947692
  - 0.39769807489307873
  - 0.28025389205616097
  - 0.364622824241699
  - 0.31667813436447917
  - 0.4029635404734847
  - 0.30272129373675866
  - 0.32642295545079464
  LT_balanced_accuracy:
  - 0.599601593625498
  - 0.7415767634854772
  - 0.508764367816092
  - 0.658185162477008
  - 0.6574803149606299
  - 0.540650406504065
  - 0.6468085106382979
  - 0.5546218487394958
  - 0.6299751243781094
  - 0.7048016395842482
  - 0.6506276150627615
  - 0.7617743702081051
  - 0.7559748427672957
  - 0.6818181818181819
  - 0.5787419651056014
  - 0.7759622367465504
  LT_f1_macro:
  - 0.23104802174569616
  - 0.5465909090909091
  - 0.18788930194134654
  - 0.391812865497076
  - 0.300127018689893
  - 0.15037593984962405
  - 0.2901315789473684
  - 0.13761528326745717
  - 0.31012402733891065
  - 0.442616933263684
  - 0.3319897229188141
  - 0.4651226909291425
  - 0.4969683359532899
  - 0.3922480620155039
  - 0.28618537094127205
  - 0.5627696132192732
  LT_f1_micro:
  - 0.24436090225563908
  - 0.6616541353383458
  - 0.19433198380566802
  - 0.4817813765182186
  - 0.3458646616541353
  - 0.15037593984962405
  - 0.32793522267206476
  - 0.1417004048582996
  - 0.3678571428571429
  - 0.49642857142857144
  - 0.35769230769230775
  - 0.6269230769230769
  - 0.6571428571428571
  - 0.425
  - 0.31153846153846154
  - 0.7346153846153847
  LT_f1_weighted:
  - 0.32081487318416846
  - 0.7320659603554341
  - 0.2514375730576082
  - 0.5992139593247626
  - 0.46289921865087325
  - 0.15037593984962402
  - 0.43803004474749613
  - 0.192644274108805
  - 0.4925891825570273
  - 0.5824034875770697
  - 0.4418556735192376
  - 0.7344128438421242
  - 0.7504090340380482
  - 0.5061240310077519
  - 0.40208521367128086
  - 0.8010343023942498
  LT_matthews_corrcoef:
  - 0.11761613269534098
  - 0.287523422132863
  - 0.01173085599777649
  - 0.14732787566709932
  - 0.14254837999809497
  - 0.08130081300813008
  - 0.14069259372390314
  - 0.06669961288398127
  - 0.1117856302848732
  - 0.24609290776330367
  - 0.18344168057885768
  - 0.2144568102433286
  - 0.2372361714195673
  - 0.22852652225356151
  - 0.09140377325940743
  - 0.29561468440591315
  LT_precision_macro:
  - 0.5347222222222222
  - 0.585552224769294
  - 0.5039253539253539
  - 0.5343039489429597
  - 0.532258064516129
  - 0.540650406504065
  - 0.5337078651685393
  - 0.5203619909502263
  - 0.5240354206198609
  - 0.5739272880997675
  - 0.5558510638297872
  - 0.5439230580740015
  - 0.5549673167305926
  - 0.5718085106382979
  - 0.5265254040677442
  - 0.5791666666666666
  LT_precision_micro:
  - 0.24436090225563908
  - 0.6616541353383458
  - 0.19433198380566802
  - 0.4817813765182186
  - 0.3458646616541353
  - 0.15037593984962405
  - 0.32793522267206476
  - 0.1417004048582996
  - 0.3678571428571429
  - 0.49642857142857144
  - 0.3576923076923077
  - 0.6269230769230769
  - 0.6571428571428571
  - 0.425
  - 0.31153846153846154
  - 0.7346153846153847
  LT_precision_weighted:
  - 0.9475250626566416
  - 0.9016678532868937
  - 0.8922592343644975
  - 0.9309399269091079
  - 0.9577977201067185
  - 0.930924873158506
  - 0.9546922622026112
  - 0.9650466228222836
  - 0.949372006867263
  - 0.9107486336322733
  - 0.9282528641571195
  - 0.9554648182006673
  - 0.9419958788982614
  - 0.9174202127659575
  - 0.9087244130086911
  - 0.9304807692307692
  LT_recall_macro:
  - 0.599601593625498
  - 0.7415767634854772
  - 0.508764367816092
  - 0.658185162477008
  - 0.6574803149606299
  - 0.540650406504065
  - 0.6468085106382979
  - 0.5546218487394958
  - 0.6299751243781094
  - 0.7048016395842482
  - 0.6506276150627615
  - 0.7617743702081051
  - 0.7559748427672957
  - 0.6818181818181819
  - 0.5787419651056014
  - 0.7759622367465504
  LT_recall_micro:
  - 0.24436090225563908
  - 0.6616541353383458
  - 0.19433198380566802
  - 0.4817813765182186
  - 0.3458646616541353
  - 0.15037593984962405
  - 0.32793522267206476
  - 0.1417004048582996
  - 0.3678571428571429
  - 0.49642857142857144
  - 0.3576923076923077
  - 0.6269230769230769
  - 0.6571428571428571
  - 0.425
  - 0.31153846153846154
  - 0.7346153846153847
  LT_recall_weighted:
  - 0.24436090225563908
  - 0.6616541353383458
  - 0.19433198380566802
  - 0.4817813765182186
  - 0.3458646616541353
  - 0.15037593984962405
  - 0.32793522267206476
  - 0.1417004048582996
  - 0.3678571428571429
  - 0.49642857142857144
  - 0.3576923076923077
  - 0.6269230769230769
  - 0.6571428571428571
  - 0.425
  - 0.31153846153846154
  - 0.7346153846153847
  LT_roc_auc:
  - 0.7662682602921647
  - 0.8381742738589212
  - 0.6772988505747127
  - 0.786020846106683
  - 0.8254593175853018
  - 0.6715447154471545
  - 0.6773049645390071
  - 0.742296918767507
  - 0.8056592039800995
  - 0.8088127653345044
  - 0.7485554891412631
  - 0.882073749543629
  - 0.820125786163522
  - 0.850387937344459
  - 0.7761707988980716
  - 0.8363592350520455
  TL_average_precision:
  - 0.38007895252611335
  - 0.39690228369527014
  - 0.5226067455319716
  - 0.4649930281462349
  - 0.39871456284125306
  - 0.2423504544473246
  - 0.38777953253978414
  - 0.3892555462660079
  - 0.06424393758684721
  - 0.12502016099245755
  - 0.13710297679335076
  - 0.15723224967559385
  - 0.2881862492020011
  - 0.3161943010502629
  - 0.31452215627422736
  - 0.2571114426565954
  TL_balanced_accuracy:
  - 0.6412213740458015
  - 0.6439066551426103
  - 0.6666666666666666
  - 0.5860181743081372
  - 0.624044565358207
  - 0.5533854166666667
  - 0.603062678062678
  - 0.5068163592622293
  - 0.5859030837004405
  - 0.5672653337851576
  - 0.6103801169590644
  - 0.6587982832618026
  - 0.6456521739130434
  - 0.5895156345800122
  - 0.6343178621659634
  - 0.5931000330141961
  TL_f1_macro:
  - 0.30059523809523814
  - 0.4389982110912344
  - 0.31666666666666665
  - 0.378954812248073
  - 0.4445402794548905
  - 0.21560601215222253
  - 0.41938255182352285
  - 0.24559558886457275
  - 0.2073642049047853
  - 0.23273657289002558
  - 0.3007534246575343
  - 0.31131261554714323
  - 0.43162674869991946
  - 0.27780616590018736
  - 0.3231707317073171
  - 0.4246062685170746
  TL_f1_micro:
  - 0.32857142857142857
  - 0.6
  - 0.36585365853658536
  - 0.46689895470383275
  - 0.5071428571428571
  - 0.21785714285714286
  - 0.4912891986062718
  - 0.2508710801393728
  - 0.21666666666666667
  - 0.25
  - 0.3252032520325203
  - 0.35365853658536583
  - 0.5958333333333333
  - 0.3375
  - 0.3983739837398374
  - 0.573170731707317
  TL_f1_weighted:
  - 0.4224914965986395
  - 0.7116279069767442
  - 0.4821138211382114
  - 0.5833435136961814
  - 0.5897249809014515
  - 0.25042350038832284
  - 0.5852662023223395
  - 0.2959325681116233
  - 0.2839306209448855
  - 0.3353580562659847
  - 0.41237220180420986
  - 0.4640356094554871
  - 0.7116689860592301
  - 0.47332510077783463
  - 0.5322724568709102
  - 0.6860797237319012
  TL_matthews_corrcoef:
  - 0.1570969873214629
  - 0.12278673416404846
  - 0.15430334996209188
  - 0.08404935757278419
  - 0.1565912180328226
  - 0.08632516379547775
  - 0.12105881768178521
  - 0.010588768568382917
  - 0.10541272063984403
  - 0.07554246958157712
  - 0.1310384781465518
  - 0.1549335072082662
  - 0.11790787101668417
  - 0.06476302870661209
  - 0.10446544268902366
  - 0.08394175528101229
  TL_precision_macro:
  - 0.5436893203883495
  - 0.5261915998112318
  - 0.5357142857142857
  - 0.5205314009661836
  - 0.5494193548387096
  - 0.5348973295031386
  - 0.5355493317610063
  - 0.5041122399612966
  - 0.5323383084577115
  - 0.521209530932792
  - 0.5388907967032968
  - 0.5377906976744186
  - 0.5238620984400598
  - 0.5117137355584082
  - 0.5203119461183977
  - 0.5189210950080515
  TL_precision_micro:
  - 0.32857142857142857
  - 0.6
  - 0.36585365853658536
  - 0.46689895470383275
  - 0.5071428571428571
  - 0.21785714285714286
  - 0.4912891986062718
  - 0.2508710801393728
  - 0.21666666666666667
  - 0.25
  - 0.3252032520325203
  - 0.35365853658536583
  - 0.5958333333333333
  - 0.3375
  - 0.3983739837398374
  - 0.573170731707317
  TL_precision_weighted:
  - 0.9413314840499307
  - 0.9337423312883436
  - 0.9547038327526133
  - 0.9051526584476137
  - 0.8566285714285714
  - 0.8990226923836881
  - 0.868214203536914
  - 0.8245112764210786
  - 0.9493366500829187
  - 0.9299337536061546
  - 0.919182189761458
  - 0.9511486103233125
  - 0.9405376688748012
  - 0.9591262836970474
  - 0.954715937092019
  - 0.9167517641359988
  TL_recall_macro:
  - 0.6412213740458015
  - 0.6439066551426103
  - 0.6666666666666666
  - 0.5860181743081372
  - 0.624044565358207
  - 0.5533854166666667
  - 0.603062678062678
  - 0.5068163592622293
  - 0.5859030837004405
  - 0.5672653337851576
  - 0.6103801169590644
  - 0.6587982832618026
  - 0.6456521739130434
  - 0.5895156345800122
  - 0.6343178621659634
  - 0.5931000330141961
  TL_recall_micro:
  - 0.32857142857142857
  - 0.6
  - 0.36585365853658536
  - 0.46689895470383275
  - 0.5071428571428571
  - 0.21785714285714286
  - 0.4912891986062718
  - 0.2508710801393728
  - 0.21666666666666667
  - 0.25
  - 0.3252032520325203
  - 0.35365853658536583
  - 0.5958333333333333
  - 0.3375
  - 0.3983739837398374
  - 0.573170731707317
  TL_recall_weighted:
  - 0.32857142857142857
  - 0.6
  - 0.36585365853658536
  - 0.46689895470383275
  - 0.5071428571428571
  - 0.21785714285714286
  - 0.4912891986062718
  - 0.2508710801393728
  - 0.21666666666666667
  - 0.25
  - 0.3252032520325203
  - 0.35365853658536583
  - 0.5958333333333333
  - 0.3375
  - 0.3983739837398374
  - 0.573170731707317
  TL_roc_auc:
  - 0.8141433418150975
  - 0.8026505329876116
  - 0.8356881214024071
  - 0.776435357290376
  - 0.7226324653452519
  - 0.6678059895833333
  - 0.7205128205128205
  - 0.6746859128575247
  - 0.5743815655709928
  - 0.4767875296509658
  - 0.5589668615984406
  - 0.6348629910861671
  - 0.6815217391304348
  - 0.6134273451870018
  - 0.6772151898734177
  - 0.623473093430175
  TT_average_precision:
  - 0.05897435897435897
  - 0.2778856809681669
  - 0.09080055016200517
  - 0.4714285714285714
  - 0.13390804597701148
  - 0.21673141713883975
  - 0.3458747917029651
  - 0.2034603315739044
  - 0.11649470899470898
  - 0.10339600250982806
  - 0.02040816326530612
  - 0.3197181583053649
  - 0.053902514794020265
  - 0.09872542430681966
  - 0.05296846011131725
  - -0.0
  TT_balanced_accuracy:
  - 0.6105263157894737
  - 0.7194444444444444
  - 0.5892857142857143
  - 0.7840909090909092
  - 0.6847826086956521
  - 0.5352941176470588
  - 0.554320987654321
  - 0.509789156626506
  - 0.5833333333333334
  - 0.6025641025641025
  - 0.5974025974025974
  - 0.6597222222222222
  - 0.7530864197530864
  - 0.576923076923077
  - 0.6216216216216216
  - 0.6025641025641025
  TT_f1_macro:
  - 0.2185344827586207
  - 0.5454545454545454
  - 0.23585250091274187
  - 0.4305006587615283
  - 0.3555555555555555
  - 0.18974358974358974
  - 0.33958958958958957
  - 0.20639534883720928
  - 0.2207792207792208
  - 0.2512938470385279
  - 0.17866847826086957
  - 0.34046591889559963
  - 0.4012829650748396
  - 0.3185096153846154
  - 0.25815217391304346
  - 0.37599999999999995
  TT_f1_micro:
  - 0.24489795918367346
  - 0.6938775510204082
  - 0.24175824175824176
  - 0.5824175824175825
  - 0.40816326530612246
  - 0.19387755102040816
  - 0.3626373626373626
  - 0.20879120879120883
  - 0.2261904761904762
  - 0.2619047619047619
  - 0.20512820512820512
  - 0.37179487179487186
  - 0.5238095238095238
  - 0.35714285714285715
  - 0.28205128205128205
  - 0.6025641025641025
  TT_f1_weighted:
  - 0.3532811400422238
  - 0.7627882321759873
  - 0.29269525655067824
  - 0.7052440313309878
  - 0.517136378360868
  - 0.14722284518202886
  - 0.43584793584793574
  - 0.2423332481472016
  - 0.2764378478664193
  - 0.32769243407541276
  - 0.3223069955406912
  - 0.4620959713280679
  - 0.6527848487934018
  - 0.4575892857142857
  - 0.37764771460423635
  - 0.7519999999999999
  TT_matthews_corrcoef:
  - 0.0928032337334619
  - 0.25245930882892614
  - 0.12824729401064425
  - 0.20389771793513883
  - 0.18613634553851857
  - 0.09987204089448493
  - 0.0743820757105781
  - 0.015843106263111948
  - 0.11867816581938534
  - 0.1345345587992625
  - 0.055607067440108786
  - 0.18667748886377503
  - 0.18792121793877736
  - 0.08570554069710086
  - 0.12734290799340264
  - 0.0
  TT_precision_macro:
  - 0.5194805194805194
  - 0.5726102941176471
  - 0.5460526315789473
  - 0.5365853658536586
  - 0.546875
  - 0.5706521739130435
  - 0.525462962962963
  - 0.5064102564102564
  - 0.5422535211267605
  - 0.5441176470588235
  - 0.5079365079365079
  - 0.5545454545454546
  - 0.5348837209302325
  - 0.5238726790450928
  - 0.5333333333333333
  - 0.5
  TT_precision_micro:
  - 0.24489795918367346
  - 0.6938775510204082
  - 0.24175824175824176
  - 0.5824175824175825
  - 0.40816326530612246
  - 0.19387755102040816
  - 0.3626373626373626
  - 0.2087912087912088
  - 0.2261904761904762
  - 0.2619047619047619
  - 0.20512820512820512
  - 0.3717948717948718
  - 0.5238095238095238
  - 0.35714285714285715
  - 0.28205128205128205
  - 0.6025641025641025
  TT_precision_weighted:
  - 0.9705804399681951
  - 0.9040741296518607
  - 0.930161943319838
  - 0.9694451889573841
  - 0.9445153061224489
  - 0.8860913930789707
  - 0.8379120879120879
  - 0.8498168498168498
  - 0.9346076458752515
  - 0.9348739495798319
  - 0.9873829873829874
  - 0.9314685314685315
  - 0.9667774086378736
  - 0.8990147783251232
  - 0.9521367521367521
  - 1.0
  TT_recall_macro:
  - 0.6105263157894737
  - 0.7194444444444444
  - 0.5892857142857143
  - 0.7840909090909092
  - 0.6847826086956521
  - 0.5352941176470588
  - 0.554320987654321
  - 0.509789156626506
  - 0.5833333333333334
  - 0.6025641025641025
  - 0.5974025974025974
  - 0.6597222222222222
  - 0.7530864197530864
  - 0.576923076923077
  - 0.6216216216216216
  - 0.30128205128205127
  TT_recall_micro:
  - 0.24489795918367346
  - 0.6938775510204082
  - 0.24175824175824176
  - 0.5824175824175825
  - 0.40816326530612246
  - 0.19387755102040816
  - 0.3626373626373626
  - 0.2087912087912088
  - 0.2261904761904762
  - 0.2619047619047619
  - 0.20512820512820512
  - 0.3717948717948718
  - 0.5238095238095238
  - 0.35714285714285715
  - 0.28205128205128205
  - 0.6025641025641025
  TT_recall_weighted:
  - 0.24489795918367346
  - 0.6938775510204082
  - 0.24175824175824176
  - 0.5824175824175825
  - 0.40816326530612246
  - 0.19387755102040816
  - 0.3626373626373626
  - 0.2087912087912088
  - 0.2261904761904762
  - 0.2619047619047619
  - 0.20512820512820512
  - 0.3717948717948718
  - 0.5238095238095238
  - 0.3571428571428572
  - 0.28205128205128205
  - 0.6025641025641025
  TT_roc_auc:
  - 0.6596491228070176
  - 0.75
  - 0.46938775510204084
  - 0.928030303030303
  - 0.6920289855072463
  - 0.6434389140271493
  - 0.7049382716049383
  - 0.48493975903614456
  - 0.670940170940171
  - 0.6346153846153846
  - 0.37662337662337664
  - 0.7384259259259259
  - 0.5843621399176955
  - 0.5779914529914529
  - 0.43074324324324326
  - .nan
  fit_time:
  - 26.555699110031128
  - 26.318030834197998
  - 26.65253973007202
  - 26.448060035705566
  - 26.66927146911621
  - 26.13984513282776
  - 26.576416730880737
  - 26.817399740219116
  - 29.31466817855835
  - 28.36994957923889
  - 29.304067134857178
  - 29.449333429336548
  - 28.97014570236206
  - 28.177805423736572
  - 29.13069796562195
  - 29.22203493118286
  score_time:
  - 0.330028772354126
  - 0.3679525852203369
  - 0.33878254890441895
  - 0.34035372734069824
  - 0.3459358215332031
  - 0.29970622062683105
  - 0.3536252975463867
  - 0.3051009178161621
  - 0.3112025260925293
  - 0.3207533359527588
  - 0.3282735347747803
  - 0.3135676383972168
  - 0.3249950408935547
  - 0.3529624938964844
  - 0.3384072780609131
  - 0.3888521194458008
start: 2023-10-09 09:46:51.551157
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
