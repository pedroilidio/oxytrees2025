active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: y_reconstruction/runs
end: 2023-10-05 17:17:45.963802
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 2
              keep_positives: true
        - - localmultioutputwrapper
          - call: bipartite_learn.wrappers.LocalMultiOutputWrapper
            params:
              combine_func_kwargs: null
              combine_predictions_func:
                load: numpy.mean
              independent_labels: false
              primary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              primary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_cols_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
              secondary_rows_estimator:
                call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: false
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: 1.0
                  max_leaf_nodes: null
                  max_samples: null
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 1
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  n_estimators: 50
                  n_jobs: 3
                  oob_score: false
                  random_state: 0
                  verbose: 10
                  warm_start: false
        verbose: false
  name: bxt_lmo
  params: {}
hash: ef92894b88378b954c5a0929262a5b3a60cdde06ad57af8acc23ec1553516f8d
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/ef92894_20231005T171738525459_bxt_lmo_gpcr.yml"
results:
  LL_average_precision:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_balanced_accuracy:
  - 0.9069838232736128
  - 0.899695652173913
  - 0.9127709584747976
  - 0.9007403581267217
  - 0.9431778779472955
  - 0.9386002948573411
  - 0.9429699019862954
  - 0.9347770043825728
  - 0.808088749126485
  - 0.9493190151911997
  - 0.9455838715308083
  - 0.9421798082735988
  - 0.8845327142979967
  - 0.948083204400894
  - 0.9342206955775011
  - 0.8396787626412849
  LL_f1_macro:
  - 0.5743785343364114
  - 0.5624293023306483
  - 0.5870571036507797
  - 0.5513857216344022
  - 0.6342398226339755
  - 0.6249321105154132
  - 0.6361733709826846
  - 0.6036845008273579
  - 0.459728835604091
  - 0.6781871917119434
  - 0.6663362000925008
  - 0.6406461218185417
  - 0.5479210265102379
  - 0.6687971893008093
  - 0.6302967417294889
  - 0.4787837885480305
  LL_f1_micro:
  - 0.8196002361474234
  - 0.8054313907396474
  - 0.8309859154929577
  - 0.806673373574782
  - 0.8894324028000338
  - 0.8805768744201737
  - 0.8890950493379439
  - 0.8727364185110664
  - 0.6294172218942397
  - 0.9020831576284052
  - 0.8948300581934722
  - 0.8877431254191818
  - 0.7766134397870925
  - 0.8995342648037259
  - 0.8725881570192948
  - 0.6880787037037037
  LL_f1_weighted:
  - 0.877881260611174
  - 0.8688770469143375
  - 0.8846272343705748
  - 0.8720982819293626
  - 0.9232124384015788
  - 0.9175564418621127
  - 0.9227377771385878
  - 0.9142932775916393
  - 0.7416235077270332
  - 0.9283665971055551
  - 0.9238691777462558
  - 0.921194029050893
  - 0.8484408277737193
  - 0.9273073205238855
  - 0.9107215500975753
  - 0.7911014975565877
  LL_matthews_corrcoef:
  - 0.34202242253132026
  - 0.32730052933973586
  - 0.35869892033162376
  - 0.3090573060746973
  - 0.41753844900605813
  - 0.40516710861726357
  - 0.42055252740141597
  - 0.37400334965868814
  - 0.22906475830854392
  - 0.48120102716518104
  - 0.4647840987967209
  - 0.42760319711092637
  - 0.31330914780374264
  - 0.4676686375936189
  - 0.41501091462874423
  - 0.23342604739954517
  LL_precision_macro:
  - 0.571857485988791
  - 0.5670045045045045
  - 0.577927548441449
  - 0.5595874713521772
  - 0.5983455882352942
  - 0.5935706084959816
  - 0.5998174071819842
  - 0.5804311774461028
  - 0.5425775556943577
  - 0.6288363171355499
  - 0.6212029161603888
  - 0.6033767772511849
  - 0.5638194218902242
  - 0.6220275344180225
  - 0.5991627420198848
  - 0.5401023890784983
  LL_precision_micro:
  - 0.8196002361474235
  - 0.8054313907396474
  - 0.8309859154929577
  - 0.806673373574782
  - 0.8894324028000338
  - 0.8805768744201737
  - 0.8890950493379438
  - 0.8727364185110664
  - 0.6294172218942397
  - 0.9020831576284052
  - 0.8948300581934722
  - 0.8877431254191818
  - 0.7766134397870925
  - 0.8995342648037259
  - 0.8725881570192947
  - 0.6880787037037037
  LL_precision_weighted:
  - 0.9740738529931645
  - 0.9739260534887592
  - 0.9736582934845807
  - 0.9769603103725485
  - 0.9782523292272126
  - 0.9776510109420072
  - 0.9778595107625353
  - 0.979528080589674
  - 0.9684429822516645
  - 0.974769509286603
  - 0.9745061927212608
  - 0.9767904921630891
  - 0.971487197738333
  - 0.9754808280810094
  - 0.9747309845684525
  - 0.9749824216281128
  LL_recall_macro:
  - 0.9069838232736128
  - 0.899695652173913
  - 0.9127709584747976
  - 0.9007403581267217
  - 0.9431778779472955
  - 0.9386002948573411
  - 0.9429699019862954
  - 0.9347770043825728
  - 0.808088749126485
  - 0.9493190151911997
  - 0.9455838715308083
  - 0.9421798082735988
  - 0.8845327142979967
  - 0.948083204400894
  - 0.9342206955775011
  - 0.8396787626412849
  LL_recall_micro:
  - 0.8196002361474235
  - 0.8054313907396474
  - 0.8309859154929577
  - 0.806673373574782
  - 0.8894324028000338
  - 0.8805768744201737
  - 0.8890950493379438
  - 0.8727364185110664
  - 0.6294172218942397
  - 0.9020831576284052
  - 0.8948300581934722
  - 0.8877431254191818
  - 0.7766134397870925
  - 0.8995342648037259
  - 0.8725881570192947
  - 0.6880787037037037
  LL_recall_weighted:
  - 0.8196002361474235
  - 0.8054313907396474
  - 0.8309859154929577
  - 0.806673373574782
  - 0.8894324028000338
  - 0.8805768744201737
  - 0.8890950493379438
  - 0.8727364185110664
  - 0.6294172218942397
  - 0.9020831576284052
  - 0.8948300581934722
  - 0.8877431254191818
  - 0.7766134397870925
  - 0.8995342648037259
  - 0.8725881570192947
  - 0.6880787037037037
  LL_roc_auc:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LT_average_precision:
  - 0.25280408844667046
  - 0.29143777629496115
  - 0.2725014049371826
  - 0.30744351651452234
  - 0.3307459202089562
  - 0.4197923229153736
  - 0.3084395766299668
  - 0.3299030380922325
  - 0.23969781959214598
  - 0.3451156960202832
  - 0.29242004319804765
  - 0.32391683053272874
  - 0.21424700753388642
  - 0.30918279578647556
  - 0.2408564059841143
  - 0.28309095818911456
  LT_balanced_accuracy:
  - 0.7862001579775015
  - 0.7545818179230042
  - 0.8047787800687285
  - 0.7933027383174012
  - 0.7803794314915362
  - 0.7726589347079038
  - 0.7880534271652033
  - 0.7496925529031502
  - 0.7140752654336096
  - 0.7371789334733103
  - 0.8263251546237044
  - 0.7883069126127227
  - 0.7763884537051543
  - 0.7563450205369366
  - 0.8228112035890285
  - 0.732255877034358
  LT_f1_macro:
  - 0.48532375963247976
  - 0.46805597428070256
  - 0.46801150528153335
  - 0.49294950284001426
  - 0.5124689064604893
  - 0.50587927232826
  - 0.5258967955210536
  - 0.5183047896689064
  - 0.3894603317930678
  - 0.49819257249959975
  - 0.529061967723101
  - 0.5443393018155044
  - 0.4525465740514734
  - 0.48641975308641977
  - 0.514331616219607
  - 0.43151637262819603
  LT_f1_micro:
  - 0.7165492957746479
  - 0.687374245472837
  - 0.6883802816901409
  - 0.6806658130601793
  - 0.7786720321931588
  - 0.7743963782696177
  - 0.8091046277665996
  - 0.7654289372599232
  - 0.5291750503018109
  - 0.7472334004024144
  - 0.7718812877263581
  - 0.7605633802816902
  - 0.6555059523809523
  - 0.7291666666666665
  - 0.7517361111111112
  - 0.568939393939394
  LT_f1_weighted:
  - 0.8117291881378593
  - 0.7908910949779376
  - 0.793871391928728
  - 0.7771311391455419
  - 0.8544194158257362
  - 0.8525420935094601
  - 0.8749990631898228
  - 0.8401758192270309
  - 0.6652169318360864
  - 0.8308990266275301
  - 0.8466407211003908
  - 0.8307357299103074
  - 0.7686837075471668
  - 0.8207659709974525
  - 0.8340150013235976
  - 0.6873052936511962
  LT_matthews_corrcoef:
  - 0.20159569890176654
  - 0.17674860951140334
  - 0.19864723747999397
  - 0.23903879790094557
  - 0.20789188701370867
  - 0.19636400977349186
  - 0.21741847347914584
  - 0.20760574290486497
  - 0.14107520438036097
  - 0.18140570877054701
  - 0.2583859894380994
  - 0.26660057689086497
  - 0.1819766997842691
  - 0.18236064294480372
  - 0.244664509552482
  - 0.18768611381625266
  LT_precision_macro:
  - 0.5355003523608175
  - 0.5306778300381833
  - 0.5323683336398408
  - 0.548703557312253
  - 0.5385362047210525
  - 0.5353544478339135
  - 0.5410260633549862
  - 0.5431532138083013
  - 0.5232420747565683
  - 0.5346869246486511
  - 0.5511478494623656
  - 0.5616321223053858
  - 0.5299537831812803
  - 0.532432270408048
  - 0.5463589255647129
  - 0.5379173153433662
  LT_precision_micro:
  - 0.7165492957746479
  - 0.687374245472837
  - 0.6883802816901409
  - 0.6806658130601793
  - 0.778672032193159
  - 0.7743963782696177
  - 0.8091046277665996
  - 0.7654289372599232
  - 0.5291750503018109
  - 0.7472334004024145
  - 0.7718812877263581
  - 0.7605633802816901
  - 0.6555059523809523
  - 0.7291666666666666
  - 0.7517361111111112
  - 0.568939393939394
  LT_precision_weighted:
  - 0.969879258689153
  - 0.9675213976965134
  - 0.9749089718874685
  - 0.9596717252129378
  - 0.9696839748826745
  - 0.9706454318419524
  - 0.9716798385844992
  - 0.9581970172599971
  - 0.9686898786933804
  - 0.9622938667296096
  - 0.968262555169728
  - 0.9517213199771373
  - 0.9720453992213782
  - 0.9676187854227676
  - 0.9696009431185282
  - 0.9543025480544941
  LT_recall_macro:
  - 0.7862001579775015
  - 0.7545818179230042
  - 0.8047787800687285
  - 0.7933027383174012
  - 0.7803794314915362
  - 0.7726589347079038
  - 0.7880534271652033
  - 0.7496925529031502
  - 0.7140752654336096
  - 0.7371789334733103
  - 0.8263251546237044
  - 0.7883069126127227
  - 0.7763884537051543
  - 0.7563450205369366
  - 0.8228112035890285
  - 0.732255877034358
  LT_recall_micro:
  - 0.7165492957746479
  - 0.687374245472837
  - 0.6883802816901409
  - 0.6806658130601793
  - 0.778672032193159
  - 0.7743963782696177
  - 0.8091046277665996
  - 0.7654289372599232
  - 0.5291750503018109
  - 0.7472334004024145
  - 0.7718812877263581
  - 0.7605633802816901
  - 0.6555059523809523
  - 0.7291666666666666
  - 0.7517361111111112
  - 0.568939393939394
  LT_recall_weighted:
  - 0.7165492957746479
  - 0.687374245472837
  - 0.6883802816901409
  - 0.6806658130601793
  - 0.778672032193159
  - 0.7743963782696177
  - 0.8091046277665996
  - 0.7654289372599232
  - 0.5291750503018109
  - 0.7472334004024145
  - 0.7718812877263581
  - 0.7605633802816901
  - 0.6555059523809523
  - 0.7291666666666666
  - 0.7517361111111112
  - 0.568939393939394
  LT_roc_auc:
  - 0.8770070268585908
  - 0.8050808653793685
  - 0.915807560137457
  - 0.8890823918816453
  - 0.829886937080805
  - 0.847105884879725
  - 0.8613047672290002
  - 0.8403560722824306
  - 0.8445718681164993
  - 0.7996181642203928
  - 0.8894855881060337
  - 0.8522444300359898
  - 0.8601142683691053
  - 0.8328186201559616
  - 0.8918592969176272
  - 0.8471767003214787
  TL_average_precision:
  - 0.4571402073690192
  - 0.48537302659798526
  - 0.46389391686994275
  - 0.3781977944059225
  - 0.5589860324898125
  - 0.5706228895874027
  - 0.6037982382288402
  - 0.48642723415695505
  - 0.48636871631168777
  - 0.5511745670150148
  - 0.5076349754760608
  - 0.4671609010740863
  - 0.4943088484831877
  - 0.4425311999793107
  - 0.5547726266585783
  - 0.4993470441423177
  TL_balanced_accuracy:
  - 0.7702412714806208
  - 0.7850560862954357
  - 0.782027538958683
  - 0.7632149715287876
  - 0.7594900935255594
  - 0.8036853295535081
  - 0.7800880688307403
  - 0.7392348109675082
  - 0.6932209743443642
  - 0.8560384298906796
  - 0.8267869649404689
  - 0.8017975954243026
  - 0.8308267591465028
  - 0.8359462265783553
  - 0.8479302765011965
  - 0.7758895379713223
  TL_f1_macro:
  - 0.47523184093933646
  - 0.4778636296525749
  - 0.4727525687871316
  - 0.463584483132269
  - 0.5496905141972621
  - 0.5642676214599959
  - 0.5550996510953276
  - 0.5192105519347565
  - 0.3862963616074133
  - 0.5507230131151216
  - 0.5230359145888431
  - 0.5086985292548082
  - 0.5366526933340942
  - 0.5926232781880147
  - 0.5939086886189608
  - 0.4720686915808867
  TL_f1_micro:
  - 0.6734031936127745
  - 0.6744011976047904
  - 0.6773952095808383
  - 0.6711309523809523
  - 0.7826846307385229
  - 0.7949101796407185
  - 0.7909181636726547
  - 0.7703373015873015
  - 0.5459081836327345
  - 0.8365768463073853
  - 0.7949101796407185
  - 0.7961309523809523
  - 0.8018745118458734
  - 0.8755532413434002
  - 0.8630564957042437
  - 0.6987577639751553
  TL_f1_weighted:
  - 0.7759888512086467
  - 0.7766263091992937
  - 0.7812327049295072
  - 0.778214338029994
  - 0.8456407239697551
  - 0.8550227805383006
  - 0.8524992831325324
  - 0.8432450676154598
  - 0.6859980117704185
  - 0.8931753688005671
  - 0.8664276664157657
  - 0.8699462828335807
  - 0.8687732017870758
  - 0.914090405959379
  - 0.9050597351854136
  - 0.8004634457444638
  TL_matthews_corrcoef:
  - 0.2041940928976409
  - 0.21524905623598203
  - 0.203626339733505
  - 0.18378567083267214
  - 0.24783427301430183
  - 0.28712084398104953
  - 0.26327911403055526
  - 0.20124617484159243
  - 0.1115710857929474
  - 0.27302796338959323
  - 0.236833705551881
  - 0.20210210902672512
  - 0.2567895668885733
  - 0.3112663383600968
  - 0.32366046247436936
  - 0.18607283266749616
  TL_precision_macro:
  - 0.5385722241331302
  - 0.5406342457133697
  - 0.5367549977445104
  - 0.5320813559798983
  - 0.5591755026617977
  - 0.5678649666495207
  - 0.5618697292016769
  - 0.5423224600180294
  - 0.5161060506335506
  - 0.5523428530001365
  - 0.5429103744205748
  - 0.5338349800431852
  - 0.5498303718182753
  - 0.5720998821618738
  - 0.5752708962428874
  - 0.5313740594437699
  TL_precision_micro:
  - 0.6734031936127745
  - 0.6744011976047904
  - 0.6773952095808383
  - 0.6711309523809523
  - 0.7826846307385229
  - 0.7949101796407185
  - 0.7909181636726547
  - 0.7703373015873016
  - 0.5459081836327345
  - 0.8365768463073853
  - 0.7949101796407185
  - 0.7961309523809523
  - 0.8018745118458734
  - 0.8755532413434002
  - 0.8630564957042437
  - 0.6987577639751553
  TL_precision_weighted:
  - 0.9628131028493845
  - 0.9643807424677178
  - 0.9671369142908018
  - 0.9675562863891303
  - 0.9481918653124478
  - 0.95497916097032
  - 0.9528243854415649
  - 0.9568948992348879
  - 0.9736283964370228
  - 0.9769201518951297
  - 0.97481317960057
  - 0.9774035615358491
  - 0.9719144148741565
  - 0.9712535412371763
  - 0.969490275573241
  - 0.9711759421236562
  TL_recall_macro:
  - 0.7702412714806208
  - 0.7850560862954357
  - 0.782027538958683
  - 0.7632149715287876
  - 0.7594900935255594
  - 0.8036853295535081
  - 0.7800880688307403
  - 0.7392348109675082
  - 0.6932209743443642
  - 0.8560384298906796
  - 0.8267869649404689
  - 0.8017975954243026
  - 0.8308267591465028
  - 0.8359462265783553
  - 0.8479302765011965
  - 0.7758895379713223
  TL_recall_micro:
  - 0.6734031936127745
  - 0.6744011976047904
  - 0.6773952095808383
  - 0.6711309523809523
  - 0.7826846307385229
  - 0.7949101796407185
  - 0.7909181636726547
  - 0.7703373015873016
  - 0.5459081836327345
  - 0.8365768463073853
  - 0.7949101796407185
  - 0.7961309523809523
  - 0.8018745118458734
  - 0.8755532413434002
  - 0.8630564957042437
  - 0.6987577639751553
  TL_recall_weighted:
  - 0.6734031936127745
  - 0.6744011976047904
  - 0.6773952095808383
  - 0.6711309523809523
  - 0.7826846307385229
  - 0.7949101796407185
  - 0.7909181636726547
  - 0.7703373015873016
  - 0.5459081836327345
  - 0.8365768463073853
  - 0.7949101796407185
  - 0.7961309523809523
  - 0.8018745118458734
  - 0.8755532413434002
  - 0.8630564957042437
  - 0.6987577639751553
  TL_roc_auc:
  - 0.8962178806743742
  - 0.8995744518078624
  - 0.8960918977751152
  - 0.8633781398807873
  - 0.8274984738980037
  - 0.8649470343633776
  - 0.854646772924545
  - 0.8074401346781013
  - 0.8544751165824473
  - 0.8793288817658711
  - 0.8745711970776857
  - 0.8368870212572793
  - 0.9118705988245883
  - 0.8981325613957805
  - 0.9031296289262789
  - 0.8891342516826168
  TT_average_precision:
  - 0.12466013622802027
  - 0.16991741285940473
  - 0.1727586872469691
  - 0.2084207815865108
  - 0.07308211097060635
  - 0.1012105420841174
  - 0.09991394963015172
  - 0.23936243706060373
  - 0.1348442006233371
  - 0.3018120682718781
  - 0.13475029535935515
  - 0.23680741335813052
  - 0.23359584538978675
  - 0.32774921933406354
  - 0.15862968713572367
  - 0.29682345862393605
  TT_balanced_accuracy:
  - 0.6841041760215536
  - 0.6905927256398743
  - 0.6960744106694663
  - 0.7172634720028085
  - 0.6654907975460123
  - 0.6657179415672829
  - 0.7129619415333701
  - 0.738823123778876
  - 0.6836377473363775
  - 0.7133769114042254
  - 0.7373126117452895
  - 0.723009837585052
  - 0.8168492233240434
  - 0.7827476038338659
  - 0.8509263657957244
  - 0.7661734693877551
  TT_f1_macro:
  - 0.38074325783646024
  - 0.38737765837190974
  - 0.37838541666666664
  - 0.3872040127994465
  - 0.4564804399920247
  - 0.4693937736342664
  - 0.4989103343151997
  - 0.518912098746417
  - 0.3536370707506737
  - 0.4676556366420457
  - 0.46960833472616864
  - 0.47854523330685644
  - 0.5090725348197207
  - 0.53925128333542
  - 0.5314031862745099
  - 0.4435901909892619
  TT_f1_micro:
  - 0.5238095238095238
  - 0.5364583333333334
  - 0.49255952380952384
  - 0.49166666666666664
  - 0.6800595238095238
  - 0.6912202380952381
  - 0.7306547619047619
  - 0.6916666666666667
  - 0.47693452380952384
  - 0.7336309523809524
  - 0.7470238095238095
  - 0.7166666666666667
  - 0.7461180124223603
  - 0.8136645962732918
  - 0.8229813664596275
  - 0.6173913043478261
  TT_f1_weighted:
  - 0.6633323528544619
  - 0.6742961217969119
  - 0.6261590866815476
  - 0.619513621032604
  - 0.7843272635944827
  - 0.7884767202121888
  - 0.8148332629548
  - 0.7735667462748761
  - 0.6233371213938825
  - 0.8293820660469587
  - 0.8406372619246598
  - 0.8111677736278471
  - 0.8306068474561501
  - 0.8749520766276256
  - 0.8866923467756668
  - 0.7348975733512119
  TT_matthews_corrcoef:
  - 0.11564590142367534
  - 0.11979615898154124
  - 0.1444635142301814
  - 0.17288184965968575
  - 0.11971766358225885
  - 0.13069194505020934
  - 0.17712884307079363
  - 0.23591644602505576
  - 0.10887808529879853
  - 0.13181747279999026
  - 0.137230507129393
  - 0.1612396963465999
  - 0.23668961557190035
  - 0.23289162881868644
  - 0.2459483043544367
  - 0.1894382269447041
  TT_precision_macro:
  - 0.5181608788093551
  - 0.5188243277105014
  - 0.5266094219950443
  - 0.5343915772704855
  - 0.5216512325551063
  - 0.5257672529894298
  - 0.536831260578409
  - 0.5582612862444435
  - 0.5161383452344062
  - 0.5203581610833927
  - 0.5198390342052314
  - 0.5291447228959446
  - 0.5442023918599604
  - 0.5479566493565139
  - 0.5430934907652638
  - 0.5337062535857716
  TT_precision_micro:
  - 0.5238095238095238
  - 0.5364583333333334
  - 0.49255952380952384
  - 0.49166666666666664
  - 0.6800595238095238
  - 0.6912202380952381
  - 0.7306547619047619
  - 0.6916666666666667
  - 0.47693452380952384
  - 0.7336309523809523
  - 0.7470238095238095
  - 0.7166666666666667
  - 0.7461180124223602
  - 0.8136645962732919
  - 0.8229813664596274
  - 0.6173913043478261
  TT_precision_weighted:
  - 0.9686403175728124
  - 0.9688441512051723
  - 0.9609193478307655
  - 0.958839049826456
  - 0.9569296676542013
  - 0.9495710058219304
  - 0.9517867290537281
  - 0.9321811746394246
  - 0.9737538607757602
  - 0.9735628425907069
  - 0.9784418415253425
  - 0.9634427562385465
  - 0.9697676060314072
  - 0.9664810838782782
  - 0.9794929745305309
  - 0.9667489835116866
  TT_recall_macro:
  - 0.6841041760215536
  - 0.6905927256398743
  - 0.6960744106694663
  - 0.7172634720028085
  - 0.6654907975460123
  - 0.6657179415672829
  - 0.7129619415333701
  - 0.738823123778876
  - 0.6836377473363775
  - 0.7133769114042254
  - 0.7373126117452895
  - 0.723009837585052
  - 0.8168492233240434
  - 0.7827476038338659
  - 0.8509263657957244
  - 0.7661734693877551
  TT_recall_micro:
  - 0.5238095238095238
  - 0.5364583333333334
  - 0.49255952380952384
  - 0.49166666666666664
  - 0.6800595238095238
  - 0.6912202380952381
  - 0.7306547619047619
  - 0.6916666666666667
  - 0.47693452380952384
  - 0.7336309523809523
  - 0.7470238095238095
  - 0.7166666666666667
  - 0.7461180124223602
  - 0.8136645962732919
  - 0.8229813664596274
  - 0.6173913043478261
  TT_recall_weighted:
  - 0.5238095238095238
  - 0.5364583333333333
  - 0.49255952380952384
  - 0.49166666666666664
  - 0.6800595238095237
  - 0.6912202380952381
  - 0.7306547619047619
  - 0.6916666666666667
  - 0.47693452380952384
  - 0.7336309523809523
  - 0.7470238095238095
  - 0.7166666666666667
  - 0.7461180124223602
  - 0.8136645962732919
  - 0.8229813664596274
  - 0.6173913043478261
  TT_roc_auc:
  - 0.8240682532555007
  - 0.8038392456219128
  - 0.8449449630079233
  - 0.865206834006202
  - 0.7266104294478528
  - 0.7448448957496022
  - 0.7682924907414703
  - 0.8056336262289601
  - 0.8269660071029934
  - 0.7654079607797363
  - 0.8062508595791501
  - 0.806260664405637
  - 0.8628556614168126
  - 0.8235046148384807
  - 0.8883927157561362
  - 0.8960612244897959
  fit_time:
  - 0.5521500110626221
  - 0.5174698829650879
  - 0.4423058032989502
  - 0.4556403160095215
  - 0.5513031482696533
  - 0.627373218536377
  - 0.5658881664276123
  - 0.6380984783172607
  - 0.4842207431793213
  - 0.5443522930145264
  - 0.5967803001403809
  - 0.580918550491333
  - 0.5736732482910156
  - 0.4864687919616699
  - 0.4851202964782715
  - 0.4836311340332031
  score_time:
  - 6.381093978881836
  - 6.640126943588257
  - 5.590328693389893
  - 5.795868873596191
  - 6.47469425201416
  - 6.398440361022949
  - 5.981797218322754
  - 6.647526264190674
  - 6.1058290004730225
  - 6.240174055099487
  - 6.590381622314453
  - 6.628559827804565
  - 6.280060768127441
  - 6.601122856140137
  - 6.723321437835693
  - 5.838703870773315
start: 2023-10-05 17:17:38.525459
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
