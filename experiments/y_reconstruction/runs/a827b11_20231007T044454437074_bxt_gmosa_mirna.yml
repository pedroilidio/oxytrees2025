active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: y_reconstruction/runs
end: 2023-10-07 06:51:09.270242
estimator:
  call: bipartite_adaptations.estimators.bxt_gmosa
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gmosa
  params: {}
hash: a827b1181220f4e3bc83dcda91139e958329fd612d424b9bd8e6389cd361d324
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/a827b11_20231007T044454437074_bxt_gmosa_mirna.yml"
results:
  LL_average_precision:
  - 0.9999984339268596
  - 0.999998878823544
  - 0.9999993645172165
  - 0.9999993225328674
  - 0.9999904657520979
  - 0.9999970901565969
  - 0.9999970972543565
  - 0.9999983669147764
  - 0.9999988566923425
  - 0.9999953380259436
  - 0.9999985385343862
  - 0.9999968182377547
  - 0.999997421123876
  - 0.9999905353360568
  - 0.9999946902061336
  - 0.9999944056425726
  LL_balanced_accuracy:
  - 0.7265908323287009
  - 0.7903117584082018
  - 0.7247432835085819
  - 0.731523080174791
  - 0.7252628285973279
  - 0.727024995070006
  - 0.7232309789026214
  - 0.8110612601727838
  - 0.8105298663823773
  - 0.7250937464583302
  - 0.7226545404477751
  - 0.7256605561337706
  - 0.7216775518647675
  - 0.7272030745731812
  - 0.7206313837466398
  - 0.7228683359802451
  LL_f1_macro:
  - 0.42114958737458097
  - 0.5017937192998838
  - 0.4174333439631555
  - 0.4274691643909203
  - 0.4193046662383184
  - 0.4223769561084295
  - 0.4151843782006597
  - 0.5276054690122948
  - 0.5260231315630184
  - 0.41934550798218634
  - 0.41379002541246257
  - 0.4194794831552532
  - 0.41452248419765053
  - 0.4219202408605359
  - 0.4116055816616495
  - 0.4159336916565758
  LL_f1_micro:
  - 0.4920324108427002
  - 0.610653072067863
  - 0.48800853784776616
  - 0.5012441558915918
  - 0.48949205295739834
  - 0.49312629446968226
  - 0.48504765936995803
  - 0.648971165252304
  - 0.6477669325216555
  - 0.4892860820908331
  - 0.4836882516506276
  - 0.490092617939593
  - 0.48271790001258713
  - 0.49316977720817934
  - 0.4800791843553684
  - 0.4848914134501323
  LL_f1_weighted:
  - 0.5949263232104322
  - 0.7013252871260832
  - 0.5918238874013579
  - 0.6037484413574266
  - 0.5925558673238632
  - 0.5955931028816295
  - 0.5891357419463685
  - 0.7330222260077979
  - 0.7323789648966691
  - 0.5922064156055811
  - 0.5882015819604102
  - 0.5933313903920899
  - 0.5860797210068626
  - 0.5960299873645766
  - 0.5844389431599145
  - 0.5882677932470455
  LL_matthews_corrcoef:
  - 0.23581363482163567
  - 0.3003252115689115
  - 0.2324769014988845
  - 0.24041792719122532
  - 0.2344146783817669
  - 0.2370280576014574
  - 0.23071726571410803
  - 0.3236132103336652
  - 0.3217905898733347
  - 0.23457039445715655
  - 0.22939760115780622
  - 0.23437563007829662
  - 0.23090979206223694
  - 0.23636394009594092
  - 0.22806059600043507
  - 0.23185507665955968
  LL_precision_macro:
  - 0.5613529569977533
  - 0.5776710123613816
  - 0.5601191600554086
  - 0.5624136259668885
  - 0.5609845860755109
  - 0.5618679675259934
  - 0.5596136532665283
  - 0.5841679142593084
  - 0.5833649150541942
  - 0.5611115044526259
  - 0.5590862186227222
  - 0.5608568206554839
  - 0.5601316322082451
  - 0.5614735433077103
  - 0.5589349921176681
  - 0.5603010476301749
  LL_precision_micro:
  - 0.4920324108427002
  - 0.610653072067863
  - 0.48800853784776616
  - 0.5012441558915918
  - 0.48949205295739834
  - 0.49312629446968226
  - 0.48504765936995803
  - 0.648971165252304
  - 0.6477669325216555
  - 0.48928608209083313
  - 0.4836882516506276
  - 0.490092617939593
  - 0.48271790001258713
  - 0.49316977720817934
  - 0.4800791843553684
  - 0.4848914134501323
  LL_precision_weighted:
  - 0.9376693726923594
  - 0.9395180598954341
  - 0.9384390066797343
  - 0.9377416785940361
  - 0.9377337683226962
  - 0.9372815080929408
  - 0.9386036194337869
  - 0.9409092702688221
  - 0.9412722405007792
  - 0.9375790082633517
  - 0.9389861823190981
  - 0.9379373157980849
  - 0.9377899660312964
  - 0.9376867006991011
  - 0.9387169416563441
  - 0.9378768251754888
  LL_recall_macro:
  - 0.7265908323287009
  - 0.7903117584082018
  - 0.7247432835085819
  - 0.731523080174791
  - 0.7252628285973279
  - 0.727024995070006
  - 0.7232309789026214
  - 0.8110612601727838
  - 0.8105298663823773
  - 0.7250937464583302
  - 0.7226545404477751
  - 0.7256605561337706
  - 0.7216775518647675
  - 0.7272030745731812
  - 0.7206313837466398
  - 0.7228683359802451
  LL_recall_micro:
  - 0.4920324108427002
  - 0.610653072067863
  - 0.48800853784776616
  - 0.5012441558915918
  - 0.48949205295739834
  - 0.49312629446968226
  - 0.48504765936995803
  - 0.648971165252304
  - 0.6477669325216555
  - 0.48928608209083313
  - 0.4836882516506276
  - 0.490092617939593
  - 0.48271790001258713
  - 0.49316977720817934
  - 0.4800791843553684
  - 0.4848914134501323
  LL_recall_weighted:
  - 0.4920324108427002
  - 0.610653072067863
  - 0.48800853784776616
  - 0.5012441558915918
  - 0.48949205295739834
  - 0.49312629446968226
  - 0.48504765936995803
  - 0.648971165252304
  - 0.6477669325216555
  - 0.48928608209083313
  - 0.4836882516506276
  - 0.490092617939593
  - 0.48271790001258713
  - 0.49316977720817934
  - 0.4800791843553684
  - 0.4848914134501323
  LL_roc_auc:
  - 0.9999998793268715
  - 0.9999999132907973
  - 0.9999999512801507
  - 0.9999999482230266
  - 0.9999992120260394
  - 0.9999997702882852
  - 0.9999997712305642
  - 0.9999998730592978
  - 0.9999999120967683
  - 0.999999630985525
  - 0.9999998897647191
  - 0.9999997522015545
  - 0.9999998010636137
  - 0.9999992436203474
  - 0.9999995910139492
  - 0.9999995637195739
  LT_average_precision:
  - 0.17316516151788086
  - 0.14993137255878397
  - 0.15559493821085102
  - 0.17704652150271444
  - 0.17110770369819567
  - 0.14498243006983896
  - 0.1532011666472564
  - 0.17061748884795228
  - 0.17061883360057128
  - 0.14595388762988293
  - 0.15222243578799693
  - 0.17573653802302977
  - 0.16746951483807432
  - 0.1445628195353657
  - 0.14886876785217382
  - 0.17041884676839966
  LT_balanced_accuracy:
  - 0.5675311979383596
  - 0.5919104357487822
  - 0.5624592014943587
  - 0.575248202745264
  - 0.5731819181755328
  - 0.5728642171543061
  - 0.56576010208091
  - 0.6084996605287251
  - 0.6088999878934338
  - 0.570737160358223
  - 0.5606191021176867
  - 0.5734144319430583
  - 0.5697420459803424
  - 0.5678206227412285
  - 0.5574204652860406
  - 0.5718397909079402
  LT_f1_macro:
  - 0.2889273114424056
  - 0.38562871108687297
  - 0.302943602454239
  - 0.3000291235664304
  - 0.2930879693588317
  - 0.30386778549434035
  - 0.30392677821606157
  - 0.398402573851651
  - 0.41090788967368835
  - 0.30749416053182443
  - 0.3058953560051444
  - 0.29749700663628226
  - 0.2953489446569797
  - 0.3009625008928858
  - 0.3018084653413468
  - 0.28907348332556876
  LT_f1_micro:
  - 0.3157325224632917
  - 0.4683596318211703
  - 0.3341277668200745
  - 0.3308784886454789
  - 0.32103065973172734
  - 0.3383588831097728
  - 0.3348617574596222
  - 0.48516048785544
  - 0.5083629893238434
  - 0.34444976731453597
  - 0.3387079113057761
  - 0.3281760702069585
  - 0.32532165343553243
  - 0.3346016972351492
  - 0.33349986312619767
  - 0.3159105828697785
  LT_f1_weighted:
  - 0.40748671251228025
  - 0.5799850777807605
  - 0.4286071820419119
  - 0.42630229464957037
  - 0.4138154735701968
  - 0.43758189711694173
  - 0.4289159847039709
  - 0.5948360930593345
  - 0.6169619989420706
  - 0.4456756137823997
  - 0.43451602839446973
  - 0.42391296810906254
  - 0.42040762536494425
  - 0.433227278874047
  - 0.4287063966468877
  - 0.4078784987030035
  LT_matthews_corrcoef:
  - 0.07842435444461095
  - 0.09392881393150346
  - 0.07233800018949356
  - 0.08569009560720277
  - 0.08446285938210198
  - 0.08105000386372233
  - 0.0763284477302724
  - 0.1113606110765464
  - 0.11127047887074125
  - 0.07784570624412535
  - 0.06979060527140463
  - 0.08327494246563519
  - 0.07947789171076407
  - 0.0757778983998105
  - 0.06626357457854304
  - 0.08311134900147056
  LT_precision_macro:
  - 0.5227686593671411
  - 0.5239978790621062
  - 0.5209448173616492
  - 0.5243952420698635
  - 0.5243706874350073
  - 0.5225388516574531
  - 0.5221488096450363
  - 0.5285742499997468
  - 0.5284231424346895
  - 0.5214171517133223
  - 0.5200874328965354
  - 0.5236149618648331
  - 0.522643210354656
  - 0.5211671968414455
  - 0.51911714444516
  - 0.5240378495174628
  LT_precision_micro:
  - 0.3157325224632917
  - 0.4683596318211703
  - 0.3341277668200745
  - 0.3308784886454789
  - 0.32103065973172734
  - 0.3383588831097728
  - 0.3348617574596222
  - 0.48516048785544
  - 0.5083629893238434
  - 0.34444976731453597
  - 0.3387079113057761
  - 0.3281760702069585
  - 0.32532165343553243
  - 0.3346016972351492
  - 0.33349986312619767
  - 0.3159105828697785
  LT_precision_weighted:
  - 0.9006973159595753
  - 0.8982434324549949
  - 0.8918430914276472
  - 0.9028108158256795
  - 0.9029630705780468
  - 0.9029919920216956
  - 0.8930160297016237
  - 0.9006849484811106
  - 0.899341158901568
  - 0.9018982339991699
  - 0.8904175857276927
  - 0.9033785314949038
  - 0.901625500435468
  - 0.9008781820229703
  - 0.8899649548300481
  - 0.9036824559172739
  LT_recall_macro:
  - 0.5675311979383596
  - 0.5919104357487822
  - 0.5624592014943587
  - 0.575248202745264
  - 0.5731819181755328
  - 0.5728642171543061
  - 0.56576010208091
  - 0.6084996605287251
  - 0.6088999878934338
  - 0.570737160358223
  - 0.5606191021176867
  - 0.5734144319430583
  - 0.5697420459803424
  - 0.5678206227412285
  - 0.5574204652860406
  - 0.5718397909079402
  LT_recall_micro:
  - 0.3157325224632917
  - 0.4683596318211703
  - 0.3341277668200745
  - 0.3308784886454789
  - 0.32103065973172734
  - 0.3383588831097728
  - 0.3348617574596222
  - 0.48516048785544
  - 0.5083629893238434
  - 0.34444976731453597
  - 0.3387079113057761
  - 0.3281760702069585
  - 0.32532165343553243
  - 0.3346016972351492
  - 0.33349986312619767
  - 0.3159105828697785
  LT_recall_weighted:
  - 0.3157325224632917
  - 0.4683596318211703
  - 0.3341277668200745
  - 0.330878488645479
  - 0.32103065973172734
  - 0.3383588831097728
  - 0.3348617574596222
  - 0.48516048785544
  - 0.5083629893238434
  - 0.34444976731453597
  - 0.3387079113057761
  - 0.3281760702069585
  - 0.32532165343553243
  - 0.3346016972351492
  - 0.33349986312619767
  - 0.3159105828697785
  LT_roc_auc:
  - 0.6704582779526032
  - 0.6602131176147135
  - 0.6538944089763912
  - 0.6792819753342562
  - 0.66999946353517
  - 0.6627344133829878
  - 0.6533802238165993
  - 0.6761459737647137
  - 0.6698861763370652
  - 0.661305804114917
  - 0.6491831059384835
  - 0.6758603086006865
  - 0.6670066171563944
  - 0.6578760265730577
  - 0.6427198719812746
  - 0.6732823793770298
  TL_average_precision:
  - 0.28544153525314186
  - 0.3019757038475759
  - 0.2854873778574668
  - 0.2958026300246241
  - 0.26259645799870973
  - 0.277822137001666
  - 0.25931296814663474
  - 0.27417487962994197
  - 0.3033246832758169
  - 0.29579470258547347
  - 0.29568507942171995
  - 0.295633038875287
  - 0.2939102482413466
  - 0.3062861566142217
  - 0.29689519720810986
  - 0.3082187492625382
  TL_balanced_accuracy:
  - 0.5351939434678888
  - 0.568299617531876
  - 0.534357968876028
  - 0.5424722560960239
  - 0.5372951468763144
  - 0.5403224102485824
  - 0.539103518544226
  - 0.5840705431195751
  - 0.5745914923707142
  - 0.5355842615435776
  - 0.5323859053733159
  - 0.5364530832372406
  - 0.5344375883316456
  - 0.5394559770078136
  - 0.5347216865639297
  - 0.5364865024165563
  TL_f1_macro:
  - 0.15513690981363454
  - 0.24076977374508626
  - 0.1501965935913292
  - 0.17060395505233814
  - 0.1567943083616673
  - 0.16962080032694593
  - 0.1582474461768596
  - 0.28615183235448166
  - 0.25748014594777824
  - 0.15439703289679418
  - 0.14813524885589918
  - 0.15660838146743275
  - 0.15139024627934333
  - 0.1678809519033797
  - 0.15108000690750475
  - 0.15908321847602158
  TL_f1_micro:
  - 0.15543092987062848
  - 0.2515991471215352
  - 0.15042609643559876
  - 0.17162812312066045
  - 0.15710281144364746
  - 0.17054854755819385
  - 0.15868991672850194
  - 0.31006875958799035
  - 0.271745403578201
  - 0.15454695358232337
  - 0.1482122736142029
  - 0.15684582511505588
  - 0.15151702531123754
  - 0.1685354659631187
  - 0.1512490724709374
  - 0.1594071882533421
  TL_f1_weighted:
  - 0.1686908994678175
  - 0.31865485086726764
  - 0.1622509025569933
  - 0.19566400523129127
  - 0.17065168171216427
  - 0.1934565622854534
  - 0.17487463294187203
  - 0.39843351483651357
  - 0.34563567627318764
  - 0.16403496807156662
  - 0.15508895944189005
  - 0.16873583999872732
  - 0.160289435929047
  - 0.18784860131235057
  - 0.1613846106160073
  - 0.17322620614497872
  TL_matthews_corrcoef:
  - 0.06318352050332626
  - 0.08915841672142545
  - 0.0622558075858293
  - 0.07067240026235891
  - 0.06683609680983398
  - 0.06766723773134184
  - 0.06863369556188767
  - 0.09885619835414944
  - 0.09445213620154852
  - 0.06585382957997805
  - 0.06112866579128765
  - 0.06621433210861107
  - 0.06404028559625607
  - 0.0680049274007271
  - 0.0638312533736289
  - 0.06533913959277636
  TL_precision_macro:
  - 0.5283582689933334
  - 0.5290968806251418
  - 0.528201503937475
  - 0.5293991220265707
  - 0.5299440021753237
  - 0.5283890213529021
  - 0.5301161144946216
  - 0.5290605591162152
  - 0.5299002129783721
  - 0.5304680122772669
  - 0.5288452162935499
  - 0.530068360391189
  - 0.52977239680487
  - 0.5293027223091088
  - 0.5293363407027086
  - 0.5292519348249937
  TL_precision_micro:
  - 0.15543092987062848
  - 0.2515991471215352
  - 0.15042609643559876
  - 0.17162812312066045
  - 0.15710281144364746
  - 0.17054854755819385
  - 0.15868991672850194
  - 0.31006875958799035
  - 0.271745403578201
  - 0.15454695358232337
  - 0.1482122736142029
  - 0.15684582511505588
  - 0.15151702531123754
  - 0.1685354659631187
  - 0.1512490724709374
  - 0.1594071882533421
  TL_precision_weighted:
  - 0.9181988495510034
  - 0.9134885390031544
  - 0.9209313336643956
  - 0.9190163043308605
  - 0.9201597346866021
  - 0.9164370901053805
  - 0.9224218180379309
  - 0.9105903710296349
  - 0.9115818629382796
  - 0.9184597020900911
  - 0.9181015771442241
  - 0.9185011558504073
  - 0.9191211972354644
  - 0.9153802347461951
  - 0.9202509230131038
  - 0.9168540868056506
  TL_recall_macro:
  - 0.5351939434678888
  - 0.568299617531876
  - 0.534357968876028
  - 0.5424722560960239
  - 0.5372951468763144
  - 0.5403224102485824
  - 0.539103518544226
  - 0.5840705431195751
  - 0.5745914923707142
  - 0.5355842615435776
  - 0.5323859053733159
  - 0.5364530832372406
  - 0.5344375883316456
  - 0.5394559770078136
  - 0.5347216865639297
  - 0.5364865024165563
  TL_recall_micro:
  - 0.15543092987062848
  - 0.2515991471215352
  - 0.15042609643559876
  - 0.17162812312066045
  - 0.15710281144364746
  - 0.17054854755819385
  - 0.15868991672850194
  - 0.31006875958799035
  - 0.271745403578201
  - 0.15454695358232337
  - 0.1482122736142029
  - 0.15684582511505588
  - 0.15151702531123754
  - 0.1685354659631187
  - 0.1512490724709374
  - 0.1594071882533421
  TL_recall_weighted:
  - 0.15543092987062848
  - 0.2515991471215352
  - 0.15042609643559876
  - 0.17162812312066045
  - 0.15710281144364746
  - 0.17054854755819385
  - 0.15868991672850194
  - 0.31006875958799035
  - 0.271745403578201
  - 0.15454695358232337
  - 0.1482122736142029
  - 0.15684582511505588
  - 0.15151702531123754
  - 0.1685354659631187
  - 0.1512490724709374
  - 0.1594071882533421
  TL_roc_auc:
  - 0.7142525816076185
  - 0.7232684555419207
  - 0.7196071397868264
  - 0.718988281245759
  - 0.710899739310625
  - 0.7196014632213164
  - 0.7149344836625078
  - 0.7163921784611789
  - 0.7338181919202601
  - 0.7373680372080604
  - 0.731202571796379
  - 0.7351318168775443
  - 0.7251445265800459
  - 0.730137302224146
  - 0.7260413157287321
  - 0.7282093321023669
  TT_average_precision:
  - 0.1193971884678671
  - 0.09910804078925854
  - 0.10850101045171973
  - 0.11274205298417224
  - 0.11021303876540965
  - 0.09843219902409579
  - 0.10617936036236021
  - 0.10148201107842356
  - 0.11817305374121245
  - 0.10893461972615945
  - 0.1148425256298395
  - 0.11530586240743479
  - 0.1262023301026278
  - 0.10803230907523945
  - 0.12219202754657138
  - 0.12479340101749992
  TT_balanced_accuracy:
  - 0.5080283579869056
  - 0.5299507849947159
  - 0.5064041965951197
  - 0.5118732121238653
  - 0.5064137360402182
  - 0.5136561659613075
  - 0.5035395316294192
  - 0.5429928960592006
  - 0.5407042151201567
  - 0.5086488072344153
  - 0.5073232789865134
  - 0.5088609364704499
  - 0.5088913709813655
  - 0.5081469146218773
  - 0.513641877275564
  - 0.5121175286311814
  TT_f1_macro:
  - 0.10061480011082913
  - 0.2365454442435861
  - 0.11808487170386142
  - 0.11714881672527447
  - 0.11335205463883047
  - 0.13335821619675672
  - 0.13119638668024736
  - 0.27752381275967564
  - 0.26442855289082684
  - 0.12128061811606117
  - 0.1250776713743773
  - 0.11299829816133955
  - 0.11159065574090538
  - 0.121272999060593
  - 0.13172943365670367
  - 0.11668377485359652
  TT_f1_micro:
  - 0.10162784976217812
  - 0.25055355092668524
  - 0.11856240774151222
  - 0.11737429358064048
  - 0.11369986850756081
  - 0.133362097304405
  - 0.13122534516765286
  - 0.3033565679196747
  - 0.28464003944773175
  - 0.12142504930966469
  - 0.12528763971071663
  - 0.11355904074350676
  - 0.11224112426035501
  - 0.12134286653517423
  - 0.131862261669954
  - 0.11700273836196166
  TT_f1_weighted:
  - 0.07459607100800891
  - 0.3260048136073948
  - 0.10059064399855709
  - 0.10498095238407779
  - 0.09822720258781777
  - 0.1349400501683583
  - 0.12691197331584858
  - 0.3951329925325381
  - 0.36908336974770084
  - 0.111592155132316
  - 0.11352105869787599
  - 0.0938849338424523
  - 0.09099693107350028
  - 0.11450519115415463
  - 0.12259916257979633
  - 0.10224823860601494
  TT_matthews_corrcoef:
  - 0.022010305353863457
  - 0.03736031793399052
  - 0.015289914896261796
  - 0.026872815688158143
  - 0.01501691619503074
  - 0.026932034708536903
  - 0.007354272103451291
  - 0.04995490896505611
  - 0.04914419099065198
  - 0.0190082721947403
  - 0.016345290437269646
  - 0.021718196329491547
  - 0.022218679499134475
  - 0.017394641598798735
  - 0.029662387840711464
  - 0.028108227288720304
  TT_precision_macro:
  - 0.5150856981764036
  - 0.5116507243163668
  - 0.5091261055958635
  - 0.5152054097803531
  - 0.5087900316833472
  - 0.5132785163785529
  - 0.5038200900453936
  - 0.5145110771688349
  - 0.5148335467284916
  - 0.5104440532097767
  - 0.5091205223770225
  - 0.51330784994846
  - 0.5138805848872994
  - 0.509284912460545
  - 0.5161241967406647
  - 0.5163001975353562
  TT_precision_micro:
  - 0.10162784976217812
  - 0.25055355092668524
  - 0.11856240774151222
  - 0.11737429358064048
  - 0.11369986850756081
  - 0.133362097304405
  - 0.13122534516765286
  - 0.3033565679196747
  - 0.28464003944773175
  - 0.12142504930966469
  - 0.12528763971071663
  - 0.11355904074350676
  - 0.11224112426035503
  - 0.12134286653517423
  - 0.131862261669954
  - 0.11700273836196166
  TT_precision_weighted:
  - 0.8986732743873507
  - 0.89180028035516
  - 0.8794713406422472
  - 0.8988193926989095
  - 0.88650804938835
  - 0.8950684161423471
  - 0.87144525435969
  - 0.8911008066179347
  - 0.889894543614647
  - 0.8882002232383316
  - 0.8794949790048985
  - 0.8909012010979716
  - 0.891655431499099
  - 0.8893791515465567
  - 0.8895216904760116
  - 0.8986989100536578
  TT_recall_macro:
  - 0.5080283579869056
  - 0.5299507849947159
  - 0.5064041965951197
  - 0.5118732121238653
  - 0.5064137360402182
  - 0.5136561659613075
  - 0.5035395316294192
  - 0.5429928960592006
  - 0.5407042151201567
  - 0.5086488072344153
  - 0.5073232789865134
  - 0.5088609364704499
  - 0.5088913709813655
  - 0.5081469146218773
  - 0.513641877275564
  - 0.5121175286311814
  TT_recall_micro:
  - 0.10162784976217812
  - 0.25055355092668524
  - 0.11856240774151222
  - 0.11737429358064048
  - 0.11369986850756081
  - 0.133362097304405
  - 0.13122534516765286
  - 0.3033565679196747
  - 0.28464003944773175
  - 0.12142504930966469
  - 0.12528763971071663
  - 0.11355904074350676
  - 0.11224112426035503
  - 0.12134286653517423
  - 0.131862261669954
  - 0.11700273836196166
  TT_recall_weighted:
  - 0.10162784976217812
  - 0.25055355092668524
  - 0.11856240774151222
  - 0.11737429358064048
  - 0.11369986850756081
  - 0.133362097304405
  - 0.13122534516765286
  - 0.3033565679196747
  - 0.28464003944773175
  - 0.12142504930966469
  - 0.12528763971071663
  - 0.11355904074350676
  - 0.11224112426035503
  - 0.12134286653517423
  - 0.131862261669954
  - 0.11700273836196166
  TT_roc_auc:
  - 0.6045380551371717
  - 0.5820509010102702
  - 0.582722505513427
  - 0.6039277602645383
  - 0.5824406227975311
  - 0.5803874127101377
  - 0.5718046731251664
  - 0.5845102267006592
  - 0.6083114105788643
  - 0.5958107444822132
  - 0.5998512751202703
  - 0.6067871167462594
  - 0.6052398630086642
  - 0.5848710964357459
  - 0.5982963424143627
  - 0.6126746025061284
  fit_time:
  - 6107.106750011444
  - 6434.061341762543
  - 6173.003512620926
  - 6460.337014436722
  - 5647.121669054031
  - 6042.607517719269
  - 6951.100084543228
  - 7479.858037233353
  - 7420.4427835941315
  - 6380.351393461227
  - 6427.999907016754
  - 6626.871757030487
  - 6658.030443906784
  - 6733.764829158783
  - 6603.659929990768
  - 7394.907225370407
  score_time:
  - 114.71186304092407
  - 97.65844321250916
  - 103.95337533950806
  - 108.94494676589966
  - 117.70973539352417
  - 124.10417556762695
  - 76.31141018867493
  - 92.71176195144653
  - 90.79271245002747
  - 89.24307298660278
  - 92.46660780906677
  - 85.49776411056519
  - 82.81486821174622
  - 82.25862526893616
  - 90.6182656288147
  - 84.92892074584961
start: 2023-10-07 04:44:54.437074
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
