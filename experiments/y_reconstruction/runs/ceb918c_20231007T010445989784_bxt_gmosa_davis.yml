active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/davis/binary/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  - force_download: false
    path: datasets/davis/binary/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
  name: davis
  pairwise: true
  y:
    force_download: false
    path: datasets/davis/binary/y100.txt
    read:
      call: numpy.loadtxt
      params: {}
directory: y_reconstruction/runs
end: 2023-10-07 01:06:46.641128
estimator:
  call: bipartite_adaptations.estimators.bxt_gmosa
  final_params:
    estimator:
      call: imblearn.pipeline.Pipeline
      params:
        memory: /tmp
        steps:
        - - symmetryenforcer
          - call: bipartite_learn.wrappers.MultipartiteSamplerWrapper
            params:
              ndim: 2
              samplers:
                call: bipartite_learn.preprocessing.monopartite.SymmetryEnforcer
                params:
                  sampling_strategy: auto
        - - classifierassampler
          - call: wrappers.ClassifierAsSampler
            params:
              estimator:
                call: bipartite_learn.model_selection._search.MultipartiteRandomizedSearchCV
                params:
                  cv:
                    call: bipartite_learn.model_selection._split.MultipartiteCrossValidator
                    params: {}
                  diagonal: false
                  error_score: .nan
                  estimator:
                    call: bipartite_learn.matrix_factorization._nrlmf.NRLMFClassifier
                    params:
                      alpha_cols: same
                      alpha_rows: 0.1
                      lambda_cols: same
                      lambda_rows: 0.625
                      learning_rate: 1.0
                      max_iter: 100
                      n_components_cols: same
                      n_components_rows: 10
                      n_neighbors: 5
                      positive_importance: 5.0
                      random_state: null
                      tol: 1.0e-05
                      verbose: false
                  n_iter: 100
                  n_jobs: 3
                  pairwise: true
                  param_distributions:
                    alpha_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    alpha_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_cols:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    lambda_rows:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    learning_rate:
                      call: scipy.stats._distn_infrastructure.rv_continuous_frozen
                      params: {}
                    n_components_rows:
                    - 50
                    - 100
                    n_neighbors:
                    - 3
                    - 5
                    - 10
                  pre_dispatch: 2*n_jobs
                  random_state: 0
                  refit: true
                  return_train_score: false
                  scoring: average_precision
                  train_test_combinations: null
                  verbose: 1
              keep_positives: true
        - - bipartiteextratreesregressor
          - call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
            params:
              bipartite_adapter: gmosa
              bootstrap: false
              ccp_alpha: 0.0
              criterion: squared_error
              max_col_features: null
              max_depth: null
              max_features: 1.0
              max_leaf_nodes: null
              max_row_features: null
              max_samples: null
              min_col_weight_fraction_leaf: 0.0
              min_cols_leaf: 1
              min_cols_split: 1
              min_impurity_decrease: 0.0
              min_row_weight_fraction_leaf: 0.0
              min_rows_leaf: 1
              min_rows_split: 1
              min_samples_leaf: 1
              min_samples_split: 2
              min_weight_fraction_leaf: 0.0
              n_estimators: 100
              n_jobs: 3
              oob_score: false
              prediction_weights: null
              random_state: 0
              verbose: 10
              warm_start: false
        verbose: false
  name: bxt_gmosa
  params: {}
hash: ceb918c2da283a105d4a1d098a7f3101f25006c4847a6f6ece18ff8ef2895824
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/y_reconstruction/runs/ceb918c_20231007T010445989784_bxt_gmosa_davis.yml"
results:
  LL_average_precision:
  - 0.9892008545075249
  - 0.9794642862610066
  - 0.9852670820305024
  - 0.9880613718421603
  - 0.9873860790005202
  - 0.9801801289867093
  - 0.9853518970523804
  - 0.9877233208410214
  - 0.9911033986901004
  - 0.9832083287426718
  - 0.9840549214093993
  - 0.9891051854536146
  - 0.9911480922663215
  - 0.9823117405536413
  - 0.9844690510874526
  - 0.9902053227376035
  LL_balanced_accuracy:
  - 0.8693529448118164
  - 0.7855365474339036
  - 0.9506065857885615
  - 0.963287145861685
  - 0.8826206208702156
  - 0.9378330929838861
  - 0.9297747551007675
  - 0.9497507788161994
  - 0.9256408664887343
  - 0.8746646702851082
  - 0.8453143461227536
  - 0.8661224236404271
  - 0.9384596180252154
  - 0.9609786700125471
  - 0.900824896887889
  - 0.9785772281556431
  LL_f1_macro:
  - 0.5492377099361372
  - 0.45823788144981376
  - 0.7205257726107589
  - 0.7626651927822095
  - 0.5876198126463287
  - 0.7091227935871157
  - 0.6850868598403422
  - 0.7347246624699106
  - 0.6554637834398863
  - 0.5772513401487166
  - 0.5359565131470725
  - 0.5609462437644135
  - 0.7000033523878734
  - 0.7807207608175646
  - 0.6296969163279709
  - 0.8533737433065217
  LL_f1_micro:
  - 0.7495409039748829
  - 0.5915526331378473
  - 0.9057406094968108
  - 0.9298960548074652
  - 0.7769089508915349
  - 0.8825306557668384
  - 0.8670564611386723
  - 0.9047365934325537
  - 0.8580652804928618
  - 0.7619809253006339
  - 0.706177651783605
  - 0.7452752185211434
  - 0.8831822759315207
  - 0.9263076831941236
  - 0.8125442948263644
  - 0.9594849988188047
  LL_f1_weighted:
  - 0.8247992265907026
  - 0.7013215861936142
  - 0.927185972212288
  - 0.9438623556041992
  - 0.839238486139541
  - 0.9089130242417802
  - 0.8988809947819434
  - 0.9249674488101077
  - 0.8955649473093106
  - 0.828496157233639
  - 0.7887568974897726
  - 0.8177399772601622
  - 0.910566768178361
  - 0.9394745411684193
  - 0.8613220372497885
  - 0.9645386173470902
  LL_matthews_corrcoef:
  - 0.3239287172619823
  - 0.24447801403395739
  - 0.5429843138333516
  - 0.602841839448548
  - 0.37339229073988484
  - 0.529124616190411
  - 0.49646797688252947
  - 0.5638972510592818
  - 0.4550158912320941
  - 0.3620692861887017
  - 0.3176156171284624
  - 0.34271805554215107
  - 0.5158298207890873
  - 0.6301217988991319
  - 0.42621638457980143
  - 0.7406497652985338
  LL_precision_macro:
  - 0.5710227272727273
  - 0.5523308661212829
  - 0.663575042158516
  - 0.6961085509472607
  - 0.5910966340933768
  - 0.6598627787307032
  - 0.6433776932826363
  - 0.676753507014028
  - 0.6216045483259633
  - 0.5874743326488706
  - 0.5730346721592859
  - 0.5802024527934593
  - 0.6517131755563406
  - 0.7153318077803204
  - 0.6133040935672515
  - 0.7865588052271313
  LL_precision_micro:
  - 0.749540903974883
  - 0.5915526331378473
  - 0.9057406094968108
  - 0.9298960548074652
  - 0.7769089508915349
  - 0.8825306557668384
  - 0.8670564611386723
  - 0.9047365934325537
  - 0.8580652804928618
  - 0.7619809253006339
  - 0.706177651783605
  - 0.7452752185211434
  - 0.8831822759315207
  - 0.9263076831941236
  - 0.8125442948263643
  - 0.9594849988188047
  LL_precision_weighted:
  - 0.9644234238600686
  - 0.9572511910542922
  - 0.9691630324492095
  - 0.9725040337852116
  - 0.9593543126597173
  - 0.9624420484304266
  - 0.9618777241224646
  - 0.9663237175982015
  - 0.9654801850851243
  - 0.9583588805659425
  - 0.9570815622498882
  - 0.9591408954762356
  - 0.9645544242406132
  - 0.9682634004053411
  - 0.9575210024825825
  - 0.9767801393354818
  LL_recall_macro:
  - 0.8693529448118164
  - 0.7855365474339036
  - 0.9506065857885615
  - 0.963287145861685
  - 0.8826206208702156
  - 0.9378330929838861
  - 0.9297747551007675
  - 0.9497507788161994
  - 0.9256408664887343
  - 0.8746646702851082
  - 0.8453143461227536
  - 0.8661224236404271
  - 0.9384596180252154
  - 0.9609786700125471
  - 0.900824896887889
  - 0.9785772281556431
  LL_recall_micro:
  - 0.749540903974883
  - 0.5915526331378473
  - 0.9057406094968108
  - 0.9298960548074652
  - 0.7769089508915349
  - 0.8825306557668384
  - 0.8670564611386723
  - 0.9047365934325537
  - 0.8580652804928618
  - 0.7619809253006339
  - 0.706177651783605
  - 0.7452752185211434
  - 0.8831822759315207
  - 0.9263076831941236
  - 0.8125442948263643
  - 0.9594849988188047
  LL_recall_weighted:
  - 0.749540903974883
  - 0.5915526331378473
  - 0.9057406094968108
  - 0.9298960548074652
  - 0.7769089508915349
  - 0.8825306557668384
  - 0.8670564611386723
  - 0.9047365934325537
  - 0.8580652804928618
  - 0.7619809253006339
  - 0.706177651783605
  - 0.7452752185211434
  - 0.8831822759315207
  - 0.9263076831941236
  - 0.8125442948263643
  - 0.9594849988188047
  LL_roc_auc:
  - 0.9994721322185633
  - 0.9987213318463004
  - 0.9992295639422843
  - 0.9993702332426402
  - 0.9991495432356572
  - 0.9985775138403877
  - 0.9990195412644477
  - 0.9992081858704022
  - 0.999524363043077
  - 0.9989489780406816
  - 0.9988631290870227
  - 0.9993128904168705
  - 0.9994580356549907
  - 0.9988210305116024
  - 0.9988521596090811
  - 0.9994097773849968
  LT_average_precision:
  - 0.7070989595474846
  - 0.6069445873614477
  - 0.5775386420193719
  - 0.5098708018619749
  - 0.6794466897212792
  - 0.6004910718004274
  - 0.560379675692386
  - 0.5089172876730259
  - 0.6940990592996426
  - 0.6047750990032852
  - 0.5506925603510231
  - 0.4710057620499274
  - 0.6585174241099397
  - 0.60382714709178
  - 0.598386730636147
  - 0.5301359543612243
  LT_balanced_accuracy:
  - 0.8364770695432855
  - 0.7340605917656
  - 0.8543179702048418
  - 0.8606305970149253
  - 0.8366150422081198
  - 0.8519584557201295
  - 0.849153794219369
  - 0.8621477423770507
  - 0.8637865203382913
  - 0.8075681730825316
  - 0.8020839600052941
  - 0.804892221180881
  - 0.8701904793007436
  - 0.8650912357191878
  - 0.8521228957760714
  - 0.879262071631285
  LT_f1_macro:
  - 0.5536562432191335
  - 0.42119962303342917
  - 0.6411703615438886
  - 0.6622716165216884
  - 0.5622313844663216
  - 0.6299044087298711
  - 0.6196628683583191
  - 0.6434937266596814
  - 0.6296305272606446
  - 0.5354684543393822
  - 0.4948962856107423
  - 0.5139175592260661
  - 0.6488213399503722
  - 0.6752709242791511
  - 0.580834943233454
  - 0.6916329572067277
  LT_f1_micro:
  - 0.7221338986044868
  - 0.5627980922098569
  - 0.8696969696969697
  - 0.8830659536541889
  - 0.7210740151916623
  - 0.8533827945592651
  - 0.8286987522281641
  - 0.8418894830659537
  - 0.815933580639463
  - 0.7390920332096803
  - 0.6657754010695187
  - 0.6846702317290553
  - 0.8251192368839427
  - 0.8839427662957074
  - 0.7725490196078431
  - 0.886096256684492
  LT_f1_weighted:
  - 0.7972658260060634
  - 0.6862416148025927
  - 0.9030290838635906
  - 0.9110059777974991
  - 0.7936012808923532
  - 0.8916875690342283
  - 0.8733808634953657
  - 0.880620506479078
  - 0.861778516315247
  - 0.8161843113358684
  - 0.7627098916347027
  - 0.7737697465539233
  - 0.8661719009916353
  - 0.9101991836142296
  - 0.8353083456112673
  - 0.9106715288743866
  LT_matthews_corrcoef:
  - 0.328610958737152
  - 0.1773037499989557
  - 0.3919740093032146
  - 0.4204312729502464
  - 0.3418101522884444
  - 0.3809076105144369
  - 0.37491979047188695
  - 0.4100705525818876
  - 0.4028856714053944
  - 0.27572941578810556
  - 0.25664054725115115
  - 0.2745747643645163
  - 0.4293735507741439
  - 0.4408431022526267
  - 0.3484627837729718
  - 0.47090894720500476
  LT_precision_macro:
  - 0.5802321851744036
  - 0.5335774377123408
  - 0.6084080098170089
  - 0.6225370619809395
  - 0.5867713601277615
  - 0.6030594700807467
  - 0.6006468006468006
  - 0.6160837404308162
  - 0.6115467830369541
  - 0.5617966335470359
  - 0.5545083314686884
  - 0.5618179933665008
  - 0.6245045837298672
  - 0.6330781334841462
  - 0.5862101791245269
  - 0.6461754635811001
  LT_precision_micro:
  - 0.7221338986044868
  - 0.5627980922098569
  - 0.8696969696969697
  - 0.8830659536541889
  - 0.7210740151916623
  - 0.8533827945592651
  - 0.828698752228164
  - 0.8418894830659537
  - 0.815933580639463
  - 0.7390920332096803
  - 0.6657754010695187
  - 0.6846702317290553
  - 0.8251192368839427
  - 0.8839427662957074
  - 0.7725490196078432
  - 0.886096256684492
  LT_precision_weighted:
  - 0.9505610470529134
  - 0.9601664355437679
  - 0.9589342556810778
  - 0.9585548904641057
  - 0.9467720550561991
  - 0.9569459148099114
  - 0.9526976421094068
  - 0.9514401313634044
  - 0.949355553570602
  - 0.9551351178994979
  - 0.9574968540881261
  - 0.9527817204825546
  - 0.9469093480610027
  - 0.9561604145616017
  - 0.953922718573579
  - 0.9555080791496562
  LT_recall_macro:
  - 0.8364770695432855
  - 0.7340605917656
  - 0.8543179702048418
  - 0.8606305970149253
  - 0.8366150422081198
  - 0.8519584557201295
  - 0.849153794219369
  - 0.8621477423770507
  - 0.8637865203382913
  - 0.8075681730825316
  - 0.8020839600052941
  - 0.804892221180881
  - 0.8701904793007436
  - 0.8650912357191878
  - 0.8521228957760714
  - 0.879262071631285
  LT_recall_micro:
  - 0.7221338986044868
  - 0.5627980922098569
  - 0.8696969696969697
  - 0.8830659536541889
  - 0.7210740151916623
  - 0.8533827945592651
  - 0.828698752228164
  - 0.8418894830659537
  - 0.815933580639463
  - 0.7390920332096803
  - 0.6657754010695187
  - 0.6846702317290553
  - 0.8251192368839427
  - 0.8839427662957074
  - 0.7725490196078432
  - 0.886096256684492
  LT_recall_weighted:
  - 0.7221338986044868
  - 0.5627980922098569
  - 0.8696969696969697
  - 0.8830659536541889
  - 0.7210740151916623
  - 0.8533827945592651
  - 0.828698752228164
  - 0.8418894830659537
  - 0.815933580639463
  - 0.7390920332096803
  - 0.6657754010695187
  - 0.6846702317290553
  - 0.8251192368839427
  - 0.8839427662957074
  - 0.7725490196078432
  - 0.886096256684492
  LT_roc_auc:
  - 0.9581843317426675
  - 0.9093499663670275
  - 0.9276986343885785
  - 0.922351119402985
  - 0.9513969407112309
  - 0.9229480157684193
  - 0.9204470402664799
  - 0.9336916251711073
  - 0.9505483323718469
  - 0.8991548377351266
  - 0.9221620784252385
  - 0.9250960211297605
  - 0.9502168583820478
  - 0.9146818187934816
  - 0.9491687182243123
  - 0.9387231840421528
  TL_average_precision:
  - 0.3459638717774054
  - 0.3677485230250619
  - 0.3534022005577037
  - 0.34515871021174804
  - 0.2390945163087247
  - 0.2516405961121054
  - 0.2972904723363393
  - 0.2416358142228225
  - 0.39355575383811875
  - 0.38692176477584195
  - 0.3544589158173104
  - 0.3504093966603033
  - 0.16033125816121457
  - 0.20374519191614499
  - 0.23244653886730046
  - 0.202304464343656
  TL_balanced_accuracy:
  - 0.747831307194976
  - 0.7387572975257132
  - 0.7512418690732401
  - 0.7519585226550276
  - 0.7607886061824407
  - 0.7597126476008463
  - 0.7673463083101637
  - 0.7541241890639481
  - 0.7769042883721783
  - 0.7960638946116125
  - 0.7558148157073712
  - 0.7542431638509111
  - 0.7096549532116181
  - 0.736153554731835
  - 0.7412608724301528
  - 0.7590427116742906
  TL_f1_macro:
  - 0.5619651058094945
  - 0.47846692150195413
  - 0.6288985399638403
  - 0.6537115351693736
  - 0.5332174707407695
  - 0.5822632261176964
  - 0.5744983758605439
  - 0.595115530790717
  - 0.6412563590971857
  - 0.6130721072861369
  - 0.5381851037462253
  - 0.5760327610872399
  - 0.5689711264149542
  - 0.6030315809931008
  - 0.5556652886376363
  - 0.6307469201118585
  TL_f1_micro:
  - 0.7508441443042474
  - 0.5985427403589835
  - 0.8382352941176471
  - 0.869950389794472
  - 0.7696818908832415
  - 0.8309934245601563
  - 0.8152019844082212
  - 0.8485116938341603
  - 0.8748889283810201
  - 0.8197974053669806
  - 0.7322820694542878
  - 0.7935861091424523
  - 0.8597831881997513
  - 0.870979207392927
  - 0.8113040396881643
  - 0.901842664776754
  TL_f1_weighted:
  - 0.8132074533607017
  - 0.6957152085821723
  - 0.8702852005686545
  - 0.8919621476419596
  - 0.8398241458468511
  - 0.8765347667438863
  - 0.8662912544439001
  - 0.8871595744685575
  - 0.9013340155010137
  - 0.863223288552453
  - 0.8054331259482528
  - 0.8466964614873679
  - 0.8982267558653745
  - 0.9018137601172851
  - 0.8659430159112977
  - 0.923593109137792
  TL_matthews_corrcoef:
  - 0.26871904177064054
  - 0.23800218836097373
  - 0.32556910039951853
  - 0.3518768555760977
  - 0.23203304092586716
  - 0.2730844331768615
  - 0.2726051969426548
  - 0.2813423664561776
  - 0.34831352622828976
  - 0.33837043478599405
  - 0.25212624799364114
  - 0.27433757949704884
  - 0.21977789390888738
  - 0.2757789354064722
  - 0.234709831876735
  - 0.3186006244256424
  TL_precision_macro:
  - 0.572841809442301
  - 0.5593123668382449
  - 0.6054713128885902
  - 0.6228548653419119
  - 0.5516120440128054
  - 0.5717861724606329
  - 0.5694918828970027
  - 0.5778689422037309
  - 0.6095345193702092
  - 0.5966806095078402
  - 0.5621227163403102
  - 0.5740050453907514
  - 0.557597402197161
  - 0.5805133139963641
  - 0.5570841685026587
  - 0.5979629548620915
  TL_precision_micro:
  - 0.7508441443042474
  - 0.5985427403589835
  - 0.8382352941176471
  - 0.869950389794472
  - 0.7696818908832415
  - 0.8309934245601563
  - 0.8152019844082211
  - 0.8485116938341601
  - 0.8748889283810201
  - 0.8197974053669806
  - 0.7322820694542878
  - 0.7935861091424522
  - 0.8597831881997512
  - 0.870979207392927
  - 0.8113040396881644
  - 0.9018426647767541
  TL_precision_weighted:
  - 0.9263292744307723
  - 0.9314295991660263
  - 0.9223934132361195
  - 0.9259570638341436
  - 0.9536130077324273
  - 0.9471872590225872
  - 0.9476091623158813
  - 0.9459259189188971
  - 0.9426277742869337
  - 0.9384634020566066
  - 0.9381151816860201
  - 0.9354228302962013
  - 0.9518477682284635
  - 0.9465244800827199
  - 0.9495162691205694
  - 0.9548576501395639
  TL_recall_macro:
  - 0.747831307194976
  - 0.7387572975257132
  - 0.7512418690732401
  - 0.7519585226550276
  - 0.7607886061824407
  - 0.7597126476008463
  - 0.7673463083101637
  - 0.7541241890639481
  - 0.7769042883721783
  - 0.7960638946116125
  - 0.7558148157073712
  - 0.7542431638509111
  - 0.7096549532116181
  - 0.736153554731835
  - 0.7412608724301528
  - 0.7590427116742906
  TL_recall_micro:
  - 0.7508441443042474
  - 0.5985427403589835
  - 0.8382352941176471
  - 0.869950389794472
  - 0.7696818908832415
  - 0.8309934245601563
  - 0.8152019844082211
  - 0.8485116938341601
  - 0.8748889283810201
  - 0.8197974053669806
  - 0.7322820694542878
  - 0.7935861091424522
  - 0.8597831881997512
  - 0.870979207392927
  - 0.8113040396881644
  - 0.9018426647767541
  TL_recall_weighted:
  - 0.7508441443042474
  - 0.5985427403589835
  - 0.8382352941176471
  - 0.869950389794472
  - 0.7696818908832415
  - 0.8309934245601563
  - 0.8152019844082211
  - 0.8485116938341601
  - 0.8748889283810201
  - 0.8197974053669806
  - 0.7322820694542878
  - 0.7935861091424522
  - 0.8597831881997512
  - 0.870979207392927
  - 0.8113040396881644
  - 0.9018426647767541
  TL_roc_auc:
  - 0.8300854900355774
  - 0.8569151620327633
  - 0.8425132174657431
  - 0.8338814688336054
  - 0.7974816221879605
  - 0.8200479299858182
  - 0.8122398770243159
  - 0.7979551198305734
  - 0.8487233605189044
  - 0.8521251777268375
  - 0.8305356841619381
  - 0.8301544316946594
  - 0.7501177889334493
  - 0.773119197406852
  - 0.7926726410121244
  - 0.788638992586361
  TT_average_precision:
  - 0.3533448514774962
  - 0.30446928465092254
  - 0.2474806814853853
  - 0.30118954527366804
  - 0.33370746930609063
  - 0.26049799278036373
  - 0.15593797471325746
  - 0.19776103459061078
  - 0.3217318311746915
  - 0.3256808741953179
  - 0.2670352102369333
  - 0.2776070837866536
  - 0.2768733171013408
  - 0.17408139733304956
  - 0.1248512349476916
  - 0.20158076363384836
  TT_balanced_accuracy:
  - 0.7813109296642855
  - 0.6888736263736264
  - 0.7125944661140906
  - 0.7575243553008596
  - 0.7511972658800993
  - 0.6723951434878588
  - 0.6710692168575656
  - 0.7299086346875024
  - 0.7681762024652996
  - 0.7791399229781771
  - 0.7727698405784476
  - 0.786723163841808
  - 0.7724748698074362
  - 0.7030256579082734
  - 0.625207756232687
  - 0.6716423184841225
  TT_f1_macro:
  - 0.5683953336469203
  - 0.47435309104303514
  - 0.6203949348658468
  - 0.6431386540328402
  - 0.5267488386326352
  - 0.5595788324863085
  - 0.5322700765825897
  - 0.5537021118416467
  - 0.6441500162178583
  - 0.6075267172770705
  - 0.5611733333333333
  - 0.5710586205900797
  - 0.6136047178311081
  - 0.5854048964218456
  - 0.5262985738048022
  - 0.5697058823529412
  TT_f1_micro:
  - 0.7281399046104928
  - 0.615262321144674
  - 0.8604278074866312
  - 0.8524064171122995
  - 0.7111817700052993
  - 0.8494965553789083
  - 0.8096256684491978
  - 0.818716577540107
  - 0.854266030736619
  - 0.8558558558558559
  - 0.7588235294117647
  - 0.7748663101604278
  - 0.8516163222045575
  - 0.9035506094329624
  - 0.83475935828877
  - 0.8577540106951872
  TT_f1_weighted:
  - 0.7936797068089619
  - 0.7121824876014821
  - 0.8860937299793713
  - 0.8798801178517816
  - 0.7899336923146799
  - 0.88850573298562
  - 0.8650967868225194
  - 0.8714987785501402
  - 0.8825230119994869
  - 0.8925840828808329
  - 0.8229220392156863
  - 0.8351073727875051
  - 0.8872939563510164
  - 0.9281862121343677
  - 0.8819790012415842
  - 0.8920185592953759
  TT_matthews_corrcoef:
  - 0.3096265965213198
  - 0.1860897304145224
  - 0.2866101197613854
  - 0.3445756240553428
  - 0.24442749905540967
  - 0.18920770625408212
  - 0.16602258149756866
  - 0.22336371549605796
  - 0.35188976339471745
  - 0.30961374325441343
  - 0.2805551119850105
  - 0.2951588081604688
  - 0.3151036284792257
  - 0.22781888489338709
  - 0.1256632508352349
  - 0.19925876337888457
  TT_precision_macro:
  - 0.5851981021389616
  - 0.5458367168972105
  - 0.5965986582942753
  - 0.6152632345729171
  - 0.5594600443650922
  - 0.5519149718803597
  - 0.5402812061594731
  - 0.5542512784132896
  - 0.6154338122134575
  - 0.5858536007580544
  - 0.5721406467573573
  - 0.5759606591140068
  - 0.5911004166649795
  - 0.5639099570576387
  - 0.5315301006215873
  - 0.5578296412183384
  TT_precision_micro:
  - 0.7281399046104928
  - 0.615262321144674
  - 0.8604278074866311
  - 0.8524064171122995
  - 0.7111817700052994
  - 0.8494965553789083
  - 0.8096256684491978
  - 0.818716577540107
  - 0.854266030736619
  - 0.8558558558558559
  - 0.7588235294117647
  - 0.7748663101604278
  - 0.8516163222045575
  - 0.9035506094329624
  - 0.83475935828877
  - 0.8577540106951872
  TT_precision_weighted:
  - 0.9270338158781184
  - 0.921190229697432
  - 0.9236037633926318
  - 0.9240831346643957
  - 0.9373033344409266
  - 0.9420275836063815
  - 0.9442978995940603
  - 0.9502617089948671
  - 0.9284848078075615
  - 0.9495861148577509
  - 0.9380214851672926
  - 0.9417893344967414
  - 0.9434900807903975
  - 0.9605656959956398
  - 0.9443774467412257
  - 0.9387424902868585
  TT_recall_macro:
  - 0.7813109296642855
  - 0.6888736263736264
  - 0.7125944661140906
  - 0.7575243553008596
  - 0.7511972658800993
  - 0.6723951434878588
  - 0.6710692168575656
  - 0.7299086346875024
  - 0.7681762024652996
  - 0.7791399229781771
  - 0.7727698405784476
  - 0.786723163841808
  - 0.7724748698074362
  - 0.7030256579082734
  - 0.625207756232687
  - 0.6716423184841225
  TT_recall_micro:
  - 0.7281399046104928
  - 0.615262321144674
  - 0.8604278074866311
  - 0.8524064171122995
  - 0.7111817700052994
  - 0.8494965553789083
  - 0.8096256684491978
  - 0.818716577540107
  - 0.854266030736619
  - 0.8558558558558559
  - 0.7588235294117647
  - 0.7748663101604278
  - 0.8516163222045575
  - 0.9035506094329624
  - 0.83475935828877
  - 0.8577540106951872
  TT_recall_weighted:
  - 0.7281399046104928
  - 0.615262321144674
  - 0.8604278074866311
  - 0.8524064171122995
  - 0.7111817700052994
  - 0.8494965553789083
  - 0.8096256684491978
  - 0.818716577540107
  - 0.854266030736619
  - 0.8558558558558559
  - 0.7588235294117647
  - 0.7748663101604278
  - 0.8516163222045575
  - 0.9035506094329624
  - 0.83475935828877
  - 0.8577540106951872
  TT_roc_auc:
  - 0.8502907595507914
  - 0.7871710901555193
  - 0.792550381927515
  - 0.8247610315186247
  - 0.8004048935521789
  - 0.7349080206033848
  - 0.7246827267104573
  - 0.7763154804312256
  - 0.8292892374792921
  - 0.8589487196811026
  - 0.797401777158289
  - 0.8648446327683617
  - 0.8055195591619232
  - 0.7118063414333038
  - 0.652256552311954
  - 0.6705114885256098
  fit_time:
  - 114.88143563270569
  - 99.67990708351135
  - 112.70085000991821
  - 115.0616819858551
  - 107.43425989151001
  - 105.75253582000732
  - 103.28317928314209
  - 109.17270851135254
  - 118.9240391254425
  - 101.9010419845581
  - 109.63084030151367
  - 116.8576328754425
  - 108.96945548057556
  - 119.3156385421753
  - 103.36947345733643
  - 108.16221308708191
  score_time:
  - 1.2051670551300049
  - 1.3622808456420898
  - 1.286224603652954
  - 1.2327079772949219
  - 1.5548069477081299
  - 1.191175937652588
  - 1.2765166759490967
  - 1.3450729846954346
  - 1.1287169456481934
  - 1.2064638137817383
  - 1.401562213897705
  - 1.104625940322876
  - 1.4185092449188232
  - 1.1368589401245117
  - 1.3531417846679688
  - 1.4100956916809082
start: 2023-10-07 01:04:45.989784
wrapper:
  call: y_reconstruction.estimators.nrlmf_y_reconstruction_wrapper
  name: nrlmf_y_reconstruction
