active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 23:27:20.412515
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_size
  params: {}
hash: ac6eb0d015f99b8f2bc6c398b914ee3c5f855c823819f9f549664fdba3bcefce
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/ac6eb0d_20231109T232719244693_ss_bxt_gso__ad_size_gpcr.yml"
results:
  LL_average_precision:
  - 0.13292219750541678
  - 0.12791295146716863
  - 0.12808467571898458
  - 0.12603828096785843
  - 0.13012411402021545
  - 0.1259381349631162
  - 0.12548957392669147
  - 0.12497407123151279
  - 0.13128101728977734
  - 0.132267461023851
  - 0.13052809978898497
  - 0.12661114730407275
  - 0.13113912124859695
  - 0.12919161676646707
  - 0.1286237990158645
  - 0.12477485083868062
  LL_balanced_accuracy:
  - .nan
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - .nan
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LL_f1_macro:
  - .nan
  - 0.5847208442674116
  - 0.5837653143612727
  - 0.5870688495533206
  - .nan
  - 0.5856492588358561
  - 0.5850966373850548
  - 0.5879130108468398
  - 0.5832018951551277
  - 0.5845640870780535
  - 0.5834040356341553
  - 0.5844570126107703
  - 0.5849046897913459
  - 0.5834786323799407
  - 0.5839119995104589
  - 0.5849495621610719
  LL_f1_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877287
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_f1_weighted:
  - .nan
  - 0.9620573306313152
  - 0.9606267694073672
  - 0.9671121516918916
  - .nan
  - 0.9653597927322017
  - 0.9651117491757567
  - 0.9693443788479165
  - 0.9565184684457021
  - 0.9572609982570296
  - 0.9575760616941908
  - 0.9630885380091844
  - 0.9588945479076647
  - 0.9590832652904875
  - 0.9602490593165409
  - 0.9656764038053118
  LL_matthews_corrcoef:
  - .nan
  - 0.3132124046895629
  - 0.31174146518670126
  - 0.31646487657500544
  - .nan
  - 0.31419512726773463
  - 0.3132085847508585
  - 0.31753943502006654
  - 0.3116447704230443
  - 0.3140383982123482
  - 0.31177719036802776
  - 0.31247201371939837
  - 0.31429780512252053
  - 0.31156273713967697
  - 0.31210792983689867
  - 0.3127981917430874
  LL_precision_macro:
  - .nan
  - 0.9864224684882836
  - 0.9859137055837564
  - 0.988231338264963
  - .nan
  - 0.9876099458728012
  - 0.9875253721244925
  - 0.9890317700453858
  - 0.9844278943805009
  - 0.9846817874069058
  - 0.9848100194634848
  - 0.9867989573698814
  - 0.9852720293724966
  - 0.9853566958698373
  - 0.9857750709160688
  - 0.9877310785045179
  LL_precision_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_precision_weighted:
  - .nan
  - 0.9736625432428543
  - 0.9727065423025402
  - 0.9770783409265276
  - .nan
  - 0.9759012036534148
  - 0.9757409151089271
  - 0.9785987102646133
  - 0.969930089376398
  - 0.9704048567021506
  - 0.9706423552353223
  - 0.9743704103598018
  - 0.9715068153079688
  - 0.971663306678258
  - 0.972446889690223
  - 0.9761295636181652
  LL_recall_macro:
  - .nan
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - .nan
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LL_recall_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_recall_weighted:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_roc_auc:
  - 0.552924791086351
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - 0.5529595015576324
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LT_average_precision:
  - 0.07131235936895594
  - 0.08529154931100295
  - 0.10012639430090764
  - 0.06100211744962603
  - 0.08484781947431215
  - 0.09844736231864509
  - 0.07289455378791992
  - 0.07126617126079549
  - 0.1246326640587656
  - 0.12421664632827728
  - 0.14075519331550343
  - 0.10911587094634427
  - 0.10160761902854837
  - 0.060280893418179916
  - 0.09957640558498866
  - 0.08069688768427805
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6072302485850868
  - 0.5578940126167549
  - 0.6164102770618558
  - 0.5219638399457114
  - 0.6014104120089429
  - 0.6007960158934709
  - 0.6033863329935216
  - 0.5796328434406566
  - 0.6268032586273208
  - 0.6085430218625346
  - 0.6127150528989935
  - 0.5783365752356253
  - 0.6246658604887982
  - 0.5736008095719983
  - 0.599968171622078
  - 0.5431225826300985
  TL_average_precision:
  - 0.15869091421392267
  - 0.08313415961057855
  - 0.08526031848183917
  - 0.05498912887287513
  - 0.1659018364198652
  - 0.1385982950892755
  - 0.1527164817313113
  - 0.13153186964787403
  - 0.07448387087702087
  - 0.14739739994732798
  - 0.11212168137663156
  - 0.11147591646495156
  - 0.16197506015063054
  - 0.16208163218563276
  - 0.19952683703410345
  - 0.11330069126326073
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6077401956565396
  - 0.5795555173040327
  - 0.5781367329547852
  - 0.5355263011843581
  - 0.5806294322900574
  - 0.6049897141925328
  - 0.5894536306185123
  - 0.5705512441116076
  - 0.5665637042479494
  - 0.5988098890166317
  - 0.6288949312679383
  - 0.6106263699207555
  - 0.6099936464234659
  - 0.6049785252426726
  - 0.6180850962816666
  - 0.5635045574257319
  TT_average_precision:
  - 0.05838928157912716
  - 0.06425568522379115
  - 0.044356474859447326
  - 0.07908850408850408
  - 0.04151785714285714
  - 0.08415090297074757
  - 0.04068191792846171
  - 0.08668831168831169
  - 0.094510582010582
  - 0.1891072027101439
  - 0.030776515151515152
  - 0.04550837759792984
  - 0.1345172812564117
  - 0.06772746499254212
  - 0.0574472049689441
  - 0.10774421230942971
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5400763358778625
  - 0.6050740907049843
  - 0.553347331813186
  - 0.5426028318998304
  - 0.4874328987730061
  - 0.5570547417116423
  - 0.5288550941612167
  - 0.5235552862262436
  - 0.6505327245053272
  - 0.6361474261701879
  - 0.5111229542016228
  - 0.571643740388869
  - 0.6194503856374359
  - 0.5451943556975507
  - 0.5683610451306413
  - 0.537795918367347
  fit_time:
  - 0.6452820301055908
  - 0.6717338562011719
  - 0.6505923271179199
  - 0.6704039573669434
  - 0.6060543060302734
  - 0.599163293838501
  - 0.6813154220581055
  - 0.5994040966033936
  - 0.754258394241333
  - 0.7638094425201416
  - 0.7092306613922119
  - 0.6938087940216064
  - 0.7352221012115479
  - 0.6872866153717041
  - 0.7514832019805908
  - 0.6616559028625488
  score_time:
  - 0.26982879638671875
  - 0.3466663360595703
  - 0.3874526023864746
  - 0.3439018726348877
  - 0.2968900203704834
  - 0.3558225631713867
  - 0.3675663471221924
  - 0.3767266273498535
  - 0.34163689613342285
  - 0.3516366481781006
  - 0.37479567527770996
  - 0.35114192962646484
  - 0.3399333953857422
  - 0.3593001365661621
  - 0.34661054611206055
  - 0.3739793300628662
start: 2023-11-09 23:27:19.244693
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
