active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-22 01:15:02.091938
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_fixed
  params: {}
hash: 28da535a16757ccf1f2b7f8e1cf28da5d4f139a46fccbd25f671fa8bc62b6dca
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/28da535_20231122T011501092329_ss_bxt_gso__md_fixed_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.5454219699575737
  - 0.5289473684210526
  - 0.5518946417534351
  - 0.5707287898237834
  - 0.5293645699614891
  - 0.5362041467304625
  - 0.5378690629011553
  - 0.5244534562570506
  - 0.5701408275174477
  - 0.5275
  - 0.5492682926829269
  - 0.5446795791487327
  - 0.554558631211857
  - 0.53125
  - 0.559570070276974
  - 0.557479674796748
  LL_balanced_accuracy:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.8257679963319577
  - .nan
  - .nan
  - .nan
  - 0.8345578231292516
  - 0.8320251854407452
  - .nan
  - .nan
  - 0.8261625380269448
  - .nan
  - .nan
  - .nan
  - 0.825136612021858
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9664470667728469
  - .nan
  - .nan
  - .nan
  - 0.9756935195130684
  - 0.9703567180846717
  - .nan
  - .nan
  - 0.9681138635375923
  - .nan
  - .nan
  - .nan
  - 0.9637978142076503
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.6964875095423532
  - .nan
  - .nan
  - .nan
  - 0.7099704764350107
  - 0.7061733064809798
  - .nan
  - .nan
  - 0.6970374326528528
  - .nan
  - .nan
  - .nan
  - 0.6956083436402524
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9850948509485095
  - .nan
  - .nan
  - .nan
  - 0.9892328398384926
  - 0.9868073878627968
  - .nan
  - .nan
  - 0.9858611825192802
  - .nan
  - .nan
  - .nan
  - 0.9838709677419355
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9719155612608756
  - .nan
  - .nan
  - .nan
  - 0.979400722533116
  - 0.9750034717400361
  - .nan
  - .nan
  - 0.9732776349614396
  - .nan
  - .nan
  - .nan
  - 0.9697580645161291
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_roc_auc:
  - 0.7662889518413599
  - 0.75
  - 0.7592592592592593
  - 0.7719487694625816
  - 0.754927236337732
  - 0.7575757575757576
  - 0.7560975609756098
  - 0.7492578849721706
  - 0.7704316201193988
  - 0.75
  - 0.76
  - 0.7572149122807017
  - 0.764511758020806
  - 0.75
  - 0.7627118644067796
  - 0.7655153508771929
  LT_average_precision:
  - 0.17215381448791056
  - 0.13898123687597372
  - 0.2052721839563945
  - 0.28739638698117553
  - 0.19149708190664455
  - 0.28998384999932986
  - 0.09621141529036266
  - 0.23953181512521038
  - 0.28542833977616583
  - 0.29181876088107184
  - 0.2571069582133463
  - 0.3125438137266348
  - 0.13509369347397515
  - 0.3399660713988199
  - 0.2134394687211589
  - 0.3415641106632934
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.697875166002656
  - 0.5009958506224066
  - 0.7044540229885057
  - 0.8030349478847333
  - 0.6860236220472442
  - 0.678760162601626
  - 0.5668439716312057
  - 0.6804388422035481
  - 0.6968283582089553
  - 0.6947738252086079
  - 0.7329149232914923
  - 0.8486673968601681
  - 0.6220125786163524
  - 0.6881862099253403
  - 0.7112029384756657
  - 0.7262164124909223
  TL_average_precision:
  - 0.28988849438410846
  - 0.3347422671890757
  - 0.39502873036249153
  - 0.2641822163701647
  - 0.26509941837515993
  - 0.2953463203463204
  - 0.2650467656971722
  - 0.2708780706257578
  - 0.07846724800166095
  - 0.12692307692307692
  - 0.1797175866495507
  - 0.050804779302853764
  - 0.1274818401937046
  - 0.2589285714285714
  - 0.3577235772357723
  - 0.1844647011081678
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6825699745547074
  - 0.6764621146643619
  - 0.7459445316588174
  - 0.657786038826931
  - 0.5620546702940795
  - 0.5861002604166666
  - 0.5954415954415954
  - 0.543103448275862
  - 0.4476448661470688
  - 0.4266350389698407
  - 0.4750243664717349
  - 0.3628260151865302
  - 0.6945652173913044
  - 0.5858369098712446
  - 0.6033755274261603
  - 0.6474083856058105
  TT_average_precision:
  - 0.046049188906331764
  - 0.22193877551020408
  - 0.09733124018838304
  - 0.0894203835380306
  - 0.17725428289338063
  - 0.16390690055286328
  - 0.34276556776556777
  - 0.1120571239105722
  - 0.12962069212069213
  - 0.09457793668319983
  - 0.01282051282051282
  - 0.18156603932466
  - 0.07195378151260504
  - 0.2976190476190476
  - 0.07341880341880341
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.4894736842105263
  - 0.5368055555555555
  - 0.4685374149659863
  - 0.6534090909090909
  - 0.7708333333333334
  - 0.5737556561085972
  - 0.6938271604938273
  - 0.5225903614457831
  - 0.6666666666666667
  - 0.6196581196581196
  - 0.2207792207792208
  - 0.6412037037037037
  - 0.6646090534979424
  - 0.5982905982905983
  - 0.589527027027027
  - .nan
  fit_time:
  - 0.6085777282714844
  - 0.5606091022491455
  - 0.673276424407959
  - 0.660132884979248
  - 0.6055192947387695
  - 0.4873473644256592
  - 0.5736880302429199
  - 0.6368801593780518
  - 0.6789088249206543
  - 0.5085766315460205
  - 0.6130084991455078
  - 0.6379420757293701
  - 0.7098135948181152
  - 0.6242012977600098
  - 0.6973888874053955
  - 0.7616622447967529
  score_time:
  - 0.186021089553833
  - 0.17565488815307617
  - 0.16091513633728027
  - 0.18483424186706543
  - 0.17891526222229004
  - 0.14889216423034668
  - 0.17057442665100098
  - 0.18433809280395508
  - 0.18831872940063477
  - 0.17630648612976074
  - 0.16405558586120605
  - 0.19101476669311523
  - 0.18450164794921875
  - 0.17270851135253906
  - 0.18841028213500977
  - 0.2005164623260498
start: 2023-11-22 01:15:01.092329
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
