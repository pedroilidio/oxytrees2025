active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-22 01:15:00.062343
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_fixed
  params: {}
hash: 0d121ac9097664e21fe69bcf071ce4ed807055730f8c539ed7f6cff802b7aa7b
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/0d121ac_20231122T011457800647_ss_bxt_gso__ad_fixed_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.5454219699575737
  - 0.5289473684210526
  - 0.5518946417534351
  - 0.5707287898237834
  - 0.5293645699614891
  - 0.5362041467304625
  - 0.5378690629011553
  - 0.5244534562570506
  - 0.5701408275174477
  - 0.5275
  - 0.5492682926829269
  - 0.5446795791487327
  - 0.554558631211857
  - 0.53125
  - 0.559570070276974
  - 0.557479674796748
  LL_balanced_accuracy:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.8257679963319577
  - .nan
  - .nan
  - .nan
  - 0.8345578231292516
  - 0.8320251854407452
  - .nan
  - .nan
  - 0.8261625380269448
  - .nan
  - .nan
  - .nan
  - 0.825136612021858
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9664470667728469
  - .nan
  - .nan
  - .nan
  - 0.9756935195130684
  - 0.9703567180846717
  - .nan
  - .nan
  - 0.9681138635375923
  - .nan
  - .nan
  - .nan
  - 0.9637978142076503
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.6964875095423532
  - .nan
  - .nan
  - .nan
  - 0.7099704764350107
  - 0.7061733064809798
  - .nan
  - .nan
  - 0.6970374326528528
  - .nan
  - .nan
  - .nan
  - 0.6956083436402524
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9850948509485095
  - .nan
  - .nan
  - .nan
  - 0.9892328398384926
  - 0.9868073878627968
  - .nan
  - .nan
  - 0.9858611825192802
  - .nan
  - .nan
  - .nan
  - 0.9838709677419355
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9719155612608756
  - .nan
  - .nan
  - .nan
  - 0.979400722533116
  - 0.9750034717400361
  - .nan
  - .nan
  - 0.9732776349614396
  - .nan
  - .nan
  - .nan
  - 0.9697580645161291
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_roc_auc:
  - 0.7662889518413599
  - 0.75
  - 0.7592592592592593
  - 0.7719487694625816
  - 0.754927236337732
  - 0.7575757575757576
  - 0.7560975609756098
  - 0.7492578849721706
  - 0.7704316201193988
  - 0.75
  - 0.76
  - 0.7572149122807017
  - 0.764511758020806
  - 0.75
  - 0.7627118644067796
  - 0.7655153508771929
  LT_average_precision:
  - 0.20443219159008633
  - 0.1825795296321612
  - 0.20686852438030254
  - 0.24164658480274148
  - 0.27596636187119244
  - 0.2746142059694691
  - 0.10273027887444364
  - 0.24638670582943029
  - 0.33205868205868205
  - 0.27321711038332147
  - 0.2405678631321899
  - 0.24656269055619706
  - 0.13948771827943843
  - 0.3334917432041151
  - 0.20788376693549113
  - 0.31816641899762105
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6779548472775564
  - 0.6166804979253112
  - 0.7304597701149425
  - 0.769773145309626
  - 0.6996391076115487
  - 0.648170731707317
  - 0.5620567375886525
  - 0.6505602240896359
  - 0.717039800995025
  - 0.6782315912750695
  - 0.7344092448694959
  - 0.8506754289886821
  - 0.6257861635220127
  - 0.6793295271556141
  - 0.6926078971533518
  - 0.7541757443718229
  TL_average_precision:
  - 0.3405027720817194
  - 0.35553477255604915
  - 0.3880711655101899
  - 0.2992206590652696
  - 0.25087557603686633
  - 0.25194354256854257
  - 0.23843944644875478
  - 0.2616816751506045
  - 0.07115384615384615
  - 0.12692307692307692
  - 0.16374296435272045
  - 0.04974202626641652
  - 0.10597947454844006
  - 0.1875
  - 0.3577235772357723
  - 0.25884783759080193
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6911577608142494
  - 0.7191011235955055
  - 0.7404500261643119
  - 0.6470466749277158
  - 0.5629615235134084
  - 0.5849609375
  - 0.5495726495726498
  - 0.5192461908580593
  - 0.4871230091494409
  - 0.46119959335818367
  - 0.513157894736842
  - 0.3560581049851436
  - 0.6291304347826088
  - 0.5971796443899449
  - 0.60056258790436
  - 0.6962693958402113
  TT_average_precision:
  - 0.07369614512471655
  - 0.24594453165881736
  - 0.0766941391941392
  - 0.10863210863210863
  - 0.213000134264232
  - 0.2053645861527635
  - 0.3037774725274725
  - 0.15057369101486748
  - 0.06643197819668409
  - 0.11207311207311207
  - 0.01282051282051282
  - 0.30128205128205127
  - 0.046031746031746035
  - 0.26190476190476186
  - 0.06267806267806267
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.6456140350877193
  - 0.6416666666666666
  - 0.4481292517006803
  - 0.731060606060606
  - 0.8007246376811595
  - 0.5153846153846153
  - 0.6790123456790124
  - 0.5587349397590361
  - 0.4401709401709402
  - 0.622863247863248
  - 0.2207792207792208
  - 0.5416666666666666
  - 0.5267489711934157
  - 0.5405982905982906
  - 0.5135135135135135
  - .nan
  fit_time:
  - 0.4931347370147705
  - 0.608283519744873
  - 0.7238705158233643
  - 0.6744630336761475
  - 0.5939958095550537
  - 0.5032594203948975
  - 0.6094553470611572
  - 0.58603835105896
  - 0.6542348861694336
  - 0.589932918548584
  - 0.6383397579193115
  - 0.6451232433319092
  - 0.6981251239776611
  - 0.5703444480895996
  - 0.6477596759796143
  - 0.7509036064147949
  score_time:
  - 0.19158267974853516
  - 0.1648850440979004
  - 0.2066967487335205
  - 0.15377402305603027
  - 0.17162394523620605
  - 0.18466973304748535
  - 0.167680025100708
  - 0.15573453903198242
  - 0.1714029312133789
  - 0.198014497756958
  - 0.16010260581970215
  - 0.16583847999572754
  - 0.20180177688598633
  - 0.20092535018920898
  - 0.17616486549377441
  - 0.21227717399597168
start: 2023-11-22 01:14:57.800647
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
