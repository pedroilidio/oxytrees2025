active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-30 14:48:58.658760
estimator:
  call: semisupervised_forests.estimators.adss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: adss_bxt_gso
  params: {}
hash: 158653d56d32c8783d657cb3aefad2c69c1154990fb6446fda2e46d1bfd94990
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/158653d_20231030T144854504396_adss_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.3873224728487886
  - 0.3576555023923445
  - 0.3795464270432178
  - 0.36749679075738123
  - 0.3521731157161196
  - 0.33329346092503986
  - 0.35301668806161746
  - 0.3510109114249037
  - 0.3784880585516178
  - 0.3556818181818182
  - 0.34268292682926826
  - 0.3603174603174603
  - 0.3645617110799439
  - 0.34375
  - 0.37081438610996276
  - 0.37302291204730226
  LL_balanced_accuracy:
  - .nan
  - 0.6590909090909091
  - .nan
  - .nan
  - .nan
  - 0.6515151515151515
  - 0.6585365853658537
  - .nan
  - .nan
  - 0.6590909090909091
  - 0.65
  - .nan
  - .nan
  - 0.65
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.7311193924241709
  - .nan
  - .nan
  - .nan
  - 0.7247720867251343
  - 0.7314322301024428
  - .nan
  - .nan
  - 0.7316516838856837
  - 0.7196581196581197
  - .nan
  - .nan
  - 0.7193685793034327
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9605263157894737
  - .nan
  - .nan
  - .nan
  - 0.969736842105263
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625000000000001
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9507226011157428
  - .nan
  - .nan
  - .nan
  - 0.9618788373999034
  - 0.9550723736054083
  - .nan
  - .nan
  - 0.9531665101301491
  - 0.9462997706900147
  - .nan
  - .nan
  - 0.9449699323477826
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.5526176822228344
  - .nan
  - .nan
  - .nan
  - 0.541975436470486
  - 0.5527051915086619
  - .nan
  - .nan
  - 0.5532065382625239
  - 0.5356832289134414
  - .nan
  - .nan
  - 0.5353729576861872
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9798927613941019
  - .nan
  - .nan
  - .nan
  - 0.9846666666666667
  - 0.9817232375979112
  - .nan
  - .nan
  - 0.9809160305343512
  - 0.9782608695652174
  - .nan
  - .nan
  - 0.9777070063694268
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9605263157894737
  - .nan
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9621137293636236
  - .nan
  - .nan
  - .nan
  - 0.9706649122807017
  - 0.9653703449223582
  - .nan
  - .nan
  - 0.9639312977099237
  - 0.9591728525980912
  - .nan
  - .nan
  - 0.9582006369426752
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.6590909090909091
  - .nan
  - .nan
  - .nan
  - 0.6515151515151515
  - 0.6585365853658537
  - .nan
  - .nan
  - 0.6590909090909091
  - 0.65
  - .nan
  - .nan
  - 0.65
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9605263157894737
  - .nan
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9605263157894737
  - .nan
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_roc_auc:
  - 0.6748504878816493
  - 0.6590909090909091
  - 0.6666666666666666
  - 0.6626067302862882
  - 0.6580447097934123
  - 0.6515151515151515
  - 0.6585365853658537
  - 0.6581014223871366
  - 0.6684622246620463
  - 0.6590909090909091
  - 0.65
  - 0.6573464912280702
  - 0.6597495410437975
  - 0.65
  - 0.6610169491525424
  - 0.6656578947368421
  LT_average_precision:
  - 0.13693687624078116
  - 0.24957586273375748
  - 0.26385620256091163
  - 0.13674433336087471
  - 0.06603155616313511
  - 0.16551796157059315
  - 0.19153536521957573
  - 0.37934151618362144
  - 0.07013068032571579
  - 0.2656124739458073
  - 0.2836021562212038
  - 0.4307119351236999
  - 0.1444313725490196
  - 0.3702101251300336
  - 0.32265355868605344
  - 0.10808606863985504
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5853917662682603
  - 0.59402489626556
  - 0.7716954022988506
  - 0.5775597792765174
  - 0.5382217847769029
  - 0.5731707317073171
  - 0.677659574468085
  - 0.784547152194211
  - 0.621113184079602
  - 0.5942028985507247
  - 0.6950587766487348
  - 0.7794815626140926
  - 0.6144654088050314
  - 0.7122676035719513
  - 0.830119375573921
  - 0.6053013798111838
  TL_average_precision:
  - 0.16358024691358025
  - 0.18877586377586378
  - 0.37651402024224323
  - 0.19899987095109045
  - 0.20610599078341013
  - 0.1625
  - 0.329944780650814
  - 0.2190954965975992
  - 0.05416666666666667
  - 0.05416666666666667
  - 0.1509581881533101
  - 0.15603502188868043
  - 0.25583333333333336
  - 0.053571428571428575
  - 0.3695315524583817
  - 0.08295809881175735
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5794105173876166
  - 0.6839527513684818
  - 0.6804029304029303
  - 0.5929368029739777
  - 0.5358207021634926
  - 0.5225423177083334
  - 0.6151709401709402
  - 0.5781208233092756
  - 0.3986784140969163
  - 0.43392070484581496
  - 0.5328947368421053
  - 0.5751072961373391
  - 0.6215217391304348
  - 0.5285101164929491
  - 0.6800281293952181
  - 0.5526576427863982
  TT_average_precision:
  - 0.030612244897959183
  - 0.25293753865182433
  - 0.10215470803706098
  - 0.03296703296703297
  - 0.06213151927437642
  - 0.230298273155416
  - 0.32706626706626707
  - 0.4632249436936937
  - 0.1562881562881563
  - 0.2904761904761905
  - 0.01282051282051282
  - 0.07521367521367522
  - 0.03571428571428571
  - 0.2976190476190476
  - 0.08141613288672112
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.41578947368421054
  - 0.6611111111111112
  - 0.6139455782312925
  - 0.38636363636363635
  - 0.5
  - 0.6203619909502263
  - 0.6641975308641975
  - 0.8644578313253012
  - 0.6837606837606838
  - 0.767094017094017
  - 0.34415584415584416
  - 0.4791666666666667
  - 0.4320987654320988
  - 0.5726495726495727
  - 0.6520270270270272
  - .nan
  fit_time:
  - 2.47413969039917
  - 2.5665955543518066
  - 1.887544870376587
  - 1.883120059967041
  - 2.543409585952759
  - 2.7613890171051025
  - 2.660734176635742
  - 2.7224643230438232
  - 2.788062810897827
  - 2.8646178245544434
  - 2.8628463745117188
  - 2.84165096282959
  - 2.714478015899658
  - 2.876295566558838
  - 2.892078399658203
  - 2.3500068187713623
  score_time:
  - 0.19336915016174316
  - 0.19853520393371582
  - 0.16348671913146973
  - 0.17350149154663086
  - 0.1634206771850586
  - 0.18723034858703613
  - 0.1640474796295166
  - 0.15544772148132324
  - 0.15734243392944336
  - 0.21563935279846191
  - 0.1824779510498047
  - 0.1714622974395752
  - 0.17008113861083984
  - 0.17339682579040527
  - 0.20670151710510254
  - 0.22317075729370117
start: 2023-10-30 14:48:54.504396
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
