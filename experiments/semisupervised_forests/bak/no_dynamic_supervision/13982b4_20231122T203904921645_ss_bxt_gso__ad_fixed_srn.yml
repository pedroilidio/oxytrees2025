active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-22 20:49:51.956277
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_fixed
  params: {}
hash: 13982b4b884ee3316a009aafbe1a747af0d9f1c5180fffc12987c94c358a4928
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/13982b4_20231122T203904921645_ss_bxt_gso__ad_fixed_srn.yml"
results:
  LL_average_precision:
  - 0.31043956043956045
  - 0.3135321585011493
  - 0.31393697904693796
  - 0.31289824492932156
  - 0.3104626920106975
  - 0.31309691275241186
  - 0.31374651818975763
  - 0.3122514757489135
  - 0.31050772523023307
  - 0.31332852192953764
  - 0.3140485358674154
  - 0.31274634668205165
  - 0.3108996636445437
  - 0.31333143351602716
  - 0.31392743184478733
  - 0.31294731263378284
  LL_balanced_accuracy:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LL_f1_macro:
  - 0.7281337930487852
  - 0.7276140047113996
  - 0.7272761330148422
  - 0.7278745634629974
  - 0.7282277202975188
  - 0.7276129923249521
  - 0.7273254783927879
  - 0.7277551796969631
  - 0.7281658357729319
  - 0.7274725625454239
  - 0.727358050792975
  - 0.7277486910318385
  - 0.72836076529905
  - 0.7275107921372921
  - 0.7273156338691005
  - 0.7278602308042376
  LL_f1_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_f1_weighted:
  - 0.9867773014842327
  - 0.9832767564481393
  - 0.9824151148968876
  - 0.9842242865375411
  - 0.9868978376855441
  - 0.9836576134985787
  - 0.9826562370890688
  - 0.9846140199382498
  - 0.9867652915002223
  - 0.9832436907593204
  - 0.9824398921378842
  - 0.9841691217693783
  - 0.9867123798169393
  - 0.9832984138780857
  - 0.9824826606909075
  - 0.9841596703263348
  LL_matthews_corrcoef:
  - 0.5448431486319819
  - 0.5443609417010167
  - 0.5439207436585922
  - 0.5446751228599022
  - 0.5449765507868785
  - 0.5443249928425076
  - 0.5439745794585498
  - 0.5444568100737082
  - 0.5448934338702066
  - 0.544147002223111
  - 0.5440441015538537
  - 0.5444869889588942
  - 0.5451975133055292
  - 0.5442006887412761
  - 0.5439751945855913
  - 0.5446589593200364
  LL_precision_macro:
  - 0.9947567610186865
  - 0.9933559856804806
  - 0.9930116010890111
  - 0.9937350525111781
  - 0.9948045695277279
  - 0.9935089679302311
  - 0.993108257961673
  - 0.9938920393056578
  - 0.9947518165105489
  - 0.9933434963750856
  - 0.9930210797182439
  - 0.9937135781516535
  - 0.9947297924308613
  - 0.9933652655193022
  - 0.9930385285173409
  - 0.99370919418804
  LL_precision_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_precision_weighted:
  - 0.9896699137809285
  - 0.9869629006498913
  - 0.9863006300201597
  - 0.9876933266807815
  - 0.9897627235580176
  - 0.9872574292838272
  - 0.9864863450449225
  - 0.9879961817679739
  - 0.989660332078433
  - 0.9869387829828868
  - 0.9863188879609665
  - 0.9876518453970167
  - 0.9896176763911533
  - 0.9869806978421226
  - 0.9863523742084683
  - 0.9876434508801099
  LL_recall_macro:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LL_recall_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_recall_weighted:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_roc_auc:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LT_average_precision:
  - 0.02891739674562637
  - 0.016957973794245323
  - 0.014967433291286091
  - 0.02151950972337024
  - 0.02688026137040374
  - 0.01609550229460259
  - 0.014619160469063286
  - 0.0218989137672576
  - 0.027955474244000945
  - 0.017248988353918686
  - 0.015969124207485176
  - 0.02027299759759375
  - 0.027931090000737256
  - 0.01613894387173367
  - 0.014915923768235712
  - 0.021920474066689722
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5217843879567038
  - 0.5234167914623781
  - 0.537024946803187
  - 0.5399452804905834
  - 0.5086602081543341
  - 0.5160185567818061
  - 0.5363573235815629
  - 0.5408749610720054
  - 0.5162724663410431
  - 0.5242376082684124
  - 0.5604067141167428
  - 0.5258523863772572
  - 0.5079120651215845
  - 0.5150492986947228
  - 0.5423543159166707
  - 0.5380774900505088
  TL_average_precision:
  - 0.05984295206001604
  - 0.06605730270929637
  - 0.084281663397221
  - 0.06740739106114264
  - 0.0989772377701095
  - 0.1083165397254773
  - 0.09518182671895092
  - 0.10744894388391385
  - 0.07900224932746962
  - 0.0803925663432483
  - 0.09394683035580956
  - 0.07597535919775136
  - 0.08269454024141225
  - 0.07967276034356151
  - 0.08191691757336067
  - 0.0743641654824084
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5675203106882062
  - 0.569824655565226
  - 0.5861069517691555
  - 0.571984162726636
  - 0.5778338185750455
  - 0.5942863769801993
  - 0.5896523627732305
  - 0.5919233685411158
  - 0.5704294263063374
  - 0.5812484070761987
  - 0.5953170019469236
  - 0.5757836851788943
  - 0.5788157025918871
  - 0.5748449820814212
  - 0.5748424369566101
  - 0.5709026142206076
  TT_average_precision:
  - 0.026494176995629226
  - 0.017392904832624196
  - 0.01178633968017822
  - 0.021758570705569066
  - 0.02970512840975592
  - 0.019707803062670212
  - 0.017107375519399698
  - 0.02133595616335746
  - 0.026415402736158465
  - 0.0171994683152246
  - 0.013493292121179305
  - 0.01901632079589868
  - 0.02713179457943961
  - 0.014645990781754803
  - 0.011102108972623795
  - 0.0221903632019558
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5214313194629185
  - 0.5184174386303928
  - 0.49135771299838804
  - 0.5531654844847365
  - 0.5066949054317476
  - 0.5438708324596352
  - 0.5424142350737751
  - 0.5440971278909753
  - 0.5119709263534978
  - 0.5378877105411708
  - 0.5229499938399201
  - 0.5069177897541476
  - 0.5097037681285667
  - 0.5078317026704123
  - 0.5064209183673469
  - 0.5335293759849972
  fit_time:
  - 442.4689586162567
  - 508.5564925670624
  - 599.7502384185791
  - 503.80705428123474
  - 570.7069969177246
  - 501.16014647483826
  - 487.7206463813782
  - 510.4638433456421
  - 619.3312880992889
  - 633.6760060787201
  - 513.1059515476227
  - 634.8275046348572
  - 606.4805915355682
  - 640.5103452205658
  - 638.1186401844025
  - 639.5873537063599
  score_time:
  - 8.824125289916992
  - 5.724584341049194
  - 8.43546986579895
  - 5.722137928009033
  - 10.812230587005615
  - 5.852442502975464
  - 9.1310875415802
  - 5.700546503067017
  - 7.209120035171509
  - 5.492881774902344
  - 5.742547512054443
  - 5.293177127838135
  - 7.895894765853882
  - 5.190431594848633
  - 5.329864740371704
  - 5.206615447998047
start: 2023-11-22 20:39:04.921645
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
