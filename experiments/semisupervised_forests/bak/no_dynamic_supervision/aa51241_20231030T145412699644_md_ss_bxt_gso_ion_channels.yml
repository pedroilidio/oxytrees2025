active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-30 14:54:24.640784
estimator:
  call: semisupervised_forests.estimators.md_ss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: aa51241cb050c268bc4a6467be71fc642fe68bd5e090d468de73665002c7f20a
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/aa51241_20231030T145412699644_md_ss_bxt_gso_ion_channels.yml"
results:
  LL_average_precision:
  - 0.32663246582317396
  - 0.3282104262674772
  - 0.3239487591028229
  - 0.3262322780037187
  - 0.32556707196748086
  - 0.325874946803909
  - 0.32374451890460826
  - 0.3262938704270025
  - 0.32559255461498604
  - 0.3263454714349574
  - 0.32403408620832297
  - 0.32536830284463414
  - 0.32536901767026805
  - 0.32540137037937994
  - 0.32419254880642945
  - 0.32347112109948567
  LL_balanced_accuracy:
  - 0.6504524886877828
  - .nan
  - 0.6500607533414338
  - .nan
  - 0.6502320185614849
  - .nan
  - 0.65
  - .nan
  - 0.6504112808460635
  - .nan
  - 0.65
  - .nan
  - 0.650174621653085
  - .nan
  - 0.6503067484662577
  - .nan
  LL_f1_macro:
  - 0.7247147376580412
  - .nan
  - 0.7247494932538617
  - .nan
  - 0.7246180167203053
  - .nan
  - 0.7246992675697045
  - .nan
  - 0.724917092571373
  - .nan
  - 0.7246235538985544
  - .nan
  - 0.7245719922026472
  - .nan
  - 0.7251051764698372
  - .nan
  LL_f1_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_f1_weighted:
  - 0.9675291813846373
  - .nan
  - 0.9699045778045997
  - .nan
  - 0.9683066504870864
  - .nan
  - 0.9700068543616309
  - .nan
  - 0.9687302172486109
  - .nan
  - 0.9696429040017699
  - .nan
  - 0.968409524086243
  - .nan
  - 0.9702234059506051
  - .nan
  LL_matthews_corrcoef:
  - 0.5413656446134067
  - .nan
  - 0.5411992376285261
  - .nan
  - 0.5411462518352902
  - .nan
  - 0.5411131214734051
  - .nan
  - 0.5415634050678383
  - .nan
  - 0.5410311761278824
  - .nan
  - 0.5410665251308358
  - .nan
  - 0.5417127859685285
  - .nan
  LL_precision_macro:
  - 0.9869922121658599
  - .nan
  - 0.987963388640448
  - .nan
  - 0.9873116741015067
  - .nan
  - 0.9880056837178202
  - .nan
  - 0.9874815905743741
  - .nan
  - 0.9878578892371996
  - .nan
  - 0.9873542902832134
  - .nan
  - 0.9880897655564378
  - .nan
  LL_precision_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_precision_weighted:
  - 0.9749418269748551
  - .nan
  - 0.9767463463343345
  - .nan
  - 0.9755339961297858
  - .nan
  - 0.9768250796348118
  - .nan
  - 0.9758501689028972
  - .nan
  - 0.9765495628653252
  - .nan
  - 0.9756130112434778
  - .nan
  - 0.9769826121976364
  - .nan
  LL_recall_macro:
  - 0.6504524886877828
  - .nan
  - 0.6500607533414338
  - .nan
  - 0.6502320185614849
  - .nan
  - 0.65
  - .nan
  - 0.6504112808460635
  - .nan
  - 0.65
  - .nan
  - 0.650174621653085
  - .nan
  - 0.6503067484662577
  - .nan
  LL_recall_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_recall_weighted:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_roc_auc:
  - 0.6504524886877828
  - 0.6515747128298138
  - 0.6500607533414338
  - 0.6516140357310113
  - 0.6502320185614849
  - 0.6507291527097232
  - 0.65
  - 0.651717974630085
  - 0.6504112808460635
  - 0.6507760035112483
  - 0.65
  - 0.6511769683861213
  - 0.650174621653085
  - 0.6506808263657891
  - 0.6503067484662577
  - 0.6506041535801406
  LT_average_precision:
  - 0.21914034920594452
  - 0.10998091505621416
  - 0.1446038018726141
  - 0.21143548411718344
  - 0.2513314571057227
  - 0.08575935924618777
  - 0.14380904071546322
  - 0.20852633495938988
  - 0.23195154564152037
  - 0.09200909244503591
  - 0.14385707230150982
  - 0.22257691725284529
  - 0.2084789480955151
  - 0.1099557376782471
  - 0.16139182448208594
  - 0.18240827750563277
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6919305875285098
  - 0.6500981236013084
  - 0.6428663793103447
  - 0.6817729302541253
  - 0.6999243501489455
  - 0.6249263027516514
  - 0.6555036398191412
  - 0.6746901806236975
  - 0.7037813245456558
  - 0.6239406622767651
  - 0.647423090523338
  - 0.6648943529943874
  - 0.6814189660724315
  - 0.6306417424725264
  - 0.6481050052668331
  - 0.6726181901519119
  TL_average_precision:
  - 0.537098339031685
  - 0.49592142806643524
  - 0.4322464446611398
  - 0.5039686965586224
  - 0.6174778767402833
  - 0.6064239456167222
  - 0.527245517145297
  - 0.5732839056487209
  - 0.42726528656862117
  - 0.5355860844713423
  - 0.489592006863738
  - 0.48838404517102335
  - 0.5479718305234025
  - 0.5427359391066738
  - 0.5286023453093038
  - 0.5917476516567793
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.8661651202573514
  - 0.8354320185086258
  - 0.815000435231649
  - 0.8443494583531221
  - 0.8613940114302056
  - 0.8596332012638367
  - 0.8456450504508732
  - 0.8521258789241863
  - 0.7762913741115565
  - 0.8302280957531863
  - 0.8270232820243628
  - 0.7947731751473981
  - 0.84385820382426
  - 0.8305768555890781
  - 0.8425691323580758
  - 0.8813386658789043
  TT_average_precision:
  - 0.18785896914653216
  - 0.0913453497605101
  - 0.10320317156334093
  - 0.1399687010497238
  - 0.32181648327596213
  - 0.0774631436448388
  - 0.2243186766771495
  - 0.2654436934316601
  - 0.24177799341652376
  - 0.09406918817794355
  - 0.12844701964304459
  - 0.26579824281481557
  - 0.23871364482667545
  - 0.06832436636884595
  - 0.14839621796722646
  - 0.11369803519585639
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.7357232732665259
  - 0.6455776672194583
  - 0.6119459564541213
  - 0.6540600578524283
  - 0.7824486067557515
  - 0.6549112480456175
  - 0.7300516641623613
  - 0.6844294853768278
  - 0.7572753251297603
  - 0.6494686400888545
  - 0.6189008620689654
  - 0.6347471568557328
  - 0.7856074650846621
  - 0.6015728216420257
  - 0.640535083291267
  - 0.6043394135145326
  fit_time:
  - 6.1577370166778564
  - 5.489462614059448
  - 5.703095197677612
  - 10.363850831985474
  - 10.720635652542114
  - 10.01919937133789
  - 11.112420320510864
  - 10.792376279830933
  - 9.985108375549316
  - 10.555934429168701
  - 10.926714658737183
  - 10.303110599517822
  - 9.65178894996643
  - 10.065160512924194
  - 11.291236639022827
  - 10.355491399765015
  score_time:
  - 0.5385243892669678
  - 0.4391913414001465
  - 0.5707113742828369
  - 0.6516222953796387
  - 0.7097537517547607
  - 0.7026162147521973
  - 0.6093966960906982
  - 0.5382080078125
  - 0.8342275619506836
  - 0.6169307231903076
  - 0.6353328227996826
  - 0.6768574714660645
  - 0.8781161308288574
  - 0.7031745910644531
  - 0.5762302875518799
  - 0.7073850631713867
start: 2023-10-30 14:54:12.699644
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
