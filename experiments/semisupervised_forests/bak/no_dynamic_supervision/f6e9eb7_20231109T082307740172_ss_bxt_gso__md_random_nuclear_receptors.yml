active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 08:23:08.466341
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_random
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_random
  params: {}
hash: f6e9eb7091c43f5606aadbad5d3eb4ad0043a9b55dfecd3ee90a8d710865b28a
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/f6e9eb7_20231109T082307740172_ss_bxt_gso__md_random_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.35252140011865407
  - 0.3576555023923445
  - 0.3623116055721961
  - 0.3871221846189754
  - 0.34019576379974326
  - 0.33329346092503986
  - 0.35301668806161746
  - 0.3510109114249037
  - 0.3655770782889427
  - 0.3556818181818182
  - 0.34268292682926826
  - 0.36689642983386356
  - 0.3758467741935484
  - 0.34375
  - 0.37081438610996276
  - 0.3781455671699574
  LL_balanced_accuracy:
  - .nan
  - 0.6590909090909091
  - 0.6574074074074074
  - .nan
  - .nan
  - 0.6515151515151515
  - 0.6585365853658537
  - .nan
  - .nan
  - 0.6590909090909091
  - 0.65
  - .nan
  - .nan
  - 0.65
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.7311193924241709
  - 0.726995463026985
  - .nan
  - .nan
  - 0.7247720867251343
  - 0.7314322301024428
  - .nan
  - .nan
  - 0.7316516838856837
  - 0.7196581196581197
  - .nan
  - .nan
  - 0.7193685793034327
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9605263157894737
  - 0.9525032092426188
  - .nan
  - .nan
  - 0.969736842105263
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625000000000001
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9507226011157428
  - 0.940718199906491
  - .nan
  - .nan
  - 0.9618788373999034
  - 0.9550723736054083
  - .nan
  - .nan
  - 0.9531665101301491
  - 0.9462997706900147
  - .nan
  - .nan
  - 0.9449699323477826
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.5526176822228344
  - 0.5472919980739969
  - .nan
  - .nan
  - 0.541975436470486
  - 0.5527051915086619
  - .nan
  - .nan
  - 0.5532065382625239
  - 0.5356832289134414
  - .nan
  - .nan
  - 0.5353729576861872
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9798927613941019
  - 0.9757217847769029
  - .nan
  - .nan
  - 0.9846666666666667
  - 0.9817232375979112
  - .nan
  - .nan
  - 0.9809160305343512
  - 0.9782608695652174
  - .nan
  - .nan
  - 0.9777070063694268
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9605263157894737
  - 0.9525032092426188
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9621137293636236
  - 0.954809483859447
  - .nan
  - .nan
  - 0.9706649122807017
  - 0.9653703449223582
  - .nan
  - .nan
  - 0.9639312977099237
  - 0.9591728525980912
  - .nan
  - .nan
  - 0.9582006369426752
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.6590909090909091
  - 0.6574074074074074
  - .nan
  - .nan
  - 0.6515151515151515
  - 0.6585365853658537
  - .nan
  - .nan
  - 0.6590909090909091
  - 0.65
  - .nan
  - .nan
  - 0.65
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9605263157894737
  - 0.9525032092426188
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9605263157894737
  - 0.9525032092426188
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_roc_auc:
  - 0.6638469205749659
  - 0.6590909090909091
  - 0.6574074074074074
  - 0.672212456052235
  - 0.656959191288714
  - 0.6515151515151515
  - 0.6585365853658537
  - 0.6581014223871366
  - 0.6600105217411195
  - 0.6590909090909091
  - 0.65
  - 0.6651206140350877
  - 0.6677812745869394
  - 0.65
  - 0.6610169491525424
  - 0.666173245614035
  LT_average_precision:
  - 0.12159147869674186
  - 0.11655806182121972
  - 0.2282817242956562
  - 0.2244823840467361
  - 0.08311343262001156
  - 0.2799832915622389
  - 0.10159694107062528
  - 0.16318038686459738
  - 0.25673234811165846
  - 0.30780084113417444
  - 0.25162101627618866
  - 0.2389143156585017
  - 0.12477896905888793
  - 0.3633744855967078
  - 0.2263105413105413
  - 0.3107123783208246
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5520584329349268
  - 0.5674688796680498
  - 0.694683908045977
  - 0.6906805640711221
  - 0.541502624671916
  - 0.627439024390244
  - 0.5285460992907802
  - 0.5856676003734826
  - 0.6071206467661692
  - 0.6586151368760065
  - 0.6974496911735405
  - 0.7199707922599489
  - 0.5888050314465408
  - 0.6609574000878349
  - 0.6689623507805326
  - 0.7075768579036552
  TL_average_precision:
  - 0.2663851399145517
  - 0.2790801790801791
  - 0.25876428877070723
  - 0.20195294016432228
  - 0.2850501490918948
  - 0.2521418396418396
  - 0.19996508088330184
  - 0.24518067956105039
  - 0.09360618014464168
  - 0.12692307692307692
  - 0.18800445368794771
  - 0.05020498922937948
  - 0.10666666666666666
  - 0.1636904761904762
  - 0.2632791327913279
  - 0.19043151969981237
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.655852417302799
  - 0.6613367905502737
  - 0.6692830978545264
  - 0.6200950020652622
  - 0.5950252623396813
  - 0.5913899739583334
  - 0.5316239316239316
  - 0.5638198342689121
  - 0.5227041680786174
  - 0.4713656387665198
  - 0.5159600389863548
  - 0.41069659953780124
  - 0.5371739130434782
  - 0.6042305334150827
  - 0.6298640412564462
  - 0.6167051832287884
  TT_average_precision:
  - 0.030612244897959183
  - 0.08163265306122448
  - 0.137941006362059
  - 0.11782661782661782
  - 0.2876039304610733
  - 0.1480900052328624
  - 0.27148962148962147
  - 0.08473557692307693
  - 0.1054112554112554
  - 0.17232142857142857
  - 0.01282051282051282
  - 0.18504273504273505
  - 0.07142857142857142
  - 0.26190476190476186
  - 0.054086538461538464
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.3736842105263158
  - 0.4444444444444444
  - 0.4982993197278911
  - 0.7367424242424242
  - 0.7436594202898551
  - 0.4176470588235294
  - 0.6691358024691356
  - 0.4646084337349398
  - 0.6132478632478633
  - 0.7510683760683761
  - 0.2142857142857143
  - 0.7222222222222223
  - 0.5493827160493827
  - 0.5673076923076923
  - 0.5118243243243243
  - .nan
  fit_time:
  - 0.48792362213134766
  - 0.4169912338256836
  - 0.5002245903015137
  - 0.4670829772949219
  - 0.41286706924438477
  - 0.39763903617858887
  - 0.44350504875183105
  - 0.44711875915527344
  - 0.4373316764831543
  - 0.41567182540893555
  - 0.44442152976989746
  - 0.48018455505371094
  - 0.5024905204772949
  - 0.4248199462890625
  - 0.45678234100341797
  - 0.5015480518341064
  score_time:
  - 0.20264911651611328
  - 0.17143630981445312
  - 0.20236611366271973
  - 0.18665242195129395
  - 0.17959880828857422
  - 0.1988685131072998
  - 0.20061588287353516
  - 0.18435120582580566
  - 0.17075586318969727
  - 0.19643545150756836
  - 0.1897268295288086
  - 0.1756739616394043
  - 0.1964716911315918
  - 0.1827397346496582
  - 0.19748234748840332
  - 0.18605637550354004
start: 2023-11-09 08:23:07.740172
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
