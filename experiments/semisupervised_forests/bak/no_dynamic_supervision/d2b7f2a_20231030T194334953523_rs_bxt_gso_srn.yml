active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-10-30 21:19:49.805456
estimator:
  call: semisupervised_forests.estimators.rs_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: rs_bxt_gso
  params: {}
hash: d2b7f2a39d51db7a9d779ae2cd629d4570103133a6e73edb1a98e2dbc3a3f94f
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/d2b7f2a_20231030T194334953523_rs_bxt_gso_srn.yml"
results:
  LL_average_precision:
  - 0.31043956043956045
  - 0.3135321585011493
  - 0.31393697904693796
  - 0.31289824492932156
  - 0.3104626920106975
  - 0.31309691275241186
  - 0.31374651818975763
  - 0.3122514757489135
  - 0.31050772523023307
  - 0.31332852192953764
  - 0.3140485358674154
  - 0.31274634668205165
  - 0.3108996636445437
  - 0.31333143351602716
  - 0.31392743184478733
  - 0.31294731263378284
  LL_balanced_accuracy:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LL_f1_macro:
  - 0.7281337930487852
  - 0.7276140047113996
  - 0.7272761330148422
  - 0.7278745634629974
  - 0.7282277202975188
  - 0.7276129923249521
  - 0.7273254783927879
  - 0.7277551796969631
  - 0.7281658357729319
  - 0.7274725625454239
  - 0.727358050792975
  - 0.7277486910318385
  - 0.72836076529905
  - 0.7275107921372921
  - 0.7273156338691005
  - 0.7278602308042376
  LL_f1_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_f1_weighted:
  - 0.9867773014842327
  - 0.9832767564481393
  - 0.9824151148968876
  - 0.9842242865375411
  - 0.9868978376855441
  - 0.9836576134985787
  - 0.9826562370890688
  - 0.9846140199382498
  - 0.9867652915002223
  - 0.9832436907593204
  - 0.9824398921378842
  - 0.9841691217693783
  - 0.9867123798169393
  - 0.9832984138780857
  - 0.9824826606909075
  - 0.9841596703263348
  LL_matthews_corrcoef:
  - 0.5448431486319819
  - 0.5443609417010167
  - 0.5439207436585922
  - 0.5446751228599022
  - 0.5449765507868785
  - 0.5443249928425076
  - 0.5439745794585498
  - 0.5444568100737082
  - 0.5448934338702066
  - 0.544147002223111
  - 0.5440441015538537
  - 0.5444869889588942
  - 0.5451975133055292
  - 0.5442006887412761
  - 0.5439751945855913
  - 0.5446589593200364
  LL_precision_macro:
  - 0.9947567610186865
  - 0.9933559856804806
  - 0.9930116010890111
  - 0.9937350525111781
  - 0.9948045695277279
  - 0.9935089679302311
  - 0.993108257961673
  - 0.9938920393056578
  - 0.9947518165105489
  - 0.9933434963750856
  - 0.9930210797182439
  - 0.9937135781516535
  - 0.9947297924308613
  - 0.9933652655193022
  - 0.9930385285173409
  - 0.99370919418804
  LL_precision_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_precision_weighted:
  - 0.9896699137809285
  - 0.9869629006498913
  - 0.9863006300201597
  - 0.9876933266807815
  - 0.9897627235580176
  - 0.9872574292838272
  - 0.9864863450449225
  - 0.9879961817679739
  - 0.989660332078433
  - 0.9869387829828868
  - 0.9863188879609665
  - 0.9876518453970167
  - 0.9896176763911533
  - 0.9869806978421226
  - 0.9863523742084683
  - 0.9876434508801099
  LL_recall_macro:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LL_recall_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_recall_weighted:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_roc_auc:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LT_average_precision:
  - 0.029129337240990708
  - 0.016912687937244975
  - 0.016059694070236837
  - 0.02171363073511983
  - 0.027181188414330662
  - 0.017466922679418257
  - 0.017731415141149853
  - 0.021034956817641903
  - 0.02850282795535023
  - 0.017473294973712913
  - 0.01497162017566084
  - 0.019596294810633994
  - 0.02847724905056486
  - 0.017575497520058003
  - 0.01662030414013201
  - 0.0206585462831021
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5262478994052089
  - 0.5293065500059028
  - 0.5643882652298258
  - 0.540286514749553
  - 0.5109122328360367
  - 0.5278391511550575
  - 0.5505958620000252
  - 0.5351567292453993
  - 0.5250907651363494
  - 0.5359955255088942
  - 0.543980922169909
  - 0.5243853888988808
  - 0.5205395049874166
  - 0.5264058587128978
  - 0.55722357924526
  - 0.5325890207807524
  TL_average_precision:
  - 0.06516112432067675
  - 0.07041229096265451
  - 0.07029551069622922
  - 0.08986559411081324
  - 0.08971530029297353
  - 0.10270105668886449
  - 0.08839617414877277
  - 0.08592087787003842
  - 0.08741913350785399
  - 0.08960360884690023
  - 0.08282858132270177
  - 0.07531140480498255
  - 0.06089694392758291
  - 0.08108889505648476
  - 0.06585019839333034
  - 0.08398938369119517
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.564898727844682
  - 0.5809911891236638
  - 0.5775600979654995
  - 0.5857780075257568
  - 0.5856404153266255
  - 0.5906986651431204
  - 0.5860349519981576
  - 0.5822993211709341
  - 0.5963268687974111
  - 0.5893246188576209
  - 0.5857955924149653
  - 0.5812655247640235
  - 0.5702442023628643
  - 0.5768217870989024
  - 0.5647160272243684
  - 0.5832253324277328
  TT_average_precision:
  - 0.02618919013081882
  - 0.015448307015651041
  - 0.013845039105188238
  - 0.018670915022839234
  - 0.029355973138042
  - 0.01592772497838251
  - 0.01552277257992871
  - 0.020049925506610087
  - 0.026469509308474012
  - 0.01751408999342105
  - 0.015057983710272473
  - 0.01921229264562985
  - 0.02698295832526842
  - 0.017940868749206106
  - 0.011590246997578386
  - 0.01954449058600542
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.512619481762289
  - 0.5166490647974966
  - 0.5405072101290859
  - 0.5158795363608383
  - 0.506758337284653
  - 0.514969385615433
  - 0.5193071401775196
  - 0.5277915390420386
  - 0.5189265741900849
  - 0.5429770795862419
  - 0.5619471328250127
  - 0.5169216692120202
  - 0.5129475826611825
  - 0.5440397386633946
  - 0.5239314058956916
  - 0.5185246124595237
  fit_time:
  - 5031.118135213852
  - 5767.379641294479
  - 5738.278963565826
  - 5709.177676916122
  - 5043.65851020813
  - 5591.2274696826935
  - 5703.164168596268
  - 5626.956278800964
  - 5052.810522317886
  - 5616.027193784714
  - 5667.256891012192
  - 5418.420970439911
  - 4614.708140611649
  - 5593.000526666641
  - 5660.821262121201
  - 1008.7993252277374
  score_time:
  - 25.708333730697632
  - 6.025190114974976
  - 6.39461612701416
  - 6.677524089813232
  - 25.083282232284546
  - 17.444029331207275
  - 7.3631250858306885
  - 11.588148832321167
  - 22.82310962677002
  - 14.985809087753296
  - 7.727755784988403
  - 22.7753164768219
  - 34.76439571380615
  - 16.989155292510986
  - 8.10516905784607
  - 6.4157023429870605
start: 2023-10-30 19:43:34.953523
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
