active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 23:49:12.451113
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_random
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_random
  params: {}
hash: c895b2f4eabadd39731509759737345bc89ec8fb09ccb778f339ca94731fa8c3
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/c895b2f_20231109T234526610406_ss_bxt_gso__ad_random_srn.yml"
results:
  LL_average_precision:
  - 0.11342229199372057
  - 0.11739848950147766
  - 0.11816217157894254
  - 0.11617616567672061
  - 0.11353501938359256
  - 0.11696981379179296
  - 0.1179205717775326
  - 0.11582152870909224
  - 0.11383853592976577
  - 0.117200494035632
  - 0.11818405821317018
  - 0.11632054356431842
  - 0.11401385325727043
  - 0.11701235249776337
  - 0.11796768773573779
  - 0.11624124384896081
  LL_balanced_accuracy:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_f1_macro:
  - 0.587525766149485
  - 0.5869569262020368
  - 0.586646374465257
  - 0.5869816036506083
  - 0.5877519171302815
  - 0.5870260223678899
  - 0.586712444341127
  - 0.5871295948036175
  - 0.5878614038397703
  - 0.5867602867102066
  - 0.586687900893901
  - 0.5870483832903317
  - 0.5879402844460085
  - 0.5866607317273869
  - 0.5865557606018998
  - 0.5869642543352205
  LL_f1_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_f1_weighted:
  - 0.9811321823453176
  - 0.9761414287195214
  - 0.9749212382495934
  - 0.9774776314203629
  - 0.9813074311317526
  - 0.9766889473454499
  - 0.9752651098766671
  - 0.9780497795168125
  - 0.9811260532825248
  - 0.9760953339344545
  - 0.9749522354593334
  - 0.9774108918568967
  - 0.9810418010034022
  - 0.9761657817869357
  - 0.9750099646383824
  - 0.977385480503414
  LL_matthews_corrcoef:
  - 0.31409515446139513
  - 0.3141683958690032
  - 0.3138616381656739
  - 0.31390578049604967
  - 0.31448500361571946
  - 0.3141728200322513
  - 0.3139073145897686
  - 0.3140545703121901
  - 0.31473502795779823
  - 0.31380563801371575
  - 0.3139332792843214
  - 0.3140481470423044
  - 0.3149043644977443
  - 0.31360011679080124
  - 0.31366898336781385
  - 0.31389415520984937
  LL_precision_macro:
  - 0.9932788302806383
  - 0.9914900047493631
  - 0.9910530770160804
  - 0.9919701600787443
  - 0.9933405484664932
  - 0.9916864403123518
  - 0.9911763690650834
  - 0.9921748283121097
  - 0.9932749711971511
  - 0.9914746742600742
  - 0.9910639546423424
  - 0.9919457817811599
  - 0.9932443637569717
  - 0.9915006342166346
  - 0.9910856057991025
  - 0.9919371538023503
  LL_precision_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_precision_weighted:
  - 0.9867581350113046
  - 0.9833014126376041
  - 0.982461332030557
  - 0.9842264253782121
  - 0.9868779600334681
  - 0.9836796181124469
  - 0.9826982055854259
  - 0.9846213911194873
  - 0.9867507367598339
  - 0.983271829190631
  - 0.9824822418385274
  - 0.9841794371787886
  - 0.9866913777610021
  - 0.983321742323542
  - 0.9825237643341496
  - 0.9841627673678994
  LL_recall_macro:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_recall_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_recall_weighted:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_roc_auc:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LT_average_precision:
  - 0.027493744098928234
  - 0.01536567315431108
  - 0.012080614156694045
  - 0.01910476164248683
  - 0.026021213878864285
  - 0.015718178774823767
  - 0.01221894087367622
  - 0.019960681660711934
  - 0.027243692737506438
  - 0.015757014478004854
  - 0.012760416569619402
  - 0.01962157644843706
  - 0.026503787505679992
  - 0.015518536515403919
  - 0.01314904201047164
  - 0.019093302437441402
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5082221653191087
  - 0.5015587107907016
  - 0.5068164066646432
  - 0.5150776962970686
  - 0.5035449623534757
  - 0.5088680727243043
  - 0.5177986127892995
  - 0.5186959078584695
  - 0.5031541464233376
  - 0.5138493920577314
  - 0.5193088673192778
  - 0.5127657457890817
  - 0.503256565303054
  - 0.5056315645284749
  - 0.5158153849131102
  - 0.5111447029039251
  TL_average_precision:
  - 0.033639806772577815
  - 0.03163027281299489
  - 0.033681443696208305
  - 0.0340637398381083
  - 0.040980239863847405
  - 0.061353274426234485
  - 0.04105342346676417
  - 0.04920384461143372
  - 0.0329855806943411
  - 0.04599069097219495
  - 0.04814630065394076
  - 0.040626175983678
  - 0.042862982880991295
  - 0.03938776934597413
  - 0.049471744049466554
  - 0.03299427342917694
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5271479999888414
  - 0.5225808965643373
  - 0.5183421491246794
  - 0.5212680903295311
  - 0.525832410348879
  - 0.5349134394540203
  - 0.5285649542003084
  - 0.53339054769694
  - 0.5190624251876564
  - 0.5258589916954645
  - 0.5315059279101053
  - 0.525948490673851
  - 0.5271629035583851
  - 0.526133156201492
  - 0.5244680406231895
  - 0.5232559389863418
  TT_average_precision:
  - 0.025316513282902603
  - 0.01498616197678407
  - 0.012108576544167839
  - 0.01920561779320854
  - 0.028388188260034117
  - 0.018383187656924677
  - 0.014467061097552195
  - 0.01855547689161135
  - 0.02534124984001094
  - 0.015354340037786515
  - 0.01169555180908618
  - 0.01809381095095381
  - 0.026514648650688442
  - 0.015186359151876393
  - 0.010945901737610227
  - 0.01931020693675362
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.4979658772649345
  - 0.5005769694285297
  - 0.4963074103215099
  - 0.5148024566999636
  - 0.5031049997365787
  - 0.5271778150555672
  - 0.5084135130211876
  - 0.5158602565809918
  - 0.5026599471921565
  - 0.5090412076805518
  - 0.5011041601073223
  - 0.4930785764985141
  - 0.5091138496214813
  - 0.49977655074429267
  - 0.5
  - 0.49494362364184846
  fit_time:
  - 157.04663467407227
  - 214.73871684074402
  - 212.70992302894592
  - 187.98129677772522
  - 184.4332365989685
  - 205.81229853630066
  - 206.32583093643188
  - 191.21630835533142
  - 158.7191140651703
  - 203.0652196407318
  - 218.92236828804016
  - 205.9796838760376
  - 172.32866740226746
  - 197.20794677734375
  - 201.70562028884888
  - 196.8384552001953
  score_time:
  - 11.826318502426147
  - 5.769054651260376
  - 6.2553040981292725
  - 8.616281270980835
  - 14.011765241622925
  - 7.5747389793396
  - 8.084478378295898
  - 11.087754487991333
  - 11.288451671600342
  - 6.3441362380981445
  - 5.622895002365112
  - 8.224610567092896
  - 10.737919569015503
  - 7.562209844589233
  - 6.884379148483276
  - 7.985921382904053
start: 2023-11-09 23:45:26.610406
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
