active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 08:25:26.698181
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_random
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_random
  params: {}
hash: a0c9741238a2f67c295ad9f5f3c42fe243f1df7999b5af5d44a5a54d8a82a0c5
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/a0c9741_20231109T082444881970_ss_bxt_gso__ad_random_enzymes.yml"
results:
  LL_average_precision:
  - 0.306728945116635
  - 0.307667724996922
  - 0.30701646365066204
  - 0.3073462740730796
  - 0.3069922693778116
  - 0.30920715189061515
  - 0.307742357193137
  - 0.307277134133476
  - 0.3080929601160361
  - 0.30938987583384714
  - 0.3081438362064258
  - 0.3089989815829255
  - 0.307919968160932
  - 0.3084116394343895
  - 0.3075131541686076
  - 0.3073667102025463
  LL_balanced_accuracy:
  - .nan
  - 0.6501424501424502
  - 0.6500302480338778
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.729079319124128
  - 0.7290547268171468
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9926171752879782
  - 0.9930440324170935
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9906444566816437
  - 0.9911836959231863
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.545949542608125
  - 0.5458635748340672
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9962968547390006
  - 0.9965116138835959
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9926171752879782
  - 0.9930440324170935
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9926718546326685
  - 0.9930925626185783
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.6501424501424502
  - 0.6500302480338778
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9926171752879782
  - 0.9930440324170935
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9926171752879782
  - 0.9930440324170935
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_roc_auc:
  - 0.6500947048494058
  - 0.6501424501424502
  - 0.6500302480338778
  - 0.6503453134801239
  - 0.6503333333333333
  - 0.6510263929618768
  - 0.6504932538444226
  - 0.6504251144538914
  - 0.650814332247557
  - 0.6509915014164306
  - 0.6505698860227954
  - 0.6511627906976745
  - 0.6504504504504505
  - 0.6503250270855905
  - 0.6501112150948903
  - 0.6502098668589054
  LT_average_precision:
  - 0.1098835869348762
  - 0.21360342535477103
  - 0.14135797720287208
  - 0.13014318988943235
  - 0.11160668935126737
  - 0.21202353769189264
  - 0.17837983845274513
  - 0.14827118609007497
  - 0.17127980626449704
  - 0.19297321934262895
  - 0.16898543558898196
  - 0.11942992856468373
  - 0.13527482585770326
  - 0.25661875025145325
  - 0.18857738044575414
  - 0.14731743578861442
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.578877398427629
  - 0.67046274481207
  - 0.6383093450815815
  - 0.6488840697087725
  - 0.6027464470360149
  - 0.6889194761775558
  - 0.6371010987986419
  - 0.6522952748996301
  - 0.6175981552887412
  - 0.6764540731836699
  - 0.6514883873181773
  - 0.6284471215840358
  - 0.6196745563359192
  - 0.6930477400910168
  - 0.6499538766955473
  - 0.6535749740064415
  TL_average_precision:
  - 0.4382171147320154
  - 0.48632606122093075
  - 0.47017965733875716
  - 0.4391290914579057
  - 0.584118943047858
  - 0.5979336450896799
  - 0.5689614054635522
  - 0.5672419054787812
  - 0.5826835493133619
  - 0.6020513256881861
  - 0.579875851439984
  - 0.6092975264475586
  - 0.5972473465995025
  - 0.5811412282746744
  - 0.5681676901797541
  - 0.5463472894071577
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.767219970680008
  - 0.7734779258954839
  - 0.7751714520518695
  - 0.7522539161225633
  - 0.8336783413148574
  - 0.8359627278667703
  - 0.8331815029532871
  - 0.8270001836915629
  - 0.8252112060400028
  - 0.8361561935212395
  - 0.8311662735317994
  - 0.8356022625000522
  - 0.8336152965268705
  - 0.8365407630708149
  - 0.8294385508406725
  - 0.8277662852898696
  TT_average_precision:
  - 0.10518381926658585
  - 0.23355801170900767
  - 0.15539090851382587
  - 0.149271290618905
  - 0.1097296404587395
  - 0.24426477618391768
  - 0.1990037001827605
  - 0.1641019714724575
  - 0.12868282695565747
  - 0.2429683389955909
  - 0.16870692789985378
  - 0.14303211185316958
  - 0.11435880949538045
  - 0.15967640213317216
  - 0.08984077027558174
  - 0.05607406397378253
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5915689736588171
  - 0.6553655158686746
  - 0.6376032426544135
  - 0.6668373937942402
  - 0.603983066385391
  - 0.7033054924449798
  - 0.6248399264786569
  - 0.7007815939273796
  - 0.6101412477355073
  - 0.7006054021523438
  - 0.6292079058420091
  - 0.6462531664299013
  - 0.5902660988233831
  - 0.6493642144141899
  - 0.5560971703567131
  - 0.6112336835375672
  fit_time:
  - 26.105226516723633
  - 27.400044202804565
  - 27.0189950466156
  - 27.13090443611145
  - 26.40639328956604
  - 27.275117874145508
  - 30.240707874298096
  - 23.214484453201294
  - 25.41215229034424
  - 28.239042282104492
  - 28.104681968688965
  - 27.449167490005493
  - 27.55942177772522
  - 27.31386375427246
  - 29.569905757904053
  - 27.09834098815918
  score_time:
  - 10.199787139892578
  - 10.676879405975342
  - 11.187659978866577
  - 11.259771347045898
  - 9.962830781936646
  - 12.393049001693726
  - 8.494946479797363
  - 9.700942277908325
  - 9.481236219406128
  - 12.342832088470459
  - 12.557604551315308
  - 12.431273937225342
  - 12.881348848342896
  - 12.615986824035645
  - 12.02077031135559
  - 11.759113311767578
start: 2023-11-09 08:24:44.881970
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
