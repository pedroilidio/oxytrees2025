active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 12:40:17.954252
estimator:
  call: semisupervised_forests.estimators.ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ds_bxt_gso
  params: {}
hash: 12ca8a09de0318351bbad8ef69c30cb48794de23aa04b0bb51f9ee835d69123e
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/12ca8a0_20231101T123743008634_ds_bxt_gso_ern.yml"
results:
  LL_average_precision:
  - 0.11755073734897781
  - 0.11904216194074933
  - 0.11824776124456182
  - 0.11212648542299664
  - 0.11707217540001573
  - 0.11935457392663087
  - 0.11865779362828048
  - 0.1125156848371946
  - 0.1172010941396867
  - 0.11893881827724695
  - 0.11827843107499672
  - 0.11201657035511642
  - 0.11712236665172569
  - 0.1193172983663681
  - 0.1185508411617553
  - 0.1125562471961105
  LL_balanced_accuracy:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_f1_macro:
  - 0.5869263150151246
  - 0.5861435721306022
  - 0.5864550390583527
  - 0.5880150750063559
  - 0.5867679904328182
  - 0.5863693085565117
  - 0.5866655249422846
  - 0.5880700084917458
  - 0.5870252315797547
  - 0.5862737524723205
  - 0.5866085416217844
  - 0.5881268637742644
  - 0.5865832349231027
  - 0.5863277483426732
  - 0.5864276751478756
  - 0.5882207775958614
  LL_f1_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_f1_weighted:
  - 0.9759390715472271
  - 0.9733263631338508
  - 0.9745797960748513
  - 0.9831593454996554
  - 0.9762422567124828
  - 0.9732889882645694
  - 0.9744183188027767
  - 0.9828144619281908
  - 0.9764412608576732
  - 0.9736066386792477
  - 0.9747478846466097
  - 0.9834233273191423
  - 0.9759470977012066
  - 0.9732743091898997
  - 0.9742211336307921
  - 0.9829683195491606
  LL_matthews_corrcoef:
  - 0.3141571461786937
  - 0.3132774763658292
  - 0.31357758539033465
  - 0.31455870316115747
  - 0.313786199868058
  - 0.313714688411654
  - 0.31401462921606976
  - 0.31474270783577457
  - 0.3142286546313658
  - 0.31345948930330475
  - 0.3138300346298245
  - 0.31471066812965903
  - 0.3135035878913886
  - 0.3136392339602798
  - 0.3136089385190437
  - 0.3149940759299084
  LL_precision_macro:
  - 0.9914174226320569
  - 0.9904824171765669
  - 0.9909314889574923
  - 0.9940029466148537
  - 0.9915274534459014
  - 0.9904673494240482
  - 0.9908719399972294
  - 0.9938791654306338
  - 0.991597393395671
  - 0.990582422518341
  - 0.9909909464206204
  - 0.9940969990606615
  - 0.9914224981038682
  - 0.9904623585075163
  - 0.9908025845776314
  - 0.9939336108611603
  LL_precision_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_precision_weighted:
  - 0.983161751742076
  - 0.9813666025288966
  - 0.982227803071867
  - 0.9881655493493736
  - 0.9833734027401535
  - 0.9813378626943587
  - 0.9821136246534958
  - 0.9879246670852959
  - 0.9835081426270568
  - 0.9815582642304476
  - 0.9823420130064394
  - 0.9883487021195555
  - 0.9831713676131173
  - 0.9813282819441631
  - 0.9819804478269578
  - 0.9880306406658245
  LL_recall_macro:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_recall_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_recall_weighted:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_roc_auc:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LT_average_precision:
  - 0.029850604098472115
  - 0.03171167555440113
  - 0.015911639413440374
  - 0.0350966337904976
  - 0.02732165663080848
  - 0.03835510544940264
  - 0.015410005501417008
  - 0.035303335003920244
  - 0.02928634225205106
  - 0.044354015810883905
  - 0.01640571741795289
  - 0.03455853817877827
  - 0.02588821756862678
  - 0.027479142515523098
  - 0.013291040524505443
  - 0.03406864371283668
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5324632639958363
  - 0.5248461364747316
  - 0.523285069338021
  - 0.5071927204490314
  - 0.5185447272859468
  - 0.515167171975045
  - 0.5213003471637543
  - 0.5064708111787217
  - 0.5231141057942986
  - 0.5270924924172647
  - 0.5209213060696858
  - 0.5038134292130066
  - 0.5171103436005079
  - 0.5155960811744145
  - 0.5141986915310117
  - 0.5018679526540493
  TL_average_precision:
  - 0.08447577850556273
  - 0.11170126068730761
  - 0.09192439318683741
  - 0.05144315161059643
  - 0.10001508223286584
  - 0.08784584728542749
  - 0.1070083214564705
  - 0.05181352431686265
  - 0.08432115363941173
  - 0.09144334323790486
  - 0.08114008718785834
  - 0.06508401515654433
  - 0.08435125750463365
  - 0.10411766984675364
  - 0.0962539385443736
  - 0.07116405883415089
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5768842360569725
  - 0.577432454771221
  - 0.5914389937867713
  - 0.5556303298743439
  - 0.5825199209824828
  - 0.5833160336815912
  - 0.5903760354774532
  - 0.5663654416017364
  - 0.5808115892799393
  - 0.5796793973663379
  - 0.5789593071994596
  - 0.5580874607496981
  - 0.5844053766437384
  - 0.5891379489105094
  - 0.5961608012686694
  - 0.5735063468581189
  TT_average_precision:
  - 0.023036579506947548
  - 0.01773310162174571
  - 0.013038988723082623
  - 0.033445226903817044
  - 0.021698508847780233
  - 0.025936817249513452
  - 0.013657151345101846
  - 0.036146596079787374
  - 0.02293772092741165
  - 0.04025460522100664
  - 0.01395566956953697
  - 0.03466574064026044
  - 0.017640842986313486
  - 0.01847613474151961
  - 0.015385397224911218
  - 0.03364537120924713
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5230962622709716
  - 0.5363226501642508
  - 0.5200005962979605
  - 0.5071760225000359
  - 0.5156956980122914
  - 0.5336282105986978
  - 0.518064017510234
  - 0.512624525292004
  - 0.5165028004011054
  - 0.5509848830300267
  - 0.5065803175189152
  - 0.4991052450934506
  - 0.5077249426669996
  - 0.5309099131156777
  - 0.5229795530164909
  - 0.508822858458168
  fit_time:
  - 148.5798704624176
  - 150.76112985610962
  - 145.62460279464722
  - 107.23825907707214
  - 135.26651430130005
  - 148.97251653671265
  - 143.48333096504211
  - 112.11535453796387
  - 132.24571228027344
  - 146.40569949150085
  - 135.55798411369324
  - 102.18330311775208
  - 140.21276354789734
  - 146.45648789405823
  - 141.29661321640015
  - 103.46748280525208
  score_time:
  - 4.132643461227417
  - 3.949298620223999
  - 4.291706800460815
  - 6.320477724075317
  - 5.164095401763916
  - 4.3435914516448975
  - 4.241819381713867
  - 6.285064697265625
  - 5.210939884185791
  - 4.233513116836548
  - 4.667180776596069
  - 6.399936199188232
  - 4.600660562515259
  - 3.8854310512542725
  - 4.575616836547852
  - 7.222301483154297
start: 2023-11-01 12:37:43.008634
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
