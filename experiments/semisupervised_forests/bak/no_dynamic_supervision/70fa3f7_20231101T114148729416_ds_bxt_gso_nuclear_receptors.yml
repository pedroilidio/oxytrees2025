active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 11:41:49.315889
estimator:
  call: semisupervised_forests.estimators.ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ds_bxt_gso
  params: {}
hash: 70fa3f7e5148f5f00f22a4588f9c15a1eaa3c8cb01763034e7d6f17dc93530e5
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/70fa3f7_20231101T114148729416_ds_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.20867446393762182
  - 0.16495215311004785
  - 0.18996339086197878
  - 0.16290115532734273
  - 0.1693196405648267
  - 0.15937001594896333
  - 0.1681643132220796
  - 0.15991266970085968
  - 0.1679449152542373
  - 0.16238636363636363
  - 0.17365853658536584
  - 0.16585365853658537
  - 0.17963709677419354
  - 0.15625
  - 0.1663290615957007
  - 0.18130081300813006
  LL_balanced_accuracy:
  - .nan
  - 0.5568181818181818
  - .nan
  - .nan
  - 0.5609756097560976
  - 0.5606060606060606
  - 0.5609756097560976
  - .nan
  - 0.5508474576271186
  - 0.5568181818181818
  - .nan
  - 0.55
  - .nan
  - 0.55
  - 0.5508474576271186
  - .nan
  LL_f1_macro:
  - .nan
  - 0.5887845280872377
  - .nan
  - .nan
  - 0.5964839832458262
  - 0.5983306300231452
  - 0.5967908902691512
  - .nan
  - 0.5750438486594838
  - 0.589468282477401
  - .nan
  - 0.5737553424974009
  - .nan
  - 0.5763459841129744
  - 0.5754822954822956
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9486842105263158
  - .nan
  - .nan
  - 0.9526315789473683
  - 0.9618421052631579
  - 0.9537869062901155
  - .nan
  - 0.93375
  - 0.95125
  - .nan
  - 0.9341463414634147
  - .nan
  - 0.94375
  - 0.9353658536585366
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9289428777342988
  - .nan
  - .nan
  - 0.9346745573153581
  - 0.9472614236836829
  - 0.936253677672442
  - .nan
  - 0.9078841142570784
  - 0.9324624008210634
  - .nan
  - 0.9083358455162465
  - .nan
  - 0.9215578111209181
  - 0.9101025045415289
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.32827793983094694
  - .nan
  - .nan
  - 0.34078780337063586
  - 0.3414124337158552
  - 0.34099716973523675
  - .nan
  - 0.30806933573693723
  - 0.32872747005868486
  - .nan
  - 0.3055586578156367
  - .nan
  - 0.30714755841697555
  - 0.30833991284483897
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9741721854304636
  - .nan
  - .nan
  - 0.976158940397351
  - 0.9808201058201058
  - 0.9767441860465116
  - .nan
  - 0.966624685138539
  - 0.9754716981132076
  - .nan
  - 0.9668304668304668
  - .nan
  - 0.9716981132075472
  - 0.9674447174447174
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9486842105263158
  - .nan
  - .nan
  - 0.9526315789473684
  - 0.9618421052631579
  - 0.9537869062901155
  - .nan
  - 0.93375
  - 0.95125
  - .nan
  - 0.9341463414634147
  - .nan
  - 0.94375
  - 0.9353658536585366
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9513349599163472
  - .nan
  - .nan
  - 0.9548902056465669
  - 0.9633058340295182
  - 0.9559363525091801
  - .nan
  - 0.9381722292191437
  - 0.9536415094339623
  - .nan
  - 0.9385150116857434
  - .nan
  - 0.9469339622641509
  - 0.9395742194522682
  - .nan
  LL_recall_macro:
  - .nan
  - 0.5568181818181818
  - .nan
  - .nan
  - 0.5609756097560976
  - 0.5606060606060606
  - 0.5609756097560976
  - .nan
  - 0.5508474576271186
  - 0.5568181818181818
  - .nan
  - 0.55
  - .nan
  - 0.55
  - 0.5508474576271186
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9486842105263158
  - .nan
  - .nan
  - 0.9526315789473684
  - 0.9618421052631579
  - 0.9537869062901155
  - .nan
  - 0.93375
  - 0.95125
  - .nan
  - 0.9341463414634147
  - .nan
  - 0.94375
  - 0.9353658536585366
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9486842105263158
  - .nan
  - .nan
  - 0.9526315789473684
  - 0.9618421052631579
  - 0.9537869062901155
  - .nan
  - 0.93375
  - 0.95125
  - .nan
  - 0.9341463414634147
  - .nan
  - 0.94375
  - 0.9353658536585366
  - .nan
  LL_roc_auc:
  - 0.5740740740740741
  - 0.5568181818181818
  - 0.5648148148148148
  - 0.553264691109995
  - 0.5609756097560976
  - 0.5606060606060606
  - 0.5609756097560976
  - 0.556199752628324
  - 0.5508474576271186
  - 0.5568181818181818
  - 0.56
  - 0.55
  - 0.5558396712999387
  - 0.55
  - 0.5508474576271186
  - 0.5583333333333333
  LT_average_precision:
  - 0.15998329156223892
  - 0.09979949874686717
  - 0.1250355022800843
  - 0.05977443609022557
  - 0.27467437533227007
  - 0.24015037593984961
  - 0.05842330184435447
  - 0.06942570100464837
  - 0.1607142857142857
  - 0.164021164021164
  - 0.08076923076923077
  - 0.05144855144855145
  - 0.12420634920634921
  - 0.10776014109347443
  - 0.08653846153846155
  - 0.10475113122171946
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.550863213811421
  - 0.5187551867219917
  - 0.6051724137931035
  - 0.49126302881667683
  - 0.6766732283464567
  - 0.5963414634146341
  - 0.5205673758865248
  - 0.5378151260504201
  - 0.5688743781094527
  - 0.6055482359830187
  - 0.46443514644351463
  - 0.5051113545089448
  - 0.5530817610062894
  - 0.5325720977894891
  - 0.5405188246097337
  - 0.5267489711934157
  TL_average_precision:
  - 0.16825396825396824
  - 0.11978021978021978
  - 0.1251451800232288
  - 0.14286309896065993
  - 0.11071428571428571
  - 0.16190476190476188
  - 0.213472706155633
  - 0.1354559653970924
  - 0.11153846153846153
  - 0.05416666666666667
  - 0.12466124661246611
  - 0.052845528455284556
  - 0.04583333333333333
  - 0.16785714285714284
  - 0.036585365853658534
  - 0.08724202626641653
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5521628498727735
  - 0.5315471045808123
  - 0.5630559916274201
  - 0.5657786038826931
  - 0.4879518072289157
  - 0.5398763020833334
  - 0.5672364672364673
  - 0.5193798449612402
  - 0.5931887495764149
  - 0.486784140969163
  - 0.5194931773879142
  - 0.4871244635193133
  - 0.5243478260869566
  - 0.5640711220110362
  - 0.48945147679324896
  - 0.5163420270716408
  TT_average_precision:
  - 0.030612244897959183
  - 0.08163265306122448
  - 0.11923076923076924
  - 0.03296703296703297
  - 0.13340891912320485
  - 0.1609105180533752
  - 0.20457875457875457
  - 0.08791208791208792
  - 0.0734126984126984
  - 0.07142857142857142
  - 0.01282051282051282
  - 0.1623931623931624
  - 0.03571428571428571
  - 0.07142857142857142
  - 0.05128205128205128
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.4736842105263158
  - 0.49444444444444446
  - 0.602891156462585
  - 0.42045454545454547
  - 0.6286231884057971
  - 0.5321266968325792
  - 0.5419753086419753
  - 0.4939759036144578
  - 0.5032051282051283
  - 0.4423076923076923
  - 0.4675324675324675
  - 0.6157407407407407
  - 0.49382716049382713
  - 0.48717948717948717
  - 0.4864864864864865
  - .nan
  fit_time:
  - 0.3168785572052002
  - 0.3195836544036865
  - 0.3095817565917969
  - 0.315230131149292
  - 0.35513949394226074
  - 0.28630852699279785
  - 0.3458261489868164
  - 0.3004171848297119
  - 0.31952548027038574
  - 0.3165459632873535
  - 0.31395959854125977
  - 0.33566832542419434
  - 0.32628893852233887
  - 0.3207085132598877
  - 0.33313822746276855
  - 0.33266210556030273
  score_time:
  - 0.18063712120056152
  - 0.17443037033081055
  - 0.18694615364074707
  - 0.17807769775390625
  - 0.18491005897521973
  - 0.18280744552612305
  - 0.18114876747131348
  - 0.18716692924499512
  - 0.20366215705871582
  - 0.2125716209411621
  - 0.18001937866210938
  - 0.21542143821716309
  - 0.19803786277770996
  - 0.19115805625915527
  - 0.20722436904907227
  - 0.17673468589782715
start: 2023-11-01 11:41:48.729416
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
