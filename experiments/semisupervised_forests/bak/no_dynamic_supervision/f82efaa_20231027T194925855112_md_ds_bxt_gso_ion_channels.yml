active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - precision_weighted
    - recall_weighted
    - precision_micro
    - recall_macro
    - matthews_corrcoef
    - f1_micro
    - precision_macro
    - roc_auc
    - f1_weighted
    - balanced_accuracy
    - average_precision
    - recall_micro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-27 19:49:40.571013
estimator:
  call: semisupervised_forests.estimators.md_ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ds_bxt_gso
  params: {}
hash: f82efaaf5e943b4494af676c4cc74294e96d570f1d818fda382391c617a8926d
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/f82efaa_20231027T194925855112_md_ds_bxt_gso_ion_channels.yml"
results:
  LL_average_precision:
  - 0.5184005661712668
  - 0.5222274126592223
  - 0.5176092708181601
  - 0.5212046109878927
  - 0.5179426335289955
  - 0.5213781598841959
  - 0.5169603706461487
  - 0.518672176399247
  - 0.5182803961535615
  - 0.517666401764147
  - 0.5171672044345165
  - 0.5168940220543823
  - 0.5184414452255325
  - 0.5183187640219469
  - 0.5174497673056435
  - 0.5170672842109275
  LL_balanced_accuracy:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_f1_macro:
  - 0.8286026200873362
  - .nan
  - 0.8292413854501421
  - .nan
  - 0.8287236090611564
  - .nan
  - 0.8289825544377944
  - .nan
  - 0.8290503652067968
  - .nan
  - 0.8289280937519903
  - .nan
  - 0.8290039908492242
  - .nan
  - 0.8292875847754466
  - .nan
  LL_f1_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538514
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_f1_weighted:
  - 0.978619720602309
  - .nan
  - 0.9802433876449146
  - .nan
  - 0.9791496381427907
  - .nan
  - 0.9802866917354942
  - .nan
  - 0.9794433538280974
  - .nan
  - 0.9800472204748734
  - .nan
  - 0.979250620929605
  - .nan
  - 0.9804349774611915
  - .nan
  LL_matthews_corrcoef:
  - 0.700447894610418
  - .nan
  - 0.7013905925141326
  - .nan
  - 0.7006174228557172
  - .nan
  - 0.7009803892718732
  - .nan
  - 0.7011211134187072
  - .nan
  - 0.700904035830809
  - .nan
  - 0.70105565880409
  - .nan
  - 0.7014558703735905
  - .nan
  LL_precision_macro:
  - 0.9906272530641673
  - .nan
  - 0.9913517380691861
  - .nan
  - 0.9908647732089868
  - .nan
  - 0.9913735061437469
  - .nan
  - 0.9909938546302183
  - .nan
  - 0.991266467443916
  - .nan
  - 0.990907549489212
  - .nan
  - 0.9914373474711773
  - .nan
  LL_precision_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_precision_weighted:
  - 0.9819443615291318
  - .nan
  - 0.983292333552872
  - .nan
  - 0.9823851865240354
  - .nan
  - 0.9833322464202088
  - .nan
  - 0.9826258367080601
  - .nan
  - 0.9831326562431352
  - .nan
  - 0.9824653978826134
  - .nan
  - 0.9834520558930446
  - .nan
  LL_recall_macro:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_recall_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_recall_weighted:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_roc_auc:
  - 0.75
  - 0.7522485401582435
  - 0.7503037667071689
  - 0.7524626290229337
  - 0.75
  - 0.7520420111407384
  - 0.75
  - 0.7511939956000198
  - 0.7502937720329025
  - 0.7499454153670204
  - 0.75
  - 0.7502265119298966
  - 0.7502910360884749
  - 0.7505726791540509
  - 0.7503067484662577
  - 0.7505951086172415
  LT_average_precision:
  - 0.3200381023717076
  - 0.106626825227667
  - 0.18141273450892575
  - 0.2740123299578538
  - 0.27610698878304
  - 0.1289878725457256
  - 0.1677199905985761
  - 0.2533923170313443
  - 0.3151532063838615
  - 0.09865914873170986
  - 0.17345367059226766
  - 0.2246352165518698
  - 0.3636219025328086
  - 0.15737021913992258
  - 0.16482972990555067
  - 0.27332092543238207
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.7683590032590262
  - 0.6755536974645254
  - 0.6531171630094044
  - 0.7327820731227888
  - 0.7584433813704656
  - 0.6359729810309273
  - 0.675780051092403
  - 0.7175858377898675
  - 0.7634744116272778
  - 0.6571327505803338
  - 0.6785007072135786
  - 0.7163103995010575
  - 0.8021634581040522
  - 0.6839721304826466
  - 0.6725464250630245
  - 0.7175732140518596
  TL_average_precision:
  - 0.6166454950087609
  - 0.6158953550498141
  - 0.6109142385208666
  - 0.5921295121158445
  - 0.7244377961850357
  - 0.7098220410329797
  - 0.6863232639088501
  - 0.6755338666578117
  - 0.6022328228733416
  - 0.584157517720977
  - 0.5652262044226195
  - 0.5395525542122935
  - 0.6697568700330607
  - 0.6957379278424695
  - 0.7050023973369115
  - 0.6959609077382739
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.9031641926046212
  - 0.8940263822549729
  - 0.8789067922015898
  - 0.8756310418567017
  - 0.927096021770118
  - 0.9047109135466597
  - 0.8887976340793879
  - 0.8847280687901281
  - 0.8636890786227757
  - 0.8694683252598411
  - 0.8631042441833535
  - 0.8324538179312998
  - 0.8880184160530785
  - 0.9068959080079982
  - 0.9160353757795708
  - 0.9005596900457887
  TT_average_precision:
  - 0.2192508241019368
  - 0.08083479053469908
  - 0.12642813457871413
  - 0.17177874448937644
  - 0.28402241078848556
  - 0.12292983937385263
  - 0.23822732280070164
  - 0.3258841518529514
  - 0.22268812832324184
  - 0.11422353559828648
  - 0.13248708221693775
  - 0.20322525894386817
  - 0.44570707354550826
  - 0.09525373196242012
  - 0.14271921827508874
  - 0.15316218859306233
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.7611850087628635
  - 0.6661074967045115
  - 0.6160089424572316
  - 0.6933741390056413
  - 0.7917478882391162
  - 0.6679113400165547
  - 0.7143548154704321
  - 0.718294783464567
  - 0.7682539219688576
  - 0.657251821685206
  - 0.6322688087774294
  - 0.6812298834132038
  - 0.8304968483500186
  - 0.6756122769963601
  - 0.6335259034905678
  - 0.6435838154692303
  fit_time:
  - 6.516514301300049
  - 8.141277551651001
  - 8.760597467422485
  - 13.38168740272522
  - 13.508290529251099
  - 12.184624433517456
  - 13.366976976394653
  - 13.817018508911133
  - 12.881287574768066
  - 12.879441976547241
  - 13.729762077331543
  - 13.00855827331543
  - 13.273675680160522
  - 13.45693325996399
  - 13.968456268310547
  - 13.659986734390259
  score_time:
  - 0.575770378112793
  - 0.45474839210510254
  - 0.5432393550872803
  - 0.6963298320770264
  - 0.8285338878631592
  - 0.6219842433929443
  - 0.890347957611084
  - 0.6017043590545654
  - 0.8283631801605225
  - 0.6455988883972168
  - 0.7134871482849121
  - 0.7060284614562988
  - 0.8808603286743164
  - 0.6718785762786865
  - 0.6720693111419678
  - 0.6348719596862793
start: 2023-10-27 19:49:25.855112
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
