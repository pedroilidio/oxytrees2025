active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-22 02:11:13.766137
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_fixed
  params: {}
hash: 15c55353306cdea13b6423fdaf19a59252e6fd749088cc5e710f0db2b67a6f5c
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/15c5535_20231122T015525602401_ss_bxt_gso__ad_fixed_srn.yml"
results:
  LL_average_precision:
  - 0.5074568288854003
  - 0.5096658275008209
  - 0.5101373839224724
  - 0.5091451500774475
  - 0.5073903646378024
  - 0.5092240117130308
  - 0.51000379928571
  - 0.5086814227887348
  - 0.5077519706397661
  - 0.5094565498234432
  - 0.5099130135216605
  - 0.5091721497997849
  - 0.507785474031817
  - 0.5096505145342909
  - 0.5098871759538369
  - 0.5091805302917183
  LL_balanced_accuracy:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LL_f1_macro:
  - 0.8314480386320037
  - 0.8310414363167833
  - 0.8309122589895
  - 0.831184864605617
  - 0.8314650310208686
  - 0.8309949768638805
  - 0.8309486760583671
  - 0.8311343420769415
  - 0.8315768911260664
  - 0.8309351784710635
  - 0.8308176732949537
  - 0.8311772764864036
  - 0.8315673743577114
  - 0.8310455215222828
  - 0.8308243288923081
  - 0.8311749613452004
  LL_f1_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_f1_weighted:
  - 0.9913144246203527
  - 0.9890129861171519
  - 0.9884522768094858
  - 0.9896339132120522
  - 0.9913917153579066
  - 0.9892602220289276
  - 0.9886107805461859
  - 0.9898907637859482
  - 0.991311605810756
  - 0.9889900368102555
  - 0.9884597553300393
  - 0.9896014518738154
  - 0.9912710681297154
  - 0.9890310190308662
  - 0.9884897683555678
  - 0.9895914431979407
  LL_matthews_corrcoef:
  - 0.7044455795413791
  - 0.703890773724703
  - 0.7037080731892178
  - 0.7040937917409927
  - 0.7044695207119591
  - 0.7038075425098462
  - 0.7037595539722392
  - 0.7040037464694384
  - 0.7046499702645479
  - 0.7037233725349716
  - 0.703558005695909
  - 0.704083033289916
  - 0.704636452228808
  - 0.7038965412335582
  - 0.7035673711922977
  - 0.7040797550103249
  LL_precision_macro:
  - 0.9962435745353895
  - 0.9952361892994805
  - 0.9949901195232996
  - 0.9955083441312799
  - 0.9962773056121375
  - 0.9953450568937491
  - 0.9950597096709662
  - 0.9956212750430053
  - 0.9962418888898645
  - 0.9952265850519946
  - 0.9949938673788046
  - 0.9954941254171301
  - 0.9962241950071564
  - 0.9952440985958353
  - 0.9950070458064404
  - 0.9954897411163542
  LL_precision_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_precision_weighted:
  - 0.9925991931584204
  - 0.9906522968794151
  - 0.9901791229895054
  - 0.9911767270935125
  - 0.9926646595001204
  - 0.9908618627864404
  - 0.9903128441962585
  - 0.9913946043365197
  - 0.9925959865981713
  - 0.9906337302491243
  - 0.9901862381990698
  - 0.9911492996631202
  - 0.9925616536340698
  - 0.990667521421689
  - 0.9902115564794455
  - 0.9911408431439362
  LL_recall_macro:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LL_recall_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_recall_weighted:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_roc_auc:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LT_average_precision:
  - 0.02971030773260444
  - 0.018962091943289697
  - 0.016346668609388288
  - 0.022852256924153158
  - 0.028681754617333622
  - 0.018488156821358112
  - 0.01534572168546196
  - 0.02431721258133356
  - 0.028741335642921025
  - 0.018280593705277074
  - 0.018367057240393857
  - 0.0245467363492358
  - 0.030748413097840443
  - 0.018379607223848328
  - 0.016471561600640446
  - 0.02265461848662459
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5349160825299364
  - 0.5448682733484971
  - 0.5513100495259353
  - 0.5595176033086574
  - 0.5238527980071409
  - 0.5357535904186294
  - 0.545075097512852
  - 0.558712118810641
  - 0.5232201659708882
  - 0.5483109255564935
  - 0.5629171153943511
  - 0.5552318834530862
  - 0.5256792638325537
  - 0.5313248700550962
  - 0.5597288021949907
  - 0.5478455755199236
  TL_average_precision:
  - 0.09871399516763371
  - 0.09835237954194334
  - 0.13555795311521346
  - 0.09757096165010838
  - 0.1260259677719957
  - 0.14759132890067309
  - 0.14580185753291652
  - 0.14839674395417524
  - 0.13770377724691402
  - 0.11844774630362459
  - 0.13644776745560006
  - 0.1209772059963369
  - 0.11401915448458809
  - 0.1235165889081811
  - 0.12992542266692161
  - 0.10823248744516303
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6183646095149891
  - 0.6291974630705081
  - 0.6398207450919232
  - 0.6160884546760531
  - 0.6142397999146838
  - 0.6389755711951981
  - 0.6447060296903709
  - 0.6364962931584895
  - 0.6337314597125678
  - 0.6353976141850445
  - 0.6527140803196343
  - 0.6360656198025789
  - 0.617226415733353
  - 0.6268805652698575
  - 0.6307190353546691
  - 0.6113997043406281
  TT_average_precision:
  - 0.029204855341865354
  - 0.016143743133194204
  - 0.014928634209647386
  - 0.02090895016025996
  - 0.031783722482243315
  - 0.018957828363991635
  - 0.015609975860950021
  - 0.02178288808367319
  - 0.028417304486753638
  - 0.018180223394702967
  - 0.016669896361422305
  - 0.023052046509306715
  - 0.02753540429873105
  - 0.01565970838499827
  - 0.012677204445884193
  - 0.020151406873675493
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5431792401939051
  - 0.529916239524737
  - 0.5724191107656179
  - 0.543457777218165
  - 0.5390937253042516
  - 0.5480408890752778
  - 0.5225413144463706
  - 0.549490478092955
  - 0.5433626565390329
  - 0.5721679915255757
  - 0.5872951773418571
  - 0.5537784223930199
  - 0.5243891207276562
  - 0.5306846631577815
  - 0.527015022675737
  - 0.5172351459333707
  fit_time:
  - 643.5600712299347
  - 880.480199098587
  - 926.8638665676117
  - 934.5891396999359
  - 673.2689833641052
  - 904.9643371105194
  - 911.6655516624451
  - 691.5709612369537
  - 906.2107813358307
  - 935.3218746185303
  - 730.4894688129425
  - 716.8155364990234
  - 661.1638698577881
  - 868.5748701095581
  - 941.7519497871399
  - 681.3566584587097
  score_time:
  - 10.174740552902222
  - 10.782210350036621
  - 5.625114917755127
  - 5.305970191955566
  - 7.724742889404297
  - 9.095539093017578
  - 7.717488527297974
  - 6.245646953582764
  - 9.041433572769165
  - 5.24442458152771
  - 5.3920392990112305
  - 5.719132900238037
  - 9.56890869140625
  - 10.663859128952026
  - 5.072549819946289
  - 6.594887733459473
start: 2023-11-22 01:55:25.602401
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
