active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 13:36:41.850380
estimator:
  call: semisupervised_forests.estimators.adss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: adss_bxt_gso
  params: {}
hash: 0f145cd063ac21f557704eac63ff8c5eaea4c634ee1059c2539ce6f76e194a78
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/0f145cd_20231101T125534326620_adss_bxt_gso_srn.yml"
results:
  LL_average_precision:
  - 0.11342229199372057
  - 0.11739848950147766
  - 0.11816217157894254
  - 0.11617616567672061
  - 0.11353501938359256
  - 0.11696981379179296
  - 0.1179205717775326
  - 0.11582152870909224
  - 0.11383853592976577
  - 0.117200494035632
  - 0.11818405821317018
  - 0.11632054356431842
  - 0.11401385325727043
  - 0.11701235249776337
  - 0.11796768773573779
  - 0.11624124384896081
  LL_balanced_accuracy:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_f1_macro:
  - 0.587525766149485
  - 0.5869569262020368
  - 0.586646374465257
  - 0.5869816036506083
  - 0.5877519171302815
  - 0.5870260223678899
  - 0.586712444341127
  - 0.5871295948036175
  - 0.5878614038397703
  - 0.5867602867102066
  - 0.586687900893901
  - 0.5870483832903317
  - 0.5879402844460085
  - 0.5866607317273869
  - 0.5865557606018998
  - 0.5869642543352205
  LL_f1_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_f1_weighted:
  - 0.9811321823453176
  - 0.9761414287195214
  - 0.9749212382495934
  - 0.9774776314203629
  - 0.9813074311317526
  - 0.9766889473454499
  - 0.9752651098766671
  - 0.9780497795168125
  - 0.9811260532825248
  - 0.9760953339344545
  - 0.9749522354593334
  - 0.9774108918568967
  - 0.9810418010034022
  - 0.9761657817869357
  - 0.9750099646383824
  - 0.977385480503414
  LL_matthews_corrcoef:
  - 0.31409515446139513
  - 0.3141683958690032
  - 0.3138616381656739
  - 0.31390578049604967
  - 0.31448500361571946
  - 0.3141728200322513
  - 0.3139073145897686
  - 0.3140545703121901
  - 0.31473502795779823
  - 0.31380563801371575
  - 0.3139332792843214
  - 0.3140481470423044
  - 0.3149043644977443
  - 0.31360011679080124
  - 0.31366898336781385
  - 0.31389415520984937
  LL_precision_macro:
  - 0.9932788302806383
  - 0.9914900047493631
  - 0.9910530770160804
  - 0.9919701600787443
  - 0.9933405484664932
  - 0.9916864403123518
  - 0.9911763690650834
  - 0.9921748283121097
  - 0.9932749711971511
  - 0.9914746742600742
  - 0.9910639546423424
  - 0.9919457817811599
  - 0.9932443637569717
  - 0.9915006342166346
  - 0.9910856057991025
  - 0.9919371538023503
  LL_precision_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_precision_weighted:
  - 0.9867581350113046
  - 0.9833014126376041
  - 0.982461332030557
  - 0.9842264253782121
  - 0.9868779600334681
  - 0.9836796181124469
  - 0.9826982055854259
  - 0.9846213911194873
  - 0.9867507367598339
  - 0.983271829190631
  - 0.9824822418385274
  - 0.9841794371787886
  - 0.9866913777610021
  - 0.983321742323542
  - 0.9825237643341496
  - 0.9841627673678994
  LL_recall_macro:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_recall_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_recall_weighted:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_roc_auc:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LT_average_precision:
  - 0.027794121229484204
  - 0.015436049314559445
  - 0.013617105988249433
  - 0.019732538560011382
  - 0.027524726852012852
  - 0.015180247372821368
  - 0.015067409147149984
  - 0.019230384019359444
  - 0.02741797835738423
  - 0.015245616077887757
  - 0.012254135367184008
  - 0.019164765516699697
  - 0.026645624294011166
  - 0.01585853947903703
  - 0.013473623468287772
  - 0.02041005842647951
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5109006885524566
  - 0.5081289961920339
  - 0.525769280389022
  - 0.5129041694180887
  - 0.5208002682569155
  - 0.5105113580649439
  - 0.5334855591691197
  - 0.5148954789348877
  - 0.5071092260389618
  - 0.5087180183507023
  - 0.5043144016273857
  - 0.5084280371178459
  - 0.5041648095967391
  - 0.5071169242425481
  - 0.5218532314840348
  - 0.5167520141842912
  TL_average_precision:
  - 0.03693975415446563
  - 0.036709294126511735
  - 0.04829771552077232
  - 0.052227247992398196
  - 0.02897890316903537
  - 0.04402903074217112
  - 0.04534085542682638
  - 0.05048770169668327
  - 0.036580204304019245
  - 0.06479568737271821
  - 0.047216041927789505
  - 0.0474106421432566
  - 0.02373488275624413
  - 0.03638876521146383
  - 0.0349677484695208
  - 0.04174788844847756
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5272577711571025
  - 0.5243652024148804
  - 0.5306047043304689
  - 0.5402442005676618
  - 0.5169790618716851
  - 0.5272127085744084
  - 0.5248026553566896
  - 0.5310070978779534
  - 0.5259575382761672
  - 0.5367260987232495
  - 0.5287443675191242
  - 0.5343305770843193
  - 0.5193676769679457
  - 0.52193329293046
  - 0.5233364783982224
  - 0.5275692005364913
  TT_average_precision:
  - 0.02580696761356147
  - 0.014998834675757867
  - 0.01337928398340538
  - 0.01855124138530313
  - 0.030495111058921713
  - 0.01576360696459072
  - 0.020221868299646114
  - 0.019852569486981705
  - 0.02580604456866626
  - 0.0159871746524656
  - 0.011687028908371673
  - 0.018522395270877227
  - 0.026042845198978055
  - 0.014526579201271164
  - 0.011546781059671175
  - 0.019169531930370274
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5104641222177884
  - 0.49834423095095476
  - 0.5208674620125164
  - 0.5130765760094015
  - 0.5257802012538855
  - 0.5177250996015936
  - 0.5454017629568194
  - 0.5235608824965597
  - 0.509322386251523
  - 0.5019923992191447
  - 0.5089534708628218
  - 0.5068610340814355
  - 0.5026538960255303
  - 0.4897519024400745
  - 0.5145391156462585
  - 0.5049646255267557
  fit_time:
  - 2376.069803237915
  - 2406.388165473938
  - 2434.2056546211243
  - 2450.9380910396576
  - 2322.3566076755524
  - 2378.3889009952545
  - 2412.7369587421417
  - 2342.078501701355
  - 2418.507884979248
  - 2287.474593400955
  - 2362.4164690971375
  - 2458.332309961319
  - 2432.5922980308533
  - 2301.118938922882
  - 2407.1609375476837
  - 2453.4163162708282
  score_time:
  - 9.167790412902832
  - 10.016934633255005
  - 8.859519958496094
  - 8.828722953796387
  - 10.929439306259155
  - 9.407966136932373
  - 8.536071300506592
  - 9.60172438621521
  - 9.511569261550903
  - 12.332151412963867
  - 9.273745775222778
  - 7.926452875137329
  - 8.363813161849976
  - 12.392462730407715
  - 9.03048324584961
  - 8.249899864196777
start: 2023-11-01 12:55:34.326620
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
