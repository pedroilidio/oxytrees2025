active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-30 14:48:59.913616
estimator:
  call: semisupervised_forests.estimators.rs_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: rs_bxt_gso
  params: {}
hash: 8674a72660e395d8f8d3d622d5183033b1136892b69505b59679fb2a482b1c7d
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/8674a72_20231030T144859307657_rs_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.37329434697855746
  - 0.3576555023923445
  - 0.3795464270432178
  - 0.40250515423814526
  - 0.3521731157161196
  - 0.33329346092503986
  - 0.35301668806161746
  - 0.3510109114249037
  - 0.360477657935285
  - 0.3556818181818182
  - 0.36146341463414633
  - 0.3492753623188406
  - 0.3758467741935484
  - 0.34375
  - 0.3550847457627119
  - 0.3503423192126658
  LL_balanced_accuracy:
  - .nan
  - 0.6590909090909091
  - .nan
  - .nan
  - .nan
  - 0.6515151515151515
  - 0.6585365853658537
  - .nan
  - .nan
  - 0.6590909090909091
  - .nan
  - .nan
  - .nan
  - 0.65
  - 0.652542372881356
  - .nan
  LL_f1_macro:
  - .nan
  - 0.7311193924241709
  - .nan
  - .nan
  - .nan
  - 0.7247720867251343
  - 0.7314322301024428
  - .nan
  - .nan
  - 0.7316516838856837
  - .nan
  - .nan
  - .nan
  - 0.7193685793034327
  - 0.7206504308231756
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9605263157894737
  - .nan
  - .nan
  - .nan
  - 0.969736842105263
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625000000000001
  - .nan
  - .nan
  - .nan
  - 0.95625
  - 0.9500000000000001
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9507226011157428
  - .nan
  - .nan
  - .nan
  - 0.9618788373999034
  - 0.9550723736054083
  - .nan
  - .nan
  - 0.9531665101301491
  - .nan
  - .nan
  - .nan
  - 0.9449699323477826
  - 0.9373441018354647
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.5526176822228344
  - .nan
  - .nan
  - .nan
  - 0.541975436470486
  - 0.5527051915086619
  - .nan
  - .nan
  - 0.5532065382625239
  - .nan
  - .nan
  - .nan
  - 0.5353729576861872
  - 0.5380410245015365
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9798927613941019
  - .nan
  - .nan
  - .nan
  - 0.9846666666666667
  - 0.9817232375979112
  - .nan
  - .nan
  - 0.9809160305343512
  - .nan
  - .nan
  - .nan
  - 0.9777070063694268
  - 0.9744389027431422
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9605263157894737
  - .nan
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - .nan
  - .nan
  - .nan
  - 0.95625
  - 0.95
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9621137293636236
  - .nan
  - .nan
  - .nan
  - 0.9706649122807017
  - 0.9653703449223582
  - .nan
  - .nan
  - 0.9639312977099237
  - .nan
  - .nan
  - .nan
  - 0.9582006369426752
  - 0.9525561097256857
  - .nan
  LL_recall_macro:
  - .nan
  - 0.6590909090909091
  - .nan
  - .nan
  - .nan
  - 0.6515151515151515
  - 0.6585365853658537
  - .nan
  - .nan
  - 0.6590909090909091
  - .nan
  - .nan
  - .nan
  - 0.65
  - 0.652542372881356
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9605263157894737
  - .nan
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - .nan
  - .nan
  - .nan
  - 0.95625
  - 0.95
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9605263157894737
  - .nan
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - .nan
  - .nan
  - .nan
  - 0.95625
  - 0.95
  - .nan
  LL_roc_auc:
  - 0.6656174588185918
  - 0.6590909090909091
  - 0.6666666666666666
  - 0.681290808638875
  - 0.6580447097934123
  - 0.6515151515151515
  - 0.6585365853658537
  - 0.6581014223871366
  - 0.6594729980100186
  - 0.6590909090909091
  - 0.66
  - 0.6562719298245614
  - 0.6677812745869394
  - 0.65
  - 0.652542372881356
  - 0.6495285087719298
  LT_average_precision:
  - 0.23211057947900054
  - 0.2548658359184675
  - 0.24334026807810888
  - 0.12485122071588238
  - 0.20426065162907267
  - 0.13603192473161516
  - 0.15691150954308847
  - 0.1498725446093867
  - 0.280479242979243
  - 0.1640652557319224
  - 0.15391499090478683
  - 0.08391608391608392
  - 0.08698735681494302
  - 0.4325420932700626
  - 0.19711967222677138
  - 0.2693928878798587
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6033200531208499
  - 0.6553526970954356
  - 0.7149425287356321
  - 0.6420907418761497
  - 0.5374015748031495
  - 0.5870934959349594
  - 0.647872340425532
  - 0.6582633053221288
  - 0.691386815920398
  - 0.5639730639730639
  - 0.6539151225343693
  - 0.46294267981014964
  - 0.5981132075471699
  - 0.7077294685990339
  - 0.7281910009182737
  - 0.7461873638344226
  TL_average_precision:
  - 0.1796296296296296
  - 0.12244386048733875
  - 0.2362530649116015
  - 0.26106997677119625
  - 0.26455453149001534
  - 0.179646164021164
  - 0.119731279543836
  - 0.21375099352398164
  - 0.05416666666666667
  - 0.12692307692307692
  - 0.17650933453778983
  - 0.11991869918699188
  - 0.2152777777777778
  - 0.029166666666666667
  - 0.23735320686540198
  - 0.09382179651756031
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5737913486005088
  - 0.6214347450302508
  - 0.6453427524856096
  - 0.6054316398182569
  - 0.5831713952584532
  - 0.5432128906250001
  - 0.5317663817663818
  - 0.6178829190056134
  - 0.45154185022026433
  - 0.4794984750931887
  - 0.5532407407407408
  - 0.6039947177286233
  - 0.711304347826087
  - 0.4248927038626609
  - 0.6244725738396624
  - 0.5653681082865633
  TT_average_precision:
  - 0.03892668178382464
  - 0.23622448979591837
  - 0.13009049773755654
  - 0.03296703296703297
  - 0.21768707482993196
  - 0.1609105180533752
  - 0.21080586080586078
  - 0.12334783272283273
  - 0.11619674185463659
  - 0.13650793650793652
  - 0.01282051282051282
  - 0.17841369157158632
  - 0.051587301587301584
  - 0.2518433179723502
  - 0.06647435897435897
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5350877192982456
  - 0.554861111111111
  - 0.6258503401360545
  - 0.36363636363636365
  - 0.5244565217391305
  - 0.48868778280542985
  - 0.648148148148148
  - 0.5632530120481929
  - 0.6367521367521367
  - 0.6196581196581197
  - 0.35714285714285715
  - 0.6435185185185185
  - 0.5329218106995884
  - 0.594017094017094
  - 0.5777027027027026
  - .nan
  fit_time:
  - 0.316784143447876
  - 0.3097226619720459
  - 0.38881397247314453
  - 0.33836984634399414
  - 0.3021376132965088
  - 0.301800012588501
  - 0.3274550437927246
  - 0.3309347629547119
  - 0.3237013816833496
  - 0.33031296730041504
  - 0.3500816822052002
  - 0.33978891372680664
  - 0.3575470447540283
  - 0.3339521884918213
  - 0.3321859836578369
  - 0.3686685562133789
  score_time:
  - 0.15016627311706543
  - 0.18667125701904297
  - 0.1966552734375
  - 0.18419337272644043
  - 0.17574405670166016
  - 0.18218183517456055
  - 0.19864654541015625
  - 0.17877602577209473
  - 0.17351412773132324
  - 0.19367456436157227
  - 0.17721176147460938
  - 0.17798304557800293
  - 0.19153070449829102
  - 0.20704317092895508
  - 0.1731865406036377
  - 0.20158076286315918
start: 2023-10-30 14:48:59.307657
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
