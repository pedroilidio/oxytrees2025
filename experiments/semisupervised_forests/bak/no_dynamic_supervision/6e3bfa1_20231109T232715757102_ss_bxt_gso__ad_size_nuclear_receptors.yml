active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 23:27:17.372071
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_size
  params: {}
hash: 6e3bfa1aecf9bbd3b9ff60c14b8a742a2077a9fecb9b80eb61ab28f6d376b8da
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/6e3bfa1_20231109T232715757102_ss_bxt_gso__ad_size_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.14463937621832357
  - 0.16495215311004785
  - 0.17272856939095704
  - 0.1820720037343914
  - 0.1652545999144202
  - 0.15937001594896333
  - 0.1681643132220796
  - 0.15991266970085968
  - 0.16552360774818403
  - 0.16238636363636363
  - 0.1548780487804878
  - 0.16347270615563297
  - 0.1836290322580645
  - 0.15625
  - 0.1663290615957007
  - 0.16585365853658537
  LL_balanced_accuracy:
  - .nan
  - 0.5568181818181818
  - 0.5555555555555556
  - .nan
  - .nan
  - 0.5606060606060606
  - 0.5609756097560976
  - .nan
  - .nan
  - 0.5568181818181818
  - 0.55
  - .nan
  - .nan
  - 0.55
  - 0.5508474576271186
  - 0.55
  LL_f1_macro:
  - .nan
  - 0.5887845280872377
  - 0.5839786381842457
  - .nan
  - .nan
  - 0.5983306300231452
  - 0.5967908902691512
  - .nan
  - .nan
  - 0.589468282477401
  - 0.5767135073128764
  - .nan
  - .nan
  - 0.5763459841129744
  - 0.5754822954822956
  - 0.5737553424974009
  LL_f1_micro:
  - .nan
  - 0.9486842105263158
  - 0.938382541720154
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - .nan
  - .nan
  - 0.95125
  - 0.945121951219512
  - .nan
  - .nan
  - 0.94375
  - 0.9353658536585366
  - 0.9341463414634147
  LL_f1_weighted:
  - .nan
  - 0.9289428777342988
  - 0.9147227540014841
  - .nan
  - .nan
  - 0.9472614236836829
  - 0.936253677672442
  - .nan
  - .nan
  - 0.9324624008210634
  - 0.9234508662838279
  - .nan
  - .nan
  - 0.9215578111209181
  - 0.9101025045415289
  - 0.9083358455162465
  LL_matthews_corrcoef:
  - .nan
  - 0.32827793983094694
  - 0.32281819256897537
  - .nan
  - .nan
  - 0.3414124337158552
  - 0.34099716973523675
  - .nan
  - .nan
  - 0.32872747005868486
  - 0.3073735961454106
  - .nan
  - .nan
  - 0.30714755841697555
  - 0.30833991284483897
  - 0.3055586578156367
  LL_precision_macro:
  - .nan
  - 0.9741721854304636
  - 0.9689521345407504
  - .nan
  - .nan
  - 0.9808201058201058
  - 0.9767441860465116
  - .nan
  - .nan
  - 0.9754716981132076
  - 0.9723926380368098
  - .nan
  - .nan
  - 0.9716981132075472
  - 0.9674447174447174
  - 0.9668304668304668
  LL_precision_micro:
  - .nan
  - 0.9486842105263158
  - 0.938382541720154
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - .nan
  - .nan
  - 0.95125
  - 0.9451219512195121
  - .nan
  - .nan
  - 0.94375
  - 0.9353658536585366
  - 0.9341463414634147
  LL_precision_weighted:
  - .nan
  - 0.9513349599163472
  - 0.9422087228293812
  - .nan
  - .nan
  - 0.9633058340295182
  - 0.9559363525091801
  - .nan
  - .nan
  - 0.9536415094339623
  - 0.9481520275325452
  - .nan
  - .nan
  - 0.9469339622641509
  - 0.9395742194522682
  - 0.9385150116857434
  LL_recall_macro:
  - .nan
  - 0.5568181818181818
  - 0.5555555555555556
  - .nan
  - .nan
  - 0.5606060606060606
  - 0.5609756097560976
  - .nan
  - .nan
  - 0.5568181818181818
  - 0.55
  - .nan
  - .nan
  - 0.55
  - 0.5508474576271186
  - 0.55
  LL_recall_micro:
  - .nan
  - 0.9486842105263158
  - 0.938382541720154
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - .nan
  - .nan
  - 0.95125
  - 0.9451219512195121
  - .nan
  - .nan
  - 0.94375
  - 0.9353658536585366
  - 0.9341463414634147
  LL_recall_weighted:
  - .nan
  - 0.9486842105263158
  - 0.938382541720154
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - .nan
  - .nan
  - 0.95125
  - 0.9451219512195121
  - .nan
  - .nan
  - 0.94375
  - 0.9353658536585366
  - 0.9341463414634147
  LL_roc_auc:
  - 0.5528276151505613
  - 0.5568181818181818
  - 0.5555555555555556
  - 0.5629959819186339
  - 0.560348044370569
  - 0.5606060606060606
  - 0.5609756097560976
  - 0.556199752628324
  - 0.5502298771701091
  - 0.5568181818181818
  - 0.55
  - 0.5493969298245615
  - 0.5632485357111635
  - 0.55
  - 0.5508474576271186
  - 0.55
  LT_average_precision:
  - 0.11929824561403508
  - 0.10932330827067668
  - 0.08032902769744875
  - 0.17072488914594175
  - 0.07231620718462824
  - 0.15100250626566414
  - 0.08620107962213225
  - 0.14349977507872244
  - 0.20238095238095238
  - 0.20202821869488535
  - 0.1884004884004884
  - 0.3034965034965035
  - 0.08333333333333333
  - 0.20820105820105822
  - 0.22888805094687448
  - 0.08547008547008547
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.49800796812749004
  - 0.5292946058091286
  - 0.564655172413793
  - 0.5942673206621705
  - 0.5570866141732284
  - 0.5388211382113821
  - 0.5179078014184397
  - 0.5331465919701214
  - 0.5600124378109452
  - 0.5849070414287806
  - 0.5756126718469815
  - 0.6363636363636364
  - 0.5031446540880502
  - 0.5830039525691699
  - 0.6466942148760331
  - 0.5348583877995643
  TL_average_precision:
  - 0.10343915343915343
  - 0.0684981684981685
  - 0.08101045296167247
  - 0.1335269066976384
  - 0.1412058371735791
  - 0.16190476190476188
  - 0.12762937153181056
  - 0.11480235492010094
  - 0.05416666666666667
  - 0.05416666666666667
  - 0.07317073170731707
  - 0.052845528455284556
  - 0.18333333333333335
  - 0.029166666666666667
  - 0.11575687185443283
  - 0.125703564727955
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.53774385072095
  - 0.524200518582541
  - 0.521847200418629
  - 0.5385171416769929
  - 0.5122425184609404
  - 0.5398763020833334
  - 0.49629629629629624
  - 0.5133654103180968
  - 0.4911894273127753
  - 0.4955947136563877
  - 0.48464912280701755
  - 0.49141630901287553
  - 0.5906521739130434
  - 0.4957081545064378
  - 0.6007969995311768
  - 0.5305381313965005
  TT_average_precision:
  - 0.030612244897959183
  - 0.13392857142857142
  - 0.07783882783882784
  - 0.0695970695970696
  - 0.2806122448979592
  - 0.1326530612244898
  - 0.19890109890109892
  - 0.11858974358974358
  - 0.07142857142857142
  - 0.07142857142857142
  - 0.01282051282051282
  - 0.07692307692307693
  - 0.03571428571428571
  - 0.07142857142857142
  - 0.08846153846153847
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.5
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.48000000000000004
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9230769230769231
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.8861538461538462
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.0
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.46153846153846156
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9230769230769231
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.8520710059171598
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.5
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9230769230769231
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9230769230769231
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.45263157894736844
  - 0.5569444444444445
  - 0.5017006802721088
  - 0.6306818181818182
  - 0.7327898550724637
  - 0.48823529411764705
  - 0.5333333333333333
  - 0.5504518072289157
  - 0.4807692307692308
  - 0.47435897435897434
  - 0.474025974025974
  - 0.5
  - 0.4814814814814815
  - 0.48717948717948717
  - 0.5945945945945946
  - .nan
  fit_time:
  - 0.25125932693481445
  - 0.28803539276123047
  - 0.3413381576538086
  - 0.280163049697876
  - 0.2506439685821533
  - 0.22701048851013184
  - 0.27733469009399414
  - 0.2888987064361572
  - 0.25623345375061035
  - 0.26303768157958984
  - 0.2912416458129883
  - 0.28044867515563965
  - 0.31264734268188477
  - 0.27353358268737793
  - 0.29001379013061523
  - 0.32952189445495605
  score_time:
  - 0.1904604434967041
  - 0.22595739364624023
  - 0.1939237117767334
  - 0.19451546669006348
  - 0.18306922912597656
  - 0.1674199104309082
  - 0.17676353454589844
  - 0.19107818603515625
  - 0.16650891304016113
  - 0.20160794258117676
  - 0.18587851524353027
  - 0.19063782691955566
  - 0.17998075485229492
  - 0.18748068809509277
  - 0.20579934120178223
  - 0.20946979522705078
start: 2023-11-09 23:27:15.757102
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
