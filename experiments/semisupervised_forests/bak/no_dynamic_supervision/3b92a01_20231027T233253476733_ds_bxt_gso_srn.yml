active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - precision_weighted
    - recall_weighted
    - precision_micro
    - recall_macro
    - matthews_corrcoef
    - f1_micro
    - precision_macro
    - roc_auc
    - f1_weighted
    - balanced_accuracy
    - average_precision
    - recall_micro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-10-28 01:45:50.576789
estimator:
  call: semisupervised_forests.estimators.ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ds_bxt_gso
  params: {}
hash: 3b92a0155ccd808d5bba7d3530503dfae53cc58573dbc81e80ab3b9c626190f5
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/3b92a01_20231027T233253476733_ds_bxt_gso_srn.yml"
results:
  LL_average_precision:
  - 0.5074568288854003
  - 0.5096658275008209
  - 0.5101373839224724
  - 0.5091451500774475
  - 0.5073903646378024
  - 0.5092240117130308
  - 0.51000379928571
  - 0.5086814227887348
  - 0.5077519706397661
  - 0.5094565498234432
  - 0.5099130135216605
  - 0.5091721497997849
  - 0.507785474031817
  - 0.5096505145342909
  - 0.5098871759538369
  - 0.5091805302917183
  LL_balanced_accuracy:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LL_f1_macro:
  - 0.8314480386320037
  - 0.8310414363167833
  - 0.8309122589895
  - 0.831184864605617
  - 0.8314650310208686
  - 0.8309949768638805
  - 0.8309486760583671
  - 0.8311343420769415
  - 0.8315768911260664
  - 0.8309351784710635
  - 0.8308176732949537
  - 0.8311772764864036
  - 0.8315673743577114
  - 0.8310455215222828
  - 0.8308243288923081
  - 0.8311749613452004
  LL_f1_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_f1_weighted:
  - 0.9913144246203527
  - 0.9890129861171519
  - 0.9884522768094858
  - 0.9896339132120522
  - 0.9913917153579066
  - 0.9892602220289276
  - 0.9886107805461859
  - 0.9898907637859482
  - 0.991311605810756
  - 0.9889900368102555
  - 0.9884597553300393
  - 0.9896014518738154
  - 0.9912710681297154
  - 0.9890310190308662
  - 0.9884897683555678
  - 0.9895914431979407
  LL_matthews_corrcoef:
  - 0.7044455795413791
  - 0.703890773724703
  - 0.7037080731892178
  - 0.7040937917409927
  - 0.7044695207119591
  - 0.7038075425098462
  - 0.7037595539722392
  - 0.7040037464694384
  - 0.7046499702645479
  - 0.7037233725349716
  - 0.703558005695909
  - 0.704083033289916
  - 0.704636452228808
  - 0.7038965412335582
  - 0.7035673711922977
  - 0.7040797550103249
  LL_precision_macro:
  - 0.9962435745353895
  - 0.9952361892994805
  - 0.9949901195232996
  - 0.9955083441312799
  - 0.9962773056121375
  - 0.9953450568937491
  - 0.9950597096709662
  - 0.9956212750430053
  - 0.9962418888898645
  - 0.9952265850519946
  - 0.9949938673788046
  - 0.9954941254171301
  - 0.9962241950071564
  - 0.9952440985958353
  - 0.9950070458064404
  - 0.9954897411163542
  LL_precision_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_precision_weighted:
  - 0.9925991931584204
  - 0.9906522968794151
  - 0.9901791229895054
  - 0.9911767270935125
  - 0.9926646595001204
  - 0.9908618627864404
  - 0.9903128441962585
  - 0.9913946043365197
  - 0.9925959865981713
  - 0.9906337302491243
  - 0.9901862381990698
  - 0.9911492996631202
  - 0.9925616536340698
  - 0.990667521421689
  - 0.9902115564794455
  - 0.9911408431439362
  LL_recall_macro:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LL_recall_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_recall_weighted:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_roc_auc:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LT_average_precision:
  - 0.030454586462799367
  - 0.018569995260843734
  - 0.016292257988256162
  - 0.022114513359536358
  - 0.030266397212452268
  - 0.01766378854063807
  - 0.01757896457975807
  - 0.021446600585384383
  - 0.02893945109484337
  - 0.01702099386313636
  - 0.01712625760703658
  - 0.020293428944841464
  - 0.028751337353755756
  - 0.01798050237660821
  - 0.017526351923327684
  - 0.022710439720117576
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5300084120447633
  - 0.5341174645615527
  - 0.5605289154802318
  - 0.5448034229621135
  - 0.5346853051211431
  - 0.5360350303557755
  - 0.5681639463031491
  - 0.5461501101895191
  - 0.5173084279360969
  - 0.514414517396183
  - 0.5763708918405199
  - 0.5282936360444168
  - 0.5174387839955968
  - 0.5253046865545539
  - 0.5628780822233587
  - 0.5472914335362773
  TL_average_precision:
  - 0.11522735724987725
  - 0.12343229123283696
  - 0.108869003615168
  - 0.11635807140515837
  - 0.13904813235969152
  - 0.14579796690682617
  - 0.1384601494942956
  - 0.14806401268489536
  - 0.09833272072578494
  - 0.13610568036188872
  - 0.1279636583260095
  - 0.12962376729880845
  - 0.09159081603005258
  - 0.11448994396658438
  - 0.10999679750874602
  - 0.09472083124771079
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.630180724908152
  - 0.6309881654683862
  - 0.624861943052108
  - 0.636638233998704
  - 0.631879934615211
  - 0.6430200223698352
  - 0.6365480531138579
  - 0.6437205871284708
  - 0.6261909375649758
  - 0.6480676234411605
  - 0.6461383991579935
  - 0.6420007972242459
  - 0.6120632994686284
  - 0.6210842630660637
  - 0.6157146597476625
  - 0.5998278523858432
  TT_average_precision:
  - 0.028570105210399207
  - 0.017264269049665056
  - 0.015288305147263495
  - 0.02087800721357235
  - 0.031262313104125104
  - 0.0185113729661128
  - 0.01467030637797728
  - 0.02124678650325288
  - 0.029144501602627666
  - 0.016304183945273814
  - 0.014905291018675505
  - 0.021331760892709953
  - 0.028019180076048193
  - 0.015995883835286287
  - 0.014345605053445277
  - 0.021112362664659802
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5413968281679524
  - 0.5267426995258944
  - 0.5291879924437071
  - 0.5429296426872604
  - 0.5266341077920025
  - 0.5591755084923464
  - 0.4998058365760586
  - 0.54234847072402
  - 0.5347434359179939
  - 0.5267514693188042
  - 0.5478977700510603
  - 0.5264169970781211
  - 0.5157668509580703
  - 0.5170381133821994
  - 0.5657287414965986
  - 0.5429520325970031
  fit_time:
  - 6480.248926639557
  - 7838.048966884613
  - 7884.943323373795
  - 7709.122026205063
  - 6786.585804700851
  - 7520.504937171936
  - 7801.0947897434235
  - 7426.85299539566
  - 7122.169568061829
  - 7852.36662197113
  - 7969.543131113052
  - 7591.023133277893
  - 1607.196053981781
  - 1843.786851644516
  - 7715.695846319199
  - 7461.254710674286
  score_time:
  - 28.070453882217407
  - 7.11755895614624
  - 6.639658451080322
  - 10.08568549156189
  - 24.76231360435486
  - 18.351168632507324
  - 7.853323936462402
  - 20.14763641357422
  - 24.339000701904297
  - 6.811300754547119
  - 6.312042951583862
  - 14.329724788665771
  - 6.4883623123168945
  - 6.406218528747559
  - 9.809420347213745
  - 20.125495195388794
start: 2023-10-27 23:32:53.476733
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
