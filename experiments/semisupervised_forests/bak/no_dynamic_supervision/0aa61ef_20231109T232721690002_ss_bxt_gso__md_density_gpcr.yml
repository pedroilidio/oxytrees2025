active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 23:27:23.009400
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_density
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_density
  params: {}
hash: 0aa61ef859675cd2ee9d6052350bb6a2c70ea7be66941a97b0681b6f04a14edd
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/0aa61ef_20231109T232721690002_ss_bxt_gso__md_density_gpcr.yml"
results:
  LL_average_precision:
  - 0.13292219750541678
  - 0.12791295146716863
  - 0.12808467571898458
  - 0.12603828096785843
  - 0.13012411402021545
  - 0.1259381349631162
  - 0.12548957392669147
  - 0.12497407123151279
  - 0.13128101728977734
  - 0.132267461023851
  - 0.13052809978898497
  - 0.12661114730407275
  - 0.13113912124859695
  - 0.12919161676646707
  - 0.1286237990158645
  - 0.12477485083868062
  LL_balanced_accuracy:
  - .nan
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - .nan
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LL_f1_macro:
  - .nan
  - 0.5847208442674116
  - 0.5837653143612727
  - 0.5870688495533206
  - .nan
  - 0.5856492588358561
  - 0.5850966373850548
  - 0.5879130108468398
  - 0.5832018951551277
  - 0.5845640870780535
  - 0.5834040356341553
  - 0.5844570126107703
  - 0.5849046897913459
  - 0.5834786323799407
  - 0.5839119995104589
  - 0.5849495621610719
  LL_f1_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877287
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_f1_weighted:
  - .nan
  - 0.9620573306313152
  - 0.9606267694073672
  - 0.9671121516918916
  - .nan
  - 0.9653597927322017
  - 0.9651117491757567
  - 0.9693443788479165
  - 0.9565184684457021
  - 0.9572609982570296
  - 0.9575760616941908
  - 0.9630885380091844
  - 0.9588945479076647
  - 0.9590832652904875
  - 0.9602490593165409
  - 0.9656764038053118
  LL_matthews_corrcoef:
  - .nan
  - 0.3132124046895629
  - 0.31174146518670126
  - 0.31646487657500544
  - .nan
  - 0.31419512726773463
  - 0.3132085847508585
  - 0.31753943502006654
  - 0.3116447704230443
  - 0.3140383982123482
  - 0.31177719036802776
  - 0.31247201371939837
  - 0.31429780512252053
  - 0.31156273713967697
  - 0.31210792983689867
  - 0.3127981917430874
  LL_precision_macro:
  - .nan
  - 0.9864224684882836
  - 0.9859137055837564
  - 0.988231338264963
  - .nan
  - 0.9876099458728012
  - 0.9875253721244925
  - 0.9890317700453858
  - 0.9844278943805009
  - 0.9846817874069058
  - 0.9848100194634848
  - 0.9867989573698814
  - 0.9852720293724966
  - 0.9853566958698373
  - 0.9857750709160688
  - 0.9877310785045179
  LL_precision_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_precision_weighted:
  - .nan
  - 0.9736625432428543
  - 0.9727065423025402
  - 0.9770783409265276
  - .nan
  - 0.9759012036534148
  - 0.9757409151089271
  - 0.9785987102646133
  - 0.969930089376398
  - 0.9704048567021506
  - 0.9706423552353223
  - 0.9743704103598018
  - 0.9715068153079688
  - 0.971663306678258
  - 0.972446889690223
  - 0.9761295636181652
  LL_recall_macro:
  - .nan
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - .nan
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LL_recall_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_recall_weighted:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_roc_auc:
  - 0.552924791086351
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - 0.5529595015576324
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LT_average_precision:
  - 0.06863034010899803
  - 0.1013257466337451
  - 0.11512805960399125
  - 0.06915670642254283
  - 0.08811890582463211
  - 0.10026702220510281
  - 0.08484140841783915
  - 0.06285357571656948
  - 0.10102873746098742
  - 0.11927403665532903
  - 0.12085083577603895
  - 0.10502061330388152
  - 0.10246134979093852
  - 0.0707938112626374
  - 0.09693396490627462
  - 0.07807942855496208
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6050320906897144
  - 0.5848926342161266
  - 0.6299237542955325
  - 0.5484018114649947
  - 0.6390213989140849
  - 0.6158961554982818
  - 0.6201974196235762
  - 0.5607056315408359
  - 0.5964546694171532
  - 0.6312128601581828
  - 0.6319537790354911
  - 0.5851116811847509
  - 0.6390583385555381
  - 0.5838407048038574
  - 0.6056150022084996
  - 0.5430966822382962
  TL_average_precision:
  - 0.1513263027049694
  - 0.09026704664641705
  - 0.09622608268155095
  - 0.05216461824341052
  - 0.17282796866225708
  - 0.15218427032768647
  - 0.1527442220096421
  - 0.12217011073435222
  - 0.06508742440312223
  - 0.14284420379355273
  - 0.10671827655332261
  - 0.12122863648389307
  - 0.15050299107257956
  - 0.14233822393231807
  - 0.19335189953618453
  - 0.1069480739715151
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6021659924835757
  - 0.5854309512197454
  - 0.5882297106890646
  - 0.5346605099288497
  - 0.5822859123829046
  - 0.6004065716274782
  - 0.5933756440191873
  - 0.57482882141563
  - 0.558247739575055
  - 0.6044450688234501
  - 0.6190719455087271
  - 0.6092661764133692
  - 0.6068234764652937
  - 0.6068624828909901
  - 0.6177124083709977
  - 0.5631116758971246
  TT_average_precision:
  - 0.06603978735422206
  - 0.1122680457631969
  - 0.07283910882798697
  - 0.06556591556591557
  - 0.031881435006435005
  - 0.1176203007984923
  - 0.07073145816768264
  - 0.07806637806637806
  - 0.0712797619047619
  - 0.18596302672942946
  - 0.019019902861366275
  - 0.03510036467782947
  - 0.09951707204938698
  - 0.055167356797791584
  - 0.025579710144927534
  - 0.10696221611844309
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5912101481814099
  - 0.6273686573866187
  - 0.5565708098886136
  - 0.5374685506991984
  - 0.5228527607361964
  - 0.6036598369395823
  - 0.5978015916791427
  - 0.5582743885237852
  - 0.5209918822932522
  - 0.6495418466207541
  - 0.5159881721908952
  - 0.5420888542478565
  - 0.6381057316309116
  - 0.5067114838480653
  - 0.5538242280285035
  - 0.5552040816326531
  fit_time:
  - 0.8345777988433838
  - 0.8259093761444092
  - 0.8444697856903076
  - 0.8374817371368408
  - 0.7271661758422852
  - 0.6926283836364746
  - 0.8153645992279053
  - 0.7664666175842285
  - 0.9097185134887695
  - 0.9208042621612549
  - 0.86802077293396
  - 0.8560144901275635
  - 0.8792760372161865
  - 0.8637926578521729
  - 0.9134783744812012
  - 0.8464906215667725
  score_time:
  - 0.30741047859191895
  - 0.39888644218444824
  - 0.37226247787475586
  - 0.41579389572143555
  - 0.29290318489074707
  - 0.3683164119720459
  - 0.37589192390441895
  - 0.35538315773010254
  - 0.3456120491027832
  - 0.3533196449279785
  - 0.35141777992248535
  - 0.3914766311645508
  - 0.34465575218200684
  - 0.38170933723449707
  - 0.34392356872558594
  - 0.36406922340393066
start: 2023-11-09 23:27:21.690002
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
