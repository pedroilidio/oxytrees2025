active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 23:28:36.001619
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_size
  params: {}
hash: 832543556ba6c7d9fa6732d3e608d33af36900d86baa6be5b4fd9dae46b81aa7
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/8325435_20231109T232756270631_ss_bxt_gso__ad_size_enzymes.yml"
results:
  LL_average_precision:
  - 0.1084664158178357
  - 0.1097779623535341
  - 0.10936342389674547
  - 0.10961731806600718
  - 0.10814067079127321
  - 0.11009627214143948
  - 0.10882000781172796
  - 0.10898602379188922
  - 0.10929877328370323
  - 0.1103910170035028
  - 0.10979194032054278
  - 0.10916895733798773
  - 0.10992800028944608
  - 0.11020273671612772
  - 0.1098254030748312
  - 0.10947305144514559
  LL_balanced_accuracy:
  - .nan
  - 0.5501424501424501
  - 0.5502117362371446
  - .nan
  - 0.55
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.5502828409805154
  - .nan
  - 0.5501083423618635
  - .nan
  - 0.5502725620835857
  LL_f1_macro:
  - .nan
  - 0.5887573627847013
  - 0.5890116575652308
  - .nan
  - 0.5888637479277989
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.5892141566355339
  - .nan
  - 0.5885762854396017
  - .nan
  - 0.5891151438147866
  LL_f1_micro:
  - .nan
  - 0.9905069379313662
  - 0.9910600485775437
  - .nan
  - 0.9918593292087268
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9913967246230431
  - .nan
  - 0.9900139480075992
  - .nan
  - 0.9910720727220258
  LL_f1_weighted:
  - .nan
  - 0.9866483082444629
  - 0.9874260138360016
  - .nan
  - 0.9885457052579808
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9878998248910561
  - .nan
  - 0.9859556163022204
  - .nan
  - 0.9874437954255652
  LL_matthews_corrcoef:
  - .nan
  - 0.3151696068607889
  - 0.3154755055857953
  - .nan
  - 0.3149368125753411
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.31575252120393954
  - .nan
  - 0.31498381128476743
  - .nan
  - 0.31566844607540057
  LL_precision_macro:
  - .nan
  - 0.99524844122391
  - 0.9955255587785709
  - .nan
  - 0.9959259795755776
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9956942204462846
  - .nan
  - 0.9950014144101308
  - .nan
  - 0.995531576856878
  LL_precision_micro:
  - .nan
  - 0.9905069379313662
  - 0.9910600485775437
  - .nan
  - 0.9918593292087268
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9913967246230431
  - .nan
  - 0.9900139480075992
  - .nan
  - 0.9910720727220258
  LL_precision_weighted:
  - .nan
  - 0.9905971516161346
  - 0.9911400511518682
  - .nan
  - 0.991925659726871
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9914708122374692
  - .nan
  - 0.9901137802787771
  - .nan
  - 0.9911518602357638
  LL_recall_macro:
  - .nan
  - 0.5501424501424501
  - 0.5502117362371446
  - .nan
  - 0.55
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.5502828409805154
  - .nan
  - 0.5501083423618635
  - .nan
  - 0.5502725620835857
  LL_recall_micro:
  - .nan
  - 0.9905069379313662
  - 0.9910600485775437
  - .nan
  - 0.9918593292087268
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9913967246230431
  - .nan
  - 0.9900139480075992
  - .nan
  - 0.9910720727220258
  LL_recall_weighted:
  - .nan
  - 0.9905069379313662
  - 0.9910600485775437
  - .nan
  - 0.9918593292087268
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9913967246230431
  - .nan
  - 0.9900139480075992
  - .nan
  - 0.9910720727220258
  LL_roc_auc:
  - 0.5500295379789325
  - 0.5501424501424501
  - 0.5502117362371446
  - 0.5505342212282904
  - 0.55
  - 0.5504398826979472
  - 0.5500594557022325
  - 0.5503597122302158
  - 0.5504885993485342
  - 0.5504249291784703
  - 0.5503899220155969
  - 0.5502828409805154
  - 0.5504504504504505
  - 0.5501083423618635
  - 0.5502282126310827
  - 0.5502725620835857
  LT_average_precision:
  - 0.047654631074652204
  - 0.10611011959239765
  - 0.06176319926129594
  - 0.04771770852074613
  - 0.049402108681898704
  - 0.09171556673433524
  - 0.08431650600519357
  - 0.05542521194928475
  - 0.0783668211194244
  - 0.074054954128916
  - 0.06600244435922785
  - 0.03464301742871302
  - 0.053291942057488814
  - 0.10188637926171229
  - 0.07783194550792495
  - 0.08153967594237295
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5352408913598913
  - 0.5872910377576003
  - 0.5635262586246508
  - 0.5545662328945067
  - 0.5526875414754079
  - 0.5906982895601843
  - 0.5632638383941017
  - 0.5666045796263557
  - 0.552510667349377
  - 0.5861969906035545
  - 0.5591284894845416
  - 0.5514851450153422
  - 0.550039536727702
  - 0.5791019594088329
  - 0.5809374865986338
  - 0.5773205066663777
  TL_average_precision:
  - 0.22597423196257943
  - 0.2570786271803984
  - 0.26232378849459037
  - 0.2402020439760543
  - 0.34257897977047086
  - 0.37532153754750247
  - 0.3329538748160044
  - 0.30112175838301825
  - 0.39967951988270284
  - 0.39397422627825635
  - 0.3325868622766755
  - 0.3376458509928492
  - 0.36248050223830197
  - 0.3360729947699854
  - 0.37061030762345054
  - 0.3162751965306819
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6501748383076612
  - 0.6646345781496612
  - 0.6651158520004605
  - 0.6512028993425486
  - 0.7140044346968853
  - 0.7109255543776487
  - 0.7040131555734831
  - 0.6780744079274282
  - 0.7220959127821915
  - 0.7205487592164468
  - 0.701541305450226
  - 0.6864108434259891
  - 0.7347247757231544
  - 0.7258501665950441
  - 0.7326621356697877
  - 0.7044228423496078
  TT_average_precision:
  - 0.035563353439786914
  - 0.12781529435677083
  - 0.09720756584861048
  - 0.03417065563106629
  - 0.06067729130864029
  - 0.1269885569305589
  - 0.10984295440630168
  - 0.09510226555515078
  - 0.09939995928690841
  - 0.04424989214794853
  - 0.06494341077300056
  - 0.0431694974129255
  - 0.02857734155851601
  - 0.03688264578885888
  - 0.05727967356746992
  - 0.025020047016387416
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5284965456710534
  - 0.600301488106091
  - 0.5703582405678992
  - 0.5440430456123737
  - 0.5501286881466362
  - 0.6143899526442571
  - 0.562277378470317
  - 0.6189119272460141
  - 0.582536231884058
  - 0.6001148182869378
  - 0.5507115416133905
  - 0.5436661219904577
  - 0.532567314816254
  - 0.581915950914804
  - 0.546364900548429
  - 0.5554894896222453
  fit_time:
  - 10.603045225143433
  - 11.740454912185669
  - 11.179239273071289
  - 11.689636945724487
  - 12.48470664024353
  - 23.84037709236145
  - 23.656322479248047
  - 20.322929620742798
  - 20.698871612548828
  - 23.798872470855713
  - 24.658852577209473
  - 22.973642826080322
  - 19.827950477600098
  - 24.485652685165405
  - 23.545151948928833
  - 23.74384880065918
  score_time:
  - 6.776561975479126
  - 7.855082750320435
  - 7.849704027175903
  - 7.084662199020386
  - 7.614549875259399
  - 13.93833041191101
  - 14.558941125869751
  - 13.554010152816772
  - 13.754196405410767
  - 14.82412600517273
  - 13.927140712738037
  - 15.741953611373901
  - 14.007723093032837
  - 15.013367414474487
  - 14.747375249862671
  - 15.4292471408844
start: 2023-11-09 23:27:56.270631
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
