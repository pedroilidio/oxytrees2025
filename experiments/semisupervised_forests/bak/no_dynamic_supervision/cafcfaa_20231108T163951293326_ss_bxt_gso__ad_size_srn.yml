active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-08 16:52:17.620211
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_size
  params: {}
hash: cafcfaa93467e1f5a240b273166865cfdf8b8cad6489028764557f84dfbbcae7
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/cafcfaa_20231108T163951293326_ss_bxt_gso__ad_size_srn.yml"
results:
  LL_average_precision:
  - 0.5074568288854003
  - 0.5096658275008209
  - 0.5101373839224724
  - 0.5091451500774475
  - 0.5073903646378024
  - 0.5092240117130308
  - 0.51000379928571
  - 0.5086814227887348
  - 0.5077519706397661
  - 0.5094565498234432
  - 0.5099130135216605
  - 0.5091721497997849
  - 0.507785474031817
  - 0.5096505145342909
  - 0.5098871759538369
  - 0.5091805302917183
  LL_balanced_accuracy:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LL_f1_macro:
  - 0.8314480386320037
  - 0.8310414363167833
  - 0.8309122589895
  - 0.831184864605617
  - 0.8314650310208686
  - 0.8309949768638805
  - 0.8309486760583671
  - 0.8311343420769415
  - 0.8315768911260664
  - 0.8309351784710635
  - 0.8308176732949537
  - 0.8311772764864036
  - 0.8315673743577114
  - 0.8310455215222828
  - 0.8308243288923081
  - 0.8311749613452004
  LL_f1_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_f1_weighted:
  - 0.9913144246203527
  - 0.9890129861171519
  - 0.9884522768094858
  - 0.9896339132120522
  - 0.9913917153579066
  - 0.9892602220289276
  - 0.9886107805461859
  - 0.9898907637859482
  - 0.991311605810756
  - 0.9889900368102555
  - 0.9884597553300393
  - 0.9896014518738154
  - 0.9912710681297154
  - 0.9890310190308662
  - 0.9884897683555678
  - 0.9895914431979407
  LL_matthews_corrcoef:
  - 0.7044455795413791
  - 0.703890773724703
  - 0.7037080731892178
  - 0.7040937917409927
  - 0.7044695207119591
  - 0.7038075425098462
  - 0.7037595539722392
  - 0.7040037464694384
  - 0.7046499702645479
  - 0.7037233725349716
  - 0.703558005695909
  - 0.704083033289916
  - 0.704636452228808
  - 0.7038965412335582
  - 0.7035673711922977
  - 0.7040797550103249
  LL_precision_macro:
  - 0.9962435745353895
  - 0.9952361892994805
  - 0.9949901195232996
  - 0.9955083441312799
  - 0.9962773056121375
  - 0.9953450568937491
  - 0.9950597096709662
  - 0.9956212750430053
  - 0.9962418888898645
  - 0.9952265850519946
  - 0.9949938673788046
  - 0.9954941254171301
  - 0.9962241950071564
  - 0.9952440985958353
  - 0.9950070458064404
  - 0.9954897411163542
  LL_precision_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_precision_weighted:
  - 0.9925991931584204
  - 0.9906522968794151
  - 0.9901791229895054
  - 0.9911767270935125
  - 0.9926646595001204
  - 0.9908618627864404
  - 0.9903128441962585
  - 0.9913946043365197
  - 0.9925959865981713
  - 0.9906337302491243
  - 0.9901862381990698
  - 0.9911492996631202
  - 0.9925616536340698
  - 0.990667521421689
  - 0.9902115564794455
  - 0.9911408431439362
  LL_recall_macro:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LL_recall_micro:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_recall_weighted:
  - 0.9925431711145997
  - 0.990562378797673
  - 0.9900797241973712
  - 0.9910967463908641
  - 0.9926096353621976
  - 0.9907759882869692
  - 0.9902161743174576
  - 0.9913185772112652
  - 0.9925399149410863
  - 0.9905434501765568
  - 0.9900869864783395
  - 0.9910688140556368
  - 0.9925050547305305
  - 0.9905779002669882
  - 0.9901128240461631
  - 0.991060201533029
  LL_roc_auc:
  - 0.75
  - 0.7501141031492469
  - 0.7501085540599218
  - 0.7501209482341558
  - 0.75
  - 0.75
  - 0.7501099868015838
  - 0.75
  - 0.7501459427904262
  - 0.75
  - 0.75
  - 0.7501204819277109
  - 0.7501452643811737
  - 0.7501142074006395
  - 0.75
  - 0.7501203659123736
  LT_average_precision:
  - 0.029245987178204667
  - 0.019251878221982044
  - 0.01697239852834214
  - 0.023301495085712234
  - 0.029083088427798214
  - 0.019093576589323813
  - 0.014982614300529731
  - 0.025599797659546352
  - 0.02879102299194234
  - 0.018955743394100798
  - 0.017338132447584503
  - 0.023877628132692966
  - 0.03036703265230237
  - 0.018182673197966532
  - 0.015621886129911375
  - 0.02400576151041164
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5225634351993244
  - 0.535904777196722
  - 0.5638438450453417
  - 0.5523459493274945
  - 0.5281322215872296
  - 0.538708077887859
  - 0.5365538535895115
  - 0.5571625300689339
  - 0.5176114212729626
  - 0.534380091309026
  - 0.5692294770366484
  - 0.5500306594916131
  - 0.5239340792522664
  - 0.524369077678877
  - 0.548679798248003
  - 0.552836862125676
  TL_average_precision:
  - 0.09668385132639354
  - 0.10035321661190419
  - 0.13411105583357763
  - 0.09802368137962351
  - 0.1300940125734152
  - 0.1398804722156369
  - 0.1432947559399631
  - 0.1468308874015495
  - 0.13693625936459547
  - 0.12027566036259518
  - 0.13619954303474668
  - 0.11658612841122439
  - 0.1184354702905562
  - 0.1241461910034094
  - 0.12901992064574974
  - 0.10346896834509887
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6198355478190362
  - 0.633221718483908
  - 0.6430299603311171
  - 0.6209693985916743
  - 0.6175709381647126
  - 0.6361863850039519
  - 0.6439994418976823
  - 0.6414403270491162
  - 0.6381855035570099
  - 0.6401480422108576
  - 0.6487676111611341
  - 0.6326541283845214
  - 0.6216151821216094
  - 0.6291790574078683
  - 0.6318600300051513
  - 0.6047263945548007
  TT_average_precision:
  - 0.027650313303089015
  - 0.016501298069787437
  - 0.015259038308163084
  - 0.01995491423486269
  - 0.030929667156873945
  - 0.016349128151884048
  - 0.014850749661048658
  - 0.023653777825285716
  - 0.026795104658466136
  - 0.017085543420215205
  - 0.015178028361351514
  - 0.02301945672586086
  - 0.027086207750342553
  - 0.016602090825986324
  - 0.01271953921456625
  - 0.020298246387440575
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5301976644941031
  - 0.5200715425440022
  - 0.5458450624013538
  - 0.5243153487786452
  - 0.542119066434856
  - 0.5197789893059341
  - 0.5014801136644451
  - 0.5660977493674257
  - 0.519146335274401
  - 0.5437883496692963
  - 0.5880751803534517
  - 0.5529791710141858
  - 0.519534911470257
  - 0.5351562315003175
  - 0.5324430272108843
  - 0.5317936279474741
  fit_time:
  - 643.2137570381165
  - 734.7427921295166
  - 693.0793786048889
  - 725.4467740058899
  - 611.4034490585327
  - 733.04745054245
  - 711.4944941997528
  - 669.299637556076
  - 638.8722796440125
  - 710.3514535427094
  - 713.5044622421265
  - 724.8588092327118
  - 618.4441728591919
  - 672.5413331985474
  - 739.3640820980072
  - 722.1725935935974
  score_time:
  - 13.153202056884766
  - 6.078973293304443
  - 7.961999177932739
  - 6.631949186325073
  - 12.848518133163452
  - 6.032378196716309
  - 7.3536057472229
  - 11.359157800674438
  - 12.413150548934937
  - 7.2935004234313965
  - 7.145251750946045
  - 6.459694147109985
  - 13.299817562103271
  - 9.91312289237976
  - 5.68973445892334
  - 6.6966400146484375
start: 2023-11-08 16:39:51.293326
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
