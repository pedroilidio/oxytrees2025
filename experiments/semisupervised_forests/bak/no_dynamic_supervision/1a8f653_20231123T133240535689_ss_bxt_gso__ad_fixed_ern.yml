active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-23 13:34:22.097897
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_fixed
  params: {}
hash: 1a8f6530bc6a27e4294ff4a86ed3bb1699355f4f284b1425e7a30774f28e3d10
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/1a8f653_20231123T133240535689_ss_bxt_gso__ad_fixed_ern.yml"
results:
  LL_average_precision:
  - 0.11755073734897781
  - 0.11904216194074933
  - 0.11824776124456182
  - 0.11212648542299664
  - 0.11707217540001573
  - 0.11935457392663087
  - 0.11865779362828048
  - 0.1125156848371946
  - 0.1172010941396867
  - 0.11893881827724695
  - 0.11827843107499672
  - 0.11201657035511642
  - 0.11712236665172569
  - 0.1193172983663681
  - 0.1185508411617553
  - 0.1125562471961105
  LL_balanced_accuracy:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_f1_macro:
  - 0.5869263150151246
  - 0.5861435721306022
  - 0.5864550390583527
  - 0.5880150750063559
  - 0.5867679904328182
  - 0.5863693085565117
  - 0.5866655249422846
  - 0.5880700084917458
  - 0.5870252315797547
  - 0.5862737524723205
  - 0.5866085416217844
  - 0.5881268637742644
  - 0.5865832349231027
  - 0.5863277483426732
  - 0.5864276751478756
  - 0.5882207775958614
  LL_f1_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_f1_weighted:
  - 0.9759390715472271
  - 0.9733263631338508
  - 0.9745797960748513
  - 0.9831593454996554
  - 0.9762422567124828
  - 0.9732889882645694
  - 0.9744183188027767
  - 0.9828144619281908
  - 0.9764412608576732
  - 0.9736066386792477
  - 0.9747478846466097
  - 0.9834233273191423
  - 0.9759470977012066
  - 0.9732743091898997
  - 0.9742211336307921
  - 0.9829683195491606
  LL_matthews_corrcoef:
  - 0.3141571461786937
  - 0.3132774763658292
  - 0.31357758539033465
  - 0.31455870316115747
  - 0.313786199868058
  - 0.313714688411654
  - 0.31401462921606976
  - 0.31474270783577457
  - 0.3142286546313658
  - 0.31345948930330475
  - 0.3138300346298245
  - 0.31471066812965903
  - 0.3135035878913886
  - 0.3136392339602798
  - 0.3136089385190437
  - 0.3149940759299084
  LL_precision_macro:
  - 0.9914174226320569
  - 0.9904824171765669
  - 0.9909314889574923
  - 0.9940029466148537
  - 0.9915274534459014
  - 0.9904673494240482
  - 0.9908719399972294
  - 0.9938791654306338
  - 0.991597393395671
  - 0.990582422518341
  - 0.9909909464206204
  - 0.9940969990606615
  - 0.9914224981038682
  - 0.9904623585075163
  - 0.9908025845776314
  - 0.9939336108611603
  LL_precision_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_precision_weighted:
  - 0.983161751742076
  - 0.9813666025288966
  - 0.982227803071867
  - 0.9881655493493736
  - 0.9833734027401535
  - 0.9813378626943587
  - 0.9821136246534958
  - 0.9879246670852959
  - 0.9835081426270568
  - 0.9815582642304476
  - 0.9823420130064394
  - 0.9883487021195555
  - 0.9831713676131173
  - 0.9813282819441631
  - 0.9819804478269578
  - 0.9880306406658245
  LL_recall_macro:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_recall_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_recall_weighted:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_roc_auc:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LT_average_precision:
  - 0.02297374663290757
  - 0.052240272515381304
  - 0.02160742729642796
  - 0.03608543452173352
  - 0.023444836215097777
  - 0.052933667811501064
  - 0.018886502118392247
  - 0.03436174253164296
  - 0.02211174674256751
  - 0.03411803744023527
  - 0.016090345736342576
  - 0.035447912798262336
  - 0.027731305229589626
  - 0.045418798044296375
  - 0.014735656686965885
  - 0.034246496381050054
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5175258309194614
  - 0.5229279815624406
  - 0.5281223174722545
  - 0.5057373515581193
  - 0.5160436366720929
  - 0.5325610413743677
  - 0.5188143119142468
  - 0.5070749077162291
  - 0.515237058420898
  - 0.5198718962339945
  - 0.5160381037280383
  - 0.5086314853595151
  - 0.5168745472363467
  - 0.5247616105949686
  - 0.5160537571454701
  - 0.49892522248932664
  TL_average_precision:
  - 0.07829159038344088
  - 0.08318254711703542
  - 0.07740516695222556
  - 0.07886993843491202
  - 0.06880943375371854
  - 0.06891613543778202
  - 0.07165543160774653
  - 0.04103510051288918
  - 0.05577337124314716
  - 0.08132382835185398
  - 0.07952387582131216
  - 0.05097109908428833
  - 0.08287673993192135
  - 0.10843660111177156
  - 0.0613868623367203
  - 0.04867894555011384
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5688424348170422
  - 0.5775481305652536
  - 0.575989470821062
  - 0.5646487764235236
  - 0.5576274752475249
  - 0.5701925499333971
  - 0.5646321319051889
  - 0.5498509751817879
  - 0.5493296123179723
  - 0.5757643785876123
  - 0.5657590738594551
  - 0.5538373511744978
  - 0.5748631681825466
  - 0.5827732168276991
  - 0.5567441089649211
  - 0.5519737556336257
  TT_average_precision:
  - 0.024249700799095254
  - 0.019777579613108637
  - 0.02790646538139217
  - 0.03395774427476317
  - 0.016512925722711742
  - 0.016922865475503736
  - 0.014300346596376296
  - 0.03528472215785896
  - 0.027729125015617518
  - 0.020049879588710108
  - 0.022237327434597384
  - 0.03588967196789793
  - 0.01917212702294988
  - 0.017860387736335945
  - 0.02212102474692946
  - 0.03478285646384306
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5220964617954238
  - 0.546304915554824
  - 0.5696645893309814
  - 0.5070292060660492
  - 0.5082290622026795
  - 0.5284364572365291
  - 0.5158248344085059
  - 0.504307629033573
  - 0.5157912639080248
  - 0.5190637565808565
  - 0.5313739217235179
  - 0.5051380074261288
  - 0.5012839160679189
  - 0.5291068245542936
  - 0.5315056070425338
  - 0.5095054328502991
  fit_time:
  - 66.77505993843079
  - 75.46231722831726
  - 74.9459753036499
  - 69.91499876976013
  - 71.1006371974945
  - 72.53768062591553
  - 76.10413885116577
  - 75.49277067184448
  - 97.86322855949402
  - 94.4232165813446
  - 93.45398783683777
  - 76.22218227386475
  - 92.05428385734558
  - 97.00315570831299
  - 96.8688645362854
  - 77.85608100891113
  score_time:
  - 5.017876148223877
  - 3.4390368461608887
  - 3.5082225799560547
  - 7.699262857437134
  - 4.555353403091431
  - 4.036319732666016
  - 4.660266160964966
  - 6.5876922607421875
  - 3.3139359951019287
  - 3.90205454826355
  - 4.183374404907227
  - 6.4091668128967285
  - 4.340527296066284
  - 3.4040589332580566
  - 3.4567794799804688
  - 6.481931686401367
start: 2023-11-23 13:32:40.535689
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
