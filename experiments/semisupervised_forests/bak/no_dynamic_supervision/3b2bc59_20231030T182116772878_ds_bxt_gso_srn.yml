active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-10-30 19:43:34.931198
estimator:
  call: semisupervised_forests.estimators.ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ds_bxt_gso
  params: {}
hash: 3b2bc5957a5d795962a3bd1c0f6a2925fa73a87c2c61577de659c3d67da824e4
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/3b2bc59_20231030T182116772878_ds_bxt_gso_srn.yml"
results:
  LL_average_precision:
  - 0.31043956043956045
  - 0.3135321585011493
  - 0.31393697904693796
  - 0.31289824492932156
  - 0.3104626920106975
  - 0.31309691275241186
  - 0.31374651818975763
  - 0.3122514757489135
  - 0.31050772523023307
  - 0.31332852192953764
  - 0.3140485358674154
  - 0.31274634668205165
  - 0.3108996636445437
  - 0.31333143351602716
  - 0.31392743184478733
  - 0.31294731263378284
  LL_balanced_accuracy:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LL_f1_macro:
  - 0.7281337930487852
  - 0.7276140047113996
  - 0.7272761330148422
  - 0.7278745634629974
  - 0.7282277202975188
  - 0.7276129923249521
  - 0.7273254783927879
  - 0.7277551796969631
  - 0.7281658357729319
  - 0.7274725625454239
  - 0.727358050792975
  - 0.7277486910318385
  - 0.72836076529905
  - 0.7275107921372921
  - 0.7273156338691005
  - 0.7278602308042376
  LL_f1_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_f1_weighted:
  - 0.9867773014842327
  - 0.9832767564481393
  - 0.9824151148968876
  - 0.9842242865375411
  - 0.9868978376855441
  - 0.9836576134985787
  - 0.9826562370890688
  - 0.9846140199382498
  - 0.9867652915002223
  - 0.9832436907593204
  - 0.9824398921378842
  - 0.9841691217693783
  - 0.9867123798169393
  - 0.9832984138780857
  - 0.9824826606909075
  - 0.9841596703263348
  LL_matthews_corrcoef:
  - 0.5448431486319819
  - 0.5443609417010167
  - 0.5439207436585922
  - 0.5446751228599022
  - 0.5449765507868785
  - 0.5443249928425076
  - 0.5439745794585498
  - 0.5444568100737082
  - 0.5448934338702066
  - 0.544147002223111
  - 0.5440441015538537
  - 0.5444869889588942
  - 0.5451975133055292
  - 0.5442006887412761
  - 0.5439751945855913
  - 0.5446589593200364
  LL_precision_macro:
  - 0.9947567610186865
  - 0.9933559856804806
  - 0.9930116010890111
  - 0.9937350525111781
  - 0.9948045695277279
  - 0.9935089679302311
  - 0.993108257961673
  - 0.9938920393056578
  - 0.9947518165105489
  - 0.9933434963750856
  - 0.9930210797182439
  - 0.9937135781516535
  - 0.9947297924308613
  - 0.9933652655193022
  - 0.9930385285173409
  - 0.99370919418804
  LL_precision_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_precision_weighted:
  - 0.9896699137809285
  - 0.9869629006498913
  - 0.9863006300201597
  - 0.9876933266807815
  - 0.9897627235580176
  - 0.9872574292838272
  - 0.9864863450449225
  - 0.9879961817679739
  - 0.989660332078433
  - 0.9869387829828868
  - 0.9863188879609665
  - 0.9876518453970167
  - 0.9896176763911533
  - 0.9869806978421226
  - 0.9863523742084683
  - 0.9876434508801099
  LL_recall_macro:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LL_recall_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_recall_weighted:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_roc_auc:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LT_average_precision:
  - 0.02956321516097531
  - 0.017064423213702155
  - 0.014741729707278897
  - 0.01941837923820705
  - 0.02828186265875994
  - 0.01772634387662653
  - 0.016281338770553197
  - 0.02194197921754528
  - 0.027874620056694107
  - 0.016443973951747445
  - 0.014633164694236062
  - 0.02024841573819091
  - 0.028696294213237588
  - 0.017562767726519476
  - 0.017546830366201145
  - 0.021652431257715588
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5284505777871757
  - 0.5307665143717926
  - 0.5555209438319575
  - 0.5225827067814348
  - 0.5231231701923849
  - 0.541102774628955
  - 0.5588847273861897
  - 0.535293287017425
  - 0.5150980658976828
  - 0.5134474793056194
  - 0.5361628202650025
  - 0.5304081973284641
  - 0.5162838235997942
  - 0.5157797863565461
  - 0.5591961908111944
  - 0.5340029624295004
  TL_average_precision:
  - 0.059217473364912745
  - 0.059696299387901434
  - 0.07044116184564744
  - 0.0847882780503282
  - 0.09661598517340585
  - 0.10571457306711729
  - 0.09777299570716194
  - 0.09653229344230373
  - 0.07794158768497932
  - 0.08515022881336004
  - 0.08534011491855352
  - 0.09989797931062938
  - 0.07100249198562562
  - 0.09408814642829695
  - 0.0974930088776214
  - 0.07429280923033532
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5732965476711868
  - 0.5668836407382865
  - 0.5741294235422142
  - 0.5907002766425935
  - 0.5907966241517522
  - 0.5967380407764065
  - 0.5886974866904364
  - 0.5899992025343644
  - 0.581817811781781
  - 0.5846717232143023
  - 0.5867044323523924
  - 0.59787262869968
  - 0.5776345601536425
  - 0.5775183839320902
  - 0.5802688507802743
  - 0.5770918696193531
  TT_average_precision:
  - 0.02655712873898623
  - 0.014740828571132406
  - 0.01284373822431055
  - 0.018586198770517075
  - 0.030086092297354653
  - 0.018903885525410537
  - 0.014977821909228226
  - 0.023631142701516304
  - 0.027240243063127806
  - 0.015951459978258163
  - 0.01338254724954694
  - 0.01923987354990958
  - 0.026592670505154865
  - 0.015059562089770192
  - 0.012721120822096537
  - 0.019739304799523565
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5083280450991694
  - 0.4864972086085837
  - 0.5152094278349352
  - 0.512564705223985
  - 0.518307465360097
  - 0.5490790522122039
  - 0.524082383658453
  - 0.5326937452834376
  - 0.5268591578215158
  - 0.5274815915329187
  - 0.5544802945887118
  - 0.5221980433827903
  - 0.5015460832859221
  - 0.5108648433379617
  - 0.526671485260771
  - 0.5155272477757683
  fit_time:
  - 4186.24023604393
  - 4831.118746995926
  - 4926.213604927063
  - 4679.429113864899
  - 4060.3851280212402
  - 4785.127155542374
  - 4916.463618993759
  - 4714.454308986664
  - 4037.893741607666
  - 4783.418706655502
  - 4930.664195299149
  - 4773.863820314407
  - 4236.90888094902
  - 1583.5761523246765
  - 1645.9914526939392
  - 1553.918522119522
  score_time:
  - 18.210230350494385
  - 7.319534540176392
  - 6.2566540241241455
  - 16.95401620864868
  - 24.18785834312439
  - 9.120971918106079
  - 6.444255590438843
  - 15.542845726013184
  - 22.648541927337646
  - 8.856492519378662
  - 6.139934062957764
  - 9.438041687011719
  - 17.067651748657227
  - 6.5746612548828125
  - 6.429669380187988
  - 6.861886024475098
start: 2023-10-30 18:21:16.772878
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
