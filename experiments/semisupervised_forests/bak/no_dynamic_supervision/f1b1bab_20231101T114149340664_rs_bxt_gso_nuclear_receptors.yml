active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 11:41:49.916093
estimator:
  call: semisupervised_forests.estimators.rs_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: rs_bxt_gso
  params: {}
hash: f1b1babf382f2336b432f48fee4afd7401affddeb30a82c647202712df1513de
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/f1b1bab_20231101T114149340664_rs_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.17501082954299327
  - 0.16495215311004785
  - 0.17272856939095704
  - 0.16939466182084922
  - 0.1652545999144202
  - 0.15937001594896333
  - 0.1681643132220796
  - 0.16370054848873847
  - 0.1679449152542373
  - 0.16238636363636363
  - 0.17365853658536584
  - 0.17505081300813008
  - 0.1816532258064516
  - 0.15625
  - 0.18205870194295165
  - 0.18130081300813006
  LL_balanced_accuracy:
  - .nan
  - 0.5568181818181818
  - 0.5555555555555556
  - .nan
  - .nan
  - 0.5606060606060606
  - 0.5609756097560976
  - 0.5568181818181818
  - 0.5508474576271186
  - 0.5568181818181818
  - .nan
  - .nan
  - 0.5564516129032258
  - 0.55
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.5887845280872377
  - 0.5839786381842457
  - .nan
  - .nan
  - 0.5983306300231452
  - 0.5967908902691512
  - 0.5891183511177831
  - 0.5750438486594838
  - 0.589468282477401
  - .nan
  - .nan
  - 0.5834871590984391
  - 0.5763459841129744
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9486842105263158
  - 0.938382541720154
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - 0.9499358151476252
  - 0.93375
  - 0.95125
  - .nan
  - .nan
  - 0.93125
  - 0.94375
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9289428777342988
  - 0.9147227540014841
  - .nan
  - .nan
  - 0.9472614236836829
  - 0.936253677672442
  - 0.9306592656994557
  - 0.9078841142570784
  - 0.9324624008210634
  - .nan
  - .nan
  - 0.9050845331743013
  - 0.9215578111209181
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.32827793983094694
  - 0.32281819256897537
  - .nan
  - .nan
  - 0.3414124337158552
  - 0.34099716973523675
  - 0.32849733690299654
  - 0.30806933573693723
  - 0.32872747005868486
  - .nan
  - .nan
  - 0.324149057000093
  - 0.30714755841697555
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9741721854304636
  - 0.9689521345407504
  - .nan
  - .nan
  - 0.9808201058201058
  - 0.9767441860465116
  - 0.9748062015503876
  - 0.966624685138539
  - 0.9754716981132076
  - .nan
  - .nan
  - 0.9653215636822194
  - 0.9716981132075472
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9486842105263158
  - 0.938382541720154
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - 0.9499358151476252
  - 0.93375
  - 0.95125
  - .nan
  - .nan
  - 0.93125
  - 0.94375
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9513349599163472
  - 0.9422087228293812
  - .nan
  - .nan
  - 0.9633058340295182
  - 0.9559363525091801
  - 0.9524584291130549
  - 0.9381722292191437
  - 0.9536415094339623
  - .nan
  - .nan
  - 0.9360182849936949
  - 0.9469339622641509
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.5568181818181818
  - 0.5555555555555556
  - .nan
  - .nan
  - 0.5606060606060606
  - 0.5609756097560976
  - 0.5568181818181818
  - 0.5508474576271186
  - 0.5568181818181818
  - .nan
  - .nan
  - 0.5564516129032258
  - 0.55
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9486842105263158
  - 0.938382541720154
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - 0.9499358151476252
  - 0.93375
  - 0.95125
  - .nan
  - .nan
  - 0.93125
  - 0.94375
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9486842105263158
  - 0.938382541720154
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - 0.9499358151476252
  - 0.93375
  - 0.95125
  - .nan
  - .nan
  - 0.93125
  - 0.94375
  - .nan
  - .nan
  LL_roc_auc:
  - 0.5634770748085195
  - 0.5568181818181818
  - 0.5555555555555556
  - 0.5539176293319941
  - 0.560348044370569
  - 0.5606060606060606
  - 0.5609756097560976
  - 0.5568181818181818
  - 0.5508474576271186
  - 0.5568181818181818
  - 0.56
  - 0.5577192982456141
  - 0.5564516129032258
  - 0.55
  - 0.559322033898305
  - 0.5583333333333333
  LT_average_precision:
  - 0.21844611528822055
  - 0.17193753614806245
  - 0.1545344129554656
  - 0.1302156490126415
  - 0.20426065162907267
  - 0.18681704260651627
  - 0.2656039136302294
  - 0.139451192082771
  - 0.2154761904761905
  - 0.10068172568172569
  - 0.25806151520437237
  - 0.04230769230769231
  - 0.09661904761904762
  - 0.10520282186948854
  - 0.11519847255141372
  - 0.10718954248366014
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5739707835325366
  - 0.5404979253112033
  - 0.6153735632183908
  - 0.542611894543225
  - 0.5685695538057742
  - 0.5788617886178862
  - 0.6070921985815603
  - 0.584733893557423
  - 0.6046330845771143
  - 0.514565949348558
  - 0.611376768280534
  - 0.4799196787148594
  - 0.5953459119496854
  - 0.4915824915824915
  - 0.5840220385674931
  - 0.5890825465988866
  TL_average_precision:
  - 0.08849206349206348
  - 0.11978021978021978
  - 0.04878048780487805
  - 0.13963016100749243
  - 0.19677419354838707
  - 0.09603174603174602
  - 0.14883640899901063
  - 0.13430654010973608
  - 0.05416666666666667
  - 0.05416666666666667
  - 0.07317073170731707
  - 0.052845528455284556
  - 0.23333333333333334
  - 0.029166666666666667
  - 0.08807588075880758
  - 0.052845528455284556
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5186598812553012
  - 0.5350043215211755
  - 0.4908424908424908
  - 0.5885997521685254
  - 0.5429459774582199
  - 0.5130208333333334
  - 0.526210826210826
  - 0.5233894680566693
  - 0.4801762114537445
  - 0.4889867841409692
  - 0.47149122807017546
  - 0.4721030042918455
  - 0.5913043478260869
  - 0.4871244635193133
  - 0.5344585091420534
  - 0.47639484978540775
  TT_average_precision:
  - 0.030612244897959183
  - 0.19642857142857142
  - 0.20879120879120877
  - 0.10531135531135531
  - 0.061224489795918366
  - 0.1326530612244898
  - 0.31978021978021975
  - 0.10817307692307693
  - 0.12261904761904763
  - 0.07142857142857142
  - 0.01282051282051282
  - 0.11965811965811966
  - 0.03571428571428571
  - 0.11507936507936507
  - 0.14405937200054847
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.4736842105263158
  - 0.5527777777777777
  - 0.5612244897959183
  - 0.6231060606060606
  - 0.4782608695652174
  - 0.49411764705882355
  - 0.6302469135802469
  - 0.5436746987951807
  - 0.6185897435897435
  - 0.4807692307692308
  - 0.44805194805194803
  - 0.5694444444444444
  - 0.45679012345679015
  - 0.5694444444444444
  - 0.7652027027027026
  - .nan
  fit_time:
  - 0.32930636405944824
  - 0.30939245223999023
  - 0.32052087783813477
  - 0.3251638412475586
  - 0.32088232040405273
  - 0.31560182571411133
  - 0.32315802574157715
  - 0.31302762031555176
  - 0.32992100715637207
  - 0.3181729316711426
  - 0.3238558769226074
  - 0.3245058059692383
  - 0.3428628444671631
  - 0.3227837085723877
  - 0.33292436599731445
  - 0.3248023986816406
  score_time:
  - 0.19122600555419922
  - 0.21482205390930176
  - 0.23446130752563477
  - 0.19338178634643555
  - 0.2018287181854248
  - 0.18872284889221191
  - 0.19811153411865234
  - 0.2070317268371582
  - 0.2137155532836914
  - 0.20426583290100098
  - 0.18840599060058594
  - 0.16039729118347168
  - 0.2042841911315918
  - 0.18295788764953613
  - 0.19751429557800293
  - 0.19250988960266113
start: 2023-11-01 11:41:49.340664
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
