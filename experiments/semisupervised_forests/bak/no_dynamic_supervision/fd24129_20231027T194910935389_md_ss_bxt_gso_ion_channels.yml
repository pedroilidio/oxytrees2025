active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - precision_weighted
    - recall_weighted
    - precision_micro
    - recall_macro
    - matthews_corrcoef
    - f1_micro
    - precision_macro
    - roc_auc
    - f1_weighted
    - balanced_accuracy
    - average_precision
    - recall_micro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-27 19:49:25.828783
estimator:
  call: semisupervised_forests.estimators.md_ss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: fd24129972929df106fa4372ce6176fa1b65c6ef873bf5470e87fdaf91fbc96f
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/fd24129_20231027T194910935389_md_ss_bxt_gso_ion_channels.yml"
results:
  LL_average_precision:
  - 0.5184005661712668
  - 0.5178891343932507
  - 0.5176092708181601
  - 0.5176088069562137
  - 0.5179426335289955
  - 0.5179382946724372
  - 0.5169603706461487
  - 0.518619900550046
  - 0.5182803961535615
  - 0.5186507064938868
  - 0.5171672044345165
  - 0.5181104432546223
  - 0.5184414452255325
  - 0.5171670971769681
  - 0.5174497673056435
  - 0.5183345832120477
  LL_balanced_accuracy:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_f1_macro:
  - 0.8286026200873362
  - .nan
  - 0.8292413854501421
  - .nan
  - 0.8287236090611564
  - .nan
  - 0.8289825544377944
  - .nan
  - 0.8290503652067968
  - .nan
  - 0.8289280937519903
  - .nan
  - 0.8290039908492242
  - .nan
  - 0.8292875847754466
  - .nan
  LL_f1_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538514
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_f1_weighted:
  - 0.978619720602309
  - .nan
  - 0.9802433876449146
  - .nan
  - 0.9791496381427907
  - .nan
  - 0.9802866917354942
  - .nan
  - 0.9794433538280974
  - .nan
  - 0.9800472204748734
  - .nan
  - 0.979250620929605
  - .nan
  - 0.9804349774611915
  - .nan
  LL_matthews_corrcoef:
  - 0.700447894610418
  - .nan
  - 0.7013905925141326
  - .nan
  - 0.7006174228557172
  - .nan
  - 0.7009803892718732
  - .nan
  - 0.7011211134187072
  - .nan
  - 0.700904035830809
  - .nan
  - 0.70105565880409
  - .nan
  - 0.7014558703735905
  - .nan
  LL_precision_macro:
  - 0.9906272530641673
  - .nan
  - 0.9913517380691861
  - .nan
  - 0.9908647732089868
  - .nan
  - 0.9913735061437469
  - .nan
  - 0.9909938546302183
  - .nan
  - 0.991266467443916
  - .nan
  - 0.990907549489212
  - .nan
  - 0.9914373474711773
  - .nan
  LL_precision_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_precision_weighted:
  - 0.9819443615291318
  - .nan
  - 0.983292333552872
  - .nan
  - 0.9823851865240354
  - .nan
  - 0.9833322464202088
  - .nan
  - 0.9826258367080601
  - .nan
  - 0.9831326562431352
  - .nan
  - 0.9824653978826134
  - .nan
  - 0.9834520558930446
  - .nan
  LL_recall_macro:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_recall_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_recall_weighted:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_roc_auc:
  - 0.75
  - 0.7499343251140763
  - 0.7503037667071689
  - 0.7505722886528436
  - 0.75
  - 0.7502324200612267
  - 0.75
  - 0.7511828986862547
  - 0.7502937720329025
  - 0.7504987085098532
  - 0.75
  - 0.7508647600465642
  - 0.7502910360884749
  - 0.7499674305694379
  - 0.7503067484662577
  - 0.7512553076730141
  LT_average_precision:
  - 0.362709185775146
  - 0.1275885726707656
  - 0.1872663160431862
  - 0.23634672003409224
  - 0.3228322926382054
  - 0.10856774910281927
  - 0.17673439529216284
  - 0.2588052275455746
  - 0.2737479569630694
  - 0.09771693096812253
  - 0.15959082124309099
  - 0.25469952809625485
  - 0.28225871976349526
  - 0.14091085865527067
  - 0.21794740092062756
  - 0.2435162797868404
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.795447198991988
  - 0.6887052111255934
  - 0.664713732149077
  - 0.6916073102627944
  - 0.7989647061531683
  - 0.6529571410356825
  - 0.6683988683741684
  - 0.7149729032909306
  - 0.7598140815975211
  - 0.6916521274631484
  - 0.667765716891238
  - 0.7286627409490362
  - 0.7725530794837726
  - 0.6761962357803657
  - 0.6834761098815259
  - 0.7083189415269775
  TL_average_precision:
  - 0.6258696089643938
  - 0.6086110226686586
  - 0.6250189239842537
  - 0.5918527449715042
  - 0.7226021618058639
  - 0.7310800558808881
  - 0.7056485790826585
  - 0.6873327424246815
  - 0.6071192625541673
  - 0.6169698508905188
  - 0.5714442798153071
  - 0.5227580600238224
  - 0.6306370362418106
  - 0.6930751085928855
  - 0.6908422199643468
  - 0.6428939810811396
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.9103855641035037
  - 0.8988403631021589
  - 0.8794970604219159
  - 0.8795279844604764
  - 0.9249353196927518
  - 0.9132185102416835
  - 0.9050521642288597
  - 0.8934760965790585
  - 0.8591406963379271
  - 0.8600813619903118
  - 0.8730865279214464
  - 0.822055342380159
  - 0.8734334364804562
  - 0.914079980823503
  - 0.903734526985998
  - 0.8882980923272699
  TT_average_precision:
  - 0.2571577887260761
  - 0.08528806991667796
  - 0.13408393860847068
  - 0.2003321759476882
  - 0.37618319085597507
  - 0.12595305837624998
  - 0.24675429939718016
  - 0.2633138051139718
  - 0.16180837913874016
  - 0.10385665406059093
  - 0.14728105873378206
  - 0.2278191086797735
  - 0.3166585092876293
  - 0.09815708695467885
  - 0.19369905207255608
  - 0.14337109953077487
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.7594279422999146
  - 0.6638049070884892
  - 0.6238506026438569
  - 0.69294863599316
  - 0.7975817159646298
  - 0.6966959440816702
  - 0.6715682440359797
  - 0.7548509561304836
  - 0.7201201376334053
  - 0.6660825774531748
  - 0.6109228056426332
  - 0.668907803447536
  - 0.8037407819387796
  - 0.6735945715184469
  - 0.677779647390955
  - 0.6029568039246307
  fit_time:
  - 6.737268686294556
  - 6.570579767227173
  - 10.206712484359741
  - 13.107863664627075
  - 13.961401224136353
  - 13.37295937538147
  - 14.224321365356445
  - 12.876409769058228
  - 13.364441871643066
  - 13.044116497039795
  - 13.847686290740967
  - 13.126358985900879
  - 13.368916273117065
  - 13.204222440719604
  - 13.828719854354858
  - 13.318523168563843
  score_time:
  - 0.5832233428955078
  - 0.47021031379699707
  - 0.5443260669708252
  - 0.7622547149658203
  - 0.692558765411377
  - 0.6975996494293213
  - 0.6000998020172119
  - 0.6274199485778809
  - 0.8782844543457031
  - 0.7218289375305176
  - 0.7180345058441162
  - 0.7550466060638428
  - 0.8439877033233643
  - 0.7653238773345947
  - 0.7007789611816406
  - 0.716524600982666
start: 2023-10-27 19:49:10.935389
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
