active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 11:46:10.517876
estimator:
  call: semisupervised_forests.estimators.ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ds_bxt_gso
  params: {}
hash: 8521165b785ae1dcdd52df56cc62400575c5425943488b505ec681dc26d33c59
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/8521165_20231101T114605780195_ds_bxt_gso_ion_channels.yml"
results:
  LL_average_precision:
  - 0.13377477399583057
  - 0.1329891227744388
  - 0.13146194745848774
  - 0.13116372465041978
  - 0.13319151040596633
  - 0.13270028574024348
  - 0.13052866716306777
  - 0.13027598377107885
  - 0.13290471307641066
  - 0.13277438072885542
  - 0.13090096798212958
  - 0.13120381133508607
  - 0.13229659011500366
  - 0.13254182453146074
  - 0.13093533030721544
  - 0.12865051305110875
  LL_balanced_accuracy:
  - 0.5503393665158371
  - .nan
  - 0.5504252733900364
  - .nan
  - 0.5504640371229699
  - .nan
  - 0.55
  - .nan
  - 0.5505287896592245
  - .nan
  - 0.55
  - .nan
  - 0.5500582072176949
  - .nan
  - 0.5503067484662577
  - .nan
  LL_f1_macro:
  - 0.5830246326395329
  - .nan
  - 0.5838124823590799
  - .nan
  - 0.583447048714696
  - .nan
  - 0.5831318283369036
  - .nan
  - 0.5836621267888888
  - .nan
  - 0.5830351581590119
  - .nan
  - 0.582798823502053
  - .nan
  - 0.583692073407322
  - .nan
  LL_f1_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - .nan
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_f1_weighted:
  - 0.9536627205559293
  - .nan
  - 0.9571259928856107
  - .nan
  - 0.9548280871486553
  - .nan
  - 0.9572197620943651
  - .nan
  - 0.9554109057637129
  - .nan
  - 0.9567010390780758
  - .nan
  - 0.9549223882988672
  - .nan
  - 0.9575233439965773
  - .nan
  LL_matthews_corrcoef:
  - 0.31198441312481723
  - .nan
  - 0.3126543364921219
  - .nan
  - 0.31250592182651615
  - .nan
  - 0.3113466596691422
  - .nan
  - 0.3127740736927638
  - .nan
  - 0.31128645486743545
  - .nan
  - 0.3112604610693923
  - .nan
  - 0.3123336797877318
  - .nan
  LL_precision_macro:
  - 0.9833904395788067
  - .nan
  - 0.9846415673903117
  - .nan
  - 0.9838096431854266
  - .nan
  - 0.9846837124356633
  - .nan
  - 0.9840192187173595
  - .nan
  - 0.9844962849196796
  - .nan
  - 0.9838520994359724
  - .nan
  - 0.9847874813216005
  - .nan
  LL_precision_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - .nan
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_precision_weighted:
  - 0.9680033804200365
  - .nan
  - 0.9703288855904003
  - .nan
  - 0.9687812769269635
  - .nan
  - 0.9704065045273832
  - .nan
  - 0.9691707504001682
  - .nan
  - 0.9700571916244725
  - .nan
  - 0.968859108874401
  - .nan
  - 0.9706007095384518
  - .nan
  LL_recall_macro:
  - 0.5503393665158371
  - .nan
  - 0.5504252733900364
  - .nan
  - 0.5504640371229699
  - .nan
  - 0.55
  - .nan
  - 0.5505287896592245
  - .nan
  - 0.55
  - .nan
  - 0.5500582072176949
  - .nan
  - 0.5503067484662577
  - .nan
  LL_recall_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - .nan
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_recall_weighted:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - .nan
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_roc_auc:
  - 0.5503393665158371
  - 0.5503082871110088
  - 0.5504252733900364
  - 0.5507518796992481
  - 0.5504640371229699
  - 0.5506555423122765
  - 0.55
  - 0.5503585757596
  - 0.5505287896592245
  - 0.5504305777693482
  - 0.55
  - 0.550796263032185
  - 0.5500582072176949
  - 0.5508280151385218
  - 0.5503067484662577
  - 0.5499807447722335
  LT_average_precision:
  - 0.09952590055165862
  - 0.04437977267504918
  - 0.10926975756422823
  - 0.08456790114318974
  - 0.05733494941110881
  - 0.06635488603823927
  - 0.06830228126911181
  - 0.12001170951646334
  - 0.0893589794620333
  - 0.06906562655936717
  - 0.09109070595100559
  - 0.06905720967107298
  - 0.08446710523459595
  - 0.0668676922602817
  - 0.09075558863036902
  - 0.1237174474608512
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5806502634335143
  - 0.544989302314143
  - 0.5750317833507489
  - 0.5569839621785632
  - 0.5719209830504572
  - 0.5524197143374822
  - 0.558586336784472
  - 0.5750987867992656
  - 0.5727479526842584
  - 0.5775492481577915
  - 0.5676212499069456
  - 0.5500100532592834
  - 0.5774019709663274
  - 0.5592705255229155
  - 0.5666641417429076
  - 0.60309492044264
  TL_average_precision:
  - 0.21139609169436355
  - 0.22108254701812244
  - 0.19695801561340467
  - 0.24310973585049422
  - 0.185810413811857
  - 0.27670626357845646
  - 0.2726109008360858
  - 0.29687689006618506
  - 0.2644861468210467
  - 0.24623809069864128
  - 0.2610341113545105
  - 0.1775255292717544
  - 0.21416277531749872
  - 0.2719554199039666
  - 0.25464111301515724
  - 0.2375162154579255
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6637610821715173
  - 0.6585719251799014
  - 0.6602097110767632
  - 0.6660208617600573
  - 0.6203241388247175
  - 0.6691465683522622
  - 0.6574157103535099
  - 0.6580234274169393
  - 0.6396161510252614
  - 0.6420773174058223
  - 0.6353827330132312
  - 0.6009589388137657
  - 0.6125266679703849
  - 0.6685054921177181
  - 0.6676093893070039
  - 0.6296631179484848
  TT_average_precision:
  - 0.15268727344982594
  - 0.05716693640631712
  - 0.09196207052286678
  - 0.08250520868263872
  - 0.07388351964471539
  - 0.09467111969184633
  - 0.08281441760182554
  - 0.22242068925472283
  - 0.10198298126520501
  - 0.09006997172859574
  - 0.10452186950902403
  - 0.13377634177652617
  - 0.07327716898058474
  - 0.0652513378457947
  - 0.08915867561599539
  - 0.10703132489239753
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.6566058508965084
  - 0.5962558999872433
  - 0.575269731726283
  - 0.6193525961676762
  - 0.6054703317606954
  - 0.5905154971029155
  - 0.6022806331432805
  - 0.650050970191226
  - 0.6351810812387007
  - 0.5911031923665921
  - 0.5862558777429466
  - 0.5691545669122381
  - 0.5441704774852717
  - 0.5871725160652498
  - 0.57179501561127
  - 0.5715243365949716
  fit_time:
  - 3.113802433013916
  - 3.848742961883545
  - 3.4241254329681396
  - 3.6133103370666504
  - 3.738473653793335
  - 3.3843679428100586
  - 2.8163235187530518
  - 3.742058515548706
  - 3.9427664279937744
  - 3.324648857116699
  - 3.1321990489959717
  - 3.2524025440216064
  - 3.487189531326294
  - 3.6398773193359375
  - 3.4857540130615234
  - 2.7042219638824463
  score_time:
  - 0.586540937423706
  - 0.6529068946838379
  - 0.9320223331451416
  - 0.7886185646057129
  - 0.8506481647491455
  - 0.8117587566375732
  - 0.8913381099700928
  - 0.7526988983154297
  - 0.737849235534668
  - 0.6707301139831543
  - 1.0170037746429443
  - 0.715989351272583
  - 0.9022178649902344
  - 0.7185730934143066
  - 0.9371311664581299
  - 0.559528112411499
start: 2023-11-01 11:46:05.780195
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
