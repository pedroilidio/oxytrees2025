active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - precision_weighted
    - recall_weighted
    - precision_micro
    - recall_macro
    - matthews_corrcoef
    - f1_micro
    - precision_macro
    - roc_auc
    - f1_weighted
    - balanced_accuracy
    - average_precision
    - recall_micro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-27 19:43:34.765175
estimator:
  call: semisupervised_forests.estimators.adss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: adss_bxt_gso
  params: {}
hash: c200e33686bf07600c22ab88c4761a834ccec31af685b6c6369940684a11b37e
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/c200e33_20231027T194329796111_adss_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.5627633150977803
  - 0.5289473684210526
  - 0.5518946417534351
  - 0.558830668689462
  - 0.5293645699614891
  - 0.5362041467304625
  - 0.5378690629011553
  - 0.5200595168631112
  - 0.5439453860640302
  - 0.5275
  - 0.5304878048780488
  - 0.5472094045264777
  - 0.5467165898617512
  - 0.53125
  - 0.5752997106242249
  - 0.5358288166214996
  LL_balanced_accuracy:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - 0.75
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.8257679963319577
  - .nan
  - .nan
  - .nan
  - 0.8345578231292516
  - 0.8320251854407452
  - .nan
  - .nan
  - 0.8261625380269448
  - 0.825346112886049
  - .nan
  - .nan
  - 0.825136612021858
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - 0.9695121951219512
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9664470667728469
  - .nan
  - .nan
  - .nan
  - 0.9756935195130684
  - 0.9703567180846717
  - .nan
  - .nan
  - 0.9681138635375923
  - 0.9646744071274579
  - .nan
  - .nan
  - 0.9637978142076503
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.6964875095423532
  - .nan
  - .nan
  - .nan
  - 0.7099704764350107
  - 0.7061733064809798
  - .nan
  - .nan
  - 0.6970374326528528
  - 0.6958999422041565
  - .nan
  - .nan
  - 0.6956083436402524
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9850948509485095
  - .nan
  - .nan
  - .nan
  - 0.9892328398384926
  - 0.9868073878627968
  - .nan
  - .nan
  - 0.9858611825192802
  - 0.9842767295597484
  - .nan
  - .nan
  - 0.9838709677419355
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - 0.9695121951219512
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9719155612608756
  - .nan
  - .nan
  - .nan
  - 0.979400722533116
  - 0.9750034717400361
  - .nan
  - .nan
  - 0.9732776349614396
  - 0.9704709311244055
  - .nan
  - .nan
  - 0.9697580645161291
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - 0.75
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - 0.9695121951219512
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - 0.9695121951219512
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_roc_auc:
  - 0.7677053824362606
  - 0.75
  - 0.7592592592592593
  - 0.7632722250125566
  - 0.754927236337732
  - 0.7575757575757576
  - 0.7560975609756098
  - 0.7488404452690166
  - 0.7607104462590636
  - 0.75
  - 0.75
  - 0.7646381578947368
  - 0.7569171256228692
  - 0.75
  - 0.771186440677966
  - 0.756359649122807
  LT_average_precision:
  - 0.2859361869973075
  - 0.1937287189758142
  - 0.11103766202837412
  - 0.4684609401487805
  - 0.24688095846781494
  - 0.2609360715684994
  - 0.1303105243214136
  - 0.44448692565752457
  - 0.35429197994987466
  - 0.18037776064091854
  - 0.30063401878970214
  - 0.27869827142554415
  - 0.28417682317682313
  - 0.3220635817425731
  - 0.2813317927106267
  - 0.3782915877141211
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6794156706507303
  - 0.6785892116182572
  - 0.6063218390804599
  - 0.7490803188228081
  - 0.6190944881889764
  - 0.6304878048780488
  - 0.6161347517730497
  - 0.8242296918767507
  - 0.6789490049751243
  - 0.6019616454399062
  - 0.7323171946602909
  - 0.7581234027017159
  - 0.6753459119496856
  - 0.6714975845410628
  - 0.8480257116620753
  - 0.7319051077221013
  TL_average_precision:
  - 0.27827450327450326
  - 0.21602564102564104
  - 0.18788952240171752
  - 0.2788456575041941
  - 0.2281175813433878
  - 0.25346320346320345
  - 0.21634811962154712
  - 0.31115193662422574
  - 0.07419374372815668
  - 0.07564102564102565
  - 0.1386109373914252
  - 0.125703564727955
  - 0.27202380952380956
  - 0.06226190476190476
  - 0.3146932110346744
  - 0.197845310295679
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6294529262086513
  - 0.6009795447997694
  - 0.6890371533228676
  - 0.6832920280875672
  - 0.5820054411193158
  - 0.5521647135416666
  - 0.5427350427350427
  - 0.6059877038225073
  - 0.5057607590647238
  - 0.48085394781430024
  - 0.522051656920078
  - 0.411687025420931
  - 0.5723913043478261
  - 0.5432250153280196
  - 0.7229254571026723
  - 0.6181908220534831
  TT_average_precision:
  - 0.03322867608581895
  - 0.08344671201814058
  - 0.14445554445554445
  - 0.5333333333333333
  - 0.08787720216291645
  - 0.17184244327101472
  - 0.16334432234432233
  - 0.19452778581068056
  - 0.08234126984126984
  - 0.07142857142857142
  - 0.01282051282051282
  - 0.07104700854700856
  - 0.03306878306878307
  - 0.0633116883116883
  - 0.06954911642411642
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5035087719298246
  - 0.4729166666666667
  - 0.7049319727891157
  - 0.9166666666666666
  - 0.5670289855072463
  - 0.5791855203619909
  - 0.5234567901234568
  - 0.6302710843373494
  - 0.5267094017094016
  - 0.46153846153846156
  - 0.38961038961038963
  - 0.41782407407407407
  - 0.39711934156378603
  - 0.2841880341880342
  - 0.6013513513513513
  - .nan
  fit_time:
  - 2.4797677993774414
  - 2.8319427967071533
  - 1.9591925144195557
  - 2.7633657455444336
  - 2.7511284351348877
  - 2.973987579345703
  - 2.8530681133270264
  - 2.854804754257202
  - 2.925701379776001
  - 3.1070823669433594
  - 3.047313690185547
  - 2.994356632232666
  - 2.8728392124176025
  - 3.04451060295105
  - 3.026122570037842
  - 2.957120656967163
  score_time:
  - 0.20399212837219238
  - 0.20603322982788086
  - 0.17687726020812988
  - 0.2085094451904297
  - 0.19103312492370605
  - 0.19949746131896973
  - 0.191680908203125
  - 0.16472196578979492
  - 0.16298198699951172
  - 0.19881916046142578
  - 0.1721789836883545
  - 0.19935011863708496
  - 0.18320035934448242
  - 0.2142655849456787
  - 0.18337082862854004
  - 0.17995357513427734
start: 2023-10-27 19:43:29.796111
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
