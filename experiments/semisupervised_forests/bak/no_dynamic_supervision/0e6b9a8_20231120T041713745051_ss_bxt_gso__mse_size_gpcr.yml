active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-20 04:17:15.278192
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__mse_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__mse_size
  params: {}
hash: 0e6b9a8e8c21e7ce1419197b661219ac4dbb2be076510801af55c2a0d5d55617
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/0e6b9a8_20231120T041713745051_ss_bxt_gso__mse_size_gpcr.yml"
results:
  LL_average_precision:
  - 0.13292219750541678
  - 0.12791295146716863
  - 0.12808467571898458
  - 0.12603828096785843
  - 0.13012411402021545
  - 0.1259381349631162
  - 0.12548957392669147
  - 0.12497407123151279
  - 0.13128101728977734
  - 0.132267461023851
  - 0.13052809978898497
  - 0.12661114730407275
  - 0.13113912124859695
  - 0.12919161676646707
  - 0.1286237990158645
  - 0.12477485083868062
  LL_balanced_accuracy:
  - .nan
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - .nan
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LL_f1_macro:
  - .nan
  - 0.5847208442674116
  - 0.5837653143612727
  - 0.5870688495533206
  - .nan
  - 0.5856492588358561
  - 0.5850966373850548
  - 0.5879130108468398
  - 0.5832018951551277
  - 0.5845640870780535
  - 0.5834040356341553
  - 0.5844570126107703
  - 0.5849046897913459
  - 0.5834786323799407
  - 0.5839119995104589
  - 0.5849495621610719
  LL_f1_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877287
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_f1_weighted:
  - .nan
  - 0.9620573306313152
  - 0.9606267694073672
  - 0.9671121516918916
  - .nan
  - 0.9653597927322017
  - 0.9651117491757567
  - 0.9693443788479165
  - 0.9565184684457021
  - 0.9572609982570296
  - 0.9575760616941908
  - 0.9630885380091844
  - 0.9588945479076647
  - 0.9590832652904875
  - 0.9602490593165409
  - 0.9656764038053118
  LL_matthews_corrcoef:
  - .nan
  - 0.3132124046895629
  - 0.31174146518670126
  - 0.31646487657500544
  - .nan
  - 0.31419512726773463
  - 0.3132085847508585
  - 0.31753943502006654
  - 0.3116447704230443
  - 0.3140383982123482
  - 0.31177719036802776
  - 0.31247201371939837
  - 0.31429780512252053
  - 0.31156273713967697
  - 0.31210792983689867
  - 0.3127981917430874
  LL_precision_macro:
  - .nan
  - 0.9864224684882836
  - 0.9859137055837564
  - 0.988231338264963
  - .nan
  - 0.9876099458728012
  - 0.9875253721244925
  - 0.9890317700453858
  - 0.9844278943805009
  - 0.9846817874069058
  - 0.9848100194634848
  - 0.9867989573698814
  - 0.9852720293724966
  - 0.9853566958698373
  - 0.9857750709160688
  - 0.9877310785045179
  LL_precision_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_precision_weighted:
  - .nan
  - 0.9736625432428543
  - 0.9727065423025402
  - 0.9770783409265276
  - .nan
  - 0.9759012036534148
  - 0.9757409151089271
  - 0.9785987102646133
  - 0.969930089376398
  - 0.9704048567021506
  - 0.9706423552353223
  - 0.9743704103598018
  - 0.9715068153079688
  - 0.971663306678258
  - 0.972446889690223
  - 0.9761295636181652
  LL_recall_macro:
  - .nan
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - .nan
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LL_recall_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_recall_weighted:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_roc_auc:
  - 0.552924791086351
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - 0.5529595015576324
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LT_average_precision:
  - 0.06301019094685481
  - 0.09145786284279775
  - 0.09010139846536905
  - 0.060797295483270695
  - 0.07411741547859874
  - 0.09121165754094553
  - 0.07003719586867782
  - 0.06305350800482519
  - 0.10038729861147339
  - 0.09945842576174858
  - 0.13692484700685204
  - 0.09755559477115779
  - 0.10390004792445592
  - 0.07921819379044348
  - 0.0903018080140838
  - 0.07174621612941229
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5903056405697819
  - 0.5703506262114385
  - 0.6099696628006874
  - 0.5365686033507948
  - 0.6067480038326414
  - 0.5961098582474227
  - 0.5967435627610247
  - 0.5727931568748812
  - 0.6100509306201415
  - 0.6142572696083968
  - 0.6408388804922233
  - 0.5625013703693262
  - 0.6137408448221839
  - 0.6026906363474016
  - 0.6229192468583009
  - 0.5490019715692184
  TL_average_precision:
  - 0.14990957101160635
  - 0.07817927808105514
  - 0.08669712605847676
  - 0.05590799106817413
  - 0.1589544679858529
  - 0.13378291623934926
  - 0.13608970740604404
  - 0.1379499190420796
  - 0.0655782073261592
  - 0.1505118553492436
  - 0.10814685906468792
  - 0.10070506052537942
  - 0.14551670133278208
  - 0.12654776641699902
  - 0.18725043278630493
  - 0.11290478588615235
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6070660125656252
  - 0.5872459859808169
  - 0.5836715236705113
  - 0.539810857910335
  - 0.5859515716966486
  - 0.5831935237043959
  - 0.5725394025532347
  - 0.5828951639690784
  - 0.5834055569717053
  - 0.629352534899123
  - 0.6191804336780237
  - 0.5935599133626448
  - 0.5817731773177317
  - 0.5903840808856305
  - 0.6071074195753732
  - 0.564177875079931
  TT_average_precision:
  - 0.06358388943812819
  - 0.11360466331054567
  - 0.053397318086828224
  - 0.06369126043039086
  - 0.03552489177489177
  - 0.07916033434650456
  - 0.05817798273155417
  - 0.07911692684419958
  - 0.06470398970398972
  - 0.17631857646170623
  - 0.028756550467076786
  - 0.0417055917055917
  - 0.13821274690839908
  - 0.08457436715235782
  - 0.029139061421670116
  - 0.09535037675967212
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5814211944319713
  - 0.605792546026044
  - 0.5722698863170328
  - 0.5302278977239483
  - 0.5420820552147239
  - 0.5722452796141669
  - 0.5758017492711369
  - 0.550589796366144
  - 0.5746067985794012
  - 0.6178212910003502
  - 0.5163835785999175
  - 0.5700954266815529
  - 0.6047486335256119
  - 0.605486776712815
  - 0.5732541567695961
  - 0.554642857142857
  fit_time:
  - 0.9870929718017578
  - 0.974139928817749
  - 0.9734842777252197
  - 0.9191148281097412
  - 0.9173173904418945
  - 0.9044146537780762
  - 1.0174005031585693
  - 0.834373950958252
  - 1.1304905414581299
  - 1.1043322086334229
  - 1.0512654781341553
  - 0.9455559253692627
  - 1.063528299331665
  - 1.053887128829956
  - 1.0984134674072266
  - 0.9665565490722656
  score_time:
  - 0.28875279426574707
  - 0.3433101177215576
  - 0.3374056816101074
  - 0.39828991889953613
  - 0.2755129337310791
  - 0.410306453704834
  - 0.3538823127746582
  - 0.3716599941253662
  - 0.3560597896575928
  - 0.36008477210998535
  - 0.3373889923095703
  - 0.33979296684265137
  - 0.3759458065032959
  - 0.36742424964904785
  - 0.3302791118621826
  - 0.3724813461303711
start: 2023-11-20 04:17:13.745051
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
