active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-14 13:12:34.801539
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__mse_density
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__mse_density
  params: {}
hash: c4392f38be9d0a09d7d4adba3a217b2cb5cc6cb73b201a3224e966ba70ca4897
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/c4392f3_20231114T130600086829_ss_bxt_gso__mse_density_ern.yml"
results:
  LL_average_precision:
  - 0.5095223865730365
  - 0.5107842944390422
  - 0.5102979928788673
  - 0.5066556069044515
  - 0.5096578689058979
  - 0.510803771170762
  - 0.5103654409046002
  - 0.5067938539321405
  - 0.509323173464814
  - 0.5106772027316135
  - 0.5099932851443694
  - 0.5069237739911575
  - 0.5095124259176254
  - 0.5105782160466159
  - 0.5102006556859028
  - 0.5067346052059881
  LL_balanced_accuracy:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LL_f1_macro:
  - 0.8309182405189923
  - 0.8307586814018457
  - 0.8308907741279159
  - 0.8316526526826057
  - 0.8310692710241894
  - 0.8307533419130508
  - 0.8308722135951685
  - 0.8316173829761762
  - 0.830969482074128
  - 0.8307880564775882
  - 0.830796992481203
  - 0.8318477578032308
  - 0.8309208033345965
  - 0.8306461407663812
  - 0.8307435430737526
  - 0.8316325003740834
  LL_f1_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_f1_weighted:
  - 0.988913546445512
  - 0.987722980614685
  - 0.9882987906880089
  - 0.9922463112278831
  - 0.9890650969602176
  - 0.9876998468075384
  - 0.9882185032999534
  - 0.9920854949952507
  - 0.989145002886385
  - 0.9878502202741921
  - 0.9883665137089277
  - 0.992373769952719
  - 0.9889251187756575
  - 0.9876871736491468
  - 0.9881256525918501
  - 0.9921544150315158
  LL_matthews_corrcoef:
  - 0.7036995331209558
  - 0.7034934238032008
  - 0.7036800473667042
  - 0.7047339211336413
  - 0.7039328307015822
  - 0.7034858763540875
  - 0.7036537950796627
  - 0.7046842107963786
  - 0.7037716557806432
  - 0.7035349496681379
  - 0.7035289052508503
  - 0.7050384450672653
  - 0.7037031401185525
  - 0.7033166743918887
  - 0.7034537008880977
  - 0.7047055173504467
  LL_precision_macro:
  - 0.9951930329146512
  - 0.9946695525242866
  - 0.9949226426198765
  - 0.9966498995963974
  - 0.9952589717549346
  - 0.9946593780516042
  - 0.9948873725584086
  - 0.9965798369457148
  - 0.9952945434802281
  - 0.9947255048014012
  - 0.99495292052346
  - 0.996704902389567
  - 0.9951981094127111
  - 0.9946543444776661
  - 0.994847109293161
  - 0.9966098661841608
  LL_precision_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_precision_weighted:
  - 0.9905691610246246
  - 0.9895641206011611
  - 0.9900495467435512
  - 0.993388986998302
  - 0.9906961659372497
  - 0.9895446267221922
  - 0.9899818391422291
  - 0.9932526182442893
  - 0.990764566109916
  - 0.9896713515806191
  - 0.9901075886643413
  - 0.9934961616644096
  - 0.9905789293393269
  - 0.9895348789514361
  - 0.9899044700418723
  - 0.9933110572197021
  LL_recall_macro:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LL_recall_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_recall_weighted:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_roc_auc:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LT_average_precision:
  - 0.062197300079119486
  - 0.18066230517003212
  - 0.025092006566472227
  - 0.03564348998419533
  - 0.054837847946283644
  - 0.1274197612454356
  - 0.023590828158405016
  - 0.03545079047164029
  - 0.04379506343541925
  - 0.1322516265396222
  - 0.022845542193711935
  - 0.03606919351813512
  - 0.07127430001511206
  - 0.1664392404928536
  - 0.018239878347616298
  - 0.034900322986037104
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5844011695370058
  - 0.6179094604313342
  - 0.5759776118538368
  - 0.5132426813086758
  - 0.5720569835640453
  - 0.6005668169307377
  - 0.5699042716781845
  - 0.5210276168472869
  - 0.5596640830977081
  - 0.6160771376808837
  - 0.5600899897617494
  - 0.5154280111757985
  - 0.5914531920826183
  - 0.6032891343433753
  - 0.5508992106701056
  - 0.5012597503900156
  TL_average_precision:
  - 0.3279912490656647
  - 0.36620535506935503
  - 0.34315207446382284
  - 0.24610039769386724
  - 0.36449149560834704
  - 0.3409765470103018
  - 0.34871339937504575
  - 0.21609480125543667
  - 0.3213501455695327
  - 0.34638711303594394
  - 0.3475385409478538
  - 0.2270622774909722
  - 0.36242059586134123
  - 0.37581619995977705
  - 0.3738721973870762
  - 0.21063397653277885
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7798254940540272
  - 0.7914582393644141
  - 0.7786721492533762
  - 0.7205221597063357
  - 0.7972146801218583
  - 0.7918368539946411
  - 0.7993976625275558
  - 0.7130142489310732
  - 0.7923444723378416
  - 0.7785479742988711
  - 0.7947713807518975
  - 0.735653161235098
  - 0.7943274744789812
  - 0.7906705837167661
  - 0.8039517729873059
  - 0.7233799678258417
  TT_average_precision:
  - 0.034612941732590365
  - 0.06872735769877023
  - 0.025873988704917347
  - 0.033397325134006034
  - 0.033244980769644675
  - 0.05795039879043233
  - 0.020151172840869078
  - 0.03682507647465698
  - 0.03543765911004929
  - 0.029817051658873484
  - 0.020521138375783482
  - 0.03778213004731785
  - 0.030548161335655077
  - 0.06818710431797814
  - 0.024611119241978906
  - 0.03385526643887201
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5658019009713966
  - 0.6138696618451477
  - 0.6396658096616911
  - 0.5125190874209015
  - 0.5704939700172286
  - 0.6282800523089297
  - 0.6055440289219307
  - 0.5185043945092666
  - 0.564468331417484
  - 0.6107756774309442
  - 0.5885675825173334
  - 0.533145995194858
  - 0.5472327653092931
  - 0.6104393803108329
  - 0.6373050806219726
  - 0.5105201746075133
  fit_time:
  - 352.1909008026123
  - 382.2388892173767
  - 368.1313166618347
  - 323.6163418292999
  - 345.0367052555084
  - 384.11318278312683
  - 366.3843057155609
  - 305.6867275238037
  - 345.52910804748535
  - 377.79885959625244
  - 378.9339385032654
  - 314.0687825679779
  - 361.04963779449463
  - 388.9156930446625
  - 372.8147678375244
  - 301.54388904571533
  score_time:
  - 5.890525579452515
  - 4.003093242645264
  - 4.519066333770752
  - 8.04267430305481
  - 7.54598069190979
  - 3.9891252517700195
  - 4.4307475090026855
  - 8.545770645141602
  - 7.476929426193237
  - 3.937847137451172
  - 4.1061179637908936
  - 7.970031261444092
  - 4.75639271736145
  - 4.146371364593506
  - 4.104681730270386
  - 8.987677335739136
start: 2023-11-14 13:06:00.086829
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
