active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-22 20:06:33.711350
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_fixed
  params: {}
hash: 2b607ccfb9d506bd73cc1167d7d0b2023ae0648bdd762574ffdcc6769df6db26
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/2b607cc_20231122T200629431728_ss_bxt_gso__ad_fixed_ion_channels.yml"
results:
  LL_average_precision:
  - 0.32663246582317396
  - 0.32600044510716425
  - 0.3239487591028229
  - 0.3272668922132747
  - 0.32556707196748086
  - 0.3268879632576892
  - 0.32374451890460826
  - 0.32510644269942257
  - 0.32559255461498604
  - 0.3263454714349574
  - 0.32403408620832297
  - 0.3240424875168476
  - 0.32536901767026805
  - 0.32540137037937994
  - 0.32419254880642945
  - 0.32463599939400384
  LL_balanced_accuracy:
  - 0.6504524886877828
  - .nan
  - 0.6500607533414338
  - .nan
  - 0.6502320185614849
  - .nan
  - 0.65
  - .nan
  - 0.6504112808460635
  - .nan
  - 0.65
  - .nan
  - 0.650174621653085
  - .nan
  - 0.6503067484662577
  - .nan
  LL_f1_macro:
  - 0.7247147376580412
  - .nan
  - 0.7247494932538617
  - .nan
  - 0.7246180167203053
  - .nan
  - 0.7246992675697045
  - .nan
  - 0.724917092571373
  - .nan
  - 0.7246235538985544
  - .nan
  - 0.7245719922026472
  - .nan
  - 0.7251051764698372
  - .nan
  LL_f1_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_f1_weighted:
  - 0.9675291813846373
  - .nan
  - 0.9699045778045997
  - .nan
  - 0.9683066504870864
  - .nan
  - 0.9700068543616309
  - .nan
  - 0.9687302172486109
  - .nan
  - 0.9696429040017699
  - .nan
  - 0.968409524086243
  - .nan
  - 0.9702234059506051
  - .nan
  LL_matthews_corrcoef:
  - 0.5413656446134067
  - .nan
  - 0.5411992376285261
  - .nan
  - 0.5411462518352902
  - .nan
  - 0.5411131214734051
  - .nan
  - 0.5415634050678383
  - .nan
  - 0.5410311761278824
  - .nan
  - 0.5410665251308358
  - .nan
  - 0.5417127859685285
  - .nan
  LL_precision_macro:
  - 0.9869922121658599
  - .nan
  - 0.987963388640448
  - .nan
  - 0.9873116741015067
  - .nan
  - 0.9880056837178202
  - .nan
  - 0.9874815905743741
  - .nan
  - 0.9878578892371996
  - .nan
  - 0.9873542902832134
  - .nan
  - 0.9880897655564378
  - .nan
  LL_precision_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_precision_weighted:
  - 0.9749418269748551
  - .nan
  - 0.9767463463343345
  - .nan
  - 0.9755339961297858
  - .nan
  - 0.9768250796348118
  - .nan
  - 0.9758501689028972
  - .nan
  - 0.9765495628653252
  - .nan
  - 0.9756130112434778
  - .nan
  - 0.9769826121976364
  - .nan
  LL_recall_macro:
  - 0.6504524886877828
  - .nan
  - 0.6500607533414338
  - .nan
  - 0.6502320185614849
  - .nan
  - 0.65
  - .nan
  - 0.6504112808460635
  - .nan
  - 0.65
  - .nan
  - 0.650174621653085
  - .nan
  - 0.6503067484662577
  - .nan
  LL_recall_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_recall_weighted:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_roc_auc:
  - 0.6504524886877828
  - 0.6504021862039957
  - 0.6500607533414338
  - 0.6521950624336336
  - 0.6502320185614849
  - 0.6512943285803204
  - 0.65
  - 0.6510883325109408
  - 0.6504112808460635
  - 0.6507760035112483
  - 0.65
  - 0.6504892072654067
  - 0.650174621653085
  - 0.6506808263657891
  - 0.6503067484662577
  - 0.6512382165774748
  LT_average_precision:
  - 0.25213400476343983
  - 0.07575695820414574
  - 0.1570321598751305
  - 0.2039858617178057
  - 0.25029727756376563
  - 0.0996321469558355
  - 0.10562240154987695
  - 0.13370510296832053
  - 0.21940508748578438
  - 0.09603183109342553
  - 0.1369474373027276
  - 0.1899528625440213
  - 0.22095094217585484
  - 0.11177628235126243
  - 0.16075369412975926
  - 0.1901699975783936
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6999835187912363
  - 0.6009519710793597
  - 0.611725661790317
  - 0.645269397094846
  - 0.6848391106590954
  - 0.6254113864285858
  - 0.5909003377953421
  - 0.618038395942118
  - 0.6797112854437696
  - 0.6129209827612935
  - 0.6282215439589072
  - 0.6647787718637488
  - 0.6696598231251696
  - 0.6316598103404987
  - 0.6496438673941604
  - 0.6322903025144054
  TL_average_precision:
  - 0.4808755045462333
  - 0.43837193775909933
  - 0.4157724422397943
  - 0.465325979722474
  - 0.5359115835041571
  - 0.5514024961880868
  - 0.5220325883063347
  - 0.5005876811266808
  - 0.4969554752918195
  - 0.3820869224480786
  - 0.4218999187037663
  - 0.4715840774404773
  - 0.5160392700035413
  - 0.5399301988937477
  - 0.5684612549868188
  - 0.567290002024273
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.8582050980399721
  - 0.8283587146089306
  - 0.8138391901397681
  - 0.8283262093764842
  - 0.8371363268734947
  - 0.8363651739574787
  - 0.8460505756502371
  - 0.8396663565916033
  - 0.81596857261848
  - 0.7731444292903165
  - 0.8026499127696036
  - 0.7964566877883876
  - 0.8266460254437437
  - 0.8466833023928371
  - 0.8599781177914436
  - 0.8439412359537795
  TT_average_precision:
  - 0.21228768119156813
  - 0.05335983351256883
  - 0.09342263792963056
  - 0.14741299121724147
  - 0.30290462033781723
  - 0.07533213463719537
  - 0.21529580096015996
  - 0.1590780276057701
  - 0.2101004525474962
  - 0.08247463638884515
  - 0.10323531706802591
  - 0.22614370242644616
  - 0.2809711316418967
  - 0.07512574179730747
  - 0.16852120954775504
  - 0.15786893308632494
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.7223003639958657
  - 0.5725156269932389
  - 0.5964789074650079
  - 0.6542258641906252
  - 0.7277758943789963
  - 0.6326450841534075
  - 0.6967828252680979
  - 0.6276012373453318
  - 0.7744153496238408
  - 0.5720028440166265
  - 0.562942789968652
  - 0.6717133967527359
  - 0.7119124129691426
  - 0.64269312002876
  - 0.6453942079383775
  - 0.6276323858204435
  fit_time:
  - 3.1907570362091064
  - 2.933412790298462
  - 3.1165003776550293
  - 2.838188648223877
  - 3.233255386352539
  - 2.801497459411621
  - 3.246690034866333
  - 2.9568254947662354
  - 3.0976383686065674
  - 2.9631927013397217
  - 2.9626739025115967
  - 3.152813673019409
  - 3.119065523147583
  - 3.0293235778808594
  - 3.1428074836730957
  - 2.9747557640075684
  score_time:
  - 1.021824836730957
  - 0.4745333194732666
  - 1.0542993545532227
  - 0.4705324172973633
  - 0.9576990604400635
  - 0.5066099166870117
  - 0.9763245582580566
  - 0.8806436061859131
  - 1.0380618572235107
  - 0.8763422966003418
  - 0.9427564144134521
  - 0.8860983848571777
  - 1.0097875595092773
  - 0.8544785976409912
  - 1.0283770561218262
  - 0.8839142322540283
start: 2023-11-22 20:06:29.431728
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
