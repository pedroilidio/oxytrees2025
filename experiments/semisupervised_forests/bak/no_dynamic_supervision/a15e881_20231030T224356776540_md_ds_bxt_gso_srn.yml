active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-10-31 00:05:39.596523
estimator:
  call: semisupervised_forests.estimators.md_ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ds_bxt_gso
  params: {}
hash: a15e8816e2978eabc83e0ed20e555c63ab2944c7d87f12b64d68f667d6aa3d00
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/a15e881_20231030T224356776540_md_ds_bxt_gso_srn.yml"
results:
  LL_average_precision:
  - 0.31043956043956045
  - 0.3135321585011493
  - 0.31393697904693796
  - 0.31289824492932156
  - 0.3104626920106975
  - 0.31309691275241186
  - 0.31374651818975763
  - 0.3122514757489135
  - 0.31050772523023307
  - 0.31332852192953764
  - 0.3140485358674154
  - 0.31274634668205165
  - 0.3108996636445437
  - 0.31333143351602716
  - 0.31392743184478733
  - 0.31294731263378284
  LL_balanced_accuracy:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LL_f1_macro:
  - 0.7281337930487852
  - 0.7276140047113996
  - 0.7272761330148422
  - 0.7278745634629974
  - 0.7282277202975188
  - 0.7276129923249521
  - 0.7273254783927879
  - 0.7277551796969631
  - 0.7281658357729319
  - 0.7274725625454239
  - 0.727358050792975
  - 0.7277486910318385
  - 0.72836076529905
  - 0.7275107921372921
  - 0.7273156338691005
  - 0.7278602308042376
  LL_f1_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_f1_weighted:
  - 0.9867773014842327
  - 0.9832767564481393
  - 0.9824151148968876
  - 0.9842242865375411
  - 0.9868978376855441
  - 0.9836576134985787
  - 0.9826562370890688
  - 0.9846140199382498
  - 0.9867652915002223
  - 0.9832436907593204
  - 0.9824398921378842
  - 0.9841691217693783
  - 0.9867123798169393
  - 0.9832984138780857
  - 0.9824826606909075
  - 0.9841596703263348
  LL_matthews_corrcoef:
  - 0.5448431486319819
  - 0.5443609417010167
  - 0.5439207436585922
  - 0.5446751228599022
  - 0.5449765507868785
  - 0.5443249928425076
  - 0.5439745794585498
  - 0.5444568100737082
  - 0.5448934338702066
  - 0.544147002223111
  - 0.5440441015538537
  - 0.5444869889588942
  - 0.5451975133055292
  - 0.5442006887412761
  - 0.5439751945855913
  - 0.5446589593200364
  LL_precision_macro:
  - 0.9947567610186865
  - 0.9933559856804806
  - 0.9930116010890111
  - 0.9937350525111781
  - 0.9948045695277279
  - 0.9935089679302311
  - 0.993108257961673
  - 0.9938920393056578
  - 0.9947518165105489
  - 0.9933434963750856
  - 0.9930210797182439
  - 0.9937135781516535
  - 0.9947297924308613
  - 0.9933652655193022
  - 0.9930385285173409
  - 0.99370919418804
  LL_precision_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_precision_weighted:
  - 0.9896699137809285
  - 0.9869629006498913
  - 0.9863006300201597
  - 0.9876933266807815
  - 0.9897627235580176
  - 0.9872574292838272
  - 0.9864863450449225
  - 0.9879961817679739
  - 0.989660332078433
  - 0.9869387829828868
  - 0.9863188879609665
  - 0.9876518453970167
  - 0.9896176763911533
  - 0.9869806978421226
  - 0.9863523742084683
  - 0.9876434508801099
  LL_recall_macro:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LL_recall_micro:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_recall_weighted:
  - 0.9895604395604396
  - 0.986787330316742
  - 0.9861064425770308
  - 0.9875371687136393
  - 0.9896552325176045
  - 0.9870898286108001
  - 0.9862974765308758
  - 0.9878477306002929
  - 0.9895506518859374
  - 0.986762552751701
  - 0.9861252260787184
  - 0.9874946171733701
  - 0.9895070766227428
  - 0.9868056153647403
  - 0.9861596761691499
  - 0.9874860046507622
  LL_roc_auc:
  - 0.65
  - 0.6501597444089458
  - 0.6500217108119843
  - 0.6502177068214804
  - 0.6500589622641509
  - 0.650093370681606
  - 0.6500219973603167
  - 0.6500496031746031
  - 0.6500291885580852
  - 0.6500455373406193
  - 0.6500868809730669
  - 0.6501204819277109
  - 0.6502033701336433
  - 0.6500685244403838
  - 0.6500435540069687
  - 0.6502166586422725
  LT_average_precision:
  - 0.029936968977369523
  - 0.01827663502990448
  - 0.013307352877435046
  - 0.02312312601087469
  - 0.028793167360084436
  - 0.01838101873828524
  - 0.01341168653438083
  - 0.02224680734611159
  - 0.03065090828000801
  - 0.0168324340308431
  - 0.014515961095351897
  - 0.021327744650606936
  - 0.02838221246464334
  - 0.016968107580849892
  - 0.013982295931481443
  - 0.020685632463059118
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5268773653144693
  - 0.5243266943704074
  - 0.5259385641841332
  - 0.5500303718377955
  - 0.519206367582813
  - 0.529107479679386
  - 0.5291608071608741
  - 0.5458523266405039
  - 0.518167487894171
  - 0.511793129148652
  - 0.5469286603522628
  - 0.5435462826175389
  - 0.5208268398203653
  - 0.513924322174269
  - 0.526079772464091
  - 0.5272441855179246
  TL_average_precision:
  - 0.06843150218066842
  - 0.08604254169896236
  - 0.07647208120397705
  - 0.07242559604934391
  - 0.09332142858145265
  - 0.09906915573925724
  - 0.0931675166078158
  - 0.08962834600368087
  - 0.08711122596242758
  - 0.10620839812279576
  - 0.08560250208191125
  - 0.06704606688051337
  - 0.07981268918690965
  - 0.06812788897878289
  - 0.09268994431761374
  - 0.07816687059237896
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5755343266206009
  - 0.5897697334863848
  - 0.5797156700364452
  - 0.5791627219883689
  - 0.5815981574403405
  - 0.5791317043044187
  - 0.5885080176777228
  - 0.5862533372635448
  - 0.5943949040647842
  - 0.5963088871699842
  - 0.5840126042827855
  - 0.576966070842996
  - 0.5807692473943354
  - 0.5714131812574464
  - 0.5767440658620755
  - 0.5741585736885216
  TT_average_precision:
  - 0.0270953366625999
  - 0.014732452122371967
  - 0.013749623149581232
  - 0.019682536128854573
  - 0.029123254443923212
  - 0.016452118984597194
  - 0.01590221627543374
  - 0.024783200412427223
  - 0.028741068868982655
  - 0.01566990630032573
  - 0.011465730718106571
  - 0.021680467737771363
  - 0.027594196959023983
  - 0.016158415136844934
  - 0.014066820496997662
  - 0.02084925360295112
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5176775969155508
  - 0.4845138241625306
  - 0.526180906975609
  - 0.5364398836005483
  - 0.5150452557820978
  - 0.5113659048018452
  - 0.5073104294235958
  - 0.5668882674124384
  - 0.5106231437288707
  - 0.522355299164448
  - 0.5028818222885382
  - 0.557072327837377
  - 0.514719039543255
  - 0.5188683306962877
  - 0.5310263605442178
  - 0.5398564244718091
  fit_time:
  - 3940.89577126503
  - 4781.333126783371
  - 4824.178003787994
  - 4685.909249782562
  - 4138.618905544281
  - 4670.206573963165
  - 4878.85396194458
  - 4479.39716219902
  - 3886.677272796631
  - 4794.9796307086945
  - 4894.05325961113
  - 4585.260334253311
  - 4055.069878101349
  - 4697.239018440247
  - 4812.983419418335
  - 4632.252772331238
  score_time:
  - 10.341115951538086
  - 6.598149538040161
  - 6.546929597854614
  - 6.926828622817993
  - 9.77682614326477
  - 6.935818910598755
  - 6.645669221878052
  - 8.951380968093872
  - 10.42639970779419
  - 6.960256576538086
  - 6.533249378204346
  - 7.808687210083008
  - 10.581822395324707
  - 6.792965650558472
  - 6.943966627120972
  - 7.412288188934326
start: 2023-10-30 22:43:56.776540
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
