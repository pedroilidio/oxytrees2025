active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - precision_weighted
    - recall_weighted
    - precision_micro
    - recall_macro
    - matthews_corrcoef
    - f1_micro
    - precision_macro
    - roc_auc
    - f1_weighted
    - balanced_accuracy
    - average_precision
    - recall_micro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-27 19:49:10.912121
estimator:
  call: semisupervised_forests.estimators.rs_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: rs_bxt_gso
  params: {}
hash: dd4954acf2ffd396e3e4d418c7aa6e67c1abe4a066ba359f67865fe03bd40388
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/dd4954a_20231027T194901580359_rs_bxt_gso_ion_channels.yml"
results:
  LL_average_precision:
  - 0.5184005661712668
  - 0.5187865219998591
  - 0.5176092708181601
  - 0.518744131433711
  - 0.5179426335289955
  - 0.5189670182531763
  - 0.5169603706461487
  - 0.5174447680846191
  - 0.5182803961535615
  - 0.5196234815855826
  - 0.5171672044345165
  - 0.5182301235735647
  - 0.5184414452255325
  - 0.5194388758010936
  - 0.5174497673056435
  - 0.51713345778909
  LL_balanced_accuracy:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_f1_macro:
  - 0.8286026200873362
  - .nan
  - 0.8292413854501421
  - .nan
  - 0.8287236090611564
  - .nan
  - 0.8289825544377944
  - .nan
  - 0.8290503652067968
  - .nan
  - 0.8289280937519903
  - .nan
  - 0.8290039908492242
  - .nan
  - 0.8292875847754466
  - .nan
  LL_f1_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538514
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_f1_weighted:
  - 0.978619720602309
  - .nan
  - 0.9802433876449146
  - .nan
  - 0.9791496381427907
  - .nan
  - 0.9802866917354942
  - .nan
  - 0.9794433538280974
  - .nan
  - 0.9800472204748734
  - .nan
  - 0.979250620929605
  - .nan
  - 0.9804349774611915
  - .nan
  LL_matthews_corrcoef:
  - 0.700447894610418
  - .nan
  - 0.7013905925141326
  - .nan
  - 0.7006174228557172
  - .nan
  - 0.7009803892718732
  - .nan
  - 0.7011211134187072
  - .nan
  - 0.700904035830809
  - .nan
  - 0.70105565880409
  - .nan
  - 0.7014558703735905
  - .nan
  LL_precision_macro:
  - 0.9906272530641673
  - .nan
  - 0.9913517380691861
  - .nan
  - 0.9908647732089868
  - .nan
  - 0.9913735061437469
  - .nan
  - 0.9909938546302183
  - .nan
  - 0.991266467443916
  - .nan
  - 0.990907549489212
  - .nan
  - 0.9914373474711773
  - .nan
  LL_precision_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_precision_weighted:
  - 0.9819443615291318
  - .nan
  - 0.983292333552872
  - .nan
  - 0.9823851865240354
  - .nan
  - 0.9833322464202088
  - .nan
  - 0.9826258367080601
  - .nan
  - 0.9831326562431352
  - .nan
  - 0.9824653978826134
  - .nan
  - 0.9834520558930446
  - .nan
  LL_recall_macro:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_recall_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_recall_weighted:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_roc_auc:
  - 0.75
  - 0.750467996038315
  - 0.7503037667071689
  - 0.7511876778702402
  - 0.75
  - 0.750805899402654
  - 0.75
  - 0.7505533643041373
  - 0.7502937720329025
  - 0.7510627666035055
  - 0.75
  - 0.750897768715929
  - 0.7502910360884749
  - 0.751166914678009
  - 0.7503067484662577
  - 0.750616971901795
  LT_average_precision:
  - 0.2776754209994173
  - 0.14289341176686787
  - 0.18669090238843059
  - 0.2587005402172212
  - 0.3205165634684112
  - 0.09915627579694421
  - 0.1651005352636872
  - 0.22151942459699547
  - 0.346921317864174
  - 0.10564482174947316
  - 0.16238609925074196
  - 0.231395238044508
  - 0.30739007172968585
  - 0.13392284975349514
  - 0.19478449989865443
  - 0.23857749401471334
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.7518496169448092
  - 0.6753272016329341
  - 0.69027385928248
  - 0.684741187262482
  - 0.7671959540408844
  - 0.6379025307754916
  - 0.6772206556019824
  - 0.6887813105259727
  - 0.7922516784300223
  - 0.6553942172971595
  - 0.6680144048239411
  - 0.7257180347111245
  - 0.7583131939567583
  - 0.6720947524962821
  - 0.6842307464700382
  - 0.6779295851885803
  TL_average_precision:
  - 0.582787205524789
  - 0.6026496394187224
  - 0.6014621059419156
  - 0.5787887950098489
  - 0.6935007668668306
  - 0.7007802375390118
  - 0.7006089728364636
  - 0.7124645467340449
  - 0.5975134088845373
  - 0.6296171647809701
  - 0.5743355623672499
  - 0.5739857886339855
  - 0.6385349085984511
  - 0.6550212545372085
  - 0.6965299359192588
  - 0.6210623991593712
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.8956921041516799
  - 0.878773067042705
  - 0.8737997605049628
  - 0.8735948717562124
  - 0.9078791561845099
  - 0.9023355968677577
  - 0.8925218545957039
  - 0.8982071753580921
  - 0.8507223089744109
  - 0.8815656304378496
  - 0.8620529442188634
  - 0.8517935605453729
  - 0.8850717767703948
  - 0.8853318335887038
  - 0.8872931268724229
  - 0.8632186154318112
  TT_average_precision:
  - 0.2019653911846671
  - 0.09053758754037208
  - 0.12579883544373796
  - 0.19236877306803674
  - 0.38128386161194044
  - 0.11355511897618706
  - 0.2412415372719611
  - 0.32620259726182843
  - 0.2656538443989278
  - 0.08707480478573058
  - 0.14705916832704913
  - 0.24370414871746957
  - 0.3550957900539773
  - 0.08462397541015228
  - 0.16679325742524878
  - 0.20551933362329006
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.7449310205365569
  - 0.6714908364162095
  - 0.6547020800933125
  - 0.6970937944480847
  - 0.7848240434688438
  - 0.6855283730341212
  - 0.7002655249778729
  - 0.7354893138357705
  - 0.805846503761591
  - 0.6260033993571512
  - 0.6244788401253918
  - 0.6898719691009226
  - 0.7604890207226136
  - 0.6721857727048038
  - 0.6736234972984089
  - 0.6401463357037026
  fit_time:
  - 4.77747654914856
  - 4.83972430229187
  - 5.559863090515137
  - 7.968127012252808
  - 8.431209087371826
  - 8.324719905853271
  - 7.935364007949829
  - 7.989532470703125
  - 7.968448877334595
  - 8.265819072723389
  - 8.112682104110718
  - 8.060131788253784
  - 8.01878023147583
  - 7.860868215560913
  - 7.833055734634399
  - 7.99902081489563
  score_time:
  - 0.5831038951873779
  - 0.4644432067871094
  - 0.5240724086761475
  - 0.962653636932373
  - 0.8417332172393799
  - 0.7867739200592041
  - 1.1056442260742188
  - 0.9638628959655762
  - 1.0657386779785156
  - 0.8159339427947998
  - 0.98899245262146
  - 0.8829693794250488
  - 1.025669813156128
  - 0.8155183792114258
  - 1.0419199466705322
  - 0.9549150466918945
start: 2023-10-27 19:49:01.580359
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
