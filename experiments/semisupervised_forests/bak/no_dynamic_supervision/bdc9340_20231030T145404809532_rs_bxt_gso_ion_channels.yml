active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-30 14:54:12.677671
estimator:
  call: semisupervised_forests.estimators.rs_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: rs_bxt_gso
  params: {}
hash: bdc93408f57d36270861f2c321389811cb246523d578c213a8c125e73e2815cf
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/bdc9340_20231030T145404809532_rs_bxt_gso_ion_channels.yml"
results:
  LL_average_precision:
  - 0.32663246582317396
  - 0.32715116186887383
  - 0.3239487591028229
  - 0.3262322780037187
  - 0.32556707196748086
  - 0.3269976570735275
  - 0.32374451890460826
  - 0.32601122773531827
  - 0.32559255461498604
  - 0.3263454714349574
  - 0.32403408620832297
  - 0.3240882429068535
  - 0.32536901767026805
  - 0.3253066107352313
  - 0.32419254880642945
  - 0.3245657987015289
  LL_balanced_accuracy:
  - 0.6504524886877828
  - .nan
  - 0.6500607533414338
  - .nan
  - 0.6502320185614849
  - .nan
  - 0.65
  - .nan
  - 0.6504112808460635
  - .nan
  - 0.65
  - .nan
  - 0.650174621653085
  - .nan
  - 0.6503067484662577
  - .nan
  LL_f1_macro:
  - 0.7247147376580412
  - .nan
  - 0.7247494932538617
  - .nan
  - 0.7246180167203053
  - .nan
  - 0.7246992675697045
  - .nan
  - 0.724917092571373
  - .nan
  - 0.7246235538985544
  - .nan
  - 0.7245719922026472
  - .nan
  - 0.7251051764698372
  - .nan
  LL_f1_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_f1_weighted:
  - 0.9675291813846373
  - .nan
  - 0.9699045778045997
  - .nan
  - 0.9683066504870864
  - .nan
  - 0.9700068543616309
  - .nan
  - 0.9687302172486109
  - .nan
  - 0.9696429040017699
  - .nan
  - 0.968409524086243
  - .nan
  - 0.9702234059506051
  - .nan
  LL_matthews_corrcoef:
  - 0.5413656446134067
  - .nan
  - 0.5411992376285261
  - .nan
  - 0.5411462518352902
  - .nan
  - 0.5411131214734051
  - .nan
  - 0.5415634050678383
  - .nan
  - 0.5410311761278824
  - .nan
  - 0.5410665251308358
  - .nan
  - 0.5417127859685285
  - .nan
  LL_precision_macro:
  - 0.9869922121658599
  - .nan
  - 0.987963388640448
  - .nan
  - 0.9873116741015067
  - .nan
  - 0.9880056837178202
  - .nan
  - 0.9874815905743741
  - .nan
  - 0.9878578892371996
  - .nan
  - 0.9873542902832134
  - .nan
  - 0.9880897655564378
  - .nan
  LL_precision_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_precision_weighted:
  - 0.9749418269748551
  - .nan
  - 0.9767463463343345
  - .nan
  - 0.9755339961297858
  - .nan
  - 0.9768250796348118
  - .nan
  - 0.9758501689028972
  - .nan
  - 0.9765495628653252
  - .nan
  - 0.9756130112434778
  - .nan
  - 0.9769826121976364
  - .nan
  LL_recall_macro:
  - 0.6504524886877828
  - .nan
  - 0.6500607533414338
  - .nan
  - 0.6502320185614849
  - .nan
  - 0.65
  - .nan
  - 0.6504112808460635
  - .nan
  - 0.65
  - .nan
  - 0.650174621653085
  - .nan
  - 0.6503067484662577
  - .nan
  LL_recall_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_recall_weighted:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_roc_auc:
  - 0.6504524886877828
  - 0.6510113282680703
  - 0.6500607533414338
  - 0.6516140357310113
  - 0.6502320185614849
  - 0.6513250231443182
  - 0.65
  - 0.6516568877358634
  - 0.6504112808460635
  - 0.6507760035112483
  - 0.65
  - 0.6505043966205778
  - 0.650174621653085
  - 0.6506501881354366
  - 0.6503067484662577
  - 0.6512229566707434
  LT_average_precision:
  - 0.19061525603156115
  - 0.10191720935377066
  - 0.15970121383410243
  - 0.20156841978534537
  - 0.2693740419995497
  - 0.10208723329907828
  - 0.1359091653402884
  - 0.1605975520817302
  - 0.21442018844189487
  - 0.09532084528734303
  - 0.13194778309733224
  - 0.19394765119012594
  - 0.22139330916655175
  - 0.09526356768760019
  - 0.1570777835275847
  - 0.213645571449848
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.7021438862690265
  - 0.6212232250448811
  - 0.6561522553117379
  - 0.6456175720492324
  - 0.7295120218390552
  - 0.638031950333567
  - 0.6240651165130922
  - 0.645261703528145
  - 0.6816543294887244
  - 0.6335032124481254
  - 0.6379745775329413
  - 0.6580399530318415
  - 0.7008112899202008
  - 0.6431832667014312
  - 0.6448746020286183
  - 0.6605237526191723
  TL_average_precision:
  - 0.48209208306347534
  - 0.47892398504511674
  - 0.46786104904960013
  - 0.43762857813182987
  - 0.4986029988931562
  - 0.5527670638971767
  - 0.538658693816702
  - 0.502541483104619
  - 0.39736482400121353
  - 0.4893010096321987
  - 0.45118181578301325
  - 0.4685520159008637
  - 0.5360596121896155
  - 0.566721513889059
  - 0.5129410381844062
  - 0.5520564741033817
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.85371750563631
  - 0.8323836631524368
  - 0.8194101552483054
  - 0.799598445042505
  - 0.8211771592498424
  - 0.8478938154049891
  - 0.8249921316006092
  - 0.8218975207691709
  - 0.7716158095732454
  - 0.8184092084842214
  - 0.7981009537447314
  - 0.8010273307325045
  - 0.8341183664114977
  - 0.8451558219724373
  - 0.8069354978202448
  - 0.8411050640246328
  TT_average_precision:
  - 0.17013093359911036
  - 0.10024453211748452
  - 0.103919244465412
  - 0.15946083647886394
  - 0.3073395511536706
  - 0.12900732928007208
  - 0.21276072869453522
  - 0.2642402528304588
  - 0.13196346481197183
  - 0.08345400549551617
  - 0.13126772099150108
  - 0.18658175284178147
  - 0.27901816669984714
  - 0.049417476372752456
  - 0.14474457997067713
  - 0.20813600960468107
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.6927155889093605
  - 0.6339775481566525
  - 0.6050835925349923
  - 0.6529473574864557
  - 0.7439566441600511
  - 0.6737721879885956
  - 0.6868740094271658
  - 0.6983250140607424
  - 0.6771563538811454
  - 0.6378191104454504
  - 0.6030564263322885
  - 0.679556183391746
  - 0.7550735384995674
  - 0.5933941491034916
  - 0.6261727148652945
  - 0.6313193447268489
  fit_time:
  - 4.215067148208618
  - 4.112173080444336
  - 4.715029954910278
  - 6.5152599811553955
  - 6.8209145069122314
  - 6.727312088012695
  - 6.786167621612549
  - 6.8414506912231445
  - 6.648023366928101
  - 6.71807861328125
  - 6.684121608734131
  - 6.578271865844727
  - 6.732810020446777
  - 6.803505182266235
  - 6.862841844558716
  - 6.307240724563599
  score_time:
  - 0.5628783702850342
  - 0.46034860610961914
  - 0.5070991516113281
  - 0.8488614559173584
  - 1.0025815963745117
  - 0.8837504386901855
  - 1.0264716148376465
  - 0.8668437004089355
  - 0.9921202659606934
  - 0.822101354598999
  - 1.000145435333252
  - 0.886458158493042
  - 1.0502123832702637
  - 0.8696749210357666
  - 0.9227180480957031
  - 0.8133268356323242
start: 2023-10-30 14:54:04.809532
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
