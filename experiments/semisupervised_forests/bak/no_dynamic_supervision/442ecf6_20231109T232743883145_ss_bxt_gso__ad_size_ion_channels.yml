active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 23:27:46.830848
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_size
  params: {}
hash: 442ecf604ef331312e629bf9e971056c01d5f620a480eb5340704663b7343c10
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/442ecf6_20231109T232743883145_ss_bxt_gso__ad_size_ion_channels.yml"
results:
  LL_average_precision:
  - 0.13377477399583057
  - 0.13302798872798172
  - 0.13146194745848774
  - 0.12995195857601313
  - 0.13319151040596633
  - 0.13259068618960163
  - 0.13052866716306777
  - 0.13027598377107885
  - 0.13290471307641066
  - 0.1328142402271899
  - 0.13090096798212958
  - 0.13002088660824432
  - 0.13229659011500366
  - 0.13254182453146074
  - 0.13093533030721544
  - 0.12865051305110875
  LL_balanced_accuracy:
  - 0.5503393665158371
  - .nan
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - .nan
  - 0.55
  - .nan
  - 0.5505287896592245
  - .nan
  - 0.55
  - .nan
  - 0.5500582072176949
  - .nan
  - 0.5503067484662577
  - .nan
  LL_f1_macro:
  - 0.5830246326395329
  - .nan
  - 0.5838124823590799
  - 0.5835535019599959
  - 0.583447048714696
  - .nan
  - 0.5831318283369036
  - .nan
  - 0.5836621267888888
  - .nan
  - 0.5830351581590119
  - .nan
  - 0.582798823502053
  - .nan
  - 0.583692073407322
  - .nan
  LL_f1_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_f1_weighted:
  - 0.9536627205559293
  - .nan
  - 0.9571259928856107
  - 0.9583788951019314
  - 0.9548280871486553
  - .nan
  - 0.9572197620943651
  - .nan
  - 0.9554109057637129
  - .nan
  - 0.9567010390780758
  - .nan
  - 0.9549223882988672
  - .nan
  - 0.9575233439965773
  - .nan
  LL_matthews_corrcoef:
  - 0.31198441312481723
  - .nan
  - 0.3126543364921219
  - 0.3118704264397513
  - 0.31250592182651615
  - .nan
  - 0.3113466596691422
  - .nan
  - 0.3127740736927638
  - .nan
  - 0.31128645486743545
  - .nan
  - 0.3112604610693923
  - .nan
  - 0.3123336797877318
  - .nan
  LL_precision_macro:
  - 0.9833904395788067
  - .nan
  - 0.9846415673903117
  - 0.9851000249024653
  - 0.9838096431854266
  - .nan
  - 0.9846837124356633
  - .nan
  - 0.9840192187173595
  - .nan
  - 0.9844962849196796
  - .nan
  - 0.9838520994359724
  - .nan
  - 0.9847874813216005
  - .nan
  LL_precision_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_precision_weighted:
  - 0.9680033804200365
  - .nan
  - 0.9703288855904003
  - 0.9711837662050161
  - 0.9687812769269635
  - .nan
  - 0.9704065045273832
  - .nan
  - 0.9691707504001682
  - .nan
  - 0.9700571916244725
  - .nan
  - 0.968859108874401
  - .nan
  - 0.9706007095384518
  - .nan
  LL_recall_macro:
  - 0.5503393665158371
  - .nan
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - .nan
  - 0.55
  - .nan
  - 0.5505287896592245
  - .nan
  - 0.55
  - .nan
  - 0.5500582072176949
  - .nan
  - 0.5503067484662577
  - .nan
  LL_recall_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_recall_weighted:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_roc_auc:
  - 0.5503393665158371
  - 0.5503277796570591
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - 0.5506165699847885
  - 0.55
  - 0.5503585757596
  - 0.5505287896592245
  - 0.5504500559980077
  - 0.55
  - 0.550168937296356
  - 0.5500582072176949
  - 0.5508280151385218
  - 0.5503067484662577
  - 0.5499807447722335
  LT_average_precision:
  - 0.10117531527284186
  - 0.05559736370162673
  - 0.09286174956431681
  - 0.12396804419220236
  - 0.10405101625330393
  - 0.0563901921439993
  - 0.05090331587116136
  - 0.10452589336008984
  - 0.1066418374960879
  - 0.04979566762651745
  - 0.0908951097366514
  - 0.06694558551583453
  - 0.12462348799465625
  - 0.05457203814389275
  - 0.09038935208682156
  - 0.13614753354987866
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5869785159468988
  - 0.553088803088803
  - 0.5550853361198188
  - 0.5602223723072891
  - 0.5829597925750143
  - 0.5487705621314538
  - 0.5219191898400675
  - 0.5681596318969379
  - 0.5785470821139612
  - 0.5431537877463889
  - 0.5527713932107496
  - 0.5481459156387332
  - 0.5781141300943281
  - 0.5438633466597138
  - 0.5480006154501663
  - 0.5813850510738606
  TL_average_precision:
  - 0.16842887578791335
  - 0.23051691411387648
  - 0.21946787298196704
  - 0.21997565585583279
  - 0.20606375277658112
  - 0.24678199476929188
  - 0.2203353590474899
  - 0.23472453232933688
  - 0.19860259261288402
  - 0.20008747530181978
  - 0.19811189408818924
  - 0.1954059147675025
  - 0.23618419079447345
  - 0.21318483491229215
  - 0.2778163609350141
  - 0.21636225790184432
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6260633773888021
  - 0.6646158537064387
  - 0.66620908528423
  - 0.6464044749003023
  - 0.6334925578548033
  - 0.6566894819421052
  - 0.645197110388522
  - 0.6491125235836097
  - 0.6418884020994126
  - 0.6311162582890467
  - 0.6481476567445308
  - 0.6206336316008716
  - 0.6477173279202478
  - 0.6572052411159964
  - 0.6737503186007467
  - 0.6272121163918968
  TT_average_precision:
  - 0.10775124964197087
  - 0.03790030601458764
  - 0.07737148064626703
  - 0.1242392215405652
  - 0.19329579470502778
  - 0.03673562174690775
  - 0.07438034393479272
  - 0.11367792309231385
  - 0.1305134799908988
  - 0.05428346333349844
  - 0.08639347154692424
  - 0.05760509414447151
  - 0.2746835988809179
  - 0.04531239139452236
  - 0.08872617596388749
  - 0.121020836326376
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.6132543926661573
  - 0.5273185355274906
  - 0.596826399688958
  - 0.5666761222891663
  - 0.6546388111986892
  - 0.5453209785707717
  - 0.5499660375028301
  - 0.5867512654668167
  - 0.6552283198227096
  - 0.5385414738400955
  - 0.5455407523510972
  - 0.5361794578356339
  - 0.6616796440489434
  - 0.5292162854446592
  - 0.5711182156411838
  - 0.5756531211554502
  fit_time:
  - 1.3363251686096191
  - 1.3184268474578857
  - 1.168828010559082
  - 1.2246665954589844
  - 1.8384945392608643
  - 1.8120005130767822
  - 1.7594480514526367
  - 1.8640844821929932
  - 1.8258812427520752
  - 1.7865252494812012
  - 1.8755381107330322
  - 1.8302688598632812
  - 1.845609188079834
  - 1.8963654041290283
  - 1.832012414932251
  - 1.8572185039520264
  score_time:
  - 0.5654327869415283
  - 0.4458792209625244
  - 0.5521979331970215
  - 0.6158738136291504
  - 1.0217041969299316
  - 0.8323142528533936
  - 0.8095521926879883
  - 0.9404792785644531
  - 1.0357143878936768
  - 0.8531460762023926
  - 1.0144734382629395
  - 0.8963487148284912
  - 1.0254580974578857
  - 0.8899452686309814
  - 1.034698247909546
  - 0.9097983837127686
start: 2023-11-09 23:27:43.883145
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
