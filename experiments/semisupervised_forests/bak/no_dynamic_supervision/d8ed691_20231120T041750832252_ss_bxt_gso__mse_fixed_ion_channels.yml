active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-20 04:17:54.271191
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__mse_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__mse_fixed
  params: {}
hash: d8ed691a0492f139987da22bbb7dc6c856a84b9f9e3037aed316c0004d423547
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/d8ed691_20231120T041750832252_ss_bxt_gso__mse_fixed_ion_channels.yml"
results:
  LL_average_precision:
  - 0.13377477399583057
  - 0.13302798872798172
  - 0.13146194745848774
  - 0.12995195857601313
  - 0.13319151040596633
  - 0.13259068618960163
  - 0.13052866716306777
  - 0.13027598377107885
  - 0.13290471307641066
  - 0.1328142402271899
  - 0.13090096798212958
  - 0.13002088660824432
  - 0.13229659011500366
  - 0.13254182453146074
  - 0.13093533030721544
  - 0.12865051305110875
  LL_balanced_accuracy:
  - 0.5503393665158371
  - .nan
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - .nan
  - 0.55
  - .nan
  - 0.5505287896592245
  - .nan
  - 0.55
  - .nan
  - 0.5500582072176949
  - .nan
  - 0.5503067484662577
  - .nan
  LL_f1_macro:
  - 0.5830246326395329
  - .nan
  - 0.5838124823590799
  - 0.5835535019599959
  - 0.583447048714696
  - .nan
  - 0.5831318283369036
  - .nan
  - 0.5836621267888888
  - .nan
  - 0.5830351581590119
  - .nan
  - 0.582798823502053
  - .nan
  - 0.583692073407322
  - .nan
  LL_f1_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_f1_weighted:
  - 0.9536627205559293
  - .nan
  - 0.9571259928856107
  - 0.9583788951019314
  - 0.9548280871486553
  - .nan
  - 0.9572197620943651
  - .nan
  - 0.9554109057637129
  - .nan
  - 0.9567010390780758
  - .nan
  - 0.9549223882988672
  - .nan
  - 0.9575233439965773
  - .nan
  LL_matthews_corrcoef:
  - 0.31198441312481723
  - .nan
  - 0.3126543364921219
  - 0.3118704264397513
  - 0.31250592182651615
  - .nan
  - 0.3113466596691422
  - .nan
  - 0.3127740736927638
  - .nan
  - 0.31128645486743545
  - .nan
  - 0.3112604610693923
  - .nan
  - 0.3123336797877318
  - .nan
  LL_precision_macro:
  - 0.9833904395788067
  - .nan
  - 0.9846415673903117
  - 0.9851000249024653
  - 0.9838096431854266
  - .nan
  - 0.9846837124356633
  - .nan
  - 0.9840192187173595
  - .nan
  - 0.9844962849196796
  - .nan
  - 0.9838520994359724
  - .nan
  - 0.9847874813216005
  - .nan
  LL_precision_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_precision_weighted:
  - 0.9680033804200365
  - .nan
  - 0.9703288855904003
  - 0.9711837662050161
  - 0.9687812769269635
  - .nan
  - 0.9704065045273832
  - .nan
  - 0.9691707504001682
  - .nan
  - 0.9700571916244725
  - .nan
  - 0.968859108874401
  - .nan
  - 0.9706007095384518
  - .nan
  LL_recall_macro:
  - 0.5503393665158371
  - .nan
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - .nan
  - 0.55
  - .nan
  - 0.5505287896592245
  - .nan
  - 0.55
  - .nan
  - 0.5500582072176949
  - .nan
  - 0.5503067484662577
  - .nan
  LL_recall_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_recall_weighted:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_roc_auc:
  - 0.5503393665158371
  - 0.5503277796570591
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - 0.5506165699847885
  - 0.55
  - 0.5503585757596
  - 0.5505287896592245
  - 0.5504500559980077
  - 0.55
  - 0.550168937296356
  - 0.5500582072176949
  - 0.5508280151385218
  - 0.5503067484662577
  - 0.5499807447722335
  LT_average_precision:
  - 0.10563495889164237
  - 0.05736358969541405
  - 0.09201359555341515
  - 0.12612727772641483
  - 0.09350451054941644
  - 0.06416647929507735
  - 0.05232389494486595
  - 0.09185011686936324
  - 0.1193973632482983
  - 0.050346440138664045
  - 0.08445444211245343
  - 0.06933206989966617
  - 0.11879992052527531
  - 0.06870664642236202
  - 0.0927644258085163
  - 0.12202168466018468
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5867350193787115
  - 0.5644288419447655
  - 0.5669509752699408
  - 0.5758900436478736
  - 0.5874454206728129
  - 0.57222378271319
  - 0.5476725969532096
  - 0.5657986326519024
  - 0.6121653591717285
  - 0.5423429000798793
  - 0.5697631299784113
  - 0.5554356781602661
  - 0.5774077407740774
  - 0.5814558104950074
  - 0.566750778189393
  - 0.5950389192640125
  TL_average_precision:
  - 0.1742547241411754
  - 0.24661159658608328
  - 0.23102849973649695
  - 0.20616299809863625
  - 0.21261413528418838
  - 0.24632844872357715
  - 0.23687439552228856
  - 0.24620734116717508
  - 0.2051226759741471
  - 0.20117016293569015
  - 0.20791940404853687
  - 0.18166196832006415
  - 0.22348492447661875
  - 0.2092684833465566
  - 0.2593746647069618
  - 0.21203648463097188
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6248466769396332
  - 0.6668317235175816
  - 0.6633229112997899
  - 0.6433046113485764
  - 0.6252201811495444
  - 0.6405120931755697
  - 0.6397984106764402
  - 0.6474557920256087
  - 0.6301979818116444
  - 0.6369016601608428
  - 0.6438614020935296
  - 0.6101285127210971
  - 0.6330073595191934
  - 0.646720896604708
  - 0.6631455468881916
  - 0.6348871189483372
  TT_average_precision:
  - 0.1237177275602323
  - 0.04215270047680966
  - 0.06990433213763425
  - 0.12013889076346702
  - 0.19499336754535498
  - 0.0490739340701559
  - 0.08622702063511026
  - 0.12511781814892084
  - 0.17437672127162218
  - 0.05272767014114239
  - 0.0824975766389183
  - 0.06492303121714887
  - 0.2558758728114577
  - 0.06580050954044009
  - 0.08576169991172439
  - 0.10477175007888295
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.6307329348851841
  - 0.5405345069524174
  - 0.5976744751166406
  - 0.5609907627890623
  - 0.6801000084752945
  - 0.582454244458751
  - 0.5675359693720027
  - 0.6079267435320586
  - 0.6829999416807604
  - 0.5542529828517577
  - 0.5336481191222571
  - 0.5527573134968886
  - 0.6494912042186791
  - 0.6147643014425022
  - 0.5756987679249164
  - 0.5548682712047748
  fit_time:
  - 2.554257392883301
  - 2.5474836826324463
  - 2.4195475578308105
  - 2.5147945880889893
  - 2.609872341156006
  - 2.4774372577667236
  - 2.440708875656128
  - 2.52186918258667
  - 2.559767723083496
  - 2.4676706790924072
  - 2.4201416969299316
  - 2.390134334564209
  - 2.6618945598602295
  - 2.7106873989105225
  - 2.5622920989990234
  - 2.488447904586792
  score_time:
  - 0.6816575527191162
  - 0.5229063034057617
  - 0.6861281394958496
  - 0.65873122215271
  - 0.6509859561920166
  - 0.5912928581237793
  - 0.7678987979888916
  - 0.6442546844482422
  - 0.7782337665557861
  - 0.5330615043640137
  - 0.7480981349945068
  - 0.5559813976287842
  - 0.7041316032409668
  - 0.5569314956665039
  - 0.7245407104492188
  - 0.6199934482574463
start: 2023-11-20 04:17:50.832252
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
