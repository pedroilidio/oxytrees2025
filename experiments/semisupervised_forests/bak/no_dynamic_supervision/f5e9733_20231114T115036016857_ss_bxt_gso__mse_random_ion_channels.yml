active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-14 11:50:42.511805
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__mse_random
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__mse_random
  params: {}
hash: f5e97333bb9a1acd72b97935df47090e38c64cbaa99610bbaaea98ebe92e508b
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/f5e9733_20231114T115036016857_ss_bxt_gso__mse_random_ion_channels.yml"
results:
  LL_average_precision:
  - 0.5184005661712668
  - 0.5189343212394332
  - 0.5176092708181601
  - 0.5198618201395582
  - 0.5179426335289955
  - 0.5200734504355284
  - 0.5169603706461487
  - 0.5175313007298582
  - 0.5182803961535615
  - 0.5187714688500588
  - 0.5171672044345165
  - 0.5169398921950044
  - 0.5184414452255325
  - 0.5194388758010936
  - 0.5174497673056435
  - 0.517103616165418
  LL_balanced_accuracy:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_f1_macro:
  - 0.8286026200873362
  - .nan
  - 0.8292413854501421
  - .nan
  - 0.8287236090611564
  - .nan
  - 0.8289825544377944
  - .nan
  - 0.8290503652067968
  - .nan
  - 0.8289280937519903
  - .nan
  - 0.8290039908492242
  - .nan
  - 0.8292875847754466
  - .nan
  LL_f1_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538514
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_f1_weighted:
  - 0.978619720602309
  - .nan
  - 0.9802433876449146
  - .nan
  - 0.9791496381427907
  - .nan
  - 0.9802866917354942
  - .nan
  - 0.9794433538280974
  - .nan
  - 0.9800472204748734
  - .nan
  - 0.979250620929605
  - .nan
  - 0.9804349774611915
  - .nan
  LL_matthews_corrcoef:
  - 0.700447894610418
  - .nan
  - 0.7013905925141326
  - .nan
  - 0.7006174228557172
  - .nan
  - 0.7009803892718732
  - .nan
  - 0.7011211134187072
  - .nan
  - 0.700904035830809
  - .nan
  - 0.70105565880409
  - .nan
  - 0.7014558703735905
  - .nan
  LL_precision_macro:
  - 0.9906272530641673
  - .nan
  - 0.9913517380691861
  - .nan
  - 0.9908647732089868
  - .nan
  - 0.9913735061437469
  - .nan
  - 0.9909938546302183
  - .nan
  - 0.991266467443916
  - .nan
  - 0.990907549489212
  - .nan
  - 0.9914373474711773
  - .nan
  LL_precision_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_precision_weighted:
  - 0.9819443615291318
  - .nan
  - 0.983292333552872
  - .nan
  - 0.9823851865240354
  - .nan
  - 0.9833322464202088
  - .nan
  - 0.9826258367080601
  - .nan
  - 0.9831326562431352
  - .nan
  - 0.9824653978826134
  - .nan
  - 0.9834520558930446
  - .nan
  LL_recall_macro:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_recall_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_recall_weighted:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_roc_auc:
  - 0.75
  - 0.7505017331372483
  - 0.7503037667071689
  - 0.7518029598723023
  - 0.75
  - 0.7514016413005488
  - 0.75
  - 0.7505754503946408
  - 0.7502937720329025
  - 0.750532143180634
  - 0.75
  - 0.7502375953286344
  - 0.7502910360884749
  - 0.751166914678009
  - 0.7503067484662577
  - 0.7506060680048032
  LT_average_precision:
  - 0.3375400836917419
  - 0.09504072026731228
  - 0.190860925181462
  - 0.25697549893341565
  - 0.30207018770975197
  - 0.12400154308055145
  - 0.14931526442305507
  - 0.19663907832594987
  - 0.31543155554483465
  - 0.12622078124495206
  - 0.17081079408978933
  - 0.24340874224004888
  - 0.3018094409292232
  - 0.14067489397238758
  - 0.2099949485132604
  - 0.21125349174257183
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.7619236228886773
  - 0.6664754199149103
  - 0.6964086990595612
  - 0.7072030079735493
  - 0.7311589494401597
  - 0.6713737838156527
  - 0.6729239994785555
  - 0.6804714427814663
  - 0.7824565329660871
  - 0.683692839207764
  - 0.6761482915208814
  - 0.7052208811838518
  - 0.7623787103985123
  - 0.6815743476833344
  - 0.6838453799812998
  - 0.6735868746726035
  TL_average_precision:
  - 0.5753311813084664
  - 0.550615994048918
  - 0.6123351543775412
  - 0.6018964012256744
  - 0.6784985313800533
  - 0.6641934685194617
  - 0.6968313515813749
  - 0.6906550845885232
  - 0.5970887393476706
  - 0.5940621186823715
  - 0.5732153415231702
  - 0.5393403142177363
  - 0.6438672430455226
  - 0.6397348228739898
  - 0.6832569054658519
  - 0.6553794511943262
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.8902233405912677
  - 0.8635840724476008
  - 0.8761234269904791
  - 0.862721225873407
  - 0.9023606636489971
  - 0.889927316794058
  - 0.9031423314300187
  - 0.9007968549576448
  - 0.8460525646409193
  - 0.8556555989277147
  - 0.8724199969893933
  - 0.8432293001794412
  - 0.8824742213306598
  - 0.8783952272595976
  - 0.9031636768150634
  - 0.8758010748412166
  TT_average_precision:
  - 0.19143460890667452
  - 0.078737301700368
  - 0.15215460996986463
  - 0.216021802601732
  - 0.3910698332497126
  - 0.13247113825328766
  - 0.225441081775412
  - 0.24368397538575898
  - 0.2211922222611508
  - 0.12577100651590065
  - 0.15201181904224975
  - 0.22095145249573603
  - 0.35645157407072364
  - 0.07693757554323512
  - 0.19054703560796232
  - 0.13673311613539846
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.734631285669348
  - 0.6546009269889868
  - 0.6501530909797822
  - 0.7151766736451823
  - 0.7703807290636684
  - 0.7236158373953832
  - 0.7149990737500772
  - 0.7203177727784026
  - 0.7716655974806089
  - 0.6792088080372919
  - 0.632335423197492
  - 0.6440240326156927
  - 0.7936287232727722
  - 0.6514537365748438
  - 0.6524183446444929
  - 0.6025130738496346
  fit_time:
  - 5.710979461669922
  - 5.190328598022461
  - 5.325882434844971
  - 5.321669101715088
  - 5.7006144523620605
  - 5.573352575302124
  - 5.594336271286011
  - 5.57966947555542
  - 5.4857518672943115
  - 5.492058038711548
  - 5.364985466003418
  - 5.4017274379730225
  - 5.829602479934692
  - 5.232671499252319
  - 5.607900142669678
  - 5.745018482208252
  score_time:
  - 0.5930888652801514
  - 0.43981266021728516
  - 0.6753170490264893
  - 0.5965824127197266
  - 0.6367707252502441
  - 0.49146318435668945
  - 0.621016263961792
  - 0.5272786617279053
  - 0.6946353912353516
  - 0.5437891483306885
  - 0.696098804473877
  - 0.5630002021789551
  - 0.5912752151489258
  - 0.5346307754516602
  - 0.7113926410675049
  - 0.48210692405700684
start: 2023-11-14 11:50:36.016857
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
