active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 12:07:15.945263
estimator:
  call: semisupervised_forests.estimators.ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ds_bxt_gso
  params: {}
hash: 1f4007385d6d9ed0c62294028041722cc47b5a0c40e16722b1e516401b6e7561
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/1f40073_20231101T120618584593_ds_bxt_gso_enzymes.yml"
results:
  LL_average_precision:
  - 0.10847055413701599
  - 0.11034175085109361
  - 0.10936342389674547
  - 0.10900338922881847
  - 0.10814067079127321
  - 0.10951577394975093
  - 0.10882384664226663
  - 0.10963403395640421
  - 0.10929877328370323
  - 0.1103910170035028
  - 0.10919807236878863
  - 0.10916895733798773
  - 0.11052257076353461
  - 0.1107384364532041
  - 0.10982870231600574
  - 0.11007273289198387
  LL_balanced_accuracy:
  - 0.5500322788896062
  - .nan
  - 0.5502117362371446
  - 0.5502210991787745
  - 0.55
  - 0.5501466275659824
  - 0.5500621890547264
  - .nan
  - .nan
  - .nan
  - 0.5500899820035993
  - 0.5502828409805154
  - .nan
  - .nan
  - 0.5502309468822171
  - .nan
  LL_f1_macro:
  - 0.5888500896640709
  - .nan
  - 0.5890116575652308
  - 0.589122832827554
  - 0.5888637479277989
  - 0.5888326802912671
  - 0.5888253769085132
  - .nan
  - .nan
  - .nan
  - 0.5887907718042104
  - 0.5892141566355339
  - .nan
  - .nan
  - 0.5889354648241061
  - .nan
  LL_f1_micro:
  - 0.9915940036421964
  - .nan
  - 0.9910600485775437
  - 0.9914388091287305
  - 0.9918593292087268
  - 0.9907774811822139
  - 0.9913005314671861
  - .nan
  - .nan
  - .nan
  - 0.9909818916384099
  - 0.9913967246230431
  - .nan
  - .nan
  - 0.9906331914484284
  - .nan
  LL_f1_weighted:
  - 0.9881733918339619
  - .nan
  - 0.9874260138360016
  - 0.987958051183212
  - 0.9885457052579808
  - 0.9870282514516676
  - 0.9877615734471793
  - .nan
  - .nan
  - .nan
  - 0.9873144508199726
  - 0.9878998248910561
  - .nan
  - .nan
  - 0.986826949989774
  - .nan
  LL_matthews_corrcoef:
  - 0.3149962357637102
  - .nan
  - 0.3154755055857953
  - 0.3155653192915496
  - 0.3149368125753411
  - 0.3152258663337589
  - 0.3150436561954516
  - .nan
  - .nan
  - .nan
  - 0.3150803425516771
  - 0.31575252120393954
  - .nan
  - .nan
  - 0.31546774957143753
  - .nan
  LL_precision_macro:
  - 0.9957930697312273
  - .nan
  - 0.9955255587785709
  - 0.9957153087445012
  - 0.9959259795755776
  - 0.9953839950409542
  - 0.9956460513567349
  - .nan
  - .nan
  - .nan
  - 0.9954864141064604
  - 0.9956942204462846
  - .nan
  - .nan
  - 0.9953116912817921
  - .nan
  LL_precision_micro:
  - 0.9915940036421964
  - .nan
  - 0.9910600485775437
  - 0.9914388091287305
  - 0.9918593292087268
  - 0.9907774811822139
  - 0.9913005314671861
  - .nan
  - .nan
  - .nan
  - 0.9909818916384099
  - 0.9913967246230431
  - .nan
  - .nan
  - 0.9906331914484284
  - .nan
  LL_precision_weighted:
  - 0.9916647305232302
  - .nan
  - 0.9911400511518682
  - 0.9915121732480561
  - 0.991925659726871
  - 0.9908626235674095
  - 0.9913762855456174
  - .nan
  - .nan
  - .nan
  - 0.9910632996517844
  - 0.9914708122374692
  - .nan
  - .nan
  - 0.9907210204288167
  - .nan
  LL_recall_macro:
  - 0.5500322788896062
  - .nan
  - 0.5502117362371446
  - 0.5502210991787745
  - 0.55
  - 0.5501466275659824
  - 0.5500621890547264
  - .nan
  - .nan
  - .nan
  - 0.5500899820035993
  - 0.5502828409805154
  - .nan
  - .nan
  - 0.5502309468822171
  - .nan
  LL_recall_micro:
  - 0.9915940036421964
  - .nan
  - 0.9910600485775437
  - 0.9914388091287305
  - 0.9918593292087268
  - 0.9907774811822139
  - 0.9913005314671861
  - .nan
  - .nan
  - .nan
  - 0.9909818916384099
  - 0.9913967246230431
  - .nan
  - .nan
  - 0.9906331914484284
  - .nan
  LL_recall_weighted:
  - 0.9915940036421964
  - .nan
  - 0.9910600485775437
  - 0.9914388091287305
  - 0.9918593292087268
  - 0.9907774811822139
  - 0.9913005314671861
  - .nan
  - .nan
  - .nan
  - 0.9909818916384099
  - 0.9913967246230431
  - .nan
  - .nan
  - 0.9906331914484284
  - .nan
  LL_roc_auc:
  - 0.5500322788896062
  - 0.5504273504273505
  - 0.5502117362371446
  - 0.5502210991787745
  - 0.55
  - 0.5501466275659824
  - 0.5500621890547264
  - 0.5506867233485938
  - 0.5504885993485342
  - 0.5504249291784703
  - 0.5500899820035993
  - 0.5502828409805154
  - 0.5507507507507508
  - 0.5503791982665223
  - 0.5502309468822171
  - 0.5505754088431254
  LT_average_precision:
  - 0.034088994939401956
  - 0.08921896847411515
  - 0.03488769543951242
  - 0.06571933495343217
  - 0.03109445825612232
  - 0.0926420511513085
  - 0.053599743586289446
  - 0.05531702941375119
  - 0.053190893566459424
  - 0.06503555068349236
  - 0.061261072946472615
  - 0.04812903908198778
  - 0.04546950567949335
  - 0.09277004285535825
  - 0.07199750952848263
  - 0.06662211894201106
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5364208090498771
  - 0.5842263547170458
  - 0.5427192079567261
  - 0.5620730739277607
  - 0.5296866487539752
  - 0.5873593744353355
  - 0.5475533826319614
  - 0.5602490107563883
  - 0.5419804452246849
  - 0.5852338732399336
  - 0.5701369120624931
  - 0.5653402183432485
  - 0.5507421047084273
  - 0.5959160339597291
  - 0.5747125681435252
  - 0.5704730772483207
  TL_average_precision:
  - 0.2624906904929971
  - 0.23852234975022157
  - 0.19769633162178143
  - 0.24289862106960247
  - 0.3901922301101926
  - 0.37377394238214806
  - 0.283148546876211
  - 0.41203893933019353
  - 0.34868111494649884
  - 0.39510896374888516
  - 0.3429821025861089
  - 0.29218912129235625
  - 0.3623837820022967
  - 0.3777507568456588
  - 0.33195817835109875
  - 0.341716541759528
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6637654371918924
  - 0.6413837165079848
  - 0.6294452988483882
  - 0.6467666894230948
  - 0.7281007558365531
  - 0.7153181143725249
  - 0.6770731119750693
  - 0.720043736233772
  - 0.6873546947790148
  - 0.7115489118384408
  - 0.6944945766759262
  - 0.6820495438709145
  - 0.7344699731548073
  - 0.7347707648701961
  - 0.7140808212889239
  - 0.7131931636274295
  TT_average_precision:
  - 0.037762162649255325
  - 0.14027580467961667
  - 0.019661770999517263
  - 0.052395073851851784
  - 0.03280303485819874
  - 0.13343800559985117
  - 0.02889670097931716
  - 0.16000590160471018
  - 0.06841221956971331
  - 0.09072738170666247
  - 0.06090373195055449
  - 0.06115982102533943
  - 0.03457984069456742
  - 0.05429562622333707
  - 0.04731701328617369
  - 0.09084066718505093
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5371697086661055
  - 0.5909487853869623
  - 0.531543564366439
  - 0.5727544742692927
  - 0.5448819976186212
  - 0.6490357768531697
  - 0.5238720783496105
  - 0.6353321250698093
  - 0.5583575350996376
  - 0.627076044750298
  - 0.5755710056577945
  - 0.5965486912948988
  - 0.5358439415370108
  - 0.5925314391642427
  - 0.5410481867470821
  - 0.6012554983311599
  fit_time:
  - 37.259071350097656
  - 44.17233943939209
  - 48.90867233276367
  - 41.02876281738281
  - 46.16358304023743
  - 44.73205924034119
  - 44.708720684051514
  - 39.73259091377258
  - 40.55656170845032
  - 43.40694618225098
  - 46.74103403091431
  - 48.269651651382446
  - 43.80674982070923
  - 46.26538395881653
  - 48.72124242782593
  - 46.25632572174072
  score_time:
  - 8.600116491317749
  - 8.92130994796753
  - 8.224727630615234
  - 9.336272478103638
  - 8.662954330444336
  - 10.208333969116211
  - 10.753804445266724
  - 6.982652425765991
  - 7.986239194869995
  - 9.061270952224731
  - 9.686080694198608
  - 8.377948999404907
  - 8.816359043121338
  - 8.132828712463379
  - 8.276922702789307
  - 8.69165825843811
start: 2023-11-01 12:06:18.584593
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
