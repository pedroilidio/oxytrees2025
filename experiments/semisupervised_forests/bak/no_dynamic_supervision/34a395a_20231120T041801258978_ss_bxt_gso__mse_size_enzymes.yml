active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-20 04:18:50.295092
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__mse_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__mse_size
  params: {}
hash: 34a395ac5fa5f74104046be8629dfbfda0f03afb19a5193886bc38e40b101a3b
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/34a395a_20231120T041801258978_ss_bxt_gso__mse_size_enzymes.yml"
results:
  LL_average_precision:
  - 0.1084664158178357
  - 0.1097779623535341
  - 0.10936342389674547
  - 0.10961731806600718
  - 0.10814067079127321
  - 0.11009627214143948
  - 0.10882000781172796
  - 0.10898602379188922
  - 0.10929877328370323
  - 0.1103910170035028
  - 0.10979194032054278
  - 0.10916895733798773
  - 0.10992800028944608
  - 0.11020273671612772
  - 0.1098254030748312
  - 0.10947305144514559
  LL_balanced_accuracy:
  - .nan
  - 0.5501424501424501
  - 0.5502117362371446
  - .nan
  - 0.55
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.5502828409805154
  - .nan
  - 0.5501083423618635
  - .nan
  - 0.5502725620835857
  LL_f1_macro:
  - .nan
  - 0.5887573627847013
  - 0.5890116575652308
  - .nan
  - 0.5888637479277989
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.5892141566355339
  - .nan
  - 0.5885762854396017
  - .nan
  - 0.5891151438147866
  LL_f1_micro:
  - .nan
  - 0.9905069379313662
  - 0.9910600485775437
  - .nan
  - 0.9918593292087268
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9913967246230431
  - .nan
  - 0.9900139480075992
  - .nan
  - 0.9910720727220258
  LL_f1_weighted:
  - .nan
  - 0.9866483082444629
  - 0.9874260138360016
  - .nan
  - 0.9885457052579808
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9878998248910561
  - .nan
  - 0.9859556163022204
  - .nan
  - 0.9874437954255652
  LL_matthews_corrcoef:
  - .nan
  - 0.3151696068607889
  - 0.3154755055857953
  - .nan
  - 0.3149368125753411
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.31575252120393954
  - .nan
  - 0.31498381128476743
  - .nan
  - 0.31566844607540057
  LL_precision_macro:
  - .nan
  - 0.99524844122391
  - 0.9955255587785709
  - .nan
  - 0.9959259795755776
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9956942204462846
  - .nan
  - 0.9950014144101308
  - .nan
  - 0.995531576856878
  LL_precision_micro:
  - .nan
  - 0.9905069379313662
  - 0.9910600485775437
  - .nan
  - 0.9918593292087268
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9913967246230431
  - .nan
  - 0.9900139480075992
  - .nan
  - 0.9910720727220258
  LL_precision_weighted:
  - .nan
  - 0.9905971516161346
  - 0.9911400511518682
  - .nan
  - 0.991925659726871
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9914708122374692
  - .nan
  - 0.9901137802787771
  - .nan
  - 0.9911518602357638
  LL_recall_macro:
  - .nan
  - 0.5501424501424501
  - 0.5502117362371446
  - .nan
  - 0.55
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.5502828409805154
  - .nan
  - 0.5501083423618635
  - .nan
  - 0.5502725620835857
  LL_recall_micro:
  - .nan
  - 0.9905069379313662
  - 0.9910600485775437
  - .nan
  - 0.9918593292087268
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9913967246230431
  - .nan
  - 0.9900139480075992
  - .nan
  - 0.9910720727220258
  LL_recall_weighted:
  - .nan
  - 0.9905069379313662
  - 0.9910600485775437
  - .nan
  - 0.9918593292087268
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - 0.9913967246230431
  - .nan
  - 0.9900139480075992
  - .nan
  - 0.9910720727220258
  LL_roc_auc:
  - 0.5500295379789325
  - 0.5501424501424501
  - 0.5502117362371446
  - 0.5505342212282904
  - 0.55
  - 0.5504398826979472
  - 0.5500594557022325
  - 0.5503597122302158
  - 0.5504885993485342
  - 0.5504249291784703
  - 0.5503899220155969
  - 0.5502828409805154
  - 0.5504504504504505
  - 0.5501083423618635
  - 0.5502282126310827
  - 0.5502725620835857
  LT_average_precision:
  - 0.043455232994374246
  - 0.09506521881204416
  - 0.050557832232120216
  - 0.047475488781783676
  - 0.039761142638111285
  - 0.087335097271544
  - 0.06697941310194001
  - 0.05228308118006025
  - 0.07150537278696938
  - 0.07780048825408387
  - 0.05097963979863724
  - 0.03524391072937814
  - 0.05200552770872431
  - 0.10354355200999474
  - 0.05701130948973746
  - 0.07425877502315795
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5429142073073739
  - 0.5820372310592695
  - 0.5480546966173613
  - 0.5541194662252577
  - 0.5463346073224417
  - 0.5838578804791372
  - 0.5691435484331887
  - 0.573259457100168
  - 0.5522795768589054
  - 0.593923990758611
  - 0.5510055253144439
  - 0.5570965243987616
  - 0.5423606364368911
  - 0.5895895631521638
  - 0.5821076519153038
  - 0.5804816051668498
  TL_average_precision:
  - 0.2346790072902003
  - 0.27742136776487847
  - 0.2502199002210387
  - 0.22945766886344537
  - 0.3516323380616387
  - 0.3847240080732417
  - 0.3443895874175868
  - 0.28615568314823725
  - 0.39132992488709856
  - 0.40459156734554147
  - 0.3391315411702721
  - 0.3352463380232591
  - 0.36037538800305563
  - 0.34195900557135717
  - 0.3864219488207469
  - 0.3125229134066599
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6513601990004823
  - 0.6786820302018932
  - 0.6607381285175868
  - 0.6392852711444577
  - 0.716869080792174
  - 0.7170766471438668
  - 0.7074319466138757
  - 0.6754794976538703
  - 0.7174494632575844
  - 0.7288909400677204
  - 0.7060432572552218
  - 0.6881960283759598
  - 0.7252587709123005
  - 0.7200984348020749
  - 0.7369577666604221
  - 0.6981211025408757
  TT_average_precision:
  - 0.03547604461907647
  - 0.11422948450485682
  - 0.08053593522116545
  - 0.031201476431878514
  - 0.05311556824186099
  - 0.12061500709842744
  - 0.11681840312788706
  - 0.09483844947087719
  - 0.10599452842761872
  - 0.04452845344247638
  - 0.07077227941358669
  - 0.04152398078894569
  - 0.03694128530526755
  - 0.046382505276906405
  - 0.04289869727408649
  - 0.01889955992234672
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5296960652472951
  - 0.6128831181854648
  - 0.5713283242703401
  - 0.5533352934212599
  - 0.5412942343952989
  - 0.6069002860505858
  - 0.5949781904970921
  - 0.6095697279485542
  - 0.5741205276268115
  - 0.5923424039533571
  - 0.5480139959826346
  - 0.5456212079851132
  - 0.5378422732383128
  - 0.5902141443678394
  - 0.5543669239543132
  - 0.5337566502814839
  fit_time:
  - 31.228042125701904
  - 31.0353901386261
  - 33.53679633140564
  - 34.2143280506134
  - 33.42962431907654
  - 34.12313938140869
  - 37.785176515579224
  - 33.2482328414917
  - 32.87400984764099
  - 39.1766152381897
  - 34.05632162094116
  - 31.794795989990234
  - 32.420180797576904
  - 39.92317795753479
  - 38.35624718666077
  - 37.01113224029541
  score_time:
  - 8.405121564865112
  - 9.78847861289978
  - 9.464409589767456
  - 9.778314113616943
  - 10.93249773979187
  - 7.998167514801025
  - 8.934591054916382
  - 9.429368257522583
  - 8.339698553085327
  - 8.472054243087769
  - 8.52597689628601
  - 10.12235951423645
  - 8.617061853408813
  - 8.875025033950806
  - 8.67535400390625
  - 9.975078344345093
start: 2023-11-20 04:18:01.258978
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
