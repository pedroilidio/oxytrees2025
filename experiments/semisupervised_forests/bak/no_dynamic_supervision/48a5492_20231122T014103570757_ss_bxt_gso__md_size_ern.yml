active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-22 01:55:25.578855
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_size
  params: {}
hash: 48a5492b37627804d14184cd415cc39654020c7ae25c50b92a87e4785d124ae7
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/48a5492_20231122T014103570757_ss_bxt_gso__md_size_ern.yml"
results:
  LL_average_precision:
  - 0.5095223865730365
  - 0.5107842944390422
  - 0.5102979928788673
  - 0.5066556069044515
  - 0.5096578689058979
  - 0.510803771170762
  - 0.5103654409046002
  - 0.5067938539321405
  - 0.509323173464814
  - 0.5106772027316135
  - 0.5099932851443694
  - 0.5069237739911575
  - 0.5095124259176254
  - 0.5105782160466159
  - 0.5102006556859028
  - 0.5067346052059881
  LL_balanced_accuracy:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LL_f1_macro:
  - 0.8309182405189923
  - 0.8307586814018457
  - 0.8308907741279159
  - 0.8316526526826057
  - 0.8310692710241894
  - 0.8307533419130508
  - 0.8308722135951685
  - 0.8316173829761762
  - 0.830969482074128
  - 0.8307880564775882
  - 0.830796992481203
  - 0.8318477578032308
  - 0.8309208033345965
  - 0.8306461407663812
  - 0.8307435430737526
  - 0.8316325003740834
  LL_f1_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_f1_weighted:
  - 0.988913546445512
  - 0.987722980614685
  - 0.9882987906880089
  - 0.9922463112278831
  - 0.9890650969602176
  - 0.9876998468075384
  - 0.9882185032999534
  - 0.9920854949952507
  - 0.989145002886385
  - 0.9878502202741921
  - 0.9883665137089277
  - 0.992373769952719
  - 0.9889251187756575
  - 0.9876871736491468
  - 0.9881256525918501
  - 0.9921544150315158
  LL_matthews_corrcoef:
  - 0.7036995331209558
  - 0.7034934238032008
  - 0.7036800473667042
  - 0.7047339211336413
  - 0.7039328307015822
  - 0.7034858763540875
  - 0.7036537950796627
  - 0.7046842107963786
  - 0.7037716557806432
  - 0.7035349496681379
  - 0.7035289052508503
  - 0.7050384450672653
  - 0.7037031401185525
  - 0.7033166743918887
  - 0.7034537008880977
  - 0.7047055173504467
  LL_precision_macro:
  - 0.9951930329146512
  - 0.9946695525242866
  - 0.9949226426198765
  - 0.9966498995963974
  - 0.9952589717549346
  - 0.9946593780516042
  - 0.9948873725584086
  - 0.9965798369457148
  - 0.9952945434802281
  - 0.9947255048014012
  - 0.99495292052346
  - 0.996704902389567
  - 0.9951981094127111
  - 0.9946543444776661
  - 0.994847109293161
  - 0.9966098661841608
  LL_precision_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_precision_weighted:
  - 0.9905691610246246
  - 0.9895641206011611
  - 0.9900495467435512
  - 0.993388986998302
  - 0.9906961659372497
  - 0.9895446267221922
  - 0.9899818391422291
  - 0.9932526182442893
  - 0.990764566109916
  - 0.9896713515806191
  - 0.9901075886643413
  - 0.9934961616644096
  - 0.9905789293393269
  - 0.9895348789514361
  - 0.9899044700418723
  - 0.9933110572197021
  LL_recall_macro:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LL_recall_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_recall_weighted:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_roc_auc:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LT_average_precision:
  - 0.058369986618246994
  - 0.1750462281820423
  - 0.028392506154301327
  - 0.035423754391923065
  - 0.05963286286485214
  - 0.14102608381003665
  - 0.026620976598354662
  - 0.03516285685485542
  - 0.04874114719962993
  - 0.12241894340952736
  - 0.025136569388277408
  - 0.03765680508866024
  - 0.07279653667353861
  - 0.09661806799009418
  - 0.017826688749216217
  - 0.036443386320782124
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5741154083247656
  - 0.6042534367380076
  - 0.5884624931494056
  - 0.5069679687543374
  - 0.5694788935924416
  - 0.5977991405032985
  - 0.5796762078667238
  - 0.5205501800133899
  - 0.5584004940662824
  - 0.5914100220129421
  - 0.5565223791487224
  - 0.5317527714815197
  - 0.5916309375168325
  - 0.5936995233190643
  - 0.5519351084814906
  - 0.5074838719527429
  TL_average_precision:
  - 0.328753317383818
  - 0.35993782153977977
  - 0.3448128183147951
  - 0.2445222277902143
  - 0.37413632058327595
  - 0.34929318313546764
  - 0.3549682121748423
  - 0.2262142924798757
  - 0.34694852815837757
  - 0.35894831696234797
  - 0.3600585546835852
  - 0.23629383699144454
  - 0.37508312739421573
  - 0.3869231345166209
  - 0.38521938461100963
  - 0.2201313994174872
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7806135055871106
  - 0.7829605359669762
  - 0.7733381444885418
  - 0.7213222836151433
  - 0.7888842583777609
  - 0.7917468069025697
  - 0.79521616414032
  - 0.7223205625852129
  - 0.7953920444102173
  - 0.7866518629977349
  - 0.8020643979453805
  - 0.7272424945074095
  - 0.796176223710252
  - 0.7935877489393718
  - 0.8037762505402098
  - 0.729150012098491
  TT_average_precision:
  - 0.034007150970955705
  - 0.05809949588866713
  - 0.03250876402061462
  - 0.033877963300064415
  - 0.03335700917370579
  - 0.044377976459869496
  - 0.024077040344422113
  - 0.03711506234232568
  - 0.044566743402547696
  - 0.030892903231344564
  - 0.021742882657431788
  - 0.03911000248631883
  - 0.02779117458166685
  - 0.05198744071702696
  - 0.025162617581627005
  - 0.035307882929230934
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5536195826715191
  - 0.6263770512657423
  - 0.6123300550812906
  - 0.5139184034592674
  - 0.5631173339504745
  - 0.6172449862934641
  - 0.6104855835086487
  - 0.5296834712181849
  - 0.5743915706250923
  - 0.5849669748096561
  - 0.5671684203048409
  - 0.5432412867796187
  - 0.5361133563491413
  - 0.6150125862006477
  - 0.6322108715641265
  - 0.5223889281655318
  fit_time:
  - 798.6540234088898
  - 838.852789402008
  - 826.0999636650085
  - 742.7590458393097
  - 782.0798859596252
  - 852.7329623699188
  - 847.1585614681244
  - 737.519278049469
  - 798.2342698574066
  - 851.0592834949493
  - 857.7946963310242
  - 664.9781620502472
  - 775.9260115623474
  - 820.1492049694061
  - 835.7494583129883
  - 618.3213102817535
  score_time:
  - 6.254771947860718
  - 4.478619337081909
  - 4.610794305801392
  - 7.3469014167785645
  - 6.887775182723999
  - 4.114443063735962
  - 4.1894001960754395
  - 7.320777416229248
  - 5.178720712661743
  - 4.221620798110962
  - 3.933029890060425
  - 7.094293117523193
  - 6.811229228973389
  - 4.663235425949097
  - 4.468180179595947
  - 7.547762393951416
start: 2023-11-22 01:41:03.570757
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
