active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-21 06:28:18.834415
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_fixed
  final_params:
    axis_decision_only: true
    bipartite_adapter: gmosa
    bootstrap: false
    ccp_alpha: 0.0
    criterion: squared_error_gso
    max_col_features: null
    max_depth: null
    max_features: 1.0
    max_leaf_nodes: null
    max_row_features: null
    max_samples: null
    min_col_weight_fraction_leaf: 0.0
    min_cols_leaf: 1
    min_cols_split: 1
    min_impurity_decrease: 0.0
    min_row_weight_fraction_leaf: 0.0
    min_rows_leaf: 1
    min_rows_split: 1
    min_samples_leaf: 1
    min_samples_split: 2
    min_weight_fraction_leaf: 0.0
    n_estimators: 100
    n_jobs: 4
    oob_score: false
    prediction_weights: null
    preprocess_X_targets: null
    random_state: 0
    ss_adapter: null
    supervision: 0.0
    unsupervised_criterion_cols: squared_error
    unsupervised_criterion_rows: squared_error
    update_supervision: null
    verbose: 10
    warm_start: false
  name: ss_bxt_gso__ad_fixed
  params: {}
hash: d15793ab135ada60e7cce5b4bd5377a3b53a9988effc98fb490e86d06b45b1b2
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/d15793a_20231121T062816272368_ss_bxt_gso__ad_fixed_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9921531701192718
  - 1.0
  - 1.0
  - 0.9924242424242424
  - 0.981318111053451
  - 1.0
  - 1.0
  - 0.9836363636363636
  - 0.9838097647356439
  - 1.0
  - 1.0
  - 0.9843137254901961
  - 0.9939817043813192
  - 1.0
  - 1.0
  - 0.9935897435897436
  LL_balanced_accuracy:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_f1_macro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_f1_micro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_f1_weighted:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_precision_macro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_precision_micro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_precision_weighted:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_recall_macro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_recall_micro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_recall_weighted:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_roc_auc:
  - 0.9996721225474767
  - 1.0
  - 1.0
  - 0.9996860873932698
  - 0.9993893958411073
  - 1.0
  - 1.0
  - 0.999443413729128
  - 0.9992680527916924
  - 1.0
  - 1.0
  - 0.999298245614035
  - 0.9997268117842469
  - 1.0
  - 1.0
  - 0.9997258771929824
  LT_average_precision:
  - 0.29871185869451883
  - 0.335726030341215
  - 0.24186674419077714
  - 0.45796878560036447
  - 0.2591832168805853
  - 0.3675517253398147
  - 0.16650472706974256
  - 0.34237905264085405
  - 0.3628022206673892
  - 0.3804577704422586
  - 0.26754631438150644
  - 0.425125390183532
  - 0.33681357226958675
  - 0.4418352276064436
  - 0.38047180424439425
  - 0.41558382604074934
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.7335989375830012
  - 0.7569294605809128
  - 0.7863505747126436
  - 0.812385039852851
  - 0.692749343832021
  - 0.7390243902439024
  - 0.7627659574468085
  - 0.8489729225023342
  - 0.7709888059701493
  - 0.6946274337578686
  - 0.8324367403865311
  - 0.8428258488499453
  - 0.7761006289308177
  - 0.7934416630068803
  - 0.9180440771349861
  - 0.8248608085209392
  TL_average_precision:
  - 0.39761456258166794
  - 0.42432689261957557
  - 0.4995688703215075
  - 0.4155003107361901
  - 0.4122943364878848
  - 0.2426943426943427
  - 0.35802611469158574
  - 0.37414111680301754
  - 0.05950142852316765
  - 0.12692307692307692
  - 0.153505332367121
  - 0.13647547574376842
  - 0.3045289855072464
  - 0.3072510822510822
  - 0.3762837047225401
  - 0.33791037037848404
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7502120441051738
  - 0.7741284932296169
  - 0.8038984824699111
  - 0.7253201156546881
  - 0.6154294597745822
  - 0.5528971354166667
  - 0.5956552706552707
  - 0.5828655439722
  - 0.4374788207387327
  - 0.3575059301931549
  - 0.4223927875243665
  - 0.4800264113568835
  - 0.5445652173913043
  - 0.5652973635806253
  - 0.6926863572433193
  - 0.6290855067679102
  TT_average_precision:
  - 0.07091836734693878
  - 0.20610062206700863
  - 0.09496394590734214
  - 0.2471819645732689
  - 0.2558408309560383
  - 0.23633082424291216
  - 0.27242535242535243
  - 0.15850739334195219
  - 0.12787114845938377
  - 0.06365754812563323
  - 0.01282051282051282
  - 0.2547193854738612
  - 0.05681818181818182
  - 0.2948051948051948
  - 0.06759398496240601
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.6140350877192982
  - 0.4590277777777778
  - 0.5510204081632654
  - 0.8806818181818181
  - 0.7128623188405797
  - 0.6904977375565611
  - 0.6722222222222223
  - 0.6649096385542168
  - 0.6837606837606838
  - 0.4177350427350427
  - 0.12987012987012986
  - 0.8182870370370371
  - 0.588477366255144
  - 0.49038461538461536
  - 0.5929054054054054
  - .nan
  fit_time:
  - 0.8224833011627197
  - 0.878467321395874
  - 0.8510243892669678
  - 0.844536304473877
  - 0.8323571681976318
  - 0.8035216331481934
  - 0.8006641864776611
  - 0.788787841796875
  - 0.9439103603363037
  - 0.895535945892334
  - 0.8295516967773438
  - 0.9717409610748291
  - 0.9711549282073975
  - 0.9576010704040527
  - 0.9409546852111816
  - 0.9403107166290283
  score_time:
  - 0.14986228942871094
  - 0.1710216999053955
  - 0.20496559143066406
  - 0.19907474517822266
  - 0.20000982284545898
  - 0.2258443832397461
  - 0.19971990585327148
  - 0.20046138763427734
  - 0.15453147888183594
  - 0.20136690139770508
  - 0.2051541805267334
  - 0.18142390251159668
  - 0.19235825538635254
  - 0.18373990058898926
  - 0.20436358451843262
  - 0.19533038139343262
start: 2023-11-21 06:28:16.272368
wrapper: null
