active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-08 16:02:35.270206
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_size
  params: {}
hash: 7665bcebfa4df327e989e8eaf534f725292bf6dcd558fb45723e9dc1dbcf663d
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/7665bce_20231108T160233135276_ss_bxt_gso__ad_size_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.5454219699575737
  - 0.5289473684210526
  - 0.5518946417534351
  - 0.5707287898237834
  - 0.5293645699614891
  - 0.5362041467304625
  - 0.5378690629011553
  - 0.5244534562570506
  - 0.5701408275174477
  - 0.5275
  - 0.5492682926829269
  - 0.5446795791487327
  - 0.554558631211857
  - 0.53125
  - 0.559570070276974
  - 0.557479674796748
  LL_balanced_accuracy:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.8257679963319577
  - .nan
  - .nan
  - .nan
  - 0.8345578231292516
  - 0.8320251854407452
  - .nan
  - .nan
  - 0.8261625380269448
  - .nan
  - .nan
  - .nan
  - 0.825136612021858
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9664470667728469
  - .nan
  - .nan
  - .nan
  - 0.9756935195130684
  - 0.9703567180846717
  - .nan
  - .nan
  - 0.9681138635375923
  - .nan
  - .nan
  - .nan
  - 0.9637978142076503
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.6964875095423532
  - .nan
  - .nan
  - .nan
  - 0.7099704764350107
  - 0.7061733064809798
  - .nan
  - .nan
  - 0.6970374326528528
  - .nan
  - .nan
  - .nan
  - 0.6956083436402524
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9850948509485095
  - .nan
  - .nan
  - .nan
  - 0.9892328398384926
  - 0.9868073878627968
  - .nan
  - .nan
  - 0.9858611825192802
  - .nan
  - .nan
  - .nan
  - 0.9838709677419355
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9719155612608756
  - .nan
  - .nan
  - .nan
  - 0.979400722533116
  - 0.9750034717400361
  - .nan
  - .nan
  - 0.9732776349614396
  - .nan
  - .nan
  - .nan
  - 0.9697580645161291
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_roc_auc:
  - 0.7662889518413599
  - 0.75
  - 0.7592592592592593
  - 0.7719487694625816
  - 0.754927236337732
  - 0.7575757575757576
  - 0.7560975609756098
  - 0.7492578849721706
  - 0.7704316201193988
  - 0.75
  - 0.76
  - 0.7572149122807017
  - 0.764511758020806
  - 0.75
  - 0.7627118644067796
  - 0.7655153508771929
  LT_average_precision:
  - 0.2157409708078002
  - 0.184759949940728
  - 0.23694347110700492
  - 0.2947038974788433
  - 0.19650746157098242
  - 0.29548693161475115
  - 0.10858899872057766
  - 0.242258631577517
  - 0.3232061819018341
  - 0.2629517396184063
  - 0.2383590018556543
  - 0.27236598814138924
  - 0.16872128510059542
  - 0.3279395446501468
  - 0.20561981214704037
  - 0.2718295120771901
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6822045152722443
  - 0.608713692946058
  - 0.8053160919540231
  - 0.753985285101165
  - 0.6804461942257218
  - 0.6330284552845529
  - 0.598758865248227
  - 0.6834733893557423
  - 0.7288557213930351
  - 0.6653491436100132
  - 0.71807132894999
  - 0.8249361080686382
  - 0.6116981132075472
  - 0.6572244180939832
  - 0.7211891643709826
  - 0.6854272573226821
  TL_average_precision:
  - 0.3627996272733115
  - 0.2908091908091908
  - 0.4283193432583676
  - 0.35642788455534324
  - 0.2534901057197072
  - 0.24970238095238093
  - 0.24332691673477583
  - 0.2666097264956372
  - 0.07628205128205129
  - 0.12692307692307692
  - 0.1541197081608368
  - 0.05048988951427977
  - 0.12408536585365854
  - 0.1875
  - 0.35772357723577236
  - 0.20840268757717162
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7069550466497032
  - 0.6447709593777009
  - 0.7549712192569334
  - 0.637752994630318
  - 0.5804508356004664
  - 0.59814453125
  - 0.5634615384615385
  - 0.5763164929163326
  - 0.49508641138597087
  - 0.48356489325652313
  - 0.538377192982456
  - 0.41020138659623634
  - 0.6658695652173914
  - 0.6063764561618639
  - 0.6075949367088607
  - 0.6792670848464841
  TT_average_precision:
  - 0.06267321743512219
  - 0.2781037414965986
  - 0.1105144855144855
  - 0.09375
  - 0.11473922902494331
  - 0.15986394557823128
  - 0.3512003209771973
  - 0.13705475558923835
  - 0.09340659340659341
  - 0.1887885422368181
  - 0.04
  - 0.19913308913308914
  - 0.047619047619047616
  - 0.26190476190476186
  - 0.09455128205128205
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.680701754385965
  - 0.6118055555555556
  - 0.5646258503401361
  - 0.75
  - 0.5471014492753623
  - 0.4714932126696832
  - 0.7030864197530866
  - 0.4706325301204819
  - 0.5865384615384615
  - 0.7307692307692308
  - 0.7272727272727273
  - 0.7129629629629628
  - 0.5041152263374484
  - 0.563034188034188
  - 0.6908783783783783
  - .nan
  fit_time:
  - 0.6447296142578125
  - 0.5822279453277588
  - 0.5819556713104248
  - 0.7386147975921631
  - 0.6586065292358398
  - 0.5601046085357666
  - 0.6239638328552246
  - 0.6440699100494385
  - 0.654932975769043
  - 0.5416848659515381
  - 0.5834426879882812
  - 0.6569364070892334
  - 0.7144696712493896
  - 0.6226632595062256
  - 0.712181806564331
  - 0.7513492107391357
  score_time:
  - 0.19292068481445312
  - 0.17961812019348145
  - 0.18544816970825195
  - 0.1980433464050293
  - 0.1777195930480957
  - 0.1790609359741211
  - 0.1955118179321289
  - 0.1767885684967041
  - 0.17581629753112793
  - 0.19079923629760742
  - 0.16952824592590332
  - 0.16196012496948242
  - 0.20543932914733887
  - 0.1795661449432373
  - 0.17263102531433105
  - 0.2060389518737793
start: 2023-11-08 16:02:33.135276
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
