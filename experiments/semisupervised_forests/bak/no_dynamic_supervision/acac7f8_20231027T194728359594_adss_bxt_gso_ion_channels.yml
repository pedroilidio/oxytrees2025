active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - precision_weighted
    - recall_weighted
    - precision_micro
    - recall_macro
    - matthews_corrcoef
    - f1_micro
    - precision_macro
    - roc_auc
    - f1_weighted
    - balanced_accuracy
    - average_precision
    - recall_micro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-27 19:48:52.339224
estimator:
  call: semisupervised_forests.estimators.adss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: adss_bxt_gso
  params: {}
hash: acac7f854f059214cf2a51b2bf2078d5934ae702c96247c4152e36e7291867b0
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/acac7f8_20231027T194728359594_adss_bxt_gso_ion_channels.yml"
results:
  LL_average_precision:
  - 0.5184005661712668
  - 0.5190602218742214
  - 0.5176092708181601
  - 0.5186347345928768
  - 0.5179426335289955
  - 0.5201724598491942
  - 0.5169603706461487
  - 0.516344279049886
  - 0.5182803961535615
  - 0.5199116982864302
  - 0.5171672044345165
  - 0.5192234959804936
  - 0.5184414452255325
  - 0.5194964972739974
  - 0.5174497673056435
  - 0.5158727846843124
  LL_balanced_accuracy:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_f1_macro:
  - 0.8286026200873362
  - .nan
  - 0.8292413854501421
  - .nan
  - 0.8287236090611564
  - .nan
  - 0.8289825544377944
  - .nan
  - 0.8290503652067968
  - .nan
  - 0.8289280937519903
  - .nan
  - 0.8290039908492242
  - .nan
  - 0.8292875847754466
  - .nan
  LL_f1_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538514
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_f1_weighted:
  - 0.978619720602309
  - .nan
  - 0.9802433876449146
  - .nan
  - 0.9791496381427907
  - .nan
  - 0.9802866917354942
  - .nan
  - 0.9794433538280974
  - .nan
  - 0.9800472204748734
  - .nan
  - 0.979250620929605
  - .nan
  - 0.9804349774611915
  - .nan
  LL_matthews_corrcoef:
  - 0.700447894610418
  - .nan
  - 0.7013905925141326
  - .nan
  - 0.7006174228557172
  - .nan
  - 0.7009803892718732
  - .nan
  - 0.7011211134187072
  - .nan
  - 0.700904035830809
  - .nan
  - 0.70105565880409
  - .nan
  - 0.7014558703735905
  - .nan
  LL_precision_macro:
  - 0.9906272530641673
  - .nan
  - 0.9913517380691861
  - .nan
  - 0.9908647732089868
  - .nan
  - 0.9913735061437469
  - .nan
  - 0.9909938546302183
  - .nan
  - 0.991266467443916
  - .nan
  - 0.990907549489212
  - .nan
  - 0.9914373474711773
  - .nan
  LL_precision_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_precision_weighted:
  - 0.9819443615291318
  - .nan
  - 0.983292333552872
  - .nan
  - 0.9823851865240354
  - .nan
  - 0.9833322464202088
  - .nan
  - 0.9826258367080601
  - .nan
  - 0.9831326562431352
  - .nan
  - 0.9824653978826134
  - .nan
  - 0.9834520558930446
  - .nan
  LL_recall_macro:
  - 0.75
  - .nan
  - 0.7503037667071689
  - .nan
  - 0.75
  - .nan
  - 0.75
  - .nan
  - 0.7502937720329025
  - .nan
  - 0.75
  - .nan
  - 0.7502910360884749
  - .nan
  - 0.7503067484662577
  - .nan
  LL_recall_micro:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_recall_weighted:
  - 0.9815994338287332
  - .nan
  - 0.9829982625961777
  - .nan
  - 0.9820573664710045
  - .nan
  - 0.9830396293538513
  - .nan
  - 0.9823071479122435
  - .nan
  - 0.9828327955654835
  - .nan
  - 0.9821406269514175
  - .nan
  - 0.9831637296268718
  - .nan
  LL_roc_auc:
  - 0.75
  - 0.7505460162034039
  - 0.7503037667071689
  - 0.7511654306882881
  - 0.75
  - 0.7514240066863763
  - 0.75
  - 0.7499458621440099
  - 0.7502937720329025
  - 0.7511299398966199
  - 0.75
  - 0.7514807876931229
  - 0.7502910360884749
  - 0.7511888886047183
  - 0.7503067484662577
  - 0.7499568283365925
  LT_average_precision:
  - 0.3638482371604968
  - 0.11100480692101394
  - 0.20198581153883022
  - 0.22303499324152085
  - 0.3695685287410794
  - 0.10630838534228437
  - 0.17794557976655936
  - 0.18670638067716633
  - 0.3103240745657145
  - 0.09197115285385228
  - 0.18388112366547454
  - 0.2304023250686739
  - 0.30801542459876086
  - 0.13090306806343682
  - 0.2182700608316277
  - 0.2376695329982581
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.7569205127250881
  - 0.668600693505152
  - 0.65833921107628
  - 0.6777859540538089
  - 0.7626391753224536
  - 0.6427303596233986
  - 0.6554487509348262
  - 0.6598880381225567
  - 0.7184939625703958
  - 0.6311606480782086
  - 0.6524868793270304
  - 0.7181181051048402
  - 0.7177308390179677
  - 0.6336143461382467
  - 0.6757858233421311
  - 0.6970996758774227
  TL_average_precision:
  - 0.6043389981917472
  - 0.5538309887451157
  - 0.55614083233898
  - 0.5564932756863514
  - 0.6696680561502998
  - 0.6787199918997239
  - 0.6984835127353117
  - 0.6637002358991991
  - 0.6057912343736696
  - 0.6175483448661697
  - 0.5917560481444158
  - 0.5631106222711493
  - 0.6726843384635672
  - 0.6760582269764278
  - 0.6642617266344304
  - 0.722685987477315
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.903104406254038
  - 0.8862698559218175
  - 0.8769974191939509
  - 0.8827833940188916
  - 0.8937877860344157
  - 0.9069712991751954
  - 0.9020521623665165
  - 0.9077458202987118
  - 0.8597222856935915
  - 0.87268964868551
  - 0.8778118293680816
  - 0.8515785215329403
  - 0.8883942674150364
  - 0.9089497936198484
  - 0.9032680085497111
  - 0.899525297399248
  TT_average_precision:
  - 0.2797004387737744
  - 0.09082560727932812
  - 0.15042528617712111
  - 0.18217858908196813
  - 0.37120586610631606
  - 0.10906224458690081
  - 0.22494406747936052
  - 0.2873567618955704
  - 0.2531884278847719
  - 0.08604067997872775
  - 0.129216278543103
  - 0.20911006990572123
  - 0.42923826976649687
  - 0.056807166035213436
  - 0.1626661003261096
  - 0.24241009937513758
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.7648631645171438
  - 0.6569758047369988
  - 0.5918764580093313
  - 0.703462355968229
  - 0.7725089696866967
  - 0.6389129035224869
  - 0.6827038264413479
  - 0.7096878515185602
  - 0.7099171866798858
  - 0.608099978122949
  - 0.6297531347962384
  - 0.6893891710178098
  - 0.7895892555514358
  - 0.6140790005841908
  - 0.6777123413165816
  - 0.6424087877599058
  fit_time:
  - 52.54133987426758
  - 54.552223682403564
  - 82.4326400756836
  - 71.08716249465942
  - 81.8164587020874
  - 81.44171786308289
  - 83.02080368995667
  - 82.08990979194641
  - 81.13073515892029
  - 81.67661190032959
  - 82.50818848609924
  - 82.57998466491699
  - 82.52315330505371
  - 81.12180423736572
  - 82.17570304870605
  - 81.89806914329529
  score_time:
  - 0.8151640892028809
  - 0.7018728256225586
  - 1.1088273525238037
  - 0.7445430755615234
  - 1.201695203781128
  - 0.9011576175689697
  - 0.9016768932342529
  - 0.9512546062469482
  - 1.0795092582702637
  - 1.018240213394165
  - 1.162125825881958
  - 0.8782017230987549
  - 1.081688642501831
  - 0.93194580078125
  - 1.156017780303955
  - 1.0053184032440186
start: 2023-10-27 19:47:28.359594
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
