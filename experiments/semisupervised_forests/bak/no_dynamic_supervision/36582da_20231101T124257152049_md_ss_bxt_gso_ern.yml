active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 12:49:19.303653
estimator:
  call: semisupervised_forests.estimators.md_ss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: 36582da17b73f9d06b3455dd694c84283935c7ce33407edbffcdd20649b0cbb7
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/36582da_20231101T124257152049_md_ss_bxt_gso_ern.yml"
results:
  LL_average_precision:
  - 0.11755073734897781
  - 0.11904216194074933
  - 0.11824776124456182
  - 0.11212648542299664
  - 0.11707217540001573
  - 0.11935457392663087
  - 0.11865779362828048
  - 0.1125156848371946
  - 0.1172010941396867
  - 0.11893881827724695
  - 0.11827843107499672
  - 0.11201657035511642
  - 0.11712236665172569
  - 0.1193172983663681
  - 0.1185508411617553
  - 0.1125562471961105
  LL_balanced_accuracy:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_f1_macro:
  - 0.5869263150151246
  - 0.5861435721306022
  - 0.5864550390583527
  - 0.5880150750063559
  - 0.5867679904328182
  - 0.5863693085565117
  - 0.5866655249422846
  - 0.5880700084917458
  - 0.5870252315797547
  - 0.5862737524723205
  - 0.5866085416217844
  - 0.5881268637742644
  - 0.5865832349231027
  - 0.5863277483426732
  - 0.5864276751478756
  - 0.5882207775958614
  LL_f1_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_f1_weighted:
  - 0.9759390715472271
  - 0.9733263631338508
  - 0.9745797960748513
  - 0.9831593454996554
  - 0.9762422567124828
  - 0.9732889882645694
  - 0.9744183188027767
  - 0.9828144619281908
  - 0.9764412608576732
  - 0.9736066386792477
  - 0.9747478846466097
  - 0.9834233273191423
  - 0.9759470977012066
  - 0.9732743091898997
  - 0.9742211336307921
  - 0.9829683195491606
  LL_matthews_corrcoef:
  - 0.3141571461786937
  - 0.3132774763658292
  - 0.31357758539033465
  - 0.31455870316115747
  - 0.313786199868058
  - 0.313714688411654
  - 0.31401462921606976
  - 0.31474270783577457
  - 0.3142286546313658
  - 0.31345948930330475
  - 0.3138300346298245
  - 0.31471066812965903
  - 0.3135035878913886
  - 0.3136392339602798
  - 0.3136089385190437
  - 0.3149940759299084
  LL_precision_macro:
  - 0.9914174226320569
  - 0.9904824171765669
  - 0.9909314889574923
  - 0.9940029466148537
  - 0.9915274534459014
  - 0.9904673494240482
  - 0.9908719399972294
  - 0.9938791654306338
  - 0.991597393395671
  - 0.990582422518341
  - 0.9909909464206204
  - 0.9940969990606615
  - 0.9914224981038682
  - 0.9904623585075163
  - 0.9908025845776314
  - 0.9939336108611603
  LL_precision_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_precision_weighted:
  - 0.983161751742076
  - 0.9813666025288966
  - 0.982227803071867
  - 0.9881655493493736
  - 0.9833734027401535
  - 0.9813378626943587
  - 0.9821136246534958
  - 0.9879246670852959
  - 0.9835081426270568
  - 0.9815582642304476
  - 0.9823420130064394
  - 0.9883487021195555
  - 0.9831713676131173
  - 0.9813282819441631
  - 0.9819804478269578
  - 0.9880306406658245
  LL_recall_macro:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_recall_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_recall_weighted:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_roc_auc:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LT_average_precision:
  - 0.025334437488740827
  - 0.0384750547819748
  - 0.0195851397107177
  - 0.034173530960927824
  - 0.030963674172067114
  - 0.042271122245093794
  - 0.01470117993539597
  - 0.033299979512620884
  - 0.02745202652834053
  - 0.04042560480848774
  - 0.01751731684595939
  - 0.0353899862108506
  - 0.028448999819436903
  - 0.05039161121514621
  - 0.013990483876765256
  - 0.03404323014899027
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5163234720083274
  - 0.5246135818937678
  - 0.5187435070759925
  - 0.4989656120052631
  - 0.5273241183194851
  - 0.5300101400734167
  - 0.5111303813378648
  - 0.49957941232667896
  - 0.5229407524329946
  - 0.5210948999314214
  - 0.5184525535746993
  - 0.5074732036664272
  - 0.5182167746820613
  - 0.5273324855235612
  - 0.5139751966234253
  - 0.5009713609184937
  TL_average_precision:
  - 0.0743053135441108
  - 0.08341531773818034
  - 0.09549008973479181
  - 0.05340077592565003
  - 0.08282774098404236
  - 0.13295044383588364
  - 0.10521133621778578
  - 0.057901520912579274
  - 0.0861422422399331
  - 0.10089767041927516
  - 0.11728658672962745
  - 0.06576351186383594
  - 0.0978076233869058
  - 0.11241654713968433
  - 0.10403260571965155
  - 0.058131555248295205
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5738059670094418
  - 0.5726421160065821
  - 0.5823114639525687
  - 0.557207906638367
  - 0.5706173600533131
  - 0.6017543289718681
  - 0.5960708115993627
  - 0.566553274492783
  - 0.5803591811284495
  - 0.5833613589732642
  - 0.5896139779557823
  - 0.5694060508645188
  - 0.5877826781931963
  - 0.6010474666119305
  - 0.5974422204276266
  - 0.5627836806842402
  TT_average_precision:
  - 0.01982949444763438
  - 0.018485500464628473
  - 0.01639579893830484
  - 0.03353871267312682
  - 0.02336817974214526
  - 0.03130178211965862
  - 0.012751773012278481
  - 0.035780920393398814
  - 0.024808118865003264
  - 0.01700050126207299
  - 0.026728558196100573
  - 0.036179691383034826
  - 0.02028637459715293
  - 0.013074989709552922
  - 0.014302828815919636
  - 0.03311244896757544
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5118429524739726
  - 0.522867544168157
  - 0.5209428857493108
  - 0.5034404883502508
  - 0.5241741880737484
  - 0.5272979552242929
  - 0.5052966876430168
  - 0.5059154000688714
  - 0.5159475211264288
  - 0.5207737429009659
  - 0.5369961085808554
  - 0.5128298542856251
  - 0.5087851027609438
  - 0.5233598401354829
  - 0.5207338921943774
  - 0.5022401387652929
  fit_time:
  - 337.188556432724
  - 365.8398001194
  - 333.78018617630005
  - 297.20491003990173
  - 348.94145011901855
  - 368.9799346923828
  - 353.86043095588684
  - 278.3061058521271
  - 347.32450318336487
  - 374.82232904434204
  - 350.54033875465393
  - 263.5602104663849
  - 326.29590106010437
  - 377.4647114276886
  - 349.9445478916168
  - 283.665563583374
  score_time:
  - 4.973747730255127
  - 4.33266806602478
  - 4.852877855300903
  - 6.004518508911133
  - 4.606337308883667
  - 4.277776718139648
  - 4.48244571685791
  - 6.900336027145386
  - 4.899331569671631
  - 4.23710036277771
  - 5.208876848220825
  - 7.269761085510254
  - 4.90442967414856
  - 4.44625186920166
  - 4.938967943191528
  - 6.467345714569092
start: 2023-11-01 12:42:57.152049
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
