active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-23 13:28:59.376950
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_fixed
  params: {}
hash: e79375b4a028ee2b1b4d81d6158926a566dd294590cbba9205926af165739db7
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/e79375b_20231123T132858061896_ss_bxt_gso__ad_fixed_gpcr.yml"
results:
  LL_average_precision:
  - 0.13292219750541678
  - 0.12791295146716863
  - 0.12808467571898458
  - 0.12603828096785843
  - 0.13012411402021545
  - 0.1259381349631162
  - 0.12548957392669147
  - 0.12497407123151279
  - 0.13128101728977734
  - 0.132267461023851
  - 0.13052809978898497
  - 0.12661114730407275
  - 0.13113912124859695
  - 0.12919161676646707
  - 0.1286237990158645
  - 0.12477485083868062
  LL_balanced_accuracy:
  - .nan
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - .nan
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LL_f1_macro:
  - .nan
  - 0.5847208442674116
  - 0.5837653143612727
  - 0.5870688495533206
  - .nan
  - 0.5856492588358561
  - 0.5850966373850548
  - 0.5879130108468398
  - 0.5832018951551277
  - 0.5845640870780535
  - 0.5834040356341553
  - 0.5844570126107703
  - 0.5849046897913459
  - 0.5834786323799407
  - 0.5839119995104589
  - 0.5849495621610719
  LL_f1_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877287
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_f1_weighted:
  - .nan
  - 0.9620573306313152
  - 0.9606267694073672
  - 0.9671121516918916
  - .nan
  - 0.9653597927322017
  - 0.9651117491757567
  - 0.9693443788479165
  - 0.9565184684457021
  - 0.9572609982570296
  - 0.9575760616941908
  - 0.9630885380091844
  - 0.9588945479076647
  - 0.9590832652904875
  - 0.9602490593165409
  - 0.9656764038053118
  LL_matthews_corrcoef:
  - .nan
  - 0.3132124046895629
  - 0.31174146518670126
  - 0.31646487657500544
  - .nan
  - 0.31419512726773463
  - 0.3132085847508585
  - 0.31753943502006654
  - 0.3116447704230443
  - 0.3140383982123482
  - 0.31177719036802776
  - 0.31247201371939837
  - 0.31429780512252053
  - 0.31156273713967697
  - 0.31210792983689867
  - 0.3127981917430874
  LL_precision_macro:
  - .nan
  - 0.9864224684882836
  - 0.9859137055837564
  - 0.988231338264963
  - .nan
  - 0.9876099458728012
  - 0.9875253721244925
  - 0.9890317700453858
  - 0.9844278943805009
  - 0.9846817874069058
  - 0.9848100194634848
  - 0.9867989573698814
  - 0.9852720293724966
  - 0.9853566958698373
  - 0.9857750709160688
  - 0.9877310785045179
  LL_precision_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_precision_weighted:
  - .nan
  - 0.9736625432428543
  - 0.9727065423025402
  - 0.9770783409265276
  - .nan
  - 0.9759012036534148
  - 0.9757409151089271
  - 0.9785987102646133
  - 0.969930089376398
  - 0.9704048567021506
  - 0.9706423552353223
  - 0.9743704103598018
  - 0.9715068153079688
  - 0.971663306678258
  - 0.972446889690223
  - 0.9761295636181652
  LL_recall_macro:
  - .nan
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - .nan
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LL_recall_micro:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_recall_weighted:
  - .nan
  - 0.9729273846672851
  - 0.9719153242810155
  - 0.9765258215962441
  - .nan
  - 0.9752888589019145
  - 0.9751201821708695
  - 0.9781187122736419
  - 0.9689634814877288
  - 0.9694695116808636
  - 0.9697225267774311
  - 0.9736753856472167
  - 0.9706420492348636
  - 0.9708083832335329
  - 0.9716400532268795
  - 0.9755291005291006
  LL_roc_auc:
  - 0.552924791086351
  - 0.5504201680672269
  - 0.55
  - 0.5512820512820513
  - 0.5529595015576324
  - 0.5506134969325154
  - 0.5503048780487805
  - 0.5515463917525774
  - 0.5501222493887531
  - 0.5508684863523573
  - 0.550125313283208
  - 0.5501432664756447
  - 0.5508905852417303
  - 0.55
  - 0.5501319261213721
  - 0.5501519756838906
  LT_average_precision:
  - 0.07272021564041922
  - 0.0874816576762874
  - 0.12603693224046272
  - 0.05891933163793994
  - 0.08086181819822787
  - 0.09891868659674777
  - 0.07948660769356597
  - 0.06307749237396476
  - 0.1250433051944191
  - 0.13866312100993172
  - 0.14426085528609747
  - 0.11520958468941875
  - 0.10819147082558624
  - 0.06549633397598566
  - 0.09885045328666384
  - 0.08489398553040364
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6139213445962757
  - 0.5749425270994513
  - 0.6417445231958763
  - 0.5264440305096131
  - 0.6154174385180453
  - 0.6030471434707904
  - 0.5931796507612878
  - 0.5602100753649922
  - 0.6259816090346492
  - 0.6306126426623965
  - 0.6324222057861958
  - 0.5914897715633486
  - 0.6420105162149459
  - 0.5961402464432406
  - 0.6129041337917774
  - 0.5479086610910185
  TL_average_precision:
  - 0.1673614573044953
  - 0.09751016433376092
  - 0.09553277874877789
  - 0.048694992489749525
  - 0.18769896796422275
  - 0.14625428878924815
  - 0.16536055255151705
  - 0.11290718173649084
  - 0.0923919420300901
  - 0.17287929882904202
  - 0.13421755754340253
  - 0.10622600315408712
  - 0.1547719382110029
  - 0.1600074927140316
  - 0.19909663859142346
  - 0.1174578052927533
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6178510294441097
  - 0.5996978129691788
  - 0.6010036026762737
  - 0.5292593044810247
  - 0.6087617095356882
  - 0.6145134938504669
  - 0.6014917134082891
  - 0.5646241620364778
  - 0.5687469073788068
  - 0.6445106095054058
  - 0.6547082492206705
  - 0.6002214570120488
  - 0.6143087838195584
  - 0.6442990943368521
  - 0.6109173819742489
  - 0.5817776127976416
  TT_average_precision:
  - 0.0654916021526721
  - 0.041922429023378116
  - 0.0680442822337779
  - 0.0633674203333646
  - 0.03257634575569358
  - 0.07767186194827427
  - 0.05807063391394294
  - 0.11400862730649966
  - 0.08024825783972125
  - 0.17425302410767526
  - 0.028273522606767566
  - 0.06303283803283803
  - 0.15096392663116726
  - 0.09742024865321426
  - 0.06224568567882759
  - 0.10928801117821016
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5746856757970364
  - 0.5831387516838797
  - 0.5905034531406356
  - 0.531259142238605
  - 0.49277223926380365
  - 0.5562263160484916
  - 0.5770388464266015
  - 0.5643238499232063
  - 0.606468797564688
  - 0.6169896112991713
  - 0.5626633200385092
  - 0.6088664658423035
  - 0.7135156739473286
  - 0.5902223109691161
  - 0.6421377672209027
  - 0.5930204081632653
  fit_time:
  - 0.7664055824279785
  - 0.8429737091064453
  - 0.7520043849945068
  - 0.8576266765594482
  - 0.7890903949737549
  - 0.7863445281982422
  - 0.8471369743347168
  - 0.7538995742797852
  - 0.9248552322387695
  - 0.9208745956420898
  - 0.8365645408630371
  - 0.76912522315979
  - 0.8615381717681885
  - 0.9029970169067383
  - 0.7876975536346436
  - 0.7797608375549316
  score_time:
  - 0.28827738761901855
  - 0.33524632453918457
  - 0.35564279556274414
  - 0.36816883087158203
  - 0.2840731143951416
  - 0.36076879501342773
  - 0.35704755783081055
  - 0.3679320812225342
  - 0.34346508979797363
  - 0.34098076820373535
  - 0.3654911518096924
  - 0.3565855026245117
  - 0.35313987731933594
  - 0.3504059314727783
  - 0.34738993644714355
  - 0.342907190322876
start: 2023-11-23 13:28:58.061896
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
