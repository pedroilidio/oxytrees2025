active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-23 13:29:36.185911
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_size
  params: {}
hash: 378de6b1fc7fa4e3d0fdaa167e24ab2f23a6dd9acb9025a99dc6c7d558161dbe
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/378de6b_20231123T132932923216_ss_bxt_gso__md_size_ion_channels.yml"
results:
  LL_average_precision:
  - 0.13377477399583057
  - 0.13302798872798172
  - 0.13146194745848774
  - 0.12995195857601313
  - 0.13319151040596633
  - 0.13259068618960163
  - 0.13052866716306777
  - 0.13027598377107885
  - 0.13290471307641066
  - 0.1328142402271899
  - 0.13090096798212958
  - 0.13002088660824432
  - 0.13229659011500366
  - 0.13254182453146074
  - 0.13093533030721544
  - 0.12865051305110875
  LL_balanced_accuracy:
  - 0.5503393665158371
  - .nan
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - .nan
  - 0.55
  - .nan
  - 0.5505287896592245
  - .nan
  - 0.55
  - .nan
  - 0.5500582072176949
  - .nan
  - 0.5503067484662577
  - .nan
  LL_f1_macro:
  - 0.5830246326395329
  - .nan
  - 0.5838124823590799
  - 0.5835535019599959
  - 0.583447048714696
  - .nan
  - 0.5831318283369036
  - .nan
  - 0.5836621267888888
  - .nan
  - 0.5830351581590119
  - .nan
  - 0.582798823502053
  - .nan
  - 0.583692073407322
  - .nan
  LL_f1_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_f1_weighted:
  - 0.9536627205559293
  - .nan
  - 0.9571259928856107
  - 0.9583788951019314
  - 0.9548280871486553
  - .nan
  - 0.9572197620943651
  - .nan
  - 0.9554109057637129
  - .nan
  - 0.9567010390780758
  - .nan
  - 0.9549223882988672
  - .nan
  - 0.9575233439965773
  - .nan
  LL_matthews_corrcoef:
  - 0.31198441312481723
  - .nan
  - 0.3126543364921219
  - 0.3118704264397513
  - 0.31250592182651615
  - .nan
  - 0.3113466596691422
  - .nan
  - 0.3127740736927638
  - .nan
  - 0.31128645486743545
  - .nan
  - 0.3112604610693923
  - .nan
  - 0.3123336797877318
  - .nan
  LL_precision_macro:
  - 0.9833904395788067
  - .nan
  - 0.9846415673903117
  - 0.9851000249024653
  - 0.9838096431854266
  - .nan
  - 0.9846837124356633
  - .nan
  - 0.9840192187173595
  - .nan
  - 0.9844962849196796
  - .nan
  - 0.9838520994359724
  - .nan
  - 0.9847874813216005
  - .nan
  LL_precision_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_precision_weighted:
  - 0.9680033804200365
  - .nan
  - 0.9703288855904003
  - 0.9711837662050161
  - 0.9687812769269635
  - .nan
  - 0.9704065045273832
  - .nan
  - 0.9691707504001682
  - .nan
  - 0.9700571916244725
  - .nan
  - 0.968859108874401
  - .nan
  - 0.9706007095384518
  - .nan
  LL_recall_macro:
  - 0.5503393665158371
  - .nan
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - .nan
  - 0.55
  - .nan
  - 0.5505287896592245
  - .nan
  - 0.55
  - .nan
  - 0.5500582072176949
  - .nan
  - 0.5503067484662577
  - .nan
  LL_recall_micro:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_recall_weighted:
  - 0.9669039590358436
  - .nan
  - 0.9693885993215852
  - 0.9702986679904029
  - 0.9677365638399733
  - .nan
  - 0.9694713328369322
  - .nan
  - 0.9681528662420382
  - .nan
  - 0.9690990320178704
  - .nan
  - 0.9678198243203864
  - .nan
  - 0.9696781666252999
  - .nan
  LL_roc_auc:
  - 0.5503393665158371
  - 0.5503277796570591
  - 0.5504252733900364
  - 0.550125313283208
  - 0.5504640371229699
  - 0.5506165699847885
  - 0.55
  - 0.5503585757596
  - 0.5505287896592245
  - 0.5504500559980077
  - 0.55
  - 0.550168937296356
  - 0.5500582072176949
  - 0.5508280151385218
  - 0.5503067484662577
  - 0.5499807447722335
  LT_average_precision:
  - 0.12030989719084538
  - 0.059047749917892516
  - 0.09057441835706524
  - 0.1268032302786864
  - 0.1126328303867972
  - 0.052896553601507246
  - 0.057352147002484824
  - 0.1004849283348961
  - 0.1130818049244148
  - 0.04790288978390642
  - 0.08593434386004
  - 0.07310641152710962
  - 0.12502950721944103
  - 0.06364551242512928
  - 0.09207906094138665
  - 0.12690898564322098
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6084309357605014
  - 0.575469591520547
  - 0.5564870689655173
  - 0.5850756529540436
  - 0.6097969172947278
  - 0.541227079556599
  - 0.5664775287194652
  - 0.5771399250082542
  - 0.5945660674323094
  - 0.5352105444524422
  - 0.5670685066626963
  - 0.5618068528533073
  - 0.5781012167150782
  - 0.5716061185468451
  - 0.572175734693636
  - 0.5910948140387637
  TL_average_precision:
  - 0.20918391054241017
  - 0.26741108266753444
  - 0.26218187582038294
  - 0.2431627662254598
  - 0.2276125826287272
  - 0.2890927070431461
  - 0.2700193293197578
  - 0.24620721947643812
  - 0.23386524638514244
  - 0.2151570327207599
  - 0.22742377242957357
  - 0.2157677210010732
  - 0.2529896139056685
  - 0.24449149540934692
  - 0.27514775283148335
  - 0.2314488565777035
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.654575921915169
  - 0.6824768543977627
  - 0.6877721080033218
  - 0.6731993476616586
  - 0.6477678032824976
  - 0.6741976868045659
  - 0.6581147873762939
  - 0.664705058217047
  - 0.6608808082410651
  - 0.6448720782580069
  - 0.666430096030631
  - 0.6488570638938734
  - 0.6607807620734785
  - 0.6731629493521466
  - 0.681366077634708
  - 0.6409523593105564
  TT_average_precision:
  - 0.10011947876083928
  - 0.042679879469909754
  - 0.10067675143913535
  - 0.11914537837667206
  - 0.22964072528771465
  - 0.04036054061487649
  - 0.0937248216994021
  - 0.12920939071124662
  - 0.15760857600934536
  - 0.047663366280923006
  - 0.08820552794219004
  - 0.06722180191761253
  - 0.2491571103197282
  - 0.07150761086301385
  - 0.07553793266047432
  - 0.1181908667838367
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.6394665887745473
  - 0.5539609644087256
  - 0.6217972395023328
  - 0.602700046345868
  - 0.664837415600192
  - 0.5433918881633403
  - 0.5766852602762282
  - 0.6328107424071991
  - 0.6774712777745378
  - 0.5433964963061441
  - 0.5719631661442006
  - 0.5497335669837635
  - 0.6300436699213118
  - 0.5707455174583201
  - 0.5452801615345785
  - 0.5651007248226032
  fit_time:
  - 2.050356149673462
  - 1.6672630310058594
  - 1.8905673027038574
  - 1.7109053134918213
  - 1.805199384689331
  - 2.2567808628082275
  - 2.3282785415649414
  - 2.162703514099121
  - 2.3996481895446777
  - 2.1305248737335205
  - 2.1818552017211914
  - 2.2834970951080322
  - 2.380648136138916
  - 2.3551039695739746
  - 2.2446327209472656
  - 2.08857798576355
  score_time:
  - 0.5801577568054199
  - 0.4931001663208008
  - 0.5874309539794922
  - 0.7014474868774414
  - 0.7640352249145508
  - 0.6980478763580322
  - 0.8220858573913574
  - 0.7338821887969971
  - 0.7963759899139404
  - 0.7306897640228271
  - 0.8017010688781738
  - 0.672325849533081
  - 0.7641067504882812
  - 0.6590847969055176
  - 0.8395841121673584
  - 0.7230184078216553
start: 2023-11-23 13:29:32.923216
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
