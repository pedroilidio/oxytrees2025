active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-10 00:18:46.300703
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_density
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_density
  params: {}
hash: 3c11805c2ec5d3a0e15a95faaf3bacf66f1049fa8f17d2ff3acaf0f01f759760
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/3c11805_20231109T234912479085_ss_bxt_gso__md_density_srn.yml"
results:
  LL_average_precision:
  - 0.11342229199372057
  - 0.11739848950147766
  - 0.11816217157894254
  - 0.11617616567672061
  - 0.11353501938359256
  - 0.11696981379179296
  - 0.1179205717775326
  - 0.11582152870909224
  - 0.11383853592976577
  - 0.117200494035632
  - 0.11818405821317018
  - 0.11632054356431842
  - 0.11401385325727043
  - 0.11701235249776337
  - 0.11796768773573779
  - 0.11624124384896081
  LL_balanced_accuracy:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_f1_macro:
  - 0.587525766149485
  - 0.5869569262020368
  - 0.586646374465257
  - 0.5869816036506083
  - 0.5877519171302815
  - 0.5870260223678899
  - 0.586712444341127
  - 0.5871295948036175
  - 0.5878614038397703
  - 0.5867602867102066
  - 0.586687900893901
  - 0.5870483832903317
  - 0.5879402844460085
  - 0.5866607317273869
  - 0.5865557606018998
  - 0.5869642543352205
  LL_f1_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_f1_weighted:
  - 0.9811321823453176
  - 0.9761414287195214
  - 0.9749212382495934
  - 0.9774776314203629
  - 0.9813074311317526
  - 0.9766889473454499
  - 0.9752651098766671
  - 0.9780497795168125
  - 0.9811260532825248
  - 0.9760953339344545
  - 0.9749522354593334
  - 0.9774108918568967
  - 0.9810418010034022
  - 0.9761657817869357
  - 0.9750099646383824
  - 0.977385480503414
  LL_matthews_corrcoef:
  - 0.31409515446139513
  - 0.3141683958690032
  - 0.3138616381656739
  - 0.31390578049604967
  - 0.31448500361571946
  - 0.3141728200322513
  - 0.3139073145897686
  - 0.3140545703121901
  - 0.31473502795779823
  - 0.31380563801371575
  - 0.3139332792843214
  - 0.3140481470423044
  - 0.3149043644977443
  - 0.31360011679080124
  - 0.31366898336781385
  - 0.31389415520984937
  LL_precision_macro:
  - 0.9932788302806383
  - 0.9914900047493631
  - 0.9910530770160804
  - 0.9919701600787443
  - 0.9933405484664932
  - 0.9916864403123518
  - 0.9911763690650834
  - 0.9921748283121097
  - 0.9932749711971511
  - 0.9914746742600742
  - 0.9910639546423424
  - 0.9919457817811599
  - 0.9932443637569717
  - 0.9915006342166346
  - 0.9910856057991025
  - 0.9919371538023503
  LL_precision_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_precision_weighted:
  - 0.9867581350113046
  - 0.9833014126376041
  - 0.982461332030557
  - 0.9842264253782121
  - 0.9868779600334681
  - 0.9836796181124469
  - 0.9826982055854259
  - 0.9846213911194873
  - 0.9867507367598339
  - 0.983271829190631
  - 0.9824822418385274
  - 0.9841794371787886
  - 0.9866913777610021
  - 0.983321742323542
  - 0.9825237643341496
  - 0.9841627673678994
  LL_recall_macro:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_recall_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_recall_weighted:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_roc_auc:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LT_average_precision:
  - 0.02722280677418114
  - 0.015305319614508896
  - 0.012221349725494874
  - 0.019294828756949597
  - 0.026032408515994285
  - 0.01589229827124395
  - 0.012363988748915348
  - 0.0199822892775985
  - 0.026995944531824734
  - 0.01538391804595282
  - 0.012696693399025393
  - 0.019496160086155866
  - 0.02664417822004995
  - 0.015374283236543955
  - 0.013205214658351233
  - 0.01946946046850279
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5076956008589594
  - 0.5076575752701603
  - 0.5117131555059313
  - 0.5168549797842885
  - 0.5039880378938467
  - 0.5080585058071501
  - 0.5170440042819278
  - 0.5157186487235748
  - 0.5015848720611716
  - 0.5052580381143821
  - 0.5172962948900272
  - 0.5121257388321305
  - 0.503397316247293
  - 0.5050089621335242
  - 0.5203765475683295
  - 0.5154007920050365
  TL_average_precision:
  - 0.03333596049571362
  - 0.030470226060849127
  - 0.03398361993309151
  - 0.03177138253637413
  - 0.04092058782838872
  - 0.058437774868015074
  - 0.04248837713479367
  - 0.05105587698800257
  - 0.032221521713378394
  - 0.04549455967130428
  - 0.04837603062058794
  - 0.039797127222070065
  - 0.040483898464836146
  - 0.038952710554620525
  - 0.050494812511942384
  - 0.035833972757295246
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5263098150581308
  - 0.5205466658456539
  - 0.5215709504936175
  - 0.5225937501113497
  - 0.5253101264164156
  - 0.5334773293084755
  - 0.5252868763584833
  - 0.5349291394304678
  - 0.5222554880262544
  - 0.5256958317798267
  - 0.5299667412757156
  - 0.525917092605647
  - 0.5280898718959682
  - 0.5264800124456723
  - 0.5250372918298303
  - 0.5247882559925535
  TT_average_precision:
  - 0.02579594428261512
  - 0.015511769984672399
  - 0.011771163703062795
  - 0.019602173957518586
  - 0.028776163310235015
  - 0.018559497830231156
  - 0.014402371342809502
  - 0.01885815666042548
  - 0.025733762168675407
  - 0.0158353151262597
  - 0.011631233806430021
  - 0.01820150122880154
  - 0.02761179523319822
  - 0.015097626082178833
  - 0.0109762193487583
  - 0.019291167034837242
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.510097525198782
  - 0.5091182816468356
  - 0.49935832396845
  - 0.5118592434035647
  - 0.5098284600389863
  - 0.5355625917383099
  - 0.5042454715205796
  - 0.5172649709237803
  - 0.5049603382458316
  - 0.5016298413882502
  - 0.505493969966188
  - 0.49262591540151696
  - 0.52365038986116
  - 0.5165709795817321
  - 0.4976995464852607
  - 0.5009082819733707
  fit_time:
  - 1372.8226261138916
  - 1767.4205906391144
  - 1722.316174030304
  - 1595.6510348320007
  - 1312.008133172989
  - 1647.9084584712982
  - 1691.1305649280548
  - 1572.442659854889
  - 1348.3430840969086
  - 1741.8843920230865
  - 1734.5780453681946
  - 1596.8200497627258
  - 1431.5915341377258
  - 1738.2729654312134
  - 1674.6418225765228
  - 1612.4719665050507
  score_time:
  - 8.817994117736816
  - 5.114764451980591
  - 5.823340892791748
  - 6.809630393981934
  - 9.41398000717163
  - 6.239739656448364
  - 6.054744243621826
  - 7.886094570159912
  - 7.655767917633057
  - 5.211275339126587
  - 5.551860809326172
  - 7.3669843673706055
  - 7.691674709320068
  - 5.788773059844971
  - 5.925232410430908
  - 6.475330829620361
start: 2023-11-09 23:49:12.479085
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
