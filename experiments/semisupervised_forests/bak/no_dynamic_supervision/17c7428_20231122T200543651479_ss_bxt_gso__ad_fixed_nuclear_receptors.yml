active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-22 20:05:45.589158
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__ad_fixed
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__ad_fixed
  params: {}
hash: 17c7428eaddbcdb00833a2e2bcbfa01ea218adc5b1fe57a5c3f257fc4ecec37b
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/17c7428_20231122T200543651479_ss_bxt_gso__ad_fixed_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.35252140011865407
  - 0.3576555023923445
  - 0.3623116055721961
  - 0.3871221846189754
  - 0.34019576379974326
  - 0.33329346092503986
  - 0.35301668806161746
  - 0.3510109114249037
  - 0.3655770782889427
  - 0.3556818181818182
  - 0.34268292682926826
  - 0.36689642983386356
  - 0.3758467741935484
  - 0.34375
  - 0.37081438610996276
  - 0.3781455671699574
  LL_balanced_accuracy:
  - .nan
  - 0.6590909090909091
  - 0.6574074074074074
  - .nan
  - .nan
  - 0.6515151515151515
  - 0.6585365853658537
  - .nan
  - .nan
  - 0.6590909090909091
  - 0.65
  - .nan
  - .nan
  - 0.65
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.7311193924241709
  - 0.726995463026985
  - .nan
  - .nan
  - 0.7247720867251343
  - 0.7314322301024428
  - .nan
  - .nan
  - 0.7316516838856837
  - 0.7196581196581197
  - .nan
  - .nan
  - 0.7193685793034327
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9605263157894737
  - 0.9525032092426188
  - .nan
  - .nan
  - 0.969736842105263
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625000000000001
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9507226011157428
  - 0.940718199906491
  - .nan
  - .nan
  - 0.9618788373999034
  - 0.9550723736054083
  - .nan
  - .nan
  - 0.9531665101301491
  - 0.9462997706900147
  - .nan
  - .nan
  - 0.9449699323477826
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.5526176822228344
  - 0.5472919980739969
  - .nan
  - .nan
  - 0.541975436470486
  - 0.5527051915086619
  - .nan
  - .nan
  - 0.5532065382625239
  - 0.5356832289134414
  - .nan
  - .nan
  - 0.5353729576861872
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9798927613941019
  - 0.9757217847769029
  - .nan
  - .nan
  - 0.9846666666666667
  - 0.9817232375979112
  - .nan
  - .nan
  - 0.9809160305343512
  - 0.9782608695652174
  - .nan
  - .nan
  - 0.9777070063694268
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9605263157894737
  - 0.9525032092426188
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9621137293636236
  - 0.954809483859447
  - .nan
  - .nan
  - 0.9706649122807017
  - 0.9653703449223582
  - .nan
  - .nan
  - 0.9639312977099237
  - 0.9591728525980912
  - .nan
  - .nan
  - 0.9582006369426752
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.6590909090909091
  - 0.6574074074074074
  - .nan
  - .nan
  - 0.6515151515151515
  - 0.6585365853658537
  - .nan
  - .nan
  - 0.6590909090909091
  - 0.65
  - .nan
  - .nan
  - 0.65
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9605263157894737
  - 0.9525032092426188
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9605263157894737
  - 0.9525032092426188
  - .nan
  - .nan
  - 0.9697368421052631
  - 0.9640564826700898
  - .nan
  - .nan
  - 0.9625
  - 0.9573170731707317
  - .nan
  - .nan
  - 0.95625
  - .nan
  - .nan
  LL_roc_auc:
  - 0.6638469205749659
  - 0.6590909090909091
  - 0.6574074074074074
  - 0.672212456052235
  - 0.656959191288714
  - 0.6515151515151515
  - 0.6585365853658537
  - 0.6581014223871366
  - 0.6600105217411195
  - 0.6590909090909091
  - 0.65
  - 0.6651206140350877
  - 0.6677812745869394
  - 0.65
  - 0.6610169491525424
  - 0.666173245614035
  LT_average_precision:
  - 0.14498974709501025
  - 0.11694038838843256
  - 0.24979015065315377
  - 0.20025495803359583
  - 0.054128376496797546
  - 0.27284972219182746
  - 0.10412730544309491
  - 0.10915462196926728
  - 0.3061507936507937
  - 0.26899684677462454
  - 0.23791676964178166
  - 0.2698770926043653
  - 0.1232595716934613
  - 0.3547759339426006
  - 0.21044587457630937
  - 0.3363876319758673
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5608233731739707
  - 0.5590041493775935
  - 0.7923850574712643
  - 0.6916002452483139
  - 0.49622703412073493
  - 0.6538617886178861
  - 0.5570921985815602
  - 0.5996732026143791
  - 0.6983830845771144
  - 0.592080222515005
  - 0.7282327156804144
  - 0.784775465498357
  - 0.5993710691823899
  - 0.6729614990484556
  - 0.6747015610651974
  - 0.6880900508351488
  TL_average_precision:
  - 0.2624649859943977
  - 0.21927655677655677
  - 0.28031656690193274
  - 0.21711855781977732
  - 0.2925673364552821
  - 0.2185846560846561
  - 0.17820672007663876
  - 0.2116033111827898
  - 0.0862246727631343
  - 0.12692307692307692
  - 0.21622429459588713
  - 0.05282907080082948
  - 0.10666666666666666
  - 0.13988095238095238
  - 0.2914892244160537
  - 0.16885553470919326
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6228795589482612
  - 0.6750216076058773
  - 0.6811878597592884
  - 0.6028500619578687
  - 0.5978105972276201
  - 0.589111328125
  - 0.5589743589743591
  - 0.5536621224271585
  - 0.5650626906133515
  - 0.46119959335818367
  - 0.5158382066276803
  - 0.4691317266424562
  - 0.5423913043478261
  - 0.6094420600858369
  - 0.6802625410220347
  - 0.5726312314295148
  TT_average_precision:
  - 0.030612244897959183
  - 0.08163265306122448
  - 0.0993118504639242
  - 0.16477272727272727
  - 0.3299319727891156
  - 0.16363160648874933
  - 0.2757742257742257
  - 0.20192307692307693
  - 0.16626984126984126
  - 0.0753968253968254
  - 0.01282051282051282
  - 0.18977732793522267
  - 0.07936507936507936
  - 0.28095238095238095
  - 0.14517345399698342
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.4368421052631579
  - 0.45
  - 0.5986394557823129
  - 0.8996212121212122
  - 0.7318840579710144
  - 0.5561085972850679
  - 0.7092592592592594
  - 0.5256024096385543
  - 0.6495726495726495
  - 0.49358974358974356
  - 0.3181818181818182
  - 0.6527777777777778
  - 0.551440329218107
  - 0.5405982905982906
  - 0.7297297297297297
  - .nan
  fit_time:
  - 0.45937395095825195
  - 0.513317346572876
  - 0.5229382514953613
  - 0.4826176166534424
  - 0.47652316093444824
  - 0.41430187225341797
  - 0.47391390800476074
  - 0.48470044136047363
  - 0.5286569595336914
  - 0.49245238304138184
  - 0.5491323471069336
  - 0.5463008880615234
  - 0.5568385124206543
  - 0.5367152690887451
  - 0.5598831176757812
  - 0.5716841220855713
  score_time:
  - 0.20962858200073242
  - 0.18453049659729004
  - 0.1930103302001953
  - 0.17962121963500977
  - 0.19184017181396484
  - 0.1713261604309082
  - 0.1806485652923584
  - 0.1993856430053711
  - 0.15856146812438965
  - 0.1955873966217041
  - 0.19421124458312988
  - 0.20345377922058105
  - 0.22470474243164062
  - 0.20902609825134277
  - 0.19918560981750488
  - 0.19789505004882812
start: 2023-11-22 20:05:43.651479
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
