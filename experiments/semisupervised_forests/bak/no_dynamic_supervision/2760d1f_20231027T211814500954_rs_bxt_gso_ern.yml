active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - precision_weighted
    - recall_weighted
    - precision_micro
    - recall_macro
    - matthews_corrcoef
    - f1_micro
    - precision_macro
    - roc_auc
    - f1_weighted
    - balanced_accuracy
    - average_precision
    - recall_micro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-10-27 21:29:38.440664
estimator:
  call: semisupervised_forests.estimators.rs_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: rs_bxt_gso
  params: {}
hash: 2760d1f896ac36abdf11314d19d3c2b9c53d6c64e1f7e5ae343c0714ebf73d72
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/2760d1f_20231027T211814500954_rs_bxt_gso_ern.yml"
results:
  LL_average_precision:
  - 0.5095223865730365
  - 0.5107842944390422
  - 0.5102979928788673
  - 0.5066556069044515
  - 0.5096578689058979
  - 0.510803771170762
  - 0.5103654409046002
  - 0.5067938539321405
  - 0.509323173464814
  - 0.5106772027316135
  - 0.5099932851443694
  - 0.5069237739911575
  - 0.5095124259176254
  - 0.5105782160466159
  - 0.5102006556859028
  - 0.5067346052059881
  LL_balanced_accuracy:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LL_f1_macro:
  - 0.8309182405189923
  - 0.8307586814018457
  - 0.8308907741279159
  - 0.8316526526826057
  - 0.8310692710241894
  - 0.8307533419130508
  - 0.8308722135951685
  - 0.8316173829761762
  - 0.830969482074128
  - 0.8307880564775882
  - 0.830796992481203
  - 0.8318477578032308
  - 0.8309208033345965
  - 0.8306461407663812
  - 0.8307435430737526
  - 0.8316325003740834
  LL_f1_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_f1_weighted:
  - 0.988913546445512
  - 0.987722980614685
  - 0.9882987906880089
  - 0.9922463112278831
  - 0.9890650969602176
  - 0.9876998468075384
  - 0.9882185032999534
  - 0.9920854949952507
  - 0.989145002886385
  - 0.9878502202741921
  - 0.9883665137089277
  - 0.992373769952719
  - 0.9889251187756575
  - 0.9876871736491468
  - 0.9881256525918501
  - 0.9921544150315158
  LL_matthews_corrcoef:
  - 0.7036995331209558
  - 0.7034934238032008
  - 0.7036800473667042
  - 0.7047339211336413
  - 0.7039328307015822
  - 0.7034858763540875
  - 0.7036537950796627
  - 0.7046842107963786
  - 0.7037716557806432
  - 0.7035349496681379
  - 0.7035289052508503
  - 0.7050384450672653
  - 0.7037031401185525
  - 0.7033166743918887
  - 0.7034537008880977
  - 0.7047055173504467
  LL_precision_macro:
  - 0.9951930329146512
  - 0.9946695525242866
  - 0.9949226426198765
  - 0.9966498995963974
  - 0.9952589717549346
  - 0.9946593780516042
  - 0.9948873725584086
  - 0.9965798369457148
  - 0.9952945434802281
  - 0.9947255048014012
  - 0.99495292052346
  - 0.996704902389567
  - 0.9951981094127111
  - 0.9946543444776661
  - 0.994847109293161
  - 0.9966098661841608
  LL_precision_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_precision_weighted:
  - 0.9905691610246246
  - 0.9895641206011611
  - 0.9900495467435512
  - 0.993388986998302
  - 0.9906961659372497
  - 0.9895446267221922
  - 0.9899818391422291
  - 0.9932526182442893
  - 0.990764566109916
  - 0.9896713515806191
  - 0.9901075886643413
  - 0.9934961616644096
  - 0.9905789293393269
  - 0.9895348789514361
  - 0.9899044700418723
  - 0.9933110572197021
  LL_recall_macro:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LL_recall_micro:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_recall_weighted:
  - 0.9904776134269635
  - 0.9894516659196175
  - 0.9899474661294783
  - 0.9933443930955485
  - 0.9906071019473082
  - 0.9894317446087952
  - 0.9898783426156338
  - 0.9932061460678595
  - 0.990676826535186
  - 0.9895612331291399
  - 0.9900067148556306
  - 0.9934530157601612
  - 0.9904875740823746
  - 0.9894217839533841
  - 0.9897993443140972
  - 0.9932653947940119
  LL_roc_auc:
  - 0.75
  - 0.7501179801793298
  - 0.7501227295041728
  - 0.75
  - 0.750132485426603
  - 0.7501177578897786
  - 0.750121891760117
  - 0.75
  - 0.75
  - 0.7501192179303767
  - 0.75
  - 0.7501883948756594
  - 0.75
  - 0.75
  - 0.75
  - 0.75
  LT_average_precision:
  - 0.05411440634735446
  - 0.1753840410184073
  - 0.022651851823060565
  - 0.03581412940157629
  - 0.06317668822832614
  - 0.10837572409045605
  - 0.02283989345365875
  - 0.037965268737045976
  - 0.04816077305190094
  - 0.17569332401092835
  - 0.018712462524196293
  - 0.03721184610379189
  - 0.07326515360308292
  - 0.1681849760793054
  - 0.02030827377930217
  - 0.03487103465796241
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.567183907187864
  - 0.6042821066990013
  - 0.5883407360127627
  - 0.5151083438355328
  - 0.5846585469792016
  - 0.6241304816176361
  - 0.5685394406451013
  - 0.5307530071326051
  - 0.5765189835208869
  - 0.6152329679964623
  - 0.5515493206004874
  - 0.5195951293767191
  - 0.6128509561241458
  - 0.6333789047398286
  - 0.5611609117029428
  - 0.5023524741701412
  TL_average_precision:
  - 0.3625546235639582
  - 0.3441425832135549
  - 0.3290808524162858
  - 0.20485402843083966
  - 0.37193327918128155
  - 0.3827017059465778
  - 0.33856807533585515
  - 0.2641172990621527
  - 0.33971988086799876
  - 0.3498498772155053
  - 0.34410106545191455
  - 0.18767839598723254
  - 0.36245524233086285
  - 0.3701823822735106
  - 0.38894723296055633
  - 0.24825646819565145
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7900904084839935
  - 0.7898831702741602
  - 0.7784440422078358
  - 0.6969294785007113
  - 0.7879051551789795
  - 0.7958349099043757
  - 0.7762776215954778
  - 0.731131922058198
  - 0.8018123082005812
  - 0.7923063838892253
  - 0.7939315868689015
  - 0.7073408594668824
  - 0.7944395273628108
  - 0.795207720062825
  - 0.805467977454018
  - 0.7304806078717444
  TT_average_precision:
  - 0.037919067913877856
  - 0.052736333959240406
  - 0.021522346599370277
  - 0.03596075055773835
  - 0.029126637736861707
  - 0.03360735073670654
  - 0.02551747743572428
  - 0.03808010648366508
  - 0.0346640156695721
  - 0.05530875077389814
  - 0.016853672529737844
  - 0.03704295216544752
  - 0.03817207817764144
  - 0.049877576537174055
  - 0.02701035692361787
  - 0.03793411015265302
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.56175456052779
  - 0.6229988700734078
  - 0.6322394732608901
  - 0.5336642504680658
  - 0.5730088199748
  - 0.6173029282563384
  - 0.6031325502836123
  - 0.5396117889418742
  - 0.5806622407375703
  - 0.6327015020243475
  - 0.533602577359336
  - 0.5234869106680395
  - 0.5902711188465916
  - 0.6430082337474917
  - 0.646630560830645
  - 0.5268227074029393
  fit_time:
  - 630.7163152694702
  - 667.9052002429962
  - 657.8309659957886
  - 561.5380401611328
  - 616.9528315067291
  - 673.3605318069458
  - 662.1870455741882
  - 573.951122045517
  - 612.1635100841522
  - 679.4778213500977
  - 658.8802182674408
  - 556.3516066074371
  - 652.6328957080841
  - 242.5732545852661
  - 235.903573513031
  - 190.86125802993774
  score_time:
  - 8.904605388641357
  - 4.429899215698242
  - 5.106770753860474
  - 9.771822690963745
  - 9.8425452709198
  - 4.353256702423096
  - 4.727929353713989
  - 10.401576280593872
  - 9.41113829612732
  - 4.1672163009643555
  - 5.525419235229492
  - 11.962610006332397
  - 5.451885938644409
  - 4.4213948249816895
  - 4.433868408203125
  - 4.601393461227417
start: 2023-10-27 21:18:14.500954
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
