active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-20 04:28:25.300051
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__mse_density
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__mse_density
  params: {}
hash: 51664a341239fa7f4c8d01c96c493aadf090aa0c939cc728d91797e3a059a397
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/51664a3_20231120T042558154030_ss_bxt_gso__mse_density_ern.yml"
results:
  LL_average_precision:
  - 0.11755073734897781
  - 0.11904216194074933
  - 0.11824776124456182
  - 0.11212648542299664
  - 0.11707217540001573
  - 0.11935457392663087
  - 0.11865779362828048
  - 0.1125156848371946
  - 0.1172010941396867
  - 0.11893881827724695
  - 0.11827843107499672
  - 0.11201657035511642
  - 0.11712236665172569
  - 0.1193172983663681
  - 0.1185508411617553
  - 0.1125562471961105
  LL_balanced_accuracy:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_f1_macro:
  - 0.5869263150151246
  - 0.5861435721306022
  - 0.5864550390583527
  - 0.5880150750063559
  - 0.5867679904328182
  - 0.5863693085565117
  - 0.5866655249422846
  - 0.5880700084917458
  - 0.5870252315797547
  - 0.5862737524723205
  - 0.5866085416217844
  - 0.5881268637742644
  - 0.5865832349231027
  - 0.5863277483426732
  - 0.5864276751478756
  - 0.5882207775958614
  LL_f1_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_f1_weighted:
  - 0.9759390715472271
  - 0.9733263631338508
  - 0.9745797960748513
  - 0.9831593454996554
  - 0.9762422567124828
  - 0.9732889882645694
  - 0.9744183188027767
  - 0.9828144619281908
  - 0.9764412608576732
  - 0.9736066386792477
  - 0.9747478846466097
  - 0.9834233273191423
  - 0.9759470977012066
  - 0.9732743091898997
  - 0.9742211336307921
  - 0.9829683195491606
  LL_matthews_corrcoef:
  - 0.3141571461786937
  - 0.3132774763658292
  - 0.31357758539033465
  - 0.31455870316115747
  - 0.313786199868058
  - 0.313714688411654
  - 0.31401462921606976
  - 0.31474270783577457
  - 0.3142286546313658
  - 0.31345948930330475
  - 0.3138300346298245
  - 0.31471066812965903
  - 0.3135035878913886
  - 0.3136392339602798
  - 0.3136089385190437
  - 0.3149940759299084
  LL_precision_macro:
  - 0.9914174226320569
  - 0.9904824171765669
  - 0.9909314889574923
  - 0.9940029466148537
  - 0.9915274534459014
  - 0.9904673494240482
  - 0.9908719399972294
  - 0.9938791654306338
  - 0.991597393395671
  - 0.990582422518341
  - 0.9909909464206204
  - 0.9940969990606615
  - 0.9914224981038682
  - 0.9904623585075163
  - 0.9908025845776314
  - 0.9939336108611603
  LL_precision_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_precision_weighted:
  - 0.983161751742076
  - 0.9813666025288966
  - 0.982227803071867
  - 0.9881655493493736
  - 0.9833734027401535
  - 0.9813378626943587
  - 0.9821136246534958
  - 0.9879246670852959
  - 0.9835081426270568
  - 0.9815582642304476
  - 0.9823420130064394
  - 0.9883487021195555
  - 0.9831713676131173
  - 0.9813282819441631
  - 0.9819804478269578
  - 0.9880306406658245
  LL_recall_macro:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_recall_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_recall_weighted:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_roc_auc:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LT_average_precision:
  - 0.022924890107637392
  - 0.050380279422635836
  - 0.01769575275866693
  - 0.03516119628275672
  - 0.02345523566724798
  - 0.04998575742249729
  - 0.017049860521932376
  - 0.03499529622507012
  - 0.019994962503029626
  - 0.027404611799843607
  - 0.015021043287422764
  - 0.03525208795407392
  - 0.02958124852224697
  - 0.047330733094099145
  - 0.014846822432931115
  - 0.0353445552302367
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5105379379631327
  - 0.5226976129609074
  - 0.5280807838238551
  - 0.5019050665941229
  - 0.5157004215020581
  - 0.5265597470601123
  - 0.519762883217241
  - 0.5056418198142817
  - 0.5091952481038144
  - 0.5183768015700397
  - 0.5169088540321332
  - 0.5051287145155379
  - 0.5195035616804312
  - 0.5276892376987381
  - 0.5132192281734685
  - 0.5017494212224005
  TL_average_precision:
  - 0.0810577507882424
  - 0.0884490417816521
  - 0.07677769524397894
  - 0.08318739144563422
  - 0.07696516936774084
  - 0.07338875827205925
  - 0.07074521324522125
  - 0.04360677558119794
  - 0.06375105330677511
  - 0.08337512737676873
  - 0.0919656449863204
  - 0.05624838348074382
  - 0.0956383248904156
  - 0.10594389521526511
  - 0.07186794539975098
  - 0.054752539844571325
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5743408446869855
  - 0.5790291981269609
  - 0.5829853387784656
  - 0.5685541775424748
  - 0.5669795554074638
  - 0.5704221383191542
  - 0.5701523645104553
  - 0.5544901083653447
  - 0.5617665206334878
  - 0.5865426347183934
  - 0.5783181221025354
  - 0.569390554429139
  - 0.5878788433497725
  - 0.593769527747265
  - 0.5714137614359696
  - 0.5605405081638438
  TT_average_precision:
  - 0.021344123631323885
  - 0.018556814831555267
  - 0.020192336190600426
  - 0.03378843748200898
  - 0.016983255145660923
  - 0.018900970399342014
  - 0.01272146768559654
  - 0.03547633125053291
  - 0.026014654795811002
  - 0.021820468547245248
  - 0.017107012453987505
  - 0.03681760531457631
  - 0.02410265749775638
  - 0.014476596543878149
  - 0.019109290370352732
  - 0.0343994331695816
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5210215129181192
  - 0.5273546996714982
  - 0.5508770433605689
  - 0.5032560365574205
  - 0.5101265139242459
  - 0.5296175523473019
  - 0.5043660281958516
  - 0.5062534298831497
  - 0.5109891851888084
  - 0.5325477759814284
  - 0.5227723006733024
  - 0.5146020156635153
  - 0.5140234707863819
  - 0.532354278484516
  - 0.5472091178821842
  - 0.5084777178123915
  fit_time:
  - 131.1793212890625
  - 143.5187864303589
  - 133.51583766937256
  - 93.82060408592224
  - 114.41845488548279
  - 119.72865676879883
  - 129.66124987602234
  - 91.13397479057312
  - 133.5999732017517
  - 133.20613932609558
  - 133.63887333869934
  - 88.29408740997314
  - 132.63828039169312
  - 117.7335000038147
  - 113.60423803329468
  - 88.40767884254456
  score_time:
  - 5.560073137283325
  - 3.371363878250122
  - 5.872286081314087
  - 5.290472030639648
  - 4.043804407119751
  - 3.5587971210479736
  - 5.822571754455566
  - 5.846728563308716
  - 5.802725076675415
  - 5.372858047485352
  - 5.7463250160217285
  - 6.053883075714111
  - 5.555696964263916
  - 3.6530590057373047
  - 4.128767251968384
  - 6.998072862625122
start: 2023-11-20 04:25:58.154030
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
    random_state: 0
