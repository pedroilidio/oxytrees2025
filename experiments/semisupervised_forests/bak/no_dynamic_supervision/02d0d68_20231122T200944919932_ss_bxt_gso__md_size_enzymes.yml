active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - f1_weighted
    - recall_weighted
    - average_precision
    - precision_weighted
    - precision_micro
    - precision_macro
    - balanced_accuracy
    - recall_micro
    - matthews_corrcoef
    - f1_micro
    - roc_auc
    - recall_macro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-22 20:11:03.745372
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_size
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_size
  params: {}
hash: 02d0d6885b104c69f686bf53a5996d37968bbb61ed162dd9ac4811c5619bdeb5
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/02d0d68_20231122T200944919932_ss_bxt_gso__md_size_enzymes.yml"
results:
  LL_average_precision:
  - 0.306728945116635
  - 0.307667724996922
  - 0.30701646365066204
  - 0.3073462740730796
  - 0.3069922693778116
  - 0.30920715189061515
  - 0.307742357193137
  - 0.307277134133476
  - 0.3080929601160361
  - 0.30938987583384714
  - 0.3081438362064258
  - 0.3089989815829255
  - 0.307919968160932
  - 0.3084116394343895
  - 0.3075131541686076
  - 0.3073667102025463
  LL_balanced_accuracy:
  - .nan
  - 0.6501424501424502
  - 0.6500302480338778
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.729079319124128
  - 0.7290547268171468
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9926171752879782
  - 0.9930440324170935
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9906444566816437
  - 0.9911836959231863
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.545949542608125
  - 0.5458635748340672
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9962968547390006
  - 0.9965116138835959
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9926171752879782
  - 0.9930440324170935
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9926718546326685
  - 0.9930925626185783
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.6501424501424502
  - 0.6500302480338778
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9926171752879782
  - 0.9930440324170935
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9926171752879782
  - 0.9930440324170935
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LL_roc_auc:
  - 0.6500947048494058
  - 0.6501424501424502
  - 0.6500302480338778
  - 0.6503453134801239
  - 0.6503333333333333
  - 0.6510263929618768
  - 0.6504932538444226
  - 0.6504251144538914
  - 0.650814332247557
  - 0.6509915014164306
  - 0.6505698860227954
  - 0.6511627906976745
  - 0.6504504504504505
  - 0.6503250270855905
  - 0.6501112150948903
  - 0.6502098668589054
  LT_average_precision:
  - 0.1034383588436208
  - 0.2076853106638394
  - 0.12364910029948431
  - 0.12162834871476894
  - 0.12027047467181334
  - 0.22505086726783546
  - 0.18406798772761826
  - 0.1452563170414642
  - 0.15799474515022674
  - 0.16982763728580025
  - 0.16604746431478265
  - 0.1260646611823713
  - 0.12938326281512652
  - 0.24958382866443585
  - 0.18968463694735882
  - 0.14885846020295337
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6133926850965881
  - 0.6845708261975054
  - 0.6532736771341928
  - 0.6608105908743072
  - 0.6287351634811625
  - 0.7056794442740502
  - 0.6800620877809238
  - 0.6722669864625874
  - 0.6401160050297641
  - 0.6788178739999315
  - 0.6874403873254961
  - 0.6686012905244391
  - 0.6516217105953932
  - 0.7213996233942361
  - 0.6868189684035183
  - 0.6877078950679275
  TL_average_precision:
  - 0.4549820186893714
  - 0.5039230933520557
  - 0.4833748994941295
  - 0.44426586403379986
  - 0.6052106533629019
  - 0.6227669020004646
  - 0.6203044180641971
  - 0.5862215382151145
  - 0.5968061718663603
  - 0.6248244265177026
  - 0.5889206904629178
  - 0.6175956380902354
  - 0.6091306788097265
  - 0.6100768080016306
  - 0.6079593513950737
  - 0.5729365271807088
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7790348033283693
  - 0.7953397625143859
  - 0.7896823227471769
  - 0.7641195806894091
  - 0.8436175692523502
  - 0.8499824937499273
  - 0.8581080432732376
  - 0.8419613430623317
  - 0.8389771586060835
  - 0.8597059119527534
  - 0.8461757499813126
  - 0.845725681802578
  - 0.8429571924707868
  - 0.8567602882757407
  - 0.8485449126812628
  - 0.8437929016763444
  TT_average_precision:
  - 0.10054776897218523
  - 0.2109521984961586
  - 0.13664665561367711
  - 0.11729008307128379
  - 0.1164090499249478
  - 0.2302019869460377
  - 0.20018390607283326
  - 0.13188051197589756
  - 0.11911371388736486
  - 0.16696364726369056
  - 0.16549391694862559
  - 0.12128690999370265
  - 0.07221624450195778
  - 0.12761076256733622
  - 0.0672115132592137
  - 0.04611699145836971
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.6011016127045394
  - 0.6518289088234936
  - 0.6601490778464234
  - 0.6575654407010523
  - 0.6394693905796424
  - 0.7096627614146501
  - 0.6441053988807198
  - 0.6846836216077329
  - 0.6312683990036232
  - 0.6710494894171992
  - 0.6668935022882446
  - 0.6638377272180089
  - 0.5933051743164898
  - 0.6680367835537424
  - 0.581794425087108
  - 0.637249567699823
  fit_time:
  - 57.44306826591492
  - 60.94945406913757
  - 64.50616312026978
  - 58.12851166725159
  - 56.99531292915344
  - 60.439820289611816
  - 61.06415247917175
  - 62.01988196372986
  - 63.45358228683472
  - 70.05931949615479
  - 70.44432020187378
  - 67.95936703681946
  - 67.39135766029358
  - 70.05345559120178
  - 68.83030390739441
  - 68.92071986198425
  score_time:
  - 8.634974002838135
  - 8.997228384017944
  - 7.820259094238281
  - 8.217146873474121
  - 8.337836503982544
  - 7.979546546936035
  - 8.256755590438843
  - 7.01085901260376
  - 7.534251689910889
  - 8.395905256271362
  - 8.154651165008545
  - 9.01010799407959
  - 8.324106216430664
  - 7.8905816078186035
  - 8.547385454177856
  - 8.012138366699219
start: 2023-11-22 20:09:44.919932
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
