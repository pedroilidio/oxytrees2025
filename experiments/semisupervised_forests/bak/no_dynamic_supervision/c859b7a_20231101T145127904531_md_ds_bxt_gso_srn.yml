active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 15:26:05.839917
estimator:
  call: semisupervised_forests.estimators.md_ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.node_size_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ds_bxt_gso
  params: {}
hash: c859b7a7fd23ecbfde657576155f2cb9221edb337dcdc42b159d6643fe2869fa
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/c859b7a_20231101T145127904531_md_ds_bxt_gso_srn.yml"
results:
  LL_average_precision:
  - 0.11342229199372057
  - 0.11739848950147766
  - 0.11816217157894254
  - 0.11617616567672061
  - 0.11353501938359256
  - 0.11696981379179296
  - 0.1179205717775326
  - 0.11582152870909224
  - 0.11383853592976577
  - 0.117200494035632
  - 0.11818405821317018
  - 0.11632054356431842
  - 0.11401385325727043
  - 0.11701235249776337
  - 0.11796768773573779
  - 0.11624124384896081
  LL_balanced_accuracy:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_f1_macro:
  - 0.587525766149485
  - 0.5869569262020368
  - 0.586646374465257
  - 0.5869816036506083
  - 0.5877519171302815
  - 0.5870260223678899
  - 0.586712444341127
  - 0.5871295948036175
  - 0.5878614038397703
  - 0.5867602867102066
  - 0.586687900893901
  - 0.5870483832903317
  - 0.5879402844460085
  - 0.5866607317273869
  - 0.5865557606018998
  - 0.5869642543352205
  LL_f1_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_f1_weighted:
  - 0.9811321823453176
  - 0.9761414287195214
  - 0.9749212382495934
  - 0.9774776314203629
  - 0.9813074311317526
  - 0.9766889473454499
  - 0.9752651098766671
  - 0.9780497795168125
  - 0.9811260532825248
  - 0.9760953339344545
  - 0.9749522354593334
  - 0.9774108918568967
  - 0.9810418010034022
  - 0.9761657817869357
  - 0.9750099646383824
  - 0.977385480503414
  LL_matthews_corrcoef:
  - 0.31409515446139513
  - 0.3141683958690032
  - 0.3138616381656739
  - 0.31390578049604967
  - 0.31448500361571946
  - 0.3141728200322513
  - 0.3139073145897686
  - 0.3140545703121901
  - 0.31473502795779823
  - 0.31380563801371575
  - 0.3139332792843214
  - 0.3140481470423044
  - 0.3149043644977443
  - 0.31360011679080124
  - 0.31366898336781385
  - 0.31389415520984937
  LL_precision_macro:
  - 0.9932788302806383
  - 0.9914900047493631
  - 0.9910530770160804
  - 0.9919701600787443
  - 0.9933405484664932
  - 0.9916864403123518
  - 0.9911763690650834
  - 0.9921748283121097
  - 0.9932749711971511
  - 0.9914746742600742
  - 0.9910639546423424
  - 0.9919457817811599
  - 0.9932443637569717
  - 0.9915006342166346
  - 0.9910856057991025
  - 0.9919371538023503
  LL_precision_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_precision_weighted:
  - 0.9867581350113046
  - 0.9833014126376041
  - 0.982461332030557
  - 0.9842264253782121
  - 0.9868779600334681
  - 0.9836796181124469
  - 0.9826982055854259
  - 0.9846213911194873
  - 0.9867507367598339
  - 0.983271829190631
  - 0.9824822418385274
  - 0.9841794371787886
  - 0.9866913777610021
  - 0.983321742323542
  - 0.9825237643341496
  - 0.9841627673678994
  LL_recall_macro:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_recall_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_recall_weighted:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_roc_auc:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LT_average_precision:
  - 0.027300630795303014
  - 0.015459674583004844
  - 0.013587621452807138
  - 0.01984859818525244
  - 0.026698796176166287
  - 0.015573834797814946
  - 0.014013660451292745
  - 0.02098769641122809
  - 0.027773633117093344
  - 0.015725971558085
  - 0.013617533494680412
  - 0.018723186434613882
  - 0.027881544328056007
  - 0.015405434198906222
  - 0.013390277863273188
  - 0.019785476631447873
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.510890874252397
  - 0.5081798357032163
  - 0.5192054725587032
  - 0.5163968149152175
  - 0.5130480382575033
  - 0.513265753112537
  - 0.5362851715925336
  - 0.5201330689015419
  - 0.509037544106449
  - 0.5103124707544238
  - 0.5278828452556829
  - 0.5104672818096537
  - 0.5108735058688395
  - 0.5070413117512066
  - 0.5212684546358249
  - 0.5148066403318843
  TL_average_precision:
  - 0.05658104013102987
  - 0.041892186372574636
  - 0.04416163267696854
  - 0.050354346564761565
  - 0.03616087389216191
  - 0.05373056054904793
  - 0.051636223042722564
  - 0.04707016751764853
  - 0.029717735761206537
  - 0.03887464055170904
  - 0.04616321616698397
  - 0.047337817952017774
  - 0.02932083168134728
  - 0.04473615988422647
  - 0.03951985270009554
  - 0.034817540672550974
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5384979249948161
  - 0.532239683040051
  - 0.5348172556591108
  - 0.535145263310859
  - 0.5244845588310231
  - 0.5353021460706885
  - 0.5380008169811035
  - 0.5341113033560001
  - 0.5241141012394299
  - 0.5299574107359817
  - 0.5269375538864449
  - 0.53778330423923
  - 0.5187312442100105
  - 0.5258411759955197
  - 0.5224184870555624
  - 0.5263293958298574
  TT_average_precision:
  - 0.0262287108535575
  - 0.014840512264484369
  - 0.01252383081178279
  - 0.018419099504047524
  - 0.030175272121017997
  - 0.015012663199710051
  - 0.014470118383208073
  - 0.023048786912880825
  - 0.02642059766200418
  - 0.01508613880124452
  - 0.013573847614209923
  - 0.019496221546910674
  - 0.027357216429524375
  - 0.01594996313352728
  - 0.011059593067996431
  - 0.01889870191352698
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5083422471254175
  - 0.49839085474315914
  - 0.5133471239004245
  - 0.49915585914547134
  - 0.5084427585480218
  - 0.5064428601383939
  - 0.5289279966712152
  - 0.524273627202912
  - 0.5115851804671506
  - 0.5071616644950745
  - 0.5435462895785137
  - 0.5185463003434064
  - 0.5132930723309732
  - 0.5165770071146415
  - 0.5046051587301587
  - 0.5121367384680995
  fit_time:
  - 1611.7673528194427
  - 2045.1662380695343
  - 2059.42041349411
  - 1922.714923620224
  - 1611.764778137207
  - 1908.8023970127106
  - 2023.6304204463959
  - 1910.5850672721863
  - 1704.7059524059296
  - 2070.784941673279
  - 1978.0393152236938
  - 1957.519995689392
  - 1673.1525654792786
  - 1937.5175726413727
  - 2043.0359029769897
  - 1917.1439259052277
  score_time:
  - 10.604364156723022
  - 5.9593565464019775
  - 6.29101824760437
  - 7.304855108261108
  - 10.568255186080933
  - 7.127356290817261
  - 6.3250837326049805
  - 7.1896812915802
  - 7.982860565185547
  - 5.896700859069824
  - 6.903351068496704
  - 6.405519008636475
  - 8.277663230895996
  - 6.744671106338501
  - 6.188002347946167
  - 7.3856940269470215
start: 2023-11-01 14:51:27.904531
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
