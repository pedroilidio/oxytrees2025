active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 12:37:42.984156
estimator:
  call: semisupervised_forests.estimators.adss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: adss_bxt_gso
  params: {}
hash: f86bfe2d35d0dcf98954a8b115af30e75973240c6885cbf7ca2edef92d229542
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/f86bfe2_20231101T121042612259_adss_bxt_gso_ern.yml"
results:
  LL_average_precision:
  - 0.11755073734897781
  - 0.11904216194074933
  - 0.11824776124456182
  - 0.11212648542299664
  - 0.11707217540001573
  - 0.11935457392663087
  - 0.11865779362828048
  - 0.1125156848371946
  - 0.1172010941396867
  - 0.11893881827724695
  - 0.11827843107499672
  - 0.11201657035511642
  - 0.11712236665172569
  - 0.1193172983663681
  - 0.1185508411617553
  - 0.1125562471961105
  LL_balanced_accuracy:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_f1_macro:
  - 0.5869263150151246
  - 0.5861435721306022
  - 0.5864550390583527
  - 0.5880150750063559
  - 0.5867679904328182
  - 0.5863693085565117
  - 0.5866655249422846
  - 0.5880700084917458
  - 0.5870252315797547
  - 0.5862737524723205
  - 0.5866085416217844
  - 0.5881268637742644
  - 0.5865832349231027
  - 0.5863277483426732
  - 0.5864276751478756
  - 0.5882207775958614
  LL_f1_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_f1_weighted:
  - 0.9759390715472271
  - 0.9733263631338508
  - 0.9745797960748513
  - 0.9831593454996554
  - 0.9762422567124828
  - 0.9732889882645694
  - 0.9744183188027767
  - 0.9828144619281908
  - 0.9764412608576732
  - 0.9736066386792477
  - 0.9747478846466097
  - 0.9834233273191423
  - 0.9759470977012066
  - 0.9732743091898997
  - 0.9742211336307921
  - 0.9829683195491606
  LL_matthews_corrcoef:
  - 0.3141571461786937
  - 0.3132774763658292
  - 0.31357758539033465
  - 0.31455870316115747
  - 0.313786199868058
  - 0.313714688411654
  - 0.31401462921606976
  - 0.31474270783577457
  - 0.3142286546313658
  - 0.31345948930330475
  - 0.3138300346298245
  - 0.31471066812965903
  - 0.3135035878913886
  - 0.3136392339602798
  - 0.3136089385190437
  - 0.3149940759299084
  LL_precision_macro:
  - 0.9914174226320569
  - 0.9904824171765669
  - 0.9909314889574923
  - 0.9940029466148537
  - 0.9915274534459014
  - 0.9904673494240482
  - 0.9908719399972294
  - 0.9938791654306338
  - 0.991597393395671
  - 0.990582422518341
  - 0.9909909464206204
  - 0.9940969990606615
  - 0.9914224981038682
  - 0.9904623585075163
  - 0.9908025845776314
  - 0.9939336108611603
  LL_precision_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_precision_weighted:
  - 0.983161751742076
  - 0.9813666025288966
  - 0.982227803071867
  - 0.9881655493493736
  - 0.9833734027401535
  - 0.9813378626943587
  - 0.9821136246534958
  - 0.9879246670852959
  - 0.9835081426270568
  - 0.9815582642304476
  - 0.9823420130064394
  - 0.9883487021195555
  - 0.9831713676131173
  - 0.9813282819441631
  - 0.9819804478269578
  - 0.9880306406658245
  LL_recall_macro:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LL_recall_micro:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_recall_weighted:
  - 0.9828676726928632
  - 0.9810050301309826
  - 0.9818995141604455
  - 0.9880218825295256
  - 0.983086807111908
  - 0.9809751481647493
  - 0.9817810167081408
  - 0.987775012837224
  - 0.9832262562876637
  - 0.9812042432392052
  - 0.9820180116127504
  - 0.9882095034956748
  - 0.9828776333482743
  - 0.9809651875093381
  - 0.9816427696804518
  - 0.9878836355018367
  LL_roc_auc:
  - 0.5502092050209205
  - 0.5500235960358659
  - 0.5500736377025037
  - 0.5500741839762612
  - 0.5500794912559619
  - 0.5501648610456901
  - 0.5502194051682107
  - 0.5501453488372093
  - 0.5502136752136753
  - 0.550071530758226
  - 0.5501482213438735
  - 0.5501130369253956
  - 0.55
  - 0.5501412429378532
  - 0.5500968054211036
  - 0.5502199413489736
  LT_average_precision:
  - 0.02497888107791846
  - 0.03457337852782939
  - 0.014939246921324329
  - 0.03381093585146394
  - 0.03222712355993549
  - 0.026164184810365233
  - 0.01850124109019968
  - 0.03421557025630507
  - 0.030731958515497263
  - 0.028406464578469313
  - 0.014493763114051782
  - 0.03381610089353991
  - 0.0313696507653923
  - 0.040960477410690144
  - 0.017240681114387278
  - 0.03601224903868954
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5170824552384934
  - 0.5321841751568146
  - 0.5109687100308852
  - 0.4990964823646328
  - 0.5165440820060831
  - 0.5153724830323437
  - 0.518038444875339
  - 0.5065913506221307
  - 0.5192367014596916
  - 0.5086177709699051
  - 0.5150002627074066
  - 0.4998726035861615
  - 0.5240964861250007
  - 0.5193105776449006
  - 0.5161910809831519
  - 0.5056100898840225
  TL_average_precision:
  - 0.053187516667695695
  - 0.07315127027578391
  - 0.05863105547284349
  - 0.052599420304305235
  - 0.07559399505918972
  - 0.07952449550724164
  - 0.08428010962780265
  - 0.06108175456310977
  - 0.08764519994650746
  - 0.06673009450624327
  - 0.08453735018125189
  - 0.05445798872601666
  - 0.09236495417118282
  - 0.07201691713029723
  - 0.10205093891947924
  - 0.07900622169299851
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5503817054608903
  - 0.573724807525131
  - 0.5671225501042152
  - 0.559773514203218
  - 0.5682131568926123
  - 0.5682805740592844
  - 0.5749491203969604
  - 0.5686133512220468
  - 0.5784830309135875
  - 0.5697277148070382
  - 0.57876653794697
  - 0.5580183082997273
  - 0.5912949267427752
  - 0.5567553614612288
  - 0.582758604903275
  - 0.5733217895692971
  TT_average_precision:
  - 0.021119529577449923
  - 0.012725893174828359
  - 0.01291698888022987
  - 0.03282613074246577
  - 0.036413226188781754
  - 0.012952256898852772
  - 0.01577795815124722
  - 0.034708630895331175
  - 0.025112886137898624
  - 0.019247379881588013
  - 0.017161905144696458
  - 0.03436474208228533
  - 0.03242065233923026
  - 0.03703265630741552
  - 0.01917257210905481
  - 0.03475257436570417
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.51638256940445
  - 0.5227197557562652
  - 0.5115047371019363
  - 0.4978892086966708
  - 0.5298115148242434
  - 0.5216906313601857
  - 0.5398786749517869
  - 0.4982604484431524
  - 0.5189288635616319
  - 0.5005893407398195
  - 0.5332154998582235
  - 0.5046178039876439
  - 0.520650126675906
  - 0.5427486021739202
  - 0.5290021075781178
  - 0.5074424243233857
  fit_time:
  - 1503.7809376716614
  - 1599.8681075572968
  - 1463.967260837555
  - 1537.0797443389893
  - 1523.9791946411133
  - 1534.129878282547
  - 1587.8104839324951
  - 1516.1318566799164
  - 1589.9746341705322
  - 1539.4634418487549
  - 1569.0581016540527
  - 1532.911153793335
  - 1532.4057784080505
  - 1612.84316945076
  - 1568.2099902629852
  - 1528.8531277179718
  score_time:
  - 9.318718671798706
  - 7.317928791046143
  - 11.209884643554688
  - 9.086711406707764
  - 9.229220390319824
  - 9.447706460952759
  - 6.9916465282440186
  - 8.238239049911499
  - 7.8576436042785645
  - 8.653162717819214
  - 8.408710241317749
  - 9.253663301467896
  - 10.511682271957397
  - 7.255892038345337
  - 7.957698345184326
  - 8.74065113067627
start: 2023-11-01 12:10:42.612259
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
