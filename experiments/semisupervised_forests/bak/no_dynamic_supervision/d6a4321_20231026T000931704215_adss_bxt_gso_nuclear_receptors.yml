active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-26 00:09:46.823720
estimator:
  call: semisupervised_forests.estimators.adss_bxt_gso
  final_params:
    axis_decision_only: true
    bipartite_adapter: gmosa
    bootstrap: false
    ccp_alpha: 0.0
    criterion: squared_error_gso
    max_col_features: null
    max_depth: null
    max_features: 1.0
    max_leaf_nodes: null
    max_row_features: null
    max_samples: null
    min_col_weight_fraction_leaf: 0.0
    min_cols_leaf: 1
    min_cols_split: 1
    min_impurity_decrease: 0.0
    min_row_weight_fraction_leaf: 0.0
    min_rows_leaf: 1
    min_rows_split: 1
    min_samples_leaf: 1
    min_samples_split: 2
    min_weight_fraction_leaf: 0.0
    n_estimators: 100
    n_jobs: 3
    oob_score: false
    prediction_weights: null
    preprocess_X_targets: null
    random_state: 0
    ss_adapter: null
    supervision: 0.0
    unsupervised_criterion_cols: squared_error
    unsupervised_criterion_rows: squared_error
    update_supervision: null
    verbose: 0
    warm_start: false
  name: adss_bxt_gso
  params: {}
hash: d6a4321b4dd6785ee629538fea4096c6cb84a0fcab16e76eecbcccdc3d27ab0e
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/d6a4321_20231026T000931704215_adss_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9921531701192718
  - 1.0
  - 1.0
  - 0.9924242424242424
  - 0.981318111053451
  - 1.0
  - 1.0
  - 0.9836363636363636
  - 0.9838097647356439
  - 1.0
  - 1.0
  - 0.9843137254901961
  - 0.9939817043813192
  - 1.0
  - 1.0
  - 0.9935897435897436
  LL_balanced_accuracy:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_f1_macro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_f1_micro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_f1_weighted:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_precision_macro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_precision_micro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_precision_weighted:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_recall_macro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_recall_micro:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_recall_weighted:
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  - .nan
  - 1.0
  - 1.0
  - .nan
  LL_roc_auc:
  - 0.9996721225474767
  - 1.0
  - 1.0
  - 0.9996860873932698
  - 0.9993893958411073
  - 1.0
  - 1.0
  - 0.999443413729128
  - 0.9992680527916924
  - 1.0
  - 1.0
  - 0.999298245614035
  - 0.9997268117842469
  - 1.0
  - 1.0
  - 0.9997258771929824
  LT_average_precision:
  - 0.34931046980195585
  - 0.37798356250847726
  - 0.23554926726753347
  - 0.46092161042931434
  - 0.26447645836415723
  - 0.3348375357585884
  - 0.16595967936446837
  - 0.36814264900674953
  - 0.39747520353170507
  - 0.41652813895199536
  - 0.26060160822065587
  - 0.3958458208458209
  - 0.38883163887006145
  - 0.4556606654175689
  - 0.3580070733972407
  - 0.4032126621251021
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.7687915006640106
  - 0.7652282157676348
  - 0.796264367816092
  - 0.8137645616186389
  - 0.6592847769028872
  - 0.7379065040650408
  - 0.7558510638297873
  - 0.8751167133520075
  - 0.7716106965174129
  - 0.7525984482506222
  - 0.807531380753138
  - 0.7933552391383717
  - 0.7755974842767296
  - 0.806104523495828
  - 0.8932506887052342
  - 0.826555313483418
  TL_average_precision:
  - 0.3866597187249362
  - 0.4353021978021978
  - 0.5226936052720024
  - 0.44075539898852434
  - 0.42816502493921854
  - 0.23849206349206345
  - 0.3788570357676049
  - 0.38495118795791633
  - 0.05932942142374191
  - 0.12692307692307692
  - 0.1494149782767669
  - 0.15140437037854543
  - 0.31289914330218066
  - 0.30767195767195765
  - 0.3744834064406425
  - 0.33886252437185005
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7513782866836302
  - 0.7646211466436186
  - 0.8124018838304553
  - 0.7248038000826105
  - 0.5983287990672367
  - 0.5546061197916667
  - 0.6034188034188034
  - 0.5847367014167335
  - 0.43104032531345304
  - 0.34733988478481864
  - 0.4337231968810916
  - 0.47606470782436444
  - 0.6245652173913043
  - 0.5766400980993256
  - 0.6922175339896859
  - 0.5990425883129746
  TT_average_precision:
  - 0.04341736694677871
  - 0.22383973326172574
  - 0.11342443660944831
  - 0.3194444444444444
  - 0.22358578775128563
  - 0.26838365223458394
  - 0.3106362181489516
  - 0.18219732853353543
  - 0.11543593282723719
  - 0.08035339922132376
  - 0.017241379310344827
  - 0.21933850463262228
  - 0.061224489795918366
  - 0.250513695214156
  - 0.05811951614277196
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5561403508771929
  - 0.60625
  - 0.5442176870748299
  - 0.9090909090909091
  - 0.8052536231884058
  - 0.7298642533936651
  - 0.6635802469135803
  - 0.6475903614457832
  - 0.5876068376068375
  - 0.4797008547008548
  - 0.36363636363636365
  - 0.6516203703703703
  - 0.5185185185185186
  - 0.5854700854700854
  - 0.518581081081081
  - .nan
  fit_time:
  - 2.352074384689331
  - 2.7821969985961914
  - 2.823845624923706
  - 2.5820705890655518
  - 2.489173412322998
  - 2.712550163269043
  - 2.7062299251556396
  - 2.8140273094177246
  - 2.6791934967041016
  - 2.8416998386383057
  - 2.61043643951416
  - 2.5641279220581055
  - 2.7662079334259033
  - 2.8011972904205322
  - 2.817343235015869
  - 2.6212384700775146
  score_time:
  - 12.667465209960938
  - 12.244394302368164
  - 12.215590238571167
  - 12.508904218673706
  - 12.587085485458374
  - 12.319800853729248
  - 12.325595378875732
  - 12.264067888259888
  - 12.376976251602173
  - 12.177671670913696
  - 12.393028736114502
  - 12.49467396736145
  - 12.289148330688477
  - 12.229727506637573
  - 12.203863382339478
  - 12.437827587127686
start: 2023-10-26 00:09:31.704215
wrapper: null
