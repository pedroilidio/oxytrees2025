active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ern/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X1.txt
  - force_download: false
    path: datasets/ern/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/ern/X2.txt
  name: ern
  pairwise: true
  y:
    force_download: false
    path: datasets/ern/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/ern/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 08:52:38.259841
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_random
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_random
  params: {}
hash: d51bc6706c4a784ea98968238a034b3f23d0f3d5e1cb937c03bf60ed1096c4be
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/d51bc67_20231109T084220589746_ss_bxt_gso__md_random_ern.yml"
results:
  LL_average_precision:
  - 0.31353656196100715
  - 0.31491322818989576
  - 0.31451339867621414
  - 0.3097570286511837
  - 0.3136250126784575
  - 0.31484863709684474
  - 0.3145116172664404
  - 0.3096547693846675
  - 0.3132621338022503
  - 0.3150414660374782
  - 0.31437795628895954
  - 0.30984202453060977
  - 0.31331739628467553
  - 0.3151781817752083
  - 0.314375748423829
  - 0.31000705772215925
  LL_balanced_accuracy:
  - 0.6501046025104602
  - 0.6500707881075979
  - 0.6502209131075111
  - 0.6502225519287834
  - 0.6502384737678856
  - 0.6500235515779558
  - 0.6501706484641638
  - 0.6500726744186046
  - 0.6501068376068376
  - 0.6502145922746781
  - 0.650197628458498
  - 0.6503391107761869
  - 0.65
  - 0.6501883239171375
  - 0.6500484027105518
  - 0.6502932551319648
  LL_f1_macro:
  - 0.7275193926069903
  - 0.7271087069294292
  - 0.7274660636260619
  - 0.7286842093068728
  - 0.7277236583928407
  - 0.7270451446750492
  - 0.7273812772562879
  - 0.7284566849357615
  - 0.7275935014081982
  - 0.7273197351997661
  - 0.7274613394976701
  - 0.7288596941367762
  - 0.7273981949510296
  - 0.7272400400900014
  - 0.7272087945333534
  - 0.7287401741192439
  LL_f1_micro:
  - 0.9866726430599133
  - 0.9852283480253
  - 0.9859284275388079
  - 0.990688075206383
  - 0.9868519348573136
  - 0.9851984660590667
  - 0.9858296796618873
  - 0.9904905794525418
  - 0.9869515414114248
  - 0.9853877185118781
  - 0.9860173006280365
  - 0.9908361970217641
  - 0.9866826037153245
  - 0.9851984660590667
  - 0.9857210569972745
  - 0.9905794525417704
  LL_f1_weighted:
  - 0.9831311193071838
  - 0.9813079114445424
  - 0.9821937631376715
  - 0.9882053374729435
  - 0.9833595330548701
  - 0.9812693849347093
  - 0.9820683237177078
  - 0.9879539773513982
  - 0.9834832322638639
  - 0.9815114670117053
  - 0.9823055195241739
  - 0.98839386921363
  - 0.983142044289331
  - 0.9812722708075634
  - 0.981929201166364
  - 0.9880688019335419
  LL_matthews_corrcoef:
  - 0.544228998578662
  - 0.5437644007978656
  - 0.5442319656676985
  - 0.5455603979568205
  - 0.5445216414850522
  - 0.543670476459642
  - 0.5441133317804158
  - 0.545233392723921
  - 0.5443108462149844
  - 0.5440693952700054
  - 0.5442146173582417
  - 0.545813124075928
  - 0.5440421377879532
  - 0.5439689126094267
  - 0.5438615116787227
  - 0.545658601707659
  LL_precision_macro:
  - 0.9932980034261327
  - 0.9925670866788961
  - 0.9929214353838818
  - 0.9953253422959856
  - 0.9933886284409184
  - 0.992551975781391
  - 0.9928714779636768
  - 0.9952258192454514
  - 0.9934390432021476
  - 0.9926477221470456
  - 0.9929664216173256
  - 0.9953999742239935
  - 0.993303079481477
  - 0.9925519011197209
  - 0.9928165487640093
  - 0.9952705784370104
  LL_precision_micro:
  - 0.9866726430599133
  - 0.9852283480253
  - 0.9859284275388079
  - 0.990688075206383
  - 0.9868519348573136
  - 0.9851984660590667
  - 0.9858296796618873
  - 0.9904905794525418
  - 0.9869515414114248
  - 0.9853877185118781
  - 0.9860173006280365
  - 0.9908361970217641
  - 0.9866826037153245
  - 0.9851984660590667
  - 0.9857210569972745
  - 0.9905794525417704
  LL_precision_weighted:
  - 0.9868512828610158
  - 0.985447940842775
  - 0.9861276406086417
  - 0.9907751353283345
  - 0.9870257883451963
  - 0.9854189504255959
  - 0.9860317065434712
  - 0.9905813788376708
  - 0.9871227621575813
  - 0.9856025856190105
  - 0.9862139974521046
  - 0.9909205044815764
  - 0.9868609748041887
  - 0.9854189526358105
  - 0.9859262011787977
  - 0.9906685600223385
  LL_recall_macro:
  - 0.6501046025104602
  - 0.6500707881075979
  - 0.6502209131075111
  - 0.6502225519287834
  - 0.6502384737678856
  - 0.6500235515779558
  - 0.6501706484641638
  - 0.6500726744186046
  - 0.6501068376068376
  - 0.6502145922746781
  - 0.650197628458498
  - 0.6503391107761869
  - 0.65
  - 0.6501883239171375
  - 0.6500484027105518
  - 0.6502932551319648
  LL_recall_micro:
  - 0.9866726430599133
  - 0.9852283480253
  - 0.9859284275388079
  - 0.990688075206383
  - 0.9868519348573136
  - 0.9851984660590667
  - 0.9858296796618873
  - 0.9904905794525418
  - 0.9869515414114248
  - 0.9853877185118781
  - 0.9860173006280365
  - 0.9908361970217641
  - 0.9866826037153245
  - 0.9851984660590667
  - 0.9857210569972745
  - 0.9905794525417704
  LL_recall_weighted:
  - 0.9866726430599133
  - 0.9852283480253
  - 0.9859284275388079
  - 0.990688075206383
  - 0.9868519348573136
  - 0.9851984660590667
  - 0.9858296796618873
  - 0.9904905794525418
  - 0.9869515414114248
  - 0.9853877185118781
  - 0.9860173006280365
  - 0.9908361970217641
  - 0.9866826037153245
  - 0.9851984660590667
  - 0.9857210569972745
  - 0.9905794525417704
  LL_roc_auc:
  - 0.6501046025104602
  - 0.6500707881075979
  - 0.6502209131075111
  - 0.6502225519287834
  - 0.6502384737678856
  - 0.6500235515779558
  - 0.6501706484641638
  - 0.6500726744186046
  - 0.6501068376068376
  - 0.6502145922746781
  - 0.650197628458498
  - 0.6503391107761869
  - 0.65
  - 0.6501883239171375
  - 0.6500484027105518
  - 0.6502932551319648
  LT_average_precision:
  - 0.03815149759710488
  - 0.13336131296276643
  - 0.024685133851536905
  - 0.034856447163782805
  - 0.04987973260622017
  - 0.11359115122718685
  - 0.025159113794512536
  - 0.03497746068119671
  - 0.03245352200446097
  - 0.05718173544151284
  - 0.0232544841204688
  - 0.03516976848506524
  - 0.05150665379342137
  - 0.08780981970029018
  - 0.016554394941838788
  - 0.035584008261881656
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5524980642808084
  - 0.570472613797465
  - 0.5502920872255769
  - 0.5020538832229445
  - 0.5702852914564541
  - 0.5660837722473812
  - 0.5570902645739424
  - 0.5042169723550533
  - 0.5419974482637634
  - 0.5580531227444694
  - 0.5461169276911806
  - 0.5049953770458846
  - 0.5741641725788498
  - 0.5635568191865137
  - 0.5318297916613609
  - 0.5008492485606897
  TL_average_precision:
  - 0.23642285608222544
  - 0.23183355679817566
  - 0.2257950190130615
  - 0.17890196162211366
  - 0.27219092122279126
  - 0.22074009923741847
  - 0.21984310322683706
  - 0.16158812730756206
  - 0.23478064443539914
  - 0.26499514055588747
  - 0.21836572722362224
  - 0.15641622554360907
  - 0.24367827502690562
  - 0.264497929805793
  - 0.24988208447296995
  - 0.12868405164750116
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7372841321107274
  - 0.6960159265198486
  - 0.7078485107620922
  - 0.6580009138077426
  - 0.7373648134044174
  - 0.7005028908199012
  - 0.6900426450452144
  - 0.6837117234092659
  - 0.7328524165272643
  - 0.7353031181779786
  - 0.7081574362387577
  - 0.677641233820527
  - 0.7189159576727263
  - 0.7325323206109331
  - 0.7199219121966585
  - 0.6593753775460858
  TT_average_precision:
  - 0.03199539892948864
  - 0.05611105280327226
  - 0.04155377853122762
  - 0.03319261470679853
  - 0.03136704316442297
  - 0.03254678140285056
  - 0.025255237491457763
  - 0.03595496225795807
  - 0.03459224492349527
  - 0.02601752907466207
  - 0.02250912991105391
  - 0.035364488036157105
  - 0.028034283040067654
  - 0.05400296175274185
  - 0.025483283123661753
  - 0.03586906828787492
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5414028485818516
  - 0.5672893734519632
  - 0.6147863173192663
  - 0.506595436076921
  - 0.5614875671783796
  - 0.5665261989765377
  - 0.5716723077257583
  - 0.5038690907144013
  - 0.5537823758162741
  - 0.5805275739612265
  - 0.546492713531683
  - 0.5180513588567506
  - 0.548617240505026
  - 0.5863114359800597
  - 0.6048341585644453
  - 0.5170228709947243
  fit_time:
  - 569.0899727344513
  - 605.9655892848969
  - 568.114049911499
  - 477.9413788318634
  - 549.4363853931427
  - 613.4256200790405
  - 608.0799806118011
  - 475.47561383247375
  - 565.3615164756775
  - 574.1853384971619
  - 601.9016695022583
  - 454.81347942352295
  - 579.1775677204132
  - 575.3284411430359
  - 584.4851195812225
  - 446.5649380683899
  score_time:
  - 5.059710502624512
  - 4.111928462982178
  - 4.606133699417114
  - 6.749614477157593
  - 6.971354961395264
  - 4.012279748916626
  - 4.176855802536011
  - 6.891639709472656
  - 5.036999464035034
  - 4.417971849441528
  - 3.9183313846588135
  - 6.961841821670532
  - 4.136056423187256
  - 4.464666843414307
  - 4.100078821182251
  - 6.8653693199157715
start: 2023-11-09 08:42:20.589746
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
