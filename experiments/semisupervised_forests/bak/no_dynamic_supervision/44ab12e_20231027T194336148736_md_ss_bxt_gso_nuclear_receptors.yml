active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - precision_weighted
    - recall_weighted
    - precision_micro
    - recall_macro
    - matthews_corrcoef
    - f1_micro
    - precision_macro
    - roc_auc
    - f1_weighted
    - balanced_accuracy
    - average_precision
    - recall_micro
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-10-27 19:43:37.130512
estimator:
  call: semisupervised_forests.estimators.md_ss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.5
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: 44ab12e2971e73bc7ad89616543d35ca7d0d7524c3da7a2282986d4214c9f396
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/44ab12e_20231027T194336148736_md_ss_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.5719829877724615
  - 0.5289473684210526
  - 0.5691294632244569
  - 0.5431237701256735
  - 0.5342691298766534
  - 0.5362041467304625
  - 0.5378690629011553
  - 0.5142553210589154
  - 0.5610569679849341
  - 0.5275
  - 0.5492682926829269
  - 0.5526648599819332
  - 0.5428763440860215
  - 0.53125
  - 0.559570070276974
  - 0.5794954567192732
  LL_balanced_accuracy:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_f1_macro:
  - .nan
  - 0.8257679963319577
  - .nan
  - .nan
  - .nan
  - 0.8345578231292516
  - 0.8320251854407452
  - .nan
  - .nan
  - 0.8261625380269448
  - .nan
  - .nan
  - .nan
  - 0.825136612021858
  - .nan
  - .nan
  LL_f1_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_f1_weighted:
  - .nan
  - 0.9664470667728469
  - .nan
  - .nan
  - .nan
  - 0.9756935195130684
  - 0.9703567180846717
  - .nan
  - .nan
  - 0.9681138635375923
  - .nan
  - .nan
  - .nan
  - 0.9637978142076503
  - .nan
  - .nan
  LL_matthews_corrcoef:
  - .nan
  - 0.6964875095423532
  - .nan
  - .nan
  - .nan
  - 0.7099704764350107
  - 0.7061733064809798
  - .nan
  - .nan
  - 0.6970374326528528
  - .nan
  - .nan
  - .nan
  - 0.6956083436402524
  - .nan
  - .nan
  LL_precision_macro:
  - .nan
  - 0.9850948509485095
  - .nan
  - .nan
  - .nan
  - 0.9892328398384926
  - 0.9868073878627968
  - .nan
  - .nan
  - 0.9858611825192802
  - .nan
  - .nan
  - .nan
  - 0.9838709677419355
  - .nan
  - .nan
  LL_precision_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_precision_weighted:
  - .nan
  - 0.9719155612608756
  - .nan
  - .nan
  - .nan
  - 0.979400722533116
  - 0.9750034717400361
  - .nan
  - .nan
  - 0.9732776349614396
  - .nan
  - .nan
  - .nan
  - 0.9697580645161291
  - .nan
  - .nan
  LL_recall_macro:
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.7575757575757576
  - 0.7560975609756098
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  - .nan
  - 0.75
  - .nan
  - .nan
  LL_recall_micro:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_recall_weighted:
  - .nan
  - 0.9710526315789474
  - .nan
  - .nan
  - .nan
  - 0.9789473684210527
  - 0.9743260590500642
  - .nan
  - .nan
  - 0.9725
  - .nan
  - .nan
  - .nan
  - 0.96875
  - .nan
  - .nan
  LL_roc_auc:
  - 0.7764793830657853
  - 0.75
  - 0.7685185185185186
  - 0.7541938724259166
  - 0.7553512670036298
  - 0.7575757575757576
  - 0.7560975609756098
  - 0.7483920841063698
  - 0.7695853061597931
  - 0.75
  - 0.76
  - 0.7650877192982455
  - 0.7564909520062942
  - 0.75
  - 0.7627118644067796
  - 0.7746271929824562
  LT_average_precision:
  - 0.21938361054150526
  - 0.23028430743404799
  - 0.22415906545078557
  - 0.28275523025069305
  - 0.17468439617562423
  - 0.1836612140043712
  - 0.12683310841205578
  - 0.1731484889379626
  - 0.29993894993894993
  - 0.26269841269841265
  - 0.17225886483102415
  - 0.11333044431516419
  - 0.3076435909769243
  - 0.3264369889369889
  - 0.23748663831868164
  - 0.39796496008463556
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.6782204515272244
  - 0.6593360995850622
  - 0.728735632183908
  - 0.7279276517473943
  - 0.6328740157480315
  - 0.6045731707317072
  - 0.5829787234042552
  - 0.569327731092437
  - 0.699471393034826
  - 0.6388522910262041
  - 0.6975493126120742
  - 0.5690032858707558
  - 0.6441509433962266
  - 0.6473429951690822
  - 0.7348484848484848
  - 0.8357540547083031
  TL_average_precision:
  - 0.22719638242894055
  - 0.21362355593124827
  - 0.2954341892985856
  - 0.27986406848195466
  - 0.40357142857142847
  - 0.24548872180451128
  - 0.34608049784201544
  - 0.19702497763893895
  - 0.05416666666666667
  - 0.12691441441441442
  - 0.18021303824149354
  - 0.06907836305253807
  - 0.31892857142857145
  - 0.17467948717948717
  - 0.0836638031759983
  - 0.15538183586964077
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.626802374893978
  - 0.6267646211466437
  - 0.7367870225013082
  - 0.5907682775712515
  - 0.6228786112190698
  - 0.5433756510416666
  - 0.6083333333333334
  - 0.520449077786688
  - 0.2973568281938326
  - 0.4534056252117926
  - 0.5227826510721247
  - 0.527236711786068
  - 0.6821739130434782
  - 0.5613120784794603
  - 0.5675105485232068
  - 0.6421261142291185
  TT_average_precision:
  - 0.030612244897959183
  - 0.08622448979591837
  - 0.16959379905808478
  - 0.15172975172975173
  - 0.18381519274376415
  - 0.17591273195668802
  - 0.3089439447424928
  - 0.0916037087912088
  - 0.12962962962962965
  - 0.07895807895807896
  - 0.02631578947368421
  - 0.18667706167706166
  - 0.031261222437693026
  - 0.28293650793650793
  - 0.04901059085841695
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.3526315789473684
  - 0.5083333333333333
  - 0.5680272108843537
  - 0.7556818181818181
  - 0.7726449275362318
  - 0.5782805429864253
  - 0.6882716049382718
  - 0.4450301204819277
  - 0.6784188034188035
  - 0.5128205128205128
  - 0.6493506493506493
  - 0.6296296296296295
  - 0.38065843621399176
  - 0.5844017094017093
  - 0.44594594594594594
  - .nan
  fit_time:
  - 0.5277614593505859
  - 0.4790761470794678
  - 0.5652525424957275
  - 0.6486532688140869
  - 0.4864211082458496
  - 0.47642946243286133
  - 0.5267341136932373
  - 0.6477634906768799
  - 0.6409657001495361
  - 0.6297285556793213
  - 0.5157644748687744
  - 0.5207710266113281
  - 0.600208044052124
  - 0.5736861228942871
  - 0.7410750389099121
  - 0.6997013092041016
  score_time:
  - 0.17583203315734863
  - 0.1648576259613037
  - 0.18563413619995117
  - 0.20689153671264648
  - 0.15430140495300293
  - 0.1773383617401123
  - 0.18916964530944824
  - 0.20700478553771973
  - 0.20606064796447754
  - 0.23137855529785156
  - 0.16887855529785156
  - 0.17567896842956543
  - 0.1879136562347412
  - 0.1821730136871338
  - 0.2054438591003418
  - 0.205277681350708
start: 2023-10-27 19:43:36.148736
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
