active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/lncRNA/normalized_lncrna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/lncRNA/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: lncrna
  pairwise: true
  y:
    force_download: false
    path: datasets/lncRNA/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: semisupervised_forests/runs
end: 2023-11-01 16:07:47.085384
estimator:
  call: semisupervised_forests.estimators.md_ss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: 64984dcc7c59548e3c8a820a8e59a143998d1f823388f6173ec20748f8cfe52f
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/64984dc_20231101T155714415713_md_ss_bxt_gso_lncrna.yml"
results:
  LL_average_precision:
  - 0.25361601458394806
  - 0.26951417828829816
  - 0.26376432189848026
  - 0.2731209993507196
  - 0.252402582994853
  - 0.26896182343655856
  - 0.26326863984584675
  - 0.2723801621492162
  - 0.25009389627249023
  - 0.26608600979858466
  - 0.2604985530593602
  - 0.2698547467800432
  - 0.2501605836412334
  - 0.2658317109783227
  - 0.2600831004629528
  - 0.2694916013308667
  LL_balanced_accuracy:
  - 0.5500139871318387
  - 0.5500108640544651
  - 0.55
  - 0.5500035350678734
  - 0.5500040277106493
  - 0.5500108995785497
  - 0.550003748406927
  - 0.5500071007597813
  - 0.550006120700208
  - 0.55
  - 0.5500152195418918
  - 0.550005392385951
  - 0.5500020392348791
  - 0.5500055397569893
  - 0.5500076289288984
  - 0.5500036025650263
  LL_f1_macro:
  - 0.5485577335833741
  - 0.5436576126504203
  - 0.5454150487320866
  - 0.5425161856080872
  - 0.54890455026083
  - 0.54382947352955
  - 0.5455764443546783
  - 0.5427557335156992
  - 0.5496099576507355
  - 0.5446972221380753
  - 0.5464551593427125
  - 0.5435393035486149
  - 0.5495805966447076
  - 0.5447884274615664
  - 0.5465657399080635
  - 0.5436482764343024
  LL_f1_micro:
  - 0.8464119596797295
  - 0.830507549820632
  - 0.8362356781015199
  - 0.8268860707850271
  - 0.8476054724264456
  - 0.8310599757205407
  - 0.8367388569680073
  - 0.8276340393703465
  - 0.849918345127926
  - 0.8339139902014153
  - 0.8395318860244233
  - 0.8301560379918589
  - 0.8498434948285247
  - 0.834179368535656
  - 0.839932157394844
  - 0.8305156037991859
  LL_f1_weighted:
  - 0.7900922521088651
  - 0.7691845851879087
  - 0.7766914837469522
  - 0.7644462451155916
  - 0.7916655478084957
  - 0.7699078663790505
  - 0.7773532902638557
  - 0.7654247375396624
  - 0.7947225834389798
  - 0.7736448583551445
  - 0.7810273512895323
  - 0.7687229171556793
  - 0.7946225881268913
  - 0.7739944498837722
  - 0.781551839466814
  - 0.7691930671141832
  LL_matthews_corrcoef:
  - 0.29051344385696615
  - 0.2876513973121021
  - 0.2886521418719513
  - 0.28697541531982573
  - 0.29069716179505783
  - 0.2877512431434439
  - 0.28875332203449805
  - 0.2871210521764701
  - 0.2911145063872366
  - 0.28823452513285897
  - 0.2892874849905674
  - 0.2875722425931482
  - 0.29108936912033206
  - 0.2882982041465815
  - 0.2893373401846748
  - 0.28763206075509706
  LL_precision_macro:
  - 0.9218722896414868
  - 0.9136267586053495
  - 0.9166002950363255
  - 0.9117453340358856
  - 0.9224901660156928
  - 0.9139136599639961
  - 0.9168611536250753
  - 0.9121339637291331
  - 0.9236864139949761
  - 0.9153957073928234
  - 0.9183089154595879
  - 0.9134443845164502
  - 0.9236478257259113
  - 0.9155332335080276
  - 0.9185166254541436
  - 0.913631209204558
  LL_precision_micro:
  - 0.8464119596797294
  - 0.8305075498206321
  - 0.8362356781015198
  - 0.8268860707850271
  - 0.8476054724264455
  - 0.8310599757205407
  - 0.8367388569680073
  - 0.8276340393703464
  - 0.849918345127926
  - 0.8339139902014153
  - 0.8395318860244233
  - 0.8301560379918589
  - 0.8498434948285247
  - 0.834179368535656
  - 0.839932157394844
  - 0.8305156037991859
  LL_precision_weighted:
  - 0.8704109235370768
  - 0.8597867744484586
  - 0.8635514703613387
  - 0.8574422947782326
  - 0.8712296214911318
  - 0.8601468324721653
  - 0.8638855431470702
  - 0.8579242668674423
  - 0.8728248836816386
  - 0.862017168943331
  - 0.865749514554062
  - 0.8595579353274174
  - 0.8727730461310058
  - 0.8621920336505562
  - 0.8660178933383302
  - 0.8597919285163057
  LL_recall_macro:
  - 0.5500139871318387
  - 0.5500108640544651
  - 0.55
  - 0.5500035350678734
  - 0.5500040277106493
  - 0.5500108995785497
  - 0.550003748406927
  - 0.5500071007597813
  - 0.550006120700208
  - 0.55
  - 0.5500152195418918
  - 0.550005392385951
  - 0.5500020392348791
  - 0.5500055397569893
  - 0.5500076289288984
  - 0.5500036025650263
  LL_recall_micro:
  - 0.8464119596797294
  - 0.8305075498206321
  - 0.8362356781015198
  - 0.8268860707850271
  - 0.8476054724264455
  - 0.8310599757205407
  - 0.8367388569680073
  - 0.8276340393703464
  - 0.849918345127926
  - 0.8339139902014153
  - 0.8395318860244233
  - 0.8301560379918589
  - 0.8498434948285247
  - 0.834179368535656
  - 0.839932157394844
  - 0.8305156037991859
  LL_recall_weighted:
  - 0.8464119596797294
  - 0.8305075498206321
  - 0.8362356781015198
  - 0.8268860707850271
  - 0.8476054724264455
  - 0.8310599757205407
  - 0.8367388569680073
  - 0.8276340393703464
  - 0.849918345127926
  - 0.8339139902014153
  - 0.8395318860244233
  - 0.8301560379918589
  - 0.8498434948285247
  - 0.834179368535656
  - 0.839932157394844
  - 0.8305156037991859
  LL_roc_auc:
  - 0.5500139871318387
  - 0.5500108640544651
  - 0.55
  - 0.5500035350678734
  - 0.5500040277106493
  - 0.5500108995785497
  - 0.550003748406927
  - 0.5500071007597813
  - 0.550006120700208
  - 0.55
  - 0.5500152195418918
  - 0.550005392385951
  - 0.5500020392348791
  - 0.5500055397569893
  - 0.5500076289288984
  - 0.5500036025650263
  LT_average_precision:
  - 0.2809455392177174
  - 0.2383842955438073
  - 0.2863105576378784
  - 0.1805809707350532
  - 0.2887414983879551
  - 0.22427464505586125
  - 0.30016977282100543
  - 0.1813706701641453
  - 0.2844602874431398
  - 0.23173326502426667
  - 0.2724743468279886
  - 0.17394458533023677
  - 0.28340571123839964
  - 0.2224693426223935
  - 0.2794112590778294
  - 0.17963841323943308
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5994595917429056
  - 0.6077472433404636
  - 0.6337181878828732
  - 0.5525315671029055
  - 0.60490739443652
  - 0.5916680557221232
  - 0.6477100847968271
  - 0.5493970320209278
  - 0.6061646840236519
  - 0.6057821418972699
  - 0.6261167290935308
  - 0.5452927227931453
  - 0.6055023303236219
  - 0.5935811169022962
  - 0.6347614980990866
  - 0.5493301538664624
  TL_average_precision:
  - 0.4686878299366499
  - 0.48926848656226757
  - 0.49006955100369126
  - 0.5128324817585004
  - 0.4692496194871295
  - 0.4755346360264209
  - 0.47098444748689205
  - 0.5020940605657281
  - 0.45726893354063325
  - 0.4683503225033089
  - 0.4575656180107933
  - 0.5024032236688885
  - 0.49586471260952536
  - 0.5058203349418936
  - 0.4979221240869437
  - 0.5293946905736123
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.7771948451540216
  - 0.7781484603745259
  - 0.7853698112727401
  - 0.796570075960282
  - 0.7697820663266541
  - 0.7671403942274637
  - 0.7658532835309424
  - 0.7816125153981176
  - 0.7526641829907507
  - 0.7562171180022333
  - 0.753017102248051
  - 0.7700477949334297
  - 0.780348031654499
  - 0.7762334028848422
  - 0.7751022368901054
  - 0.7866138850005686
  TT_average_precision:
  - 0.27450152084599994
  - 0.2291453394325156
  - 0.2579393975585124
  - 0.1564246093426555
  - 0.2669485142823242
  - 0.21931377486017872
  - 0.28355008554060884
  - 0.15678913343793346
  - 0.2783067959188886
  - 0.23416539315134877
  - 0.26395385713514175
  - 0.16618418763403997
  - 0.28826587845412915
  - 0.22877146957343653
  - 0.26033439674680947
  - 0.1770961152081651
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5904240370548512
  - 0.605273470700622
  - 0.607686007567516
  - 0.5276020655030238
  - 0.5865756529589927
  - 0.5932731252758134
  - 0.6292816508445825
  - 0.518408221034323
  - 0.5899266890675583
  - 0.598024147506133
  - 0.6049000417304214
  - 0.5223411284515306
  - 0.5929921129601923
  - 0.5959853203125793
  - 0.6044109938546027
  - 0.5394883480435365
  fit_time:
  - 560.2632582187653
  - 611.0500881671906
  - 601.0248589515686
  - 595.1139166355133
  - 564.2801246643066
  - 622.8338270187378
  - 627.000571012497
  - 592.7551236152649
  - 578.5038113594055
  - 601.6097736358643
  - 607.8179354667664
  - 599.2058639526367
  - 574.7888195514679
  - 616.8198668956757
  - 595.6830909252167
  - 598.8173158168793
  score_time:
  - 8.541315078735352
  - 5.406971454620361
  - 6.086469650268555
  - 6.1553943157196045
  - 8.084140062332153
  - 5.576181888580322
  - 5.458576202392578
  - 6.171922922134399
  - 7.172204971313477
  - 5.926560163497925
  - 5.294049024581909
  - 5.956833600997925
  - 6.972300291061401
  - 5.020280122756958
  - 5.7932374477386475
  - 5.454061508178711
start: 2023-11-01 15:57:14.415713
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
