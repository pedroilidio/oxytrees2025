active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 11:41:50.695669
estimator:
  call: semisupervised_forests.estimators.md_ss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: md_ss_bxt_gso
  params: {}
hash: c4f510636b8c8f342833f5bdca2aaaa5024425927af0311a9397a3a0b224f56f
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/c4f5106_20231101T114149938440_md_ss_bxt_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.1742690058479532
  - 0.16495215311004785
  - 0.18996339086197878
  - 0.16939466182084922
  - 0.1652545999144202
  - 0.15937001594896333
  - 0.1681643132220796
  - 0.16370054848873847
  - 0.1836440677966102
  - 0.16238636363636363
  - 0.17365853658536584
  - 0.16347270615563297
  - 0.21141129032258066
  - 0.15625
  - 0.1663290615957007
  - 0.16585365853658537
  LL_balanced_accuracy:
  - 0.5555555555555556
  - 0.5568181818181818
  - .nan
  - .nan
  - .nan
  - 0.5606060606060606
  - 0.5609756097560976
  - 0.5568181818181818
  - .nan
  - 0.5568181818181818
  - .nan
  - .nan
  - .nan
  - 0.55
  - 0.5508474576271186
  - 0.55
  LL_f1_macro:
  - 0.5835616438356165
  - 0.5887845280872377
  - .nan
  - .nan
  - .nan
  - 0.5983306300231452
  - 0.5967908902691512
  - 0.5891183511177831
  - .nan
  - 0.589468282477401
  - .nan
  - .nan
  - .nan
  - 0.5763459841129744
  - 0.5754822954822956
  - 0.5737553424974009
  LL_f1_micro:
  - 0.9368421052631579
  - 0.9486842105263158
  - .nan
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - 0.9499358151476252
  - .nan
  - 0.95125
  - .nan
  - .nan
  - .nan
  - 0.94375
  - 0.9353658536585366
  - 0.9341463414634147
  LL_f1_weighted:
  - 0.9126171593366978
  - 0.9289428777342988
  - .nan
  - .nan
  - .nan
  - 0.9472614236836829
  - 0.936253677672442
  - 0.9306592656994557
  - .nan
  - 0.9324624008210634
  - .nan
  - .nan
  - .nan
  - 0.9215578111209181
  - 0.9101025045415289
  - 0.9083358455162465
  LL_matthews_corrcoef:
  - 0.32254879433564765
  - 0.32827793983094694
  - .nan
  - .nan
  - .nan
  - 0.3414124337158552
  - 0.34099716973523675
  - 0.32849733690299654
  - .nan
  - 0.32872747005868486
  - .nan
  - .nan
  - .nan
  - 0.30714755841697555
  - 0.30833991284483897
  - 0.3055586578156367
  LL_precision_macro:
  - 0.9681697612732095
  - 0.9741721854304636
  - .nan
  - .nan
  - .nan
  - 0.9808201058201058
  - 0.9767441860465116
  - 0.9748062015503876
  - .nan
  - 0.9754716981132076
  - .nan
  - .nan
  - .nan
  - 0.9716981132075472
  - 0.9674447174447174
  - 0.9668304668304668
  LL_precision_micro:
  - 0.9368421052631579
  - 0.9486842105263158
  - .nan
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - 0.9499358151476252
  - .nan
  - 0.95125
  - .nan
  - .nan
  - .nan
  - 0.94375
  - 0.9353658536585366
  - 0.9341463414634147
  LL_precision_weighted:
  - 0.9408627669970683
  - 0.9513349599163472
  - .nan
  - .nan
  - .nan
  - 0.9633058340295182
  - 0.9559363525091801
  - 0.9524584291130549
  - .nan
  - 0.9536415094339623
  - .nan
  - .nan
  - .nan
  - 0.9469339622641509
  - 0.9395742194522682
  - 0.9385150116857434
  LL_recall_macro:
  - 0.5555555555555556
  - 0.5568181818181818
  - .nan
  - .nan
  - .nan
  - 0.5606060606060606
  - 0.5609756097560976
  - 0.5568181818181818
  - .nan
  - 0.5568181818181818
  - .nan
  - .nan
  - .nan
  - 0.55
  - 0.5508474576271186
  - 0.55
  LL_recall_micro:
  - 0.9368421052631579
  - 0.9486842105263158
  - .nan
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - 0.9499358151476252
  - .nan
  - 0.95125
  - .nan
  - .nan
  - .nan
  - 0.94375
  - 0.9353658536585366
  - 0.9341463414634147
  LL_recall_weighted:
  - 0.9368421052631579
  - 0.9486842105263158
  - .nan
  - .nan
  - .nan
  - 0.9618421052631579
  - 0.9537869062901155
  - 0.9499358151476252
  - .nan
  - 0.95125
  - .nan
  - .nan
  - .nan
  - 0.94375
  - 0.9353658536585366
  - 0.9341463414634147
  LL_roc_auc:
  - 0.5555555555555556
  - 0.5568181818181818
  - 0.5648148148148148
  - 0.5539176293319941
  - 0.560348044370569
  - 0.5606060606060606
  - 0.5609756097560976
  - 0.5568181818181818
  - 0.559322033898305
  - 0.5568181818181818
  - 0.56
  - 0.5493969298245615
  - 0.5725806451612904
  - 0.55
  - 0.5508474576271186
  - 0.55
  LT_average_precision:
  - 0.18220551378446115
  - 0.12280701754385964
  - 0.0633468286099865
  - 0.13945922498554078
  - 0.09441216678058784
  - 0.07518796992481203
  - 0.05008996851102114
  - 0.139451192082771
  - 0.21269841269841266
  - 0.09642857142857143
  - 0.25848595848595846
  - 0.05664335664335665
  - 0.12521645021645023
  - 0.14955908289241623
  - 0.15413105413105413
  - 0.0909502262443439
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.549402390438247
  - 0.5630705394190871
  - 0.49942528735632186
  - 0.6362660944206009
  - 0.5623359580052494
  - 0.4817073170731707
  - 0.5102836879432624
  - 0.5805322128851542
  - 0.601523631840796
  - 0.48023715415019763
  - 0.6309025702331141
  - 0.5206279664110989
  - 0.5270440251572327
  - 0.5748060313277704
  - 0.5296143250688705
  - 0.5098039215686274
  TL_average_precision:
  - 0.14047619047619048
  - 0.04642857142857143
  - 0.3062717770034843
  - 0.1411536972512582
  - 0.18387096774193548
  - 0.2
  - 0.16695702671312426
  - 0.16751541141785045
  - 0.05416666666666667
  - 0.12692307692307692
  - 0.07317073170731707
  - 0.052845528455284556
  - 0.3041666666666667
  - 0.029166666666666667
  - 0.036585365853658534
  - 0.08317698561601
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5432569974554707
  - 0.4850187265917603
  - 0.6334379905808476
  - 0.5684634448574968
  - 0.5373105324523902
  - 0.553955078125
  - 0.5392450142450143
  - 0.5332130446404704
  - 0.460352422907489
  - 0.5221958658082005
  - 0.4583333333333333
  - 0.463519313304721
  - 0.6269565217391305
  - 0.47639484978540775
  - 0.47890295358649787
  - 0.5554638494552657
  TT_average_precision:
  - 0.030612244897959183
  - 0.08163265306122448
  - 0.07692307692307693
  - 0.3443223443223443
  - 0.061224489795918366
  - 0.1326530612244898
  - 0.14346764346764349
  - 0.08791208791208792
  - 0.0765542328042328
  - 0.07142857142857142
  - 0.01282051282051282
  - 0.26556776556776557
  - 0.03571428571428571
  - 0.07142857142857142
  - 0.05128205128205128
  - -0.0
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.4789473684210526
  - 0.4277777777777778
  - 0.4642857142857143
  - 0.8219696969696969
  - 0.47282608695652173
  - 0.4764705882352941
  - 0.5580246913580247
  - 0.45783132530120485
  - 0.5395299145299145
  - 0.48717948717948717
  - 0.4155844155844156
  - 0.5555555555555555
  - 0.41358024691358025
  - 0.46153846153846156
  - 0.4527027027027027
  - .nan
  fit_time:
  - 0.44820594787597656
  - 0.4799332618713379
  - 0.4539048671722412
  - 0.46465158462524414
  - 0.4157721996307373
  - 0.4080514907836914
  - 0.4268202781677246
  - 0.4407355785369873
  - 0.4194772243499756
  - 0.45230889320373535
  - 0.46701574325561523
  - 0.4395732879638672
  - 0.44531965255737305
  - 0.4526338577270508
  - 0.508228063583374
  - 0.4474341869354248
  score_time:
  - 0.2077014446258545
  - 0.21001529693603516
  - 0.21117329597473145
  - 0.18557476997375488
  - 0.1852717399597168
  - 0.21025753021240234
  - 0.2147057056427002
  - 0.2030792236328125
  - 0.17681527137756348
  - 0.2039024829864502
  - 0.17528128623962402
  - 0.1632213592529297
  - 0.19939565658569336
  - 0.1644420623779297
  - 0.22588491439819336
  - 0.2000720500946045
start: 2023-11-01 11:41:49.938440
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
