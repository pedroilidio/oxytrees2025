active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/lncRNA/normalized_lncrna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/lncRNA/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: lncrna
  pairwise: true
  y:
    force_download: false
    path: datasets/lncRNA/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: semisupervised_forests/runs
end: 2023-11-01 15:42:08.562464
estimator:
  call: semisupervised_forests.estimators.adss_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: true
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.0
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision: null
          verbose: 10
          warm_start: false
    verbose: false
  name: adss_bxt_gso
  params: {}
hash: b71c6df80c69e76435efadf9da346d6e0752e6b8711ad5bced147f7429c7f248
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/b71c6df_20231101T152605865130_adss_bxt_gso_lncrna.yml"
results:
  LL_average_precision:
  - 0.25361601458394806
  - 0.26951417828829816
  - 0.26376432189848026
  - 0.2731209993507196
  - 0.252402582994853
  - 0.26896182343655856
  - 0.26326863984584675
  - 0.2723801621492162
  - 0.25009389627249023
  - 0.26608600979858466
  - 0.2604985530593602
  - 0.2698547467800432
  - 0.2501605836412334
  - 0.2658317109783227
  - 0.2600831004629528
  - 0.2694916013308667
  LL_balanced_accuracy:
  - 0.5500139871318387
  - 0.5500108640544651
  - 0.55
  - 0.5500035350678734
  - 0.5500040277106493
  - 0.5500108995785497
  - 0.550003748406927
  - 0.5500071007597813
  - 0.550006120700208
  - 0.55
  - 0.5500152195418918
  - 0.550005392385951
  - 0.5500020392348791
  - 0.5500055397569893
  - 0.5500076289288984
  - 0.5500036025650263
  LL_f1_macro:
  - 0.5485577335833741
  - 0.5436576126504203
  - 0.5454150487320866
  - 0.5425161856080872
  - 0.54890455026083
  - 0.54382947352955
  - 0.5455764443546783
  - 0.5427557335156992
  - 0.5496099576507355
  - 0.5446972221380753
  - 0.5464551593427125
  - 0.5435393035486149
  - 0.5495805966447076
  - 0.5447884274615664
  - 0.5465657399080635
  - 0.5436482764343024
  LL_f1_micro:
  - 0.8464119596797295
  - 0.830507549820632
  - 0.8362356781015199
  - 0.8268860707850271
  - 0.8476054724264456
  - 0.8310599757205407
  - 0.8367388569680073
  - 0.8276340393703465
  - 0.849918345127926
  - 0.8339139902014153
  - 0.8395318860244233
  - 0.8301560379918589
  - 0.8498434948285247
  - 0.834179368535656
  - 0.839932157394844
  - 0.8305156037991859
  LL_f1_weighted:
  - 0.7900922521088651
  - 0.7691845851879087
  - 0.7766914837469522
  - 0.7644462451155916
  - 0.7916655478084957
  - 0.7699078663790505
  - 0.7773532902638557
  - 0.7654247375396624
  - 0.7947225834389798
  - 0.7736448583551445
  - 0.7810273512895323
  - 0.7687229171556793
  - 0.7946225881268913
  - 0.7739944498837722
  - 0.781551839466814
  - 0.7691930671141832
  LL_matthews_corrcoef:
  - 0.29051344385696615
  - 0.2876513973121021
  - 0.2886521418719513
  - 0.28697541531982573
  - 0.29069716179505783
  - 0.2877512431434439
  - 0.28875332203449805
  - 0.2871210521764701
  - 0.2911145063872366
  - 0.28823452513285897
  - 0.2892874849905674
  - 0.2875722425931482
  - 0.29108936912033206
  - 0.2882982041465815
  - 0.2893373401846748
  - 0.28763206075509706
  LL_precision_macro:
  - 0.9218722896414868
  - 0.9136267586053495
  - 0.9166002950363255
  - 0.9117453340358856
  - 0.9224901660156928
  - 0.9139136599639961
  - 0.9168611536250753
  - 0.9121339637291331
  - 0.9236864139949761
  - 0.9153957073928234
  - 0.9183089154595879
  - 0.9134443845164502
  - 0.9236478257259113
  - 0.9155332335080276
  - 0.9185166254541436
  - 0.913631209204558
  LL_precision_micro:
  - 0.8464119596797294
  - 0.8305075498206321
  - 0.8362356781015198
  - 0.8268860707850271
  - 0.8476054724264455
  - 0.8310599757205407
  - 0.8367388569680073
  - 0.8276340393703464
  - 0.849918345127926
  - 0.8339139902014153
  - 0.8395318860244233
  - 0.8301560379918589
  - 0.8498434948285247
  - 0.834179368535656
  - 0.839932157394844
  - 0.8305156037991859
  LL_precision_weighted:
  - 0.8704109235370768
  - 0.8597867744484586
  - 0.8635514703613387
  - 0.8574422947782326
  - 0.8712296214911318
  - 0.8601468324721653
  - 0.8638855431470702
  - 0.8579242668674423
  - 0.8728248836816386
  - 0.862017168943331
  - 0.865749514554062
  - 0.8595579353274174
  - 0.8727730461310058
  - 0.8621920336505562
  - 0.8660178933383302
  - 0.8597919285163057
  LL_recall_macro:
  - 0.5500139871318387
  - 0.5500108640544651
  - 0.55
  - 0.5500035350678734
  - 0.5500040277106493
  - 0.5500108995785497
  - 0.550003748406927
  - 0.5500071007597813
  - 0.550006120700208
  - 0.55
  - 0.5500152195418918
  - 0.550005392385951
  - 0.5500020392348791
  - 0.5500055397569893
  - 0.5500076289288984
  - 0.5500036025650263
  LL_recall_micro:
  - 0.8464119596797294
  - 0.8305075498206321
  - 0.8362356781015198
  - 0.8268860707850271
  - 0.8476054724264455
  - 0.8310599757205407
  - 0.8367388569680073
  - 0.8276340393703464
  - 0.849918345127926
  - 0.8339139902014153
  - 0.8395318860244233
  - 0.8301560379918589
  - 0.8498434948285247
  - 0.834179368535656
  - 0.839932157394844
  - 0.8305156037991859
  LL_recall_weighted:
  - 0.8464119596797294
  - 0.8305075498206321
  - 0.8362356781015198
  - 0.8268860707850271
  - 0.8476054724264455
  - 0.8310599757205407
  - 0.8367388569680073
  - 0.8276340393703464
  - 0.849918345127926
  - 0.8339139902014153
  - 0.8395318860244233
  - 0.8301560379918589
  - 0.8498434948285247
  - 0.834179368535656
  - 0.839932157394844
  - 0.8305156037991859
  LL_roc_auc:
  - 0.5500139871318387
  - 0.5500108640544651
  - 0.55
  - 0.5500035350678734
  - 0.5500040277106493
  - 0.5500108995785497
  - 0.550003748406927
  - 0.5500071007597813
  - 0.550006120700208
  - 0.55
  - 0.5500152195418918
  - 0.550005392385951
  - 0.5500020392348791
  - 0.5500055397569893
  - 0.5500076289288984
  - 0.5500036025650263
  LT_average_precision:
  - 0.27989016833071606
  - 0.24213624694722283
  - 0.2988712055985261
  - 0.1838499848511243
  - 0.2928718626290602
  - 0.24308517251023287
  - 0.2775652719418515
  - 0.18154380710292933
  - 0.28689206540446655
  - 0.23742965773770475
  - 0.2920778964856793
  - 0.1757928260628974
  - 0.2790131697626682
  - 0.24681996852065236
  - 0.29586395587009207
  - 0.17376627688601246
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.594717606631924
  - 0.6143876714746522
  - 0.6450536215714847
  - 0.5521709290883424
  - 0.6086613419892137
  - 0.6184263783356369
  - 0.6213607495961011
  - 0.551960010128203
  - 0.6080837168347016
  - 0.6107983544569879
  - 0.6415295355933871
  - 0.5469603971624979
  - 0.5898825208620209
  - 0.6119793314290746
  - 0.6390742646211142
  - 0.5436863604693892
  TL_average_precision:
  - 0.33037492040046
  - 0.32511188990742707
  - 0.3244673606366775
  - 0.36882627136342977
  - 0.29716644541403336
  - 0.33312835397697954
  - 0.31542811179294244
  - 0.3610109437508838
  - 0.32956776234960894
  - 0.32489804226601204
  - 0.34799080244022235
  - 0.355971186477493
  - 0.36779869082326727
  - 0.362044184417632
  - 0.31320741554327686
  - 0.3656028642443972
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.6757906817780179
  - 0.6505835213408768
  - 0.652927570302875
  - 0.6781487066747692
  - 0.6410183863517855
  - 0.659315359374472
  - 0.650783781159513
  - 0.6795099456020113
  - 0.6536475192387217
  - 0.6371216213561418
  - 0.6560439291295815
  - 0.6565650968223683
  - 0.6881401950480727
  - 0.6678174606064816
  - 0.6287044660375231
  - 0.6558157456902656
  TT_average_precision:
  - 0.24213786350633704
  - 0.18470093613902852
  - 0.2113155794566686
  - 0.15074268683080078
  - 0.23564242240142658
  - 0.1920608857068826
  - 0.20941607655827596
  - 0.15417164022660731
  - 0.24867647878529017
  - 0.19463978190754325
  - 0.23543409352689953
  - 0.1664177956290978
  - 0.26593597542131225
  - 0.2046091085193775
  - 0.21614862837414237
  - 0.17286914582642382
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.5437081647021512
  - 0.5473727516347477
  - 0.553245240486554
  - 0.5115533736726845
  - 0.541719619534418
  - 0.5463822020945677
  - 0.5493188412603652
  - 0.5142646886892943
  - 0.5384332212901185
  - 0.5435202777223028
  - 0.5597412590222716
  - 0.5165116243733897
  - 0.5504764082054344
  - 0.5566023823350769
  - 0.5477249438442707
  - 0.526200179865166
  fit_time:
  - 919.395791053772
  - 929.8778309822083
  - 931.1527976989746
  - 936.7820544242859
  - 939.1598229408264
  - 930.3481559753418
  - 918.2001941204071
  - 951.3971045017242
  - 937.5039954185486
  - 935.4910502433777
  - 936.7445390224457
  - 909.8863875865936
  - 867.845103263855
  - 939.9894232749939
  - 931.5145125389099
  - 949.313841342926
  score_time:
  - 13.86015510559082
  - 14.332705020904541
  - 14.610261917114258
  - 13.004185676574707
  - 12.678168058395386
  - 14.428714752197266
  - 12.659457445144653
  - 11.039784669876099
  - 13.134830713272095
  - 14.016173839569092
  - 13.587214708328247
  - 11.728315591812134
  - 15.415274143218994
  - 13.437227725982666
  - 14.311241865158081
  - 11.307523012161255
start: 2023-11-01 15:26:05.865130
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
