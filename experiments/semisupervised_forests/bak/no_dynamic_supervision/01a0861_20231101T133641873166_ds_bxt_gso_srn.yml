active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_micro
    - f1_micro
    - precision_micro
    - f1_weighted
    - average_precision
    - recall_macro
    - roc_auc
    - matthews_corrcoef
    - precision_macro
    - balanced_accuracy
    - precision_weighted
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: semisupervised_forests/runs
end: 2023-11-01 13:56:44.375819
estimator:
  call: semisupervised_forests.estimators.ds_bxt_gso
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.9
          random_state: null
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 3
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: squared_error
          unsupervised_criterion_rows: squared_error
          update_supervision:
            load: semisupervised_forests.estimators.density_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ds_bxt_gso
  params: {}
hash: 01a086105bc2e1dac399cd099e7011a34119b35fa3636f4420a6e27833be387f
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/01a0861_20231101T133641873166_ds_bxt_gso_srn.yml"
results:
  LL_average_precision:
  - 0.11342229199372057
  - 0.11739848950147766
  - 0.11816217157894254
  - 0.11617616567672061
  - 0.11353501938359256
  - 0.11696981379179296
  - 0.1179205717775326
  - 0.11582152870909224
  - 0.11383853592976577
  - 0.117200494035632
  - 0.11818405821317018
  - 0.11632054356431842
  - 0.11401385325727043
  - 0.11701235249776337
  - 0.11796768773573779
  - 0.11624124384896081
  LL_balanced_accuracy:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_f1_macro:
  - 0.587525766149485
  - 0.5869569262020368
  - 0.586646374465257
  - 0.5869816036506083
  - 0.5877519171302815
  - 0.5870260223678899
  - 0.586712444341127
  - 0.5871295948036175
  - 0.5878614038397703
  - 0.5867602867102066
  - 0.586687900893901
  - 0.5870483832903317
  - 0.5879402844460085
  - 0.5866607317273869
  - 0.5865557606018998
  - 0.5869642543352205
  LL_f1_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_f1_weighted:
  - 0.9811321823453176
  - 0.9761414287195214
  - 0.9749212382495934
  - 0.9774776314203629
  - 0.9813074311317526
  - 0.9766889473454499
  - 0.9752651098766671
  - 0.9780497795168125
  - 0.9811260532825248
  - 0.9760953339344545
  - 0.9749522354593334
  - 0.9774108918568967
  - 0.9810418010034022
  - 0.9761657817869357
  - 0.9750099646383824
  - 0.977385480503414
  LL_matthews_corrcoef:
  - 0.31409515446139513
  - 0.3141683958690032
  - 0.3138616381656739
  - 0.31390578049604967
  - 0.31448500361571946
  - 0.3141728200322513
  - 0.3139073145897686
  - 0.3140545703121901
  - 0.31473502795779823
  - 0.31380563801371575
  - 0.3139332792843214
  - 0.3140481470423044
  - 0.3149043644977443
  - 0.31360011679080124
  - 0.31366898336781385
  - 0.31389415520984937
  LL_precision_macro:
  - 0.9932788302806383
  - 0.9914900047493631
  - 0.9910530770160804
  - 0.9919701600787443
  - 0.9933405484664932
  - 0.9916864403123518
  - 0.9911763690650834
  - 0.9921748283121097
  - 0.9932749711971511
  - 0.9914746742600742
  - 0.9910639546423424
  - 0.9919457817811599
  - 0.9932443637569717
  - 0.9915006342166346
  - 0.9910856057991025
  - 0.9919371538023503
  LL_precision_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_precision_weighted:
  - 0.9867581350113046
  - 0.9833014126376041
  - 0.982461332030557
  - 0.9842264253782121
  - 0.9868779600334681
  - 0.9836796181124469
  - 0.9826982055854259
  - 0.9846213911194873
  - 0.9867507367598339
  - 0.983271829190631
  - 0.9824822418385274
  - 0.9841794371787886
  - 0.9866913777610021
  - 0.983321742323542
  - 0.9825237643341496
  - 0.9841627673678994
  LL_recall_macro:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LL_recall_micro:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_recall_weighted:
  - 0.9865777080062794
  - 0.9830122818358112
  - 0.9821417797888387
  - 0.9839689722042663
  - 0.9867008296730112
  - 0.9834036689346309
  - 0.9823873912669021
  - 0.9843768839893204
  - 0.9865701038834275
  - 0.9829816553268452
  - 0.9821634656790974
  - 0.9839204202911033
  - 0.986509098514955
  - 0.9830333304624924
  - 0.9822065282921367
  - 0.9839031952458875
  LL_roc_auc:
  - 0.55
  - 0.5502053856686444
  - 0.5501519756838906
  - 0.5500725689404935
  - 0.5501179245283019
  - 0.550186741363212
  - 0.5501539815222173
  - 0.5500992063492064
  - 0.5502043199065966
  - 0.5500910746812386
  - 0.5501737619461338
  - 0.5501204819277108
  - 0.5502614758861127
  - 0.5500228414801279
  - 0.5500871080139372
  - 0.5500722195474241
  LT_average_precision:
  - 0.027771392454181545
  - 0.015998692196491495
  - 0.013017757314680379
  - 0.019341352996346303
  - 0.02650119335441867
  - 0.018376101538107807
  - 0.01220304732988565
  - 0.021048744877192035
  - 0.027242029565090815
  - 0.015469565653244978
  - 0.012906649051917199
  - 0.019229335181638486
  - 0.027613581278067366
  - 0.016312869103390623
  - 0.012455895206618774
  - 0.019040999845651562
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.5128193718223415
  - 0.5153989759087816
  - 0.5127811452438047
  - 0.5131908386334411
  - 0.5075247271852283
  - 0.5196904048358805
  - 0.511691624764528
  - 0.5174736504785766
  - 0.505901763911893
  - 0.5106228606773102
  - 0.5176208745817629
  - 0.5130559481564526
  - 0.5094124280603516
  - 0.510696278983783
  - 0.5071061144583715
  - 0.5074895180840683
  TL_average_precision:
  - 0.0337705870430367
  - 0.042151996252711016
  - 0.03759330997014095
  - 0.03572697826522959
  - 0.047515601456113124
  - 0.043935053915539486
  - 0.04492544904640162
  - 0.044634535191624566
  - 0.04061343281169853
  - 0.04633211878704019
  - 0.04545991619264332
  - 0.045763472953737026
  - 0.030503763197849542
  - 0.03893527448702029
  - 0.049047574601574224
  - 0.05622447630643627
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.5248746070136383
  - 0.5371176201902973
  - 0.5238885611948932
  - 0.5278584916665622
  - 0.5321173566695833
  - 0.5307654632280814
  - 0.5302948528509446
  - 0.5280661270362034
  - 0.526753139957931
  - 0.5303264311272613
  - 0.5273125526131935
  - 0.5354844708178618
  - 0.5179647793831981
  - 0.5266648860889556
  - 0.5250121617713936
  - 0.5354296143682326
  TT_average_precision:
  - 0.026267216753126692
  - 0.016640519719237943
  - 0.012510139963414754
  - 0.01981648849638496
  - 0.028626469261743115
  - 0.015925271825471418
  - 0.015715329138227575
  - 0.01960703218260154
  - 0.026137389495532633
  - 0.01505936554988958
  - 0.014385942944189718
  - 0.018343286568739448
  - 0.02924906709195941
  - 0.01498854616967411
  - 0.010931236251433298
  - 0.01818354946145125
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.506749426376696
  - 0.5009628645657931
  - 0.5171956054246163
  - 0.5070192926494865
  - 0.5057854696802065
  - 0.5124141329419165
  - 0.5392236004818077
  - 0.5034944732987082
  - 0.5008002422959074
  - 0.4961994009660143
  - 0.5382061847202639
  - 0.5010504990519381
  - 0.515409111490401
  - 0.5075824211308082
  - 0.4766391723356009
  - 0.49026569810593473
  fit_time:
  - 971.5480804443359
  - 1177.639747619629
  - 1195.1520552635193
  - 1110.4728875160217
  - 1008.2349510192871
  - 1160.0781013965607
  - 1180.867516040802
  - 1072.4926726818085
  - 994.07483959198
  - 1188.0408391952515
  - 1191.0822522640228
  - 1129.97603058815
  - 974.3344371318817
  - 1182.4135885238647
  - 1176.253249168396
  - 1118.90669631958
  score_time:
  - 14.762139558792114
  - 6.692596912384033
  - 6.134557485580444
  - 10.08604621887207
  - 11.323472023010254
  - 7.0923237800598145
  - 6.806062936782837
  - 9.283234596252441
  - 15.165597915649414
  - 6.016832113265991
  - 5.860907077789307
  - 7.885426044464111
  - 15.28757357597351
  - 5.837071418762207
  - 6.723616361618042
  - 7.804701566696167
start: 2023-11-01 13:36:41.873166
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop90
  params:
    drop: 0.9
