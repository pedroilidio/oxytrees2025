active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - recall_macro
    - f1_weighted
    - precision_micro
    - balanced_accuracy
    - precision_macro
    - roc_auc
    - precision_weighted
    - average_precision
    - f1_micro
    - recall_micro
    - matthews_corrcoef
    - recall_weighted
    - f1_macro
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: semisupervised_forests/runs
end: 2023-11-09 08:24:02.549677
estimator:
  call: semisupervised_forests.estimators.ss_bxt_gso__md_random
  final_params:
    memory: null
    steps:
    - - dropper
      - call: bipartite_positive_dropper.BipartitePositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: bipartite_learn.ensemble._semisupervised_forest.BipartiteExtraTreesRegressorSS
        params:
          axis_decision_only: false
          bipartite_adapter: gmosa
          bootstrap: false
          ccp_alpha: 0.0
          criterion: squared_error_gso
          max_col_features: null
          max_depth: null
          max_features: 1.0
          max_leaf_nodes: null
          max_row_features: null
          max_samples: null
          min_col_weight_fraction_leaf: 0.0
          min_cols_leaf: 1
          min_cols_split: 1
          min_impurity_decrease: 0.0
          min_row_weight_fraction_leaf: 0.0
          min_rows_leaf: 1
          min_rows_split: 1
          min_samples_leaf: 1
          min_samples_split: 2
          min_weight_fraction_leaf: 0.0
          n_estimators: 100
          n_jobs: 4
          oob_score: false
          prediction_weights: null
          preprocess_X_targets: null
          random_state: 0
          ss_adapter: null
          supervision: 0.5
          unsupervised_criterion_cols: mean_distance
          unsupervised_criterion_rows: mean_distance
          update_supervision:
            load: semisupervised_forests.estimators.random_updater
          verbose: 10
          warm_start: false
    verbose: false
  name: ss_bxt_gso__md_random
  params: {}
hash: 9dacb783b72296ec01543a23a4952cf816a5f297107023d9f2ea6f017d4f7de5
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/semisupervised_forests/runs/9dacb78_20231109T082358030449_ss_bxt_gso__md_random_ion_channels.yml"
results:
  LL_average_precision:
  - 0.32663246582317396
  - 0.32600044510716425
  - 0.3239487591028229
  - 0.3272668922132747
  - 0.32556707196748086
  - 0.3268879632576892
  - 0.32374451890460826
  - 0.32510644269942257
  - 0.32559255461498604
  - 0.3263454714349574
  - 0.32403408620832297
  - 0.3240424875168476
  - 0.32536901767026805
  - 0.32540137037937994
  - 0.32419254880642945
  - 0.32463599939400384
  LL_balanced_accuracy:
  - 0.6504524886877828
  - .nan
  - 0.6500607533414338
  - .nan
  - 0.6502320185614849
  - .nan
  - 0.65
  - .nan
  - 0.6504112808460635
  - .nan
  - 0.65
  - .nan
  - 0.650174621653085
  - .nan
  - 0.6503067484662577
  - .nan
  LL_f1_macro:
  - 0.7247147376580412
  - .nan
  - 0.7247494932538617
  - .nan
  - 0.7246180167203053
  - .nan
  - 0.7246992675697045
  - .nan
  - 0.724917092571373
  - .nan
  - 0.7246235538985544
  - .nan
  - 0.7245719922026472
  - .nan
  - 0.7251051764698372
  - .nan
  LL_f1_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_f1_weighted:
  - 0.9675291813846373
  - .nan
  - 0.9699045778045997
  - .nan
  - 0.9683066504870864
  - .nan
  - 0.9700068543616309
  - .nan
  - 0.9687302172486109
  - .nan
  - 0.9696429040017699
  - .nan
  - 0.968409524086243
  - .nan
  - 0.9702234059506051
  - .nan
  LL_matthews_corrcoef:
  - 0.5413656446134067
  - .nan
  - 0.5411992376285261
  - .nan
  - 0.5411462518352902
  - .nan
  - 0.5411131214734051
  - .nan
  - 0.5415634050678383
  - .nan
  - 0.5410311761278824
  - .nan
  - 0.5410665251308358
  - .nan
  - 0.5417127859685285
  - .nan
  LL_precision_macro:
  - 0.9869922121658599
  - .nan
  - 0.987963388640448
  - .nan
  - 0.9873116741015067
  - .nan
  - 0.9880056837178202
  - .nan
  - 0.9874815905743741
  - .nan
  - 0.9878578892371996
  - .nan
  - 0.9873542902832134
  - .nan
  - 0.9880897655564378
  - .nan
  LL_precision_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_precision_weighted:
  - 0.9749418269748551
  - .nan
  - 0.9767463463343345
  - .nan
  - 0.9755339961297858
  - .nan
  - 0.9768250796348118
  - .nan
  - 0.9758501689028972
  - .nan
  - 0.9765495628653252
  - .nan
  - 0.9756130112434778
  - .nan
  - 0.9769826121976364
  - .nan
  LL_recall_macro:
  - 0.6504524886877828
  - .nan
  - 0.6500607533414338
  - .nan
  - 0.6502320185614849
  - .nan
  - 0.65
  - .nan
  - 0.6504112808460635
  - .nan
  - 0.65
  - .nan
  - 0.650174621653085
  - .nan
  - 0.6503067484662577
  - .nan
  LL_recall_micro:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_recall_weighted:
  - 0.9742725115523917
  - .nan
  - 0.9761727475800447
  - .nan
  - 0.974896965155489
  - .nan
  - 0.9762554810953917
  - .nan
  - 0.9752300070771408
  - .nan
  - 0.975965913791677
  - .nan
  - 0.9749802256359019
  - .nan
  - 0.9764209481260859
  - .nan
  LL_roc_auc:
  - 0.6504524886877828
  - 0.6504021862039957
  - 0.6500607533414338
  - 0.6521950624336336
  - 0.6502320185614849
  - 0.6512943285803204
  - 0.65
  - 0.6510883325109408
  - 0.6504112808460635
  - 0.6507760035112483
  - 0.65
  - 0.6504892072654067
  - 0.650174621653085
  - 0.6506808263657891
  - 0.6503067484662577
  - 0.6512382165774748
  LT_average_precision:
  - 0.24671592905638742
  - 0.08666397483237673
  - 0.1549153594762779
  - 0.20892371502366558
  - 0.251436425727487
  - 0.1038637131641653
  - 0.10716999628478219
  - 0.14854902367541906
  - 0.21642664525555405
  - 0.10045834700635169
  - 0.1323852813281564
  - 0.21403720158524311
  - 0.23278535413284612
  - 0.11407780047849869
  - 0.1592409457878901
  - 0.18833767789160202
  LT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  LT_roc_auc:
  - 0.7099216876757775
  - 0.627594373263163
  - 0.6463203152211773
  - 0.6612001653175811
  - 0.7331325944132113
  - 0.6479064229488678
  - 0.630176765077862
  - 0.6418704615378146
  - 0.7079844084302682
  - 0.6444189699825924
  - 0.6410249013623167
  - 0.6960753413405487
  - 0.7125330664934625
  - 0.6508015141858353
  - 0.6682569741155864
  - 0.6558475068753273
  TL_average_precision:
  - 0.5036863417039946
  - 0.4754605567449993
  - 0.48098426700217023
  - 0.4965037263366967
  - 0.5480159371062037
  - 0.5650697913309644
  - 0.5659044696173204
  - 0.511689363310767
  - 0.49908898782988625
  - 0.4458544077208741
  - 0.43875214986483335
  - 0.47518572836462764
  - 0.5471916149866729
  - 0.5686393150728947
  - 0.5800498871826899
  - 0.5886212659209806
  TL_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TL_roc_auc:
  - 0.8461865951287625
  - 0.8311114897244132
  - 0.8209913400664846
  - 0.8295273562455867
  - 0.8333535901480386
  - 0.8430491679981574
  - 0.8598477441438622
  - 0.8251778145995352
  - 0.8058485298162628
  - 0.8071234068569817
  - 0.810984564851554
  - 0.7999210939502691
  - 0.8324974935868564
  - 0.8515884416768054
  - 0.8621686266237198
  - 0.8555854248804153
  TT_average_precision:
  - 0.20821423151013851
  - 0.06107122319734253
  - 0.12396479444996782
  - 0.14484420858967725
  - 0.2932194810809106
  - 0.10210920042676516
  - 0.20500037338963717
  - 0.18265944673348972
  - 0.19689409499633068
  - 0.10050055014044124
  - 0.12582778391949037
  - 0.24176185247345328
  - 0.28691198333017687
  - 0.0724640760783505
  - 0.14926252936825796
  - 0.15487192126273777
  TT_balanced_accuracy:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_f1_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_matthews_corrcoef:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_precision_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_macro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_micro:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_recall_weighted:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  TT_roc_auc:
  - 0.7133712308452793
  - 0.6009227367436324
  - 0.6681279160186625
  - 0.6327689258945551
  - 0.7464403763030766
  - 0.6856111468775866
  - 0.6938620505114959
  - 0.6891222581552305
  - 0.7339388814369862
  - 0.6357555155411204
  - 0.5845101880877743
  - 0.7061351119376296
  - 0.7534832941951963
  - 0.6404664539612637
  - 0.6533344551012397
  - 0.6718911280646894
  fit_time:
  - 3.0660769939422607
  - 2.970330238342285
  - 3.2702083587646484
  - 3.0815837383270264
  - 3.516660690307617
  - 3.287231922149658
  - 3.5637624263763428
  - 3.40126371383667
  - 3.436216354370117
  - 3.226433038711548
  - 3.3761134147644043
  - 3.293834924697876
  - 3.5252373218536377
  - 3.211860179901123
  - 3.3926234245300293
  - 3.519089698791504
  score_time:
  - 0.6204028129577637
  - 0.49097657203674316
  - 0.9087026119232178
  - 0.4842960834503174
  - 0.9526059627532959
  - 0.8353226184844971
  - 0.8477044105529785
  - 0.8154661655426025
  - 0.9357445240020752
  - 0.8224697113037109
  - 0.8759920597076416
  - 0.8095502853393555
  - 0.8485698699951172
  - 0.7562522888183594
  - 1.0438764095306396
  - 0.7240447998046875
start: 2023-11-09 08:23:58.030449
wrapper:
  call: bipartite_positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
