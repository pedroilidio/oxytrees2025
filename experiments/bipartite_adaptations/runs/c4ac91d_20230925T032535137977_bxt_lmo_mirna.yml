active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: bipartite_adaptations/runs
end: 2023-09-25 04:09:40.807175
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: bipartite_learn.wrappers.LocalMultiOutputWrapper
      params:
        combine_func_kwargs: null
        combine_predictions_func:
          load: numpy.mean
        independent_labels: false
        primary_cols_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_cols_estimator__bootstrap: false
        primary_cols_estimator__ccp_alpha: 0.0
        primary_cols_estimator__criterion: squared_error
        primary_cols_estimator__max_depth: null
        primary_cols_estimator__max_features: 1.0
        primary_cols_estimator__max_leaf_nodes: null
        primary_cols_estimator__max_samples: null
        primary_cols_estimator__min_impurity_decrease: 0.0
        primary_cols_estimator__min_samples_leaf: 1
        primary_cols_estimator__min_samples_split: 2
        primary_cols_estimator__min_weight_fraction_leaf: 0.0
        primary_cols_estimator__n_estimators: 50
        primary_cols_estimator__n_jobs: 3
        primary_cols_estimator__oob_score: false
        primary_cols_estimator__random_state: 0
        primary_cols_estimator__verbose: 10
        primary_cols_estimator__warm_start: false
        primary_rows_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_rows_estimator__bootstrap: false
        primary_rows_estimator__ccp_alpha: 0.0
        primary_rows_estimator__criterion: squared_error
        primary_rows_estimator__max_depth: null
        primary_rows_estimator__max_features: 1.0
        primary_rows_estimator__max_leaf_nodes: null
        primary_rows_estimator__max_samples: null
        primary_rows_estimator__min_impurity_decrease: 0.0
        primary_rows_estimator__min_samples_leaf: 1
        primary_rows_estimator__min_samples_split: 2
        primary_rows_estimator__min_weight_fraction_leaf: 0.0
        primary_rows_estimator__n_estimators: 50
        primary_rows_estimator__n_jobs: 3
        primary_rows_estimator__oob_score: false
        primary_rows_estimator__random_state: 0
        primary_rows_estimator__verbose: 10
        primary_rows_estimator__warm_start: false
        secondary_cols_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_cols_estimator__bootstrap: false
        secondary_cols_estimator__ccp_alpha: 0.0
        secondary_cols_estimator__criterion: squared_error
        secondary_cols_estimator__max_depth: null
        secondary_cols_estimator__max_features: 1.0
        secondary_cols_estimator__max_leaf_nodes: null
        secondary_cols_estimator__max_samples: null
        secondary_cols_estimator__min_impurity_decrease: 0.0
        secondary_cols_estimator__min_samples_leaf: 1
        secondary_cols_estimator__min_samples_split: 2
        secondary_cols_estimator__min_weight_fraction_leaf: 0.0
        secondary_cols_estimator__n_estimators: 50
        secondary_cols_estimator__n_jobs: 3
        secondary_cols_estimator__oob_score: false
        secondary_cols_estimator__random_state: 0
        secondary_cols_estimator__verbose: 10
        secondary_cols_estimator__warm_start: false
        secondary_rows_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_rows_estimator__bootstrap: false
        secondary_rows_estimator__ccp_alpha: 0.0
        secondary_rows_estimator__criterion: squared_error
        secondary_rows_estimator__max_depth: null
        secondary_rows_estimator__max_features: 1.0
        secondary_rows_estimator__max_leaf_nodes: null
        secondary_rows_estimator__max_samples: null
        secondary_rows_estimator__min_impurity_decrease: 0.0
        secondary_rows_estimator__min_samples_leaf: 1
        secondary_rows_estimator__min_samples_split: 2
        secondary_rows_estimator__min_weight_fraction_leaf: 0.0
        secondary_rows_estimator__n_estimators: 50
        secondary_rows_estimator__n_jobs: 3
        secondary_rows_estimator__oob_score: false
        secondary_rows_estimator__random_state: 0
        secondary_rows_estimator__verbose: 10
        secondary_rows_estimator__warm_start: false
  name: bxt_lmo
  params: {}
hash: c4ac91d644a453f3d33034796a2966272fa6552f87813269776b9f841419a8af
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/c4ac91d_20230925T032535137977_bxt_lmo_mirna.yml"
results:
  LL_average_precision:
  - 0.9999999574061432
  - 0.9999999447705892
  - 0.9999999989288516
  - 0.9999999577852506
  - 0.9999999666784143
  - 0.9999999672892359
  - 0.9999999903000732
  - 0.9999999773240815
  - 0.9999999757517867
  - 0.9999999389068782
  - 0.9999999901545192
  - 0.9999999385236996
  - 0.9999999413574494
  - 0.9999998890104351
  - 0.999999960940419
  - 0.9999999082560732
  LL_balanced_accuracy:
  - 0.9999901385776377
  - 0.9999888992495893
  - 0.9999987687458445
  - 0.999990169236592
  - 0.9999913786308281
  - 0.999991372510353
  - 0.999996309926789
  - 0.9999926328662571
  - 0.9999913826851061
  - 0.9999876811487083
  - 0.9999963119772228
  - 0.9999877265675627
  - 0.9999876864274878
  - 0.9999839865980144
  - 0.9999926217231228
  - 0.9999852722064444
  LL_f1_macro:
  - 0.9999306092537311
  - 0.9999224967642167
  - 0.9999912022713281
  - 0.9999309120743053
  - 0.9999392203603554
  - 0.9999397372434241
  - 0.9999735329050767
  - 0.9999481607669657
  - 0.9999388722012175
  - 0.999913397741542
  - 0.9999733498828177
  - 0.9999131685891792
  - 0.999912947460996
  - 0.9998873283397841
  - 0.9999469020922882
  - 0.9998957774405421
  LL_f1_micro:
  - 0.9999816784382701
  - 0.9999793882430539
  - 0.9999977098047838
  - 0.9999817371612243
  - 0.9999839800437116
  - 0.9999839800437116
  - 0.9999931343044478
  - 0.9999863126197646
  - 0.9999839800437116
  - 0.9999771143481594
  - 0.9999931343044478
  - 0.9999771876996076
  - 0.9999771143481594
  - 0.9999702486526072
  - 0.9999862686088956
  - 0.9999726252395291
  LL_f1_weighted:
  - 0.9999816795289383
  - 0.9999793896117232
  - 0.9999977098221124
  - 0.9999817382434265
  - 0.9999839808792835
  - 0.999983980870905
  - 0.9999931344608278
  - 0.9999863132284704
  - 0.9999839808849259
  - 0.99997711604818
  - 0.9999931344620985
  - 0.9999771894004433
  - 0.9999771160586058
  - 0.9999702515283131
  - 0.999986269236689
  - 0.9999726276894212
  LL_matthews_corrcoef:
  - 0.9998612281364537
  - 0.9998450055403222
  - 0.9999824046974538
  - 0.9998618336937488
  - 0.9998784481082605
  - 0.9998794817492889
  - 0.9999470672111034
  - 0.9998963269080599
  - 0.9998777518748565
  - 0.9998268104807319
  - 0.999946701186027
  - 0.9998263522554716
  - 0.9998259100759893
  - 0.9997746820644088
  - 0.9998938098228308
  - 0.9997915766018347
  LL_precision_macro:
  - 0.9998710966452902
  - 0.9998561151079137
  - 0.9999836360661103
  - 0.9998716714789861
  - 0.999887074917726
  - 0.9998881145706796
  - 0.9999507583218437
  - 0.9999036979969184
  - 0.9998863747037626
  - 0.9998391403661165
  - 0.9999503902632623
  - 0.9998386368037178
  - 0.9998382348183377
  - 0.9997907141477236
  - 0.9999011922798234
  - 0.9998063204106007
  LL_precision_micro:
  - 0.9999816784382701
  - 0.9999793882430539
  - 0.9999977098047838
  - 0.9999817371612243
  - 0.9999839800437116
  - 0.9999839800437116
  - 0.9999931343044478
  - 0.9999863126197646
  - 0.9999839800437116
  - 0.9999771143481594
  - 0.9999931343044478
  - 0.9999771876996076
  - 0.9999771143481594
  - 0.9999702486526072
  - 0.9999862686088956
  - 0.9999726252395291
  LL_precision_weighted:
  - 0.9999816831616916
  - 0.9999793941744947
  - 0.9999977098797369
  - 0.9999817418485105
  - 0.9999839836618214
  - 0.999983983628511
  - 0.9999931349806046
  - 0.9999863152560089
  - 0.9999839836842561
  - 0.9999771217109146
  - 0.9999931349856586
  - 0.999977195061739
  - 0.9999771217523626
  - 0.9999702611056794
  - 0.9999862713224305
  - 0.9999726358433939
  LL_recall_macro:
  - 0.9999901385776377
  - 0.9999888992495893
  - 0.9999987687458445
  - 0.999990169236592
  - 0.9999913786308281
  - 0.999991372510353
  - 0.999996309926789
  - 0.9999926328662571
  - 0.9999913826851061
  - 0.9999876811487083
  - 0.9999963119772228
  - 0.9999877265675627
  - 0.9999876864274878
  - 0.9999839865980144
  - 0.9999926217231228
  - 0.9999852722064444
  LL_recall_micro:
  - 0.9999816784382701
  - 0.9999793882430539
  - 0.9999977098047838
  - 0.9999817371612243
  - 0.9999839800437116
  - 0.9999839800437116
  - 0.9999931343044478
  - 0.9999863126197646
  - 0.9999839800437116
  - 0.9999771143481594
  - 0.9999931343044478
  - 0.9999771876996076
  - 0.9999771143481594
  - 0.9999702486526072
  - 0.9999862686088956
  - 0.9999726252395291
  LL_recall_weighted:
  - 0.9999816784382701
  - 0.9999793882430539
  - 0.9999977098047838
  - 0.9999817371612243
  - 0.9999839800437116
  - 0.9999839800437116
  - 0.9999931343044478
  - 0.9999863126197646
  - 0.9999839800437116
  - 0.9999771143481594
  - 0.9999931343044478
  - 0.9999771876996076
  - 0.9999771143481594
  - 0.9999702486526072
  - 0.9999862686088956
  - 0.9999726252395291
  LL_roc_auc:
  - 0.9999999979735497
  - 0.999999997396357
  - 0.9999999999597023
  - 0.9999999979888609
  - 0.9999999985293803
  - 0.9999999985418883
  - 0.9999999996365534
  - 0.999999998975013
  - 0.999999998920697
  - 0.9999999973834384
  - 0.9999999996340401
  - 0.9999999973849221
  - 0.9999999972901293
  - 0.9999999950402635
  - 0.9999999985416503
  - 0.9999999958781646
  LT_average_precision:
  - 0.1480361817337128
  - 0.12979692429137057
  - 0.13477721356794264
  - 0.14915993709484904
  - 0.14826386258339264
  - 0.1228176382434632
  - 0.13050925539963357
  - 0.15078581811036096
  - 0.14914499296520473
  - 0.12553881282530038
  - 0.131534693485002
  - 0.1552394834655776
  - 0.1427079762999833
  - 0.1270929830045074
  - 0.1280867894050283
  - 0.1476479116622469
  LT_balanced_accuracy:
  - 0.6089766942215813
  - 0.6057799610749705
  - 0.6011692210490674
  - 0.616054325857881
  - 0.6113375600375415
  - 0.6063236396674592
  - 0.5970992035371232
  - 0.6143407942081418
  - 0.6107912018712738
  - 0.6009143010336985
  - 0.6015975773410864
  - 0.6174416134528042
  - 0.6040659276873371
  - 0.6042148782108773
  - 0.6007942079095886
  - 0.6142882639969616
  LT_f1_macro:
  - 0.5101846601361054
  - 0.5074119085742421
  - 0.5107085259254361
  - 0.516002437387902
  - 0.5146030520287053
  - 0.511618666731526
  - 0.5101849469943656
  - 0.5183257544341408
  - 0.5108131092972729
  - 0.506547221318646
  - 0.5124150216766292
  - 0.5175909435998214
  - 0.5103014619224365
  - 0.5097619676099998
  - 0.5133143522219505
  - 0.5157081847683256
  LT_f1_micro:
  - 0.7144696471619548
  - 0.7143943129520053
  - 0.7144764957264959
  - 0.7226647857715819
  - 0.7227347385710375
  - 0.7243566931289351
  - 0.7159047358335613
  - 0.729565007082887
  - 0.7159047358335613
  - 0.717978373939228
  - 0.7179167807281687
  - 0.7271395501502955
  - 0.7203873528606625
  - 0.721324938406789
  - 0.7214754995893785
  - 0.7242303838579276
  LT_f1_weighted:
  - 0.7818309632723895
  - 0.7826813837859574
  - 0.7798373388558616
  - 0.7877716486163813
  - 0.7876309649908859
  - 0.7897692409235242
  - 0.7805647404273122
  - 0.7925918259928703
  - 0.7832078773029173
  - 0.7855478329097482
  - 0.7821959251124034
  - 0.7913742018489702
  - 0.7863126202136015
  - 0.7875378227559623
  - 0.7848461291200834
  - 0.7890363226265786
  LT_matthews_corrcoef:
  - 0.123883413082942
  - 0.11902620111866714
  - 0.11773712986746313
  - 0.1327544568312749
  - 0.12770971513943946
  - 0.12081159801537174
  - 0.11357482546348635
  - 0.13186238145033508
  - 0.12558560542784053
  - 0.11358708946023845
  - 0.11876592725752762
  - 0.1342641250245655
  - 0.11868729944097804
  - 0.11819113595899385
  - 0.11810827015106991
  - 0.13073142158388232
  LT_precision_macro:
  - 0.5352072985575103
  - 0.5334827986529049
  - 0.5342545677570868
  - 0.5379644310504821
  - 0.536622347695372
  - 0.5343184315846337
  - 0.5332115004788112
  - 0.5380172443312352
  - 0.5355888915913245
  - 0.5319628307382811
  - 0.5347088627664452
  - 0.5383740795502961
  - 0.5338407473071191
  - 0.5335104374228865
  - 0.5345991197494967
  - 0.5373850822289967
  LT_precision_micro:
  - 0.7144696471619548
  - 0.7143943129520053
  - 0.7144764957264957
  - 0.7226647857715819
  - 0.7227347385710375
  - 0.7243566931289351
  - 0.7159047358335614
  - 0.7295650070828871
  - 0.7159047358335614
  - 0.717978373939228
  - 0.7179167807281687
  - 0.7271395501502954
  - 0.7203873528606625
  - 0.7213249384067889
  - 0.7214754995893786
  - 0.7242303838579276
  LT_precision_weighted:
  - 0.8908503657084583
  - 0.8925389855370838
  - 0.8846911002160709
  - 0.8925665118182136
  - 0.8913800146427362
  - 0.8931107604356512
  - 0.8833932301691367
  - 0.8924750390015298
  - 0.8920562156659501
  - 0.8927152242472595
  - 0.8846952848472129
  - 0.8940235121082997
  - 0.8910044678403979
  - 0.8924392478190046
  - 0.8850562921966253
  - 0.8927385978837198
  LT_recall_macro:
  - 0.6089766942215813
  - 0.6057799610749705
  - 0.6011692210490674
  - 0.616054325857881
  - 0.6113375600375415
  - 0.6063236396674592
  - 0.5970992035371232
  - 0.6143407942081418
  - 0.6107912018712738
  - 0.6009143010336985
  - 0.6015975773410864
  - 0.6174416134528042
  - 0.6040659276873371
  - 0.6042148782108773
  - 0.6007942079095886
  - 0.6142882639969616
  LT_recall_micro:
  - 0.7144696471619548
  - 0.7143943129520053
  - 0.7144764957264957
  - 0.7226647857715819
  - 0.7227347385710375
  - 0.7243566931289351
  - 0.7159047358335614
  - 0.7295650070828871
  - 0.7159047358335614
  - 0.717978373939228
  - 0.7179167807281687
  - 0.7271395501502954
  - 0.7203873528606625
  - 0.7213249384067889
  - 0.7214754995893786
  - 0.7242303838579276
  LT_recall_weighted:
  - 0.7144696471619548
  - 0.7143943129520053
  - 0.7144764957264957
  - 0.7226647857715819
  - 0.7227347385710375
  - 0.7243566931289352
  - 0.7159047358335614
  - 0.7295650070828871
  - 0.7159047358335614
  - 0.7179783739392281
  - 0.7179167807281687
  - 0.7271395501502954
  - 0.7203873528606625
  - 0.7213249384067889
  - 0.7214754995893786
  - 0.7242303838579276
  LT_roc_auc:
  - 0.6426504432055311
  - 0.6439188589953839
  - 0.6320603472419931
  - 0.6534887486655219
  - 0.6502609375882068
  - 0.6390602555420251
  - 0.6249421495099579
  - 0.6521274337887274
  - 0.6466238750262829
  - 0.6390817870229919
  - 0.6281525356600931
  - 0.6512868110344946
  - 0.6416475774382229
  - 0.6426241568024588
  - 0.6256621972906802
  - 0.6490400410556361
  TL_average_precision:
  - 0.28679963870328795
  - 0.28823123328598094
  - 0.28846121054852936
  - 0.28503766957921145
  - 0.25105642480592866
  - 0.25643685957135925
  - 0.25159755586681476
  - 0.2600834866352048
  - 0.28913867555616607
  - 0.2907180795189377
  - 0.2842757205459416
  - 0.29220197941657555
  - 0.2909280331339663
  - 0.3151233202101679
  - 0.2975257780030459
  - 0.3062149577120544
  TL_balanced_accuracy:
  - 0.6360536361096079
  - 0.648932977569656
  - 0.6416260397803828
  - 0.6437030399437523
  - 0.6392734551201165
  - 0.6438476099626653
  - 0.6375425552002625
  - 0.6408741604130337
  - 0.6560889857418475
  - 0.6555895904963449
  - 0.6550933603525491
  - 0.6575063795064716
  - 0.64776323992393
  - 0.6575789045628968
  - 0.6527693137356357
  - 0.6517869810689855
  TL_f1_macro:
  - 0.5285987807826273
  - 0.5295720460993791
  - 0.5247350821253669
  - 0.5296576519845023
  - 0.5255741481761151
  - 0.5278866936281303
  - 0.5255136546961104
  - 0.5227535258836
  - 0.538524650199244
  - 0.533266611566414
  - 0.537670135752928
  - 0.5355307156625061
  - 0.5318228117164367
  - 0.5417811363399873
  - 0.5310917533841722
  - 0.5319360082004547
  TL_f1_micro:
  - 0.7357927861839173
  - 0.7279701629656038
  - 0.7278056204965069
  - 0.7325938986386747
  - 0.7264888559100777
  - 0.727691208398604
  - 0.7302608074312255
  - 0.7198046789392942
  - 0.7382993926402287
  - 0.7276774672273064
  - 0.7394399098579163
  - 0.7320362152092922
  - 0.7321227361420287
  - 0.742572896913733
  - 0.7299172781487894
  - 0.7284681130834976
  TL_f1_weighted:
  - 0.7973617597641249
  - 0.7919825279420672
  - 0.7928866791003746
  - 0.7953029871649039
  - 0.7908357805287815
  - 0.7916423270923281
  - 0.794051291540352
  - 0.7862738709782996
  - 0.7986006405517518
  - 0.7911151433867947
  - 0.7998625622788647
  - 0.7944358926068339
  - 0.7945580073821359
  - 0.8013090925795532
  - 0.7937253852776047
  - 0.7918213429699101
  TL_matthews_corrcoef:
  - 0.15694605947719842
  - 0.16984164810365818
  - 0.1596366084931629
  - 0.16468160790499378
  - 0.15891777395378706
  - 0.16435771199425986
  - 0.15657568475633196
  - 0.15925825915014263
  - 0.18136800489183974
  - 0.1786462769180832
  - 0.17946805414375608
  - 0.18116433977828492
  - 0.170015373595971
  - 0.18463297748894217
  - 0.17375133090269793
  - 0.17419673186704038
  TL_precision_macro:
  - 0.5452616818810638
  - 0.5484214206639955
  - 0.5449843948378362
  - 0.547180685935366
  - 0.5453332238663964
  - 0.5469480471364787
  - 0.5445606543756929
  - 0.5450103713718165
  - 0.5526852568137796
  - 0.551279928424007
  - 0.5519183773968966
  - 0.5520939502738575
  - 0.5489046316151742
  - 0.5540829631843671
  - 0.549403777912332
  - 0.5499787616491403
  TL_precision_micro:
  - 0.7357927861839173
  - 0.7279701629656038
  - 0.7278056204965069
  - 0.7325938986386747
  - 0.7264888559100777
  - 0.7276912083986039
  - 0.7302608074312255
  - 0.7198046789392943
  - 0.7382993926402287
  - 0.7276774672273064
  - 0.7394399098579163
  - 0.7320362152092922
  - 0.7321227361420287
  - 0.742572896913733
  - 0.7299172781487894
  - 0.7284681130834977
  TL_precision_weighted:
  - 0.8969025127238276
  - 0.8990201360714392
  - 0.900256432271287
  - 0.8984261628672032
  - 0.8971998030084928
  - 0.8978559255533093
  - 0.8983394485912692
  - 0.8977532455953386
  - 0.8987996232842604
  - 0.8985559628786159
  - 0.8997622176961121
  - 0.8994911265949922
  - 0.8980720463954979
  - 0.8984440398111111
  - 0.9005356318837828
  - 0.8982829867109199
  TL_recall_macro:
  - 0.6360536361096079
  - 0.648932977569656
  - 0.6416260397803828
  - 0.6437030399437523
  - 0.6392734551201165
  - 0.6438476099626653
  - 0.6375425552002625
  - 0.6408741604130337
  - 0.6560889857418475
  - 0.6555895904963449
  - 0.6550933603525491
  - 0.6575063795064716
  - 0.64776323992393
  - 0.6575789045628968
  - 0.6527693137356357
  - 0.6517869810689855
  TL_recall_micro:
  - 0.7357927861839173
  - 0.7279701629656038
  - 0.7278056204965069
  - 0.7325938986386747
  - 0.7264888559100777
  - 0.7276912083986039
  - 0.7302608074312255
  - 0.7198046789392943
  - 0.7382993926402287
  - 0.7276774672273064
  - 0.7394399098579163
  - 0.7320362152092922
  - 0.7321227361420287
  - 0.742572896913733
  - 0.7299172781487894
  - 0.7284681130834977
  TL_recall_weighted:
  - 0.7357927861839173
  - 0.7279701629656038
  - 0.7278056204965069
  - 0.7325938986386747
  - 0.7264888559100777
  - 0.7276912083986039
  - 0.7302608074312255
  - 0.7198046789392943
  - 0.7382993926402287
  - 0.7276774672273064
  - 0.7394399098579163
  - 0.7320362152092922
  - 0.7321227361420287
  - 0.742572896913733
  - 0.7299172781487894
  - 0.7284681130834977
  TL_roc_auc:
  - 0.6885490255950539
  - 0.7020078697422106
  - 0.6979453943912524
  - 0.6986425934084777
  - 0.6907574719030138
  - 0.6997123692407479
  - 0.6923115215526726
  - 0.6958462324295327
  - 0.7138218610988897
  - 0.7135498394419141
  - 0.7084902877906357
  - 0.7138320582326766
  - 0.6996757160742141
  - 0.7164816372275377
  - 0.7072472528695216
  - 0.7107435665616572
  TT_average_precision:
  - 0.12070443035514133
  - 0.10174840589892857
  - 0.10989300189771543
  - 0.11106200733834995
  - 0.1091203630138682
  - 0.09846953306653797
  - 0.10568564122455064
  - 0.09957300974147591
  - 0.12111166290600758
  - 0.10925295673555858
  - 0.1137930353427074
  - 0.1162913194372044
  - 0.1241125499886203
  - 0.11003919794388037
  - 0.12030899189953324
  - 0.12166034118686557
  TT_balanced_accuracy:
  - 0.5677392472073612
  - 0.5518742242150813
  - 0.5523912503124261
  - 0.5633352018324207
  - 0.5603308035108924
  - 0.551438237209305
  - 0.5592697420700878
  - 0.5522414432735869
  - 0.5836043568431521
  - 0.5717098743203244
  - 0.5733157694117648
  - 0.5756117758396175
  - 0.5664543712802453
  - 0.562553450621599
  - 0.567300817649114
  - 0.5736290598442036
  TT_f1_macro:
  - 0.5265577116671838
  - 0.5171007843847587
  - 0.5193939223519739
  - 0.5261945312675745
  - 0.5179542433640795
  - 0.5165735839825247
  - 0.5210182304643407
  - 0.5166739571311266
  - 0.5350047268662746
  - 0.5278958020732547
  - 0.5276258564258479
  - 0.5347720359813354
  - 0.5203137854171058
  - 0.5196813414872123
  - 0.5235894112828986
  - 0.527518810388258
  TT_f1_micro:
  - 0.7951451533541086
  - 0.7942840741348204
  - 0.7865958668197475
  - 0.8002773925104022
  - 0.7814349112426036
  - 0.790680473372781
  - 0.7833045693622617
  - 0.7881088706331425
  - 0.7930226824457595
  - 0.7915228468113084
  - 0.7811061801446417
  - 0.8003277736287445
  - 0.7751684746877053
  - 0.7858933267587114
  - 0.775620479947403
  - 0.7883578126296573
  TT_f1_weighted:
  - 0.8339367306199047
  - 0.8335880855622795
  - 0.8248809264205493
  - 0.8369799231251027
  - 0.8248992633026003
  - 0.8305437672459071
  - 0.8237722703161375
  - 0.8284889842739308
  - 0.8323060869801469
  - 0.8312941369731872
  - 0.8226680237655558
  - 0.8360059697436509
  - 0.8198436533266505
  - 0.8285416108625075
  - 0.8181868978323519
  - 0.8294325270768735
  TT_matthews_corrcoef:
  - 0.089815168296067
  - 0.06850522772369914
  - 0.07119815807924287
  - 0.0852215751306477
  - 0.07793835256645619
  - 0.06801186538520687
  - 0.07902966104883008
  - 0.06903088568220458
  - 0.11065271894777917
  - 0.09469046557157736
  - 0.09691410576934963
  - 0.10300529143437116
  - 0.08579347713187924
  - 0.08078038883944227
  - 0.08896028111120709
  - 0.0963584378596708
  TT_precision_macro:
  - 0.529771383609258
  - 0.5226170429364778
  - 0.52418904723426
  - 0.5286677734404523
  - 0.5251711664990362
  - 0.5224813975173451
  - 0.5263443331595206
  - 0.5228040367927531
  - 0.5366129968367166
  - 0.5312588899197834
  - 0.5320270249239365
  - 0.5350808122996117
  - 0.5276901299966339
  - 0.5260795813668444
  - 0.529397605749182
  - 0.5315261004500215
  TT_precision_micro:
  - 0.7951451533541086
  - 0.7942840741348204
  - 0.7865958668197475
  - 0.8002773925104022
  - 0.7814349112426036
  - 0.790680473372781
  - 0.7833045693622617
  - 0.7881088706331425
  - 0.7930226824457594
  - 0.7915228468113084
  - 0.7811061801446417
  - 0.8003277736287445
  - 0.7751684746877054
  - 0.7858933267587114
  - 0.775620479947403
  - 0.7883578126296573
  TT_precision_weighted:
  - 0.884740038965344
  - 0.884057375735332
  - 0.8743679919150663
  - 0.8842671681820752
  - 0.8826850169932571
  - 0.8819640668791332
  - 0.8770621552177201
  - 0.8808404593848987
  - 0.8851219448456759
  - 0.8840023398474305
  - 0.8788059078298432
  - 0.8826632035458571
  - 0.88037510710508
  - 0.8850204244911983
  - 0.8756929811255121
  - 0.8843633041920345
  TT_recall_macro:
  - 0.5677392472073612
  - 0.5518742242150813
  - 0.5523912503124261
  - 0.5633352018324207
  - 0.5603308035108924
  - 0.551438237209305
  - 0.5592697420700878
  - 0.5522414432735869
  - 0.5836043568431521
  - 0.5717098743203244
  - 0.5733157694117648
  - 0.5756117758396175
  - 0.5664543712802453
  - 0.562553450621599
  - 0.567300817649114
  - 0.5736290598442036
  TT_recall_micro:
  - 0.7951451533541086
  - 0.7942840741348204
  - 0.7865958668197475
  - 0.8002773925104022
  - 0.7814349112426036
  - 0.790680473372781
  - 0.7833045693622617
  - 0.7881088706331425
  - 0.7930226824457594
  - 0.7915228468113084
  - 0.7811061801446417
  - 0.8003277736287445
  - 0.7751684746877054
  - 0.7858933267587114
  - 0.775620479947403
  - 0.7883578126296573
  TT_recall_weighted:
  - 0.7951451533541086
  - 0.7942840741348204
  - 0.7865958668197475
  - 0.8002773925104022
  - 0.7814349112426036
  - 0.790680473372781
  - 0.7833045693622617
  - 0.7881088706331425
  - 0.7930226824457594
  - 0.7915228468113084
  - 0.7811061801446417
  - 0.8003277736287445
  - 0.7751684746877054
  - 0.7858933267587114
  - 0.775620479947403
  - 0.7883578126296573
  TT_roc_auc:
  - 0.5998331338568006
  - 0.5860040843434048
  - 0.5793291496638422
  - 0.5995821853454406
  - 0.5826628969047831
  - 0.5891943623980452
  - 0.577047198382216
  - 0.5798643535902218
  - 0.6170383648160455
  - 0.6040881712432065
  - 0.6039199788943973
  - 0.6109650824345444
  - 0.6001904153475616
  - 0.5961977445872254
  - 0.5928078240355502
  - 0.6001902596927787
  fit_time:
  - 197.13438653945923
  - 176.3552486896515
  - 202.68656015396118
  - 196.36774945259094
  - 207.79115653038025
  - 191.3401141166687
  - 198.3011486530304
  - 179.65671968460083
  - 218.62662410736084
  - 195.13290929794312
  - 174.43475222587585
  - 162.35346913337708
  - 193.6998255252838
  - 187.71230816841125
  - 182.53183817863464
  - 180.0553629398346
  score_time:
  - 2447.878570318222
  - 2254.613225698471
  - 2368.4200451374054
  - 2354.4167363643646
  - 2325.006231546402
  - 2241.3485486507416
  - 2331.2678277492523
  - 2267.954745531082
  - 2370.216035604477
  - 2206.0481951236725
  - 2301.3360974788666
  - 2191.736602306366
  - 2355.3754076957703
  - 2300.7051424980164
  - 2412.013664007187
  - 2302.9529337882996
start: 2023-09-25 03:25:35.137977
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
