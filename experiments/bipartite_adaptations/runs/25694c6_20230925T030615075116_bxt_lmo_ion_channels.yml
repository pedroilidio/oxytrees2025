active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-25 03:06:27.433183
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: bipartite_learn.wrappers.LocalMultiOutputWrapper
      params:
        combine_func_kwargs: null
        combine_predictions_func:
          load: numpy.mean
        independent_labels: false
        primary_cols_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_cols_estimator__bootstrap: false
        primary_cols_estimator__ccp_alpha: 0.0
        primary_cols_estimator__criterion: squared_error
        primary_cols_estimator__max_depth: null
        primary_cols_estimator__max_features: 1.0
        primary_cols_estimator__max_leaf_nodes: null
        primary_cols_estimator__max_samples: null
        primary_cols_estimator__min_impurity_decrease: 0.0
        primary_cols_estimator__min_samples_leaf: 1
        primary_cols_estimator__min_samples_split: 2
        primary_cols_estimator__min_weight_fraction_leaf: 0.0
        primary_cols_estimator__n_estimators: 50
        primary_cols_estimator__n_jobs: 3
        primary_cols_estimator__oob_score: false
        primary_cols_estimator__random_state: 0
        primary_cols_estimator__verbose: 10
        primary_cols_estimator__warm_start: false
        primary_rows_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_rows_estimator__bootstrap: false
        primary_rows_estimator__ccp_alpha: 0.0
        primary_rows_estimator__criterion: squared_error
        primary_rows_estimator__max_depth: null
        primary_rows_estimator__max_features: 1.0
        primary_rows_estimator__max_leaf_nodes: null
        primary_rows_estimator__max_samples: null
        primary_rows_estimator__min_impurity_decrease: 0.0
        primary_rows_estimator__min_samples_leaf: 1
        primary_rows_estimator__min_samples_split: 2
        primary_rows_estimator__min_weight_fraction_leaf: 0.0
        primary_rows_estimator__n_estimators: 50
        primary_rows_estimator__n_jobs: 3
        primary_rows_estimator__oob_score: false
        primary_rows_estimator__random_state: 0
        primary_rows_estimator__verbose: 10
        primary_rows_estimator__warm_start: false
        secondary_cols_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_cols_estimator__bootstrap: false
        secondary_cols_estimator__ccp_alpha: 0.0
        secondary_cols_estimator__criterion: squared_error
        secondary_cols_estimator__max_depth: null
        secondary_cols_estimator__max_features: 1.0
        secondary_cols_estimator__max_leaf_nodes: null
        secondary_cols_estimator__max_samples: null
        secondary_cols_estimator__min_impurity_decrease: 0.0
        secondary_cols_estimator__min_samples_leaf: 1
        secondary_cols_estimator__min_samples_split: 2
        secondary_cols_estimator__min_weight_fraction_leaf: 0.0
        secondary_cols_estimator__n_estimators: 50
        secondary_cols_estimator__n_jobs: 3
        secondary_cols_estimator__oob_score: false
        secondary_cols_estimator__random_state: 0
        secondary_cols_estimator__verbose: 10
        secondary_cols_estimator__warm_start: false
        secondary_rows_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_rows_estimator__bootstrap: false
        secondary_rows_estimator__ccp_alpha: 0.0
        secondary_rows_estimator__criterion: squared_error
        secondary_rows_estimator__max_depth: null
        secondary_rows_estimator__max_features: 1.0
        secondary_rows_estimator__max_leaf_nodes: null
        secondary_rows_estimator__max_samples: null
        secondary_rows_estimator__min_impurity_decrease: 0.0
        secondary_rows_estimator__min_samples_leaf: 1
        secondary_rows_estimator__min_samples_split: 2
        secondary_rows_estimator__min_weight_fraction_leaf: 0.0
        secondary_rows_estimator__n_estimators: 50
        secondary_rows_estimator__n_jobs: 3
        secondary_rows_estimator__oob_score: false
        secondary_rows_estimator__random_state: 0
        secondary_rows_estimator__verbose: 10
        secondary_rows_estimator__warm_start: false
  name: bxt_lmo
  params: {}
hash: 25694c6a288ecb70158d888bc3150b988923fdcad0313a6a457629f426849e06
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/25694c6_20230925T030615075116_bxt_lmo_ion_channels.yml"
results:
  LL_average_precision:
  - 1.0
  - 0.9998399470899471
  - 1.0
  - 0.9998125722216542
  - 1.0
  - 0.9998303302250579
  - 1.0
  - 0.999810691991176
  - 1.0
  - 0.9997706857716627
  - 1.0
  - 0.9997382158402652
  - 1.0
  - 0.9999287850733514
  - 1.0
  - 0.9999180999180999
  LL_balanced_accuracy:
  - 1.0
  - 0.9997624908235091
  - 1.0
  - 0.9997647159479808
  - 1.0
  - 0.9997627469588474
  - 1.0
  - 0.9997647562018819
  - 1.0
  - 0.9997194527169926
  - 1.0
  - 0.9997219489241562
  - 1.0
  - 0.9998491054106489
  - 1.0
  - 0.9998504529140317
  LL_f1_macro:
  - 1.0
  - 0.9967184799944591
  - 1.0
  - 0.9964598038413885
  - 1.0
  - 0.9966249806153942
  - 1.0
  - 0.9964427006434948
  - 1.0
  - 0.996074014309148
  - 1.0
  - 0.99581613181255
  - 1.0
  - 0.9978148366776676
  - 1.0
  - 0.9976627718342639
  LL_f1_micro:
  - 1.0
  - 0.9995420673577287
  - 1.0
  - 0.9995449656655911
  - 1.0
  - 0.9995420673577287
  - 1.0
  - 0.9995449656655911
  - 1.0
  - 0.9994588068773157
  - 1.0
  - 0.9994622321502441
  - 1.0
  - 0.9997085883185546
  - 1.0
  - 0.9997104326962852
  LL_f1_weighted:
  - 1.0
  - 0.9995434612838122
  - 1.0
  - 0.9995464694888759
  - 1.0
  - 0.9995435042175785
  - 1.0
  - 0.9995464772897437
  - 1.0
  - 0.9994607797209035
  - 1.0
  - 0.999464332531526
  - 1.0
  - 0.9997091811215905
  - 1.0
  - 0.9997110661707199
  LL_matthews_corrcoef:
  - 1.0
  - 0.9934583658789553
  - 1.0
  - 0.992944508445281
  - 1.0
  - 0.9932726001023354
  - 1.0
  - 0.9929105423720336
  - 1.0
  - 0.9921786312630287
  - 1.0
  - 0.9916670006753905
  - 1.0
  - 0.9956391844038072
  - 1.0
  - 0.995336421196946
  LL_precision_macro:
  - 1.0
  - 0.9937142857142858
  - 1.0
  - 0.9932014833127318
  - 1.0
  - 0.9935294117647059
  - 1.0
  - 0.993167701863354
  - 1.0
  - 0.992485549132948
  - 1.0
  - 0.9919753086419754
  - 1.0
  - 0.9957983193277311
  - 1.0
  - 0.9954954954954955
  LL_precision_micro:
  - 1.0
  - 0.9995420673577287
  - 1.0
  - 0.9995449656655911
  - 1.0
  - 0.9995420673577287
  - 1.0
  - 0.9995449656655911
  - 1.0
  - 0.9994588068773157
  - 1.0
  - 0.9994622321502441
  - 1.0
  - 0.9997085883185546
  - 1.0
  - 0.9997104326962852
  LL_precision_weighted:
  - 1.0
  - 0.9995478242252315
  - 1.0
  - 0.9995511527826226
  - 1.0
  - 0.9995479935448639
  - 1.0
  - 0.9995511835260613
  - 1.0
  - 0.9994669404155756
  - 1.0
  - 0.9994708629922773
  - 1.0
  - 0.9997110371562138
  - 1.0
  - 0.9997130414107331
  LL_recall_macro:
  - 1.0
  - 0.9997624908235091
  - 1.0
  - 0.9997647159479808
  - 1.0
  - 0.9997627469588474
  - 1.0
  - 0.9997647562018819
  - 1.0
  - 0.9997194527169926
  - 1.0
  - 0.9997219489241562
  - 1.0
  - 0.9998491054106489
  - 1.0
  - 0.9998504529140317
  LL_recall_micro:
  - 1.0
  - 0.9995420673577287
  - 1.0
  - 0.9995449656655911
  - 1.0
  - 0.9995420673577287
  - 1.0
  - 0.9995449656655911
  - 1.0
  - 0.9994588068773157
  - 1.0
  - 0.9994622321502441
  - 1.0
  - 0.9997085883185546
  - 1.0
  - 0.9997104326962852
  LL_recall_weighted:
  - 1.0
  - 0.9995420673577287
  - 1.0
  - 0.9995449656655911
  - 1.0
  - 0.9995420673577287
  - 1.0
  - 0.9995449656655911
  - 1.0
  - 0.9994588068773157
  - 1.0
  - 0.9994622321502441
  - 1.0
  - 0.9997085883185546
  - 1.0
  - 0.9997104326962852
  LL_roc_auc:
  - 1.0
  - 0.9999969761563179
  - 1.0
  - 0.9999967567361251
  - 1.0
  - 0.9999968894118562
  - 1.0
  - 0.9999967409549378
  - 1.0
  - 0.9999957193489681
  - 1.0
  - 0.9999954646625019
  - 1.0
  - 0.9999987212322937
  - 1.0
  - 0.9999986404810367
  LT_average_precision:
  - 0.4489729922682797
  - 0.13195860827533937
  - 0.26541312199154915
  - 0.308484145520052
  - 0.39980787150036345
  - 0.14355390593510992
  - 0.23908999092615105
  - 0.28502078699888
  - 0.41331855268061113
  - 0.12788945675745012
  - 0.21664660295899626
  - 0.29630941373553327
  - 0.44630793576434613
  - 0.1449301085147437
  - 0.2738014449682328
  - 0.33572934387936093
  LT_balanced_accuracy:
  - 0.7418659918231938
  - 0.6474010771463001
  - 0.6517345872518286
  - 0.6901192504258944
  - 0.7671954308745562
  - 0.6821127311457273
  - 0.6412833021152804
  - 0.6925969309323077
  - 0.7515404667633967
  - 0.6751310009390006
  - 0.6552436164669099
  - 0.6954251191029065
  - 0.7613648727510114
  - 0.6626991714467814
  - 0.6810973949888154
  - 0.7175337218438973
  LT_f1_macro:
  - 0.5848247645927911
  - 0.5612925059169194
  - 0.5773107964881057
  - 0.6261640090736931
  - 0.5870174639120602
  - 0.5701213713741067
  - 0.5552625879377818
  - 0.6115070073245286
  - 0.6013002311878883
  - 0.569917169125193
  - 0.5575805523313448
  - 0.6226626067912044
  - 0.5901290729220904
  - 0.5721628040112751
  - 0.5697618623270863
  - 0.6207414620950835
  LT_f1_micro:
  - 0.8848193365396473
  - 0.8883956098162535
  - 0.8906485671191554
  - 0.9141528406234288
  - 0.8771735109137995
  - 0.8803798248859293
  - 0.8717948717948718
  - 0.9042232277526395
  - 0.8912319644839067
  - 0.8862991737575533
  - 0.869281045751634
  - 0.9122674710910005
  - 0.8874090516709828
  - 0.8927118017018127
  - 0.875062845651081
  - 0.9003267973856209
  LT_f1_weighted:
  - 0.9169382969482908
  - 0.9159111379791652
  - 0.9137943936796387
  - 0.9274738190840567
  - 0.9124344929387276
  - 0.9113651371251705
  - 0.9035801458293888
  - 0.922364343064431
  - 0.919575254680307
  - 0.9153217070365535
  - 0.9027942165027221
  - 0.9272255415569871
  - 0.9193065993473409
  - 0.9183776425198898
  - 0.9071326594768183
  - 0.9201773152623461
  LT_matthews_corrcoef:
  - 0.2513264349213877
  - 0.16940226732636057
  - 0.19158240960765738
  - 0.2751704056164848
  - 0.26931711195071206
  - 0.20136000931025527
  - 0.16128872667786648
  - 0.2571862377926037
  - 0.2769721338611837
  - 0.19608907426974598
  - 0.17273596191239055
  - 0.2730560430685832
  - 0.26773195626350255
  - 0.1909275482478231
  - 0.20141495838832502
  - 0.28345440196934896
  LT_precision_macro:
  - 0.5652892293932632
  - 0.5486718427213882
  - 0.5604737198285585
  - 0.5995674451134221
  - 0.5678639100901437
  - 0.5556603773584905
  - 0.546031719537779
  - 0.585859053659014
  - 0.5762437590288162
  - 0.5548888044403953
  - 0.5480498219779599
  - 0.5953812936107391
  - 0.5685635369150852
  - 0.5560133901662933
  - 0.5560029942245666
  - 0.5923378652683766
  LT_precision_micro:
  - 0.8848193365396473
  - 0.8883956098162535
  - 0.8906485671191554
  - 0.9141528406234288
  - 0.8771735109137995
  - 0.8803798248859293
  - 0.8717948717948718
  - 0.9042232277526395
  - 0.8912319644839067
  - 0.8862991737575533
  - 0.869281045751634
  - 0.9122674710910005
  - 0.8874090516709828
  - 0.8927118017018127
  - 0.875062845651081
  - 0.9003267973856209
  LT_precision_weighted:
  - 0.9614442655645153
  - 0.9507992582861976
  - 0.9433183252304549
  - 0.9446666792870121
  - 0.9627503758544592
  - 0.9524349707975169
  - 0.9445223857469356
  - 0.9462917262126801
  - 0.9594903478426633
  - 0.9532422846090165
  - 0.9466783674528079
  - 0.946784573630454
  - 0.9640560999869991
  - 0.9513224590606364
  - 0.9499605233450676
  - 0.947403580265187
  LT_recall_macro:
  - 0.7418659918231938
  - 0.6474010771463001
  - 0.6517345872518286
  - 0.6901192504258944
  - 0.7671954308745562
  - 0.6821127311457273
  - 0.6412833021152804
  - 0.6925969309323077
  - 0.7515404667633967
  - 0.6751310009390006
  - 0.6552436164669099
  - 0.6954251191029065
  - 0.7613648727510114
  - 0.6626991714467814
  - 0.6810973949888154
  - 0.7175337218438973
  LT_recall_micro:
  - 0.8848193365396473
  - 0.8883956098162535
  - 0.8906485671191554
  - 0.9141528406234288
  - 0.8771735109137995
  - 0.8803798248859293
  - 0.8717948717948718
  - 0.9042232277526395
  - 0.8912319644839067
  - 0.8862991737575533
  - 0.869281045751634
  - 0.9122674710910005
  - 0.8874090516709828
  - 0.8927118017018127
  - 0.875062845651081
  - 0.9003267973856209
  LT_recall_weighted:
  - 0.8848193365396473
  - 0.8883956098162535
  - 0.8906485671191554
  - 0.9141528406234288
  - 0.8771735109137995
  - 0.8803798248859293
  - 0.8717948717948718
  - 0.9042232277526395
  - 0.8912319644839067
  - 0.8862991737575533
  - 0.869281045751634
  - 0.9122674710910005
  - 0.8874090516709828
  - 0.8927118017018127
  - 0.875062845651081
  - 0.9003267973856209
  LT_roc_auc:
  - 0.8294064638237467
  - 0.683945601652608
  - 0.6841594827586206
  - 0.7093333870951484
  - 0.8021638682499772
  - 0.6848326988579442
  - 0.6957246133192451
  - 0.7192688409926837
  - 0.7697248112534737
  - 0.6815672520855981
  - 0.6769741494826175
  - 0.7589011056077122
  - 0.8353082561003353
  - 0.6880813392046662
  - 0.7448163709744232
  - 0.7485498379387113
  TL_average_precision:
  - 0.7873511861902955
  - 0.7526085256497366
  - 0.7416099913283352
  - 0.7310394765237095
  - 0.8203359101057571
  - 0.8416192555596681
  - 0.8336362206633804
  - 0.8209507594119128
  - 0.6947151583839764
  - 0.7326621674304516
  - 0.7284020354394022
  - 0.6996823528472131
  - 0.7733356372369989
  - 0.8240076034575925
  - 0.8148349829769839
  - 0.7930571834953646
  TL_balanced_accuracy:
  - 0.9160148829441113
  - 0.8850639670992678
  - 0.8870108055079153
  - 0.8764962194027939
  - 0.923802129646593
  - 0.9248701796433043
  - 0.9216097907098879
  - 0.9248893903336781
  - 0.8747422942643821
  - 0.8852741852043455
  - 0.8853639167219898
  - 0.8707828321263779
  - 0.8866523877069394
  - 0.9129737107815199
  - 0.9108256529770924
  - 0.9081337984161431
  TL_f1_macro:
  - 0.702939490842643
  - 0.7021163376925743
  - 0.7161602382237124
  - 0.716058067772723
  - 0.718472951238909
  - 0.7423387963671786
  - 0.7702221553583071
  - 0.7257233846757201
  - 0.7051879960817432
  - 0.702072328649707
  - 0.7218744384566252
  - 0.7052190668579981
  - 0.7217143580380878
  - 0.7609725757034773
  - 0.7616410736978113
  - 0.7466299478104368
  TL_f1_micro:
  - 0.9246908954664669
  - 0.9304358686149619
  - 0.9353437577562671
  - 0.9408041697691735
  - 0.9266891469963782
  - 0.938928437617085
  - 0.9532141970712336
  - 0.9377016629436585
  - 0.9248157861870863
  - 0.9274384913200949
  - 0.9398113675850087
  - 0.9363365599404319
  - 0.9334332459098289
  - 0.9461720994130136
  - 0.9503598907917598
  - 0.9442789774137503
  TL_f1_weighted:
  - 0.942416903959814
  - 0.9457765960135988
  - 0.9486848249669055
  - 0.9526857114983762
  - 0.9430476950510966
  - 0.9512117766542896
  - 0.961230118798333
  - 0.9513467920924699
  - 0.940514835284473
  - 0.9433927587233834
  - 0.9518188277206394
  - 0.9496497049519077
  - 0.9466808338250567
  - 0.9555529492944418
  - 0.9589404116247623
  - 0.9546932511388089
  TL_matthews_corrcoef:
  - 0.4933254251286425
  - 0.4756840605593717
  - 0.495924513751602
  - 0.48958476893293
  - 0.5192477849720072
  - 0.5514024224805469
  - 0.5882663700877858
  - 0.5270908043747888
  - 0.47670426088884554
  - 0.476532228176275
  - 0.5025012105415915
  - 0.472017445898245
  - 0.5044135007106537
  - 0.572035631489401
  - 0.5711433598958899
  - 0.5487154222645365
  TL_precision_macro:
  - 0.6462507623261227
  - 0.6469076210732017
  - 0.6588722587583751
  - 0.6591604600647232
  - 0.6590472553920208
  - 0.6789044313328093
  - 0.7052000035350126
  - 0.6634688476442528
  - 0.6516021515503511
  - 0.6473515312025142
  - 0.6638110469343251
  - 0.6502230213536175
  - 0.6645101567897354
  - 0.698090553436338
  - 0.6985055796718682
  - 0.6844300911854103
  TL_precision_micro:
  - 0.9246908954664669
  - 0.9304358686149619
  - 0.9353437577562671
  - 0.9408041697691735
  - 0.9266891469963782
  - 0.938928437617085
  - 0.9532141970712336
  - 0.9377016629436585
  - 0.9248157861870863
  - 0.9274384913200949
  - 0.9398113675850087
  - 0.9363365599404319
  - 0.9334332459098289
  - 0.9461720994130136
  - 0.9503598907917598
  - 0.9442789774137503
  TL_precision_weighted:
  - 0.973073422921804
  - 0.9712805863369894
  - 0.9711811159722343
  - 0.972245396861364
  - 0.9723295767388391
  - 0.9735877302040085
  - 0.9759380106151281
  - 0.9754355687301791
  - 0.9668814042361894
  - 0.9701159357144598
  - 0.9719977551267649
  - 0.9713135570728473
  - 0.9693334719509106
  - 0.9726450068748799
  - 0.9743530250480672
  - 0.9731853352706555
  TL_recall_macro:
  - 0.9160148829441113
  - 0.8850639670992678
  - 0.8870108055079153
  - 0.8764962194027939
  - 0.923802129646593
  - 0.9248701796433043
  - 0.9216097907098879
  - 0.9248893903336781
  - 0.8747422942643821
  - 0.8852741852043455
  - 0.8853639167219898
  - 0.8707828321263779
  - 0.8866523877069394
  - 0.9129737107815199
  - 0.9108256529770924
  - 0.9081337984161431
  TL_recall_micro:
  - 0.9246908954664669
  - 0.9304358686149619
  - 0.9353437577562671
  - 0.9408041697691735
  - 0.9266891469963782
  - 0.938928437617085
  - 0.9532141970712336
  - 0.9377016629436585
  - 0.9248157861870863
  - 0.9274384913200949
  - 0.9398113675850087
  - 0.9363365599404319
  - 0.9334332459098289
  - 0.9461720994130136
  - 0.9503598907917598
  - 0.9442789774137503
  TL_recall_weighted:
  - 0.9246908954664669
  - 0.9304358686149619
  - 0.9353437577562671
  - 0.9408041697691735
  - 0.9266891469963782
  - 0.938928437617085
  - 0.9532141970712336
  - 0.9377016629436585
  - 0.9248157861870863
  - 0.9274384913200949
  - 0.9398113675850087
  - 0.9363365599404319
  - 0.9334332459098289
  - 0.9461720994130136
  - 0.9503598907917598
  - 0.9442789774137503
  TL_roc_auc:
  - 0.9439758501715483
  - 0.9166343426923923
  - 0.9219399098011816
  - 0.895893233623066
  - 0.9548473366012341
  - 0.9568783647133337
  - 0.9439762979599894
  - 0.9513839760666276
  - 0.8962671361919305
  - 0.9080372007712929
  - 0.9037508105479304
  - 0.886652160503717
  - 0.9124719825927063
  - 0.9389585541059173
  - 0.9313648192475577
  - 0.933609580402895
  TT_average_precision:
  - 0.3489451593571329
  - 0.11664836404517995
  - 0.16438296300461502
  - 0.24460232115721525
  - 0.4159867042788761
  - 0.1307658616136493
  - 0.2877889706978151
  - 0.3820132215837841
  - 0.2638998606672963
  - 0.11920879565027753
  - 0.17638981617377164
  - 0.3013856110978991
  - 0.5358627429397161
  - 0.08982274781751247
  - 0.19889979173418496
  - 0.22175712040216472
  TT_balanced_accuracy:
  - 0.7267761650114591
  - 0.6341497640005103
  - 0.6252332814930015
  - 0.6704209483323478
  - 0.8013885357516173
  - 0.6800607008185413
  - 0.6643620196364983
  - 0.722841676040495
  - 0.7006648393304952
  - 0.641502448546859
  - 0.5982680250783698
  - 0.6586724840855447
  - 0.7984921517735757
  - 0.6355233002291826
  - 0.6204386112513322
  - 0.6387142111698096
  TT_f1_macro:
  - 0.5802890405459655
  - 0.5631453435804702
  - 0.5457489878542511
  - 0.5959923029083942
  - 0.6008343639820575
  - 0.5708693292431748
  - 0.5704429268890882
  - 0.6302149310974713
  - 0.5680271013719864
  - 0.573185528871497
  - 0.5533989646551638
  - 0.6008863819500403
  - 0.6353839275113737
  - 0.5486102545595193
  - 0.5507740992902886
  - 0.5951768534153196
  TT_f1_micro:
  - 0.8786533481317055
  - 0.8941916389197189
  - 0.8838612368024132
  - 0.9038461538461539
  - 0.8816130225675176
  - 0.8886422493525711
  - 0.8804675716440422
  - 0.9023378582202112
  - 0.8990011098779135
  - 0.901590825009249
  - 0.8925339366515838
  - 0.9042232277526395
  - 0.9012208657047724
  - 0.878283388827229
  - 0.8672699849170438
  - 0.9144042232277526
  TT_f1_weighted:
  - 0.911906763720463
  - 0.9181091358205572
  - 0.9140076086491901
  - 0.9225966475749764
  - 0.9155492168561882
  - 0.9174685976514031
  - 0.9092270704251277
  - 0.9206388726596743
  - 0.927957838432743
  - 0.9223672039298152
  - 0.9132254256396821
  - 0.9199673546974113
  - 0.9252936213730655
  - 0.910108977113679
  - 0.8979811759751654
  - 0.9267395483457701
  TT_matthews_corrcoef:
  - 0.2390001101656934
  - 0.16325348490904626
  - 0.13854160442169164
  - 0.22454265125922787
  - 0.3042652499370113
  - 0.19954762281013308
  - 0.1917665227363593
  - 0.2988843222569351
  - 0.20437059994796095
  - 0.1791219000720786
  - 0.1302493102755581
  - 0.22483542769457265
  - 0.34540219158911784
  - 0.14887100884918142
  - 0.14400620442981943
  - 0.20585559629200156
  TT_precision_macro:
  - 0.5629707410568559
  - 0.5496678106993294
  - 0.5383160449181577
  - 0.5739630349553586
  - 0.576792355495837
  - 0.5552858752467363
  - 0.5559350623150722
  - 0.6002189532925991
  - 0.5520361990950227
  - 0.5566856888607246
  - 0.5431597226405255
  - 0.5796467166912003
  - 0.5999211145466431
  - 0.5408833337852127
  - 0.5430463841678794
  - 0.5763738015149354
  TT_precision_micro:
  - 0.8786533481317055
  - 0.8941916389197189
  - 0.8838612368024132
  - 0.9038461538461539
  - 0.8816130225675176
  - 0.8886422493525712
  - 0.8804675716440422
  - 0.9023378582202112
  - 0.8990011098779135
  - 0.901590825009249
  - 0.8925339366515838
  - 0.9042232277526395
  - 0.9012208657047724
  - 0.878283388827229
  - 0.8672699849170438
  - 0.9144042232277526
  TT_precision_weighted:
  - 0.9578468120299889
  - 0.9478508700671913
  - 0.9515111592058569
  - 0.9466368803996057
  - 0.9654272350889832
  - 0.9551559088668324
  - 0.9468347873483034
  - 0.9459044863577463
  - 0.9655335198196072
  - 0.9481786416884733
  - 0.9379364842788273
  - 0.939760801956447
  - 0.9612224359687543
  - 0.95038709009639
  - 0.9369538632870132
  - 0.9415780468813447
  TT_recall_macro:
  - 0.7267761650114591
  - 0.6341497640005103
  - 0.6252332814930015
  - 0.6704209483323478
  - 0.8013885357516173
  - 0.6800607008185413
  - 0.6643620196364983
  - 0.722841676040495
  - 0.7006648393304952
  - 0.641502448546859
  - 0.5982680250783698
  - 0.6586724840855447
  - 0.7984921517735757
  - 0.6355233002291826
  - 0.6204386112513322
  - 0.6387142111698096
  TT_recall_micro:
  - 0.8786533481317055
  - 0.8941916389197189
  - 0.8838612368024132
  - 0.9038461538461539
  - 0.8816130225675176
  - 0.8886422493525712
  - 0.8804675716440422
  - 0.9023378582202112
  - 0.8990011098779135
  - 0.901590825009249
  - 0.8925339366515838
  - 0.9042232277526395
  - 0.9012208657047724
  - 0.878283388827229
  - 0.8672699849170438
  - 0.9144042232277526
  TT_recall_weighted:
  - 0.8786533481317055
  - 0.8941916389197189
  - 0.8838612368024132
  - 0.9038461538461539
  - 0.8816130225675176
  - 0.8886422493525712
  - 0.8804675716440422
  - 0.9023378582202112
  - 0.8990011098779135
  - 0.901590825009249
  - 0.8925339366515838
  - 0.9042232277526395
  - 0.9012208657047724
  - 0.878283388827229
  - 0.8672699849170438
  - 0.9144042232277526
  TT_roc_auc:
  - 0.843717700984137
  - 0.7477526895437343
  - 0.6866956648522551
  - 0.6475196969939111
  - 0.8423194997692837
  - 0.7225719672583464
  - 0.7175616985365251
  - 0.7812851518560181
  - 0.7437044380941273
  - 0.6674625145145819
  - 0.6653977272727273
  - 0.6968224733566983
  - 0.8721151073208916
  - 0.7171078056891206
  - 0.728257333557687
  - 0.7110117426594097
  fit_time:
  - 0.8113982677459717
  - 0.7491486072540283
  - 0.9048314094543457
  - 0.7733216285705566
  - 0.7960107326507568
  - 0.8084447383880615
  - 0.8293321132659912
  - 0.8869359493255615
  - 0.8479089736938477
  - 0.9316401481628418
  - 0.7594993114471436
  - 0.842618465423584
  - 0.8065946102142334
  - 0.8457658290863037
  - 0.7550363540649414
  - 0.8644263744354248
  score_time:
  - 11.05295729637146
  - 10.501423120498657
  - 11.411540746688843
  - 10.429449081420898
  - 11.257185697555542
  - 10.905345916748047
  - 9.995936155319214
  - 11.419265747070312
  - 11.089721918106079
  - 10.722106695175171
  - 9.478610038757324
  - 11.255872249603271
  - 10.528650522232056
  - 11.143928289413452
  - 10.103364706039429
  - 10.638967275619507
start: 2023-09-25 03:06:15.075116
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
