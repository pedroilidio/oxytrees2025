active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-25 02:26:37.242911
estimator:
  call: bipartite_adaptations.estimators.brf_gso
  final_params:
    estimator:
      call: bipartite_learn.ensemble._forest.BipartiteRandomForestRegressor
      params:
        bipartite_adapter: gmosa
        bootstrap: true
        ccp_alpha: 0.0
        criterion: squared_error_gso
        max_col_features: 0.5
        max_depth: null
        max_features: 1.0
        max_leaf_nodes: null
        max_row_features: 0.5
        max_samples: null
        min_col_weight_fraction_leaf: 0.0
        min_cols_leaf: 1
        min_cols_split: 1
        min_impurity_decrease: 0.0
        min_row_weight_fraction_leaf: 0.0
        min_rows_leaf: 1
        min_rows_split: 1
        min_samples_leaf: 1
        min_samples_split: 2
        min_weight_fraction_leaf: 0.0
        n_estimators: 100
        n_jobs: 3
        oob_score: false
        prediction_weights: null
        random_state: 0
        verbose: 10
        warm_start: false
  name: brf_gso
  params: {}
hash: d339d2968edc4f44f35e87c61c831fadf812ae8abb5b94effe481b7ba6587a5a
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/d339d29_20230925T022636567666_brf_gso_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9805675667575002
  - 1.0
  - 0.9999999999999999
  - 0.9815723273143995
  - 0.9730812111502126
  - 1.0
  - 1.0
  - 0.9684639239475392
  - 0.9795246650609837
  - 1.0
  - 1.0
  - 0.9785862888652774
  - 0.9920860744996203
  - 1.0
  - 0.9999999999999999
  - 0.9816314570582626
  LL_balanced_accuracy:
  - 0.9235127478753541
  - 0.9175977653631284
  - 0.9144827586206896
  - 0.9302486187845305
  - 0.9200278164116829
  - 0.9078404401650619
  - 0.9308943089430894
  - 0.9190476190476191
  - 0.9352226720647774
  - 0.9259259259259259
  - 0.9311688311688311
  - 0.9342105263157895
  - 0.924119241192412
  - 0.9313333333333333
  - 0.9204993429697765
  - 0.918421052631579
  LL_f1_macro:
  - 0.7085889570552147
  - 0.6686911675606981
  - 0.686001456285432
  - 0.7231727869902222
  - 0.6646599982350527
  - 0.6142424242424243
  - 0.6857081830263908
  - 0.6685189356962278
  - 0.7410688999474045
  - 0.68
  - 0.7057588929059864
  - 0.737516005121639
  - 0.7216561459317063
  - 0.7094407086261553
  - 0.703678484286478
  - 0.7014890318944056
  LL_f1_micro:
  - 0.8578947368421053
  - 0.8447368421052631
  - 0.8408215661103978
  - 0.8703465982028241
  - 0.8486842105263158
  - 0.8236842105263158
  - 0.8690629011553274
  - 0.8472400513478819
  - 0.88
  - 0.8599999999999999
  - 0.8707317073170732
  - 0.8780487804878049
  - 0.8599999999999999
  - 0.8712500000000001
  - 0.8524390243902439
  - 0.8487804878048779
  LL_f1_weighted:
  - 0.8875363254762674
  - 0.8822339352393042
  - 0.8759178981365329
  - 0.8965165892811213
  - 0.886273525647977
  - 0.8738006379585326
  - 0.9004951385488593
  - 0.8844215421914952
  - 0.9027600436946231
  - 0.8936
  - 0.8992123560590524
  - 0.9014709097154991
  - 0.8874725383965405
  - 0.8991668459154205
  - 0.8834201351519575
  - 0.8804890651189381
  LL_matthews_corrcoef:
  - 0.5313584777877386
  - 0.476280621658729
  - 0.501481725450557
  - 0.5507998151074719
  - 0.4698764222818564
  - 0.401475340969469
  - 0.49707770729157336
  - 0.47564093326788176
  - 0.5756134192412514
  - 0.49016926355349294
  - 0.5257283294537934
  - 0.5706644326895116
  - 0.549768947851894
  - 0.5309587661287608
  - 0.5250339802253736
  - 0.5223823266483161
  LL_precision_macro:
  - 0.6666666666666666
  - 0.6358024691358024
  - 0.651685393258427
  - 0.6762820512820513
  - 0.6314102564102564
  - 0.5988023952095809
  - 0.6433566433566433
  - 0.6349693251533742
  - 0.6903225806451613
  - 0.641025641025641
  - 0.6602564102564102
  - 0.6875
  - 0.6781609195402298
  - 0.6633986928104575
  - 0.6638888888888889
  - 0.6630434782608696
  LL_precision_micro:
  - 0.8578947368421053
  - 0.8447368421052631
  - 0.8408215661103979
  - 0.8703465982028241
  - 0.8486842105263158
  - 0.8236842105263158
  - 0.8690629011553274
  - 0.8472400513478819
  - 0.88
  - 0.86
  - 0.8707317073170732
  - 0.8780487804878049
  - 0.86
  - 0.87125
  - 0.8524390243902439
  - 0.848780487804878
  LL_precision_weighted:
  - 0.9526315789473684
  - 0.9578297595841455
  - 0.9517099133143904
  - 0.9542888647509957
  - 0.9602311066126855
  - 0.9651591553734635
  - 0.9624585940375414
  - 0.958764185639919
  - 0.9543225806451613
  - 0.9605128205128206
  - 0.9585678549093183
  - 0.9542682926829268
  - 0.9501149425287356
  - 0.9579248366013071
  - 0.9516327913279132
  - 0.9506892895015907
  LL_recall_macro:
  - 0.9235127478753541
  - 0.9175977653631284
  - 0.9144827586206896
  - 0.9302486187845305
  - 0.9200278164116829
  - 0.9078404401650619
  - 0.9308943089430894
  - 0.9190476190476191
  - 0.9352226720647774
  - 0.9259259259259259
  - 0.9311688311688311
  - 0.9342105263157895
  - 0.924119241192412
  - 0.9313333333333333
  - 0.9204993429697765
  - 0.918421052631579
  LL_recall_micro:
  - 0.8578947368421053
  - 0.8447368421052631
  - 0.8408215661103979
  - 0.8703465982028241
  - 0.8486842105263158
  - 0.8236842105263158
  - 0.8690629011553274
  - 0.8472400513478819
  - 0.88
  - 0.86
  - 0.8707317073170732
  - 0.8780487804878049
  - 0.86
  - 0.87125
  - 0.8524390243902439
  - 0.848780487804878
  LL_recall_weighted:
  - 0.8578947368421053
  - 0.8447368421052631
  - 0.8408215661103979
  - 0.8703465982028241
  - 0.8486842105263158
  - 0.8236842105263158
  - 0.8690629011553274
  - 0.8472400513478819
  - 0.88
  - 0.86
  - 0.8707317073170732
  - 0.8780487804878049
  - 0.86
  - 0.87125
  - 0.8524390243902439
  - 0.848780487804878
  LL_roc_auc:
  - 0.9987278354842094
  - 1.0
  - 1.0
  - 0.9988573581115017
  - 0.9986431018691272
  - 1.0
  - 1.0
  - 0.9984230055658627
  - 0.9985589789336444
  - 1.0
  - 1.0
  - 0.9984868421052631
  - 0.9993989859253432
  - 1.0
  - 1.0
  - 0.9988706140350877
  LT_average_precision:
  - 0.22008986914634984
  - 0.3074370368588491
  - 0.2362046722884108
  - 0.40971579153342486
  - 0.19081582567718502
  - 0.3298192785886284
  - 0.15689721903424264
  - 0.2967634002517724
  - 0.28203804883423134
  - 0.3492503578506926
  - 0.28248348865353967
  - 0.43218466392953203
  - 0.3200751988372024
  - 0.3661558236053341
  - 0.35533712546980406
  - 0.42011554029609477
  LT_balanced_accuracy:
  - 0.6764940239043824
  - 0.6666390041493776
  - 0.6728448275862069
  - 0.802728387492336
  - 0.6043307086614174
  - 0.5808943089430895
  - 0.5679078014184398
  - 0.7556022408963585
  - 0.7101990049751243
  - 0.6979944371248719
  - 0.6552102012353058
  - 0.8254837531945967
  - 0.7459119496855346
  - 0.7053872053872055
  - 0.7392102846648301
  - 0.7959331880900509
  LT_f1_macro:
  - 0.5284179789341954
  - 0.5931521184962567
  - 0.5293583091490048
  - 0.6114858960466986
  - 0.4743083003952569
  - 0.5491525423728814
  - 0.47143317796734385
  - 0.5701357466063348
  - 0.5191835933666961
  - 0.6493624772313297
  - 0.5627360701386783
  - 0.6877047390259883
  - 0.5498817966903073
  - 0.6192657267587491
  - 0.5700258397932816
  - 0.6292162698412698
  LT_f1_micro:
  - 0.7443609022556391
  - 0.7857142857142857
  - 0.7368421052631579
  - 0.8178137651821861
  - 0.6992481203007519
  - 0.8195488721804511
  - 0.7044534412955465
  - 0.8380566801619433
  - 0.75
  - 0.8428571428571429
  - 0.7653846153846153
  - 0.9153846153846154
  - 0.7571428571428571
  - 0.7964285714285714
  - 0.7538461538461538
  - 0.823076923076923
  LT_f1_weighted:
  - 0.8115431450667548
  - 0.8204386109503237
  - 0.8038947954707806
  - 0.8625181368282085
  - 0.7871556361258878
  - 0.845800943035555
  - 0.7882839018831317
  - 0.8847710993459981
  - 0.8237660680993033
  - 0.8596018735362998
  - 0.8123258038314145
  - 0.9317939758428948
  - 0.8225937183383992
  - 0.828892967048696
  - 0.8122361359570661
  - 0.862261523199023
  LT_matthews_corrcoef:
  - 0.18407550924807106
  - 0.23552635911405947
  - 0.18483960574817151
  - 0.34102508185964087
  - 0.09443830174873792
  - 0.11935656211564653
  - 0.06451916104544005
  - 0.25261263815776364
  - 0.19309418777829962
  - 0.3182621107574508
  - 0.19848624494037911
  - 0.4295319607154953
  - 0.2500752047236783
  - 0.29202594129147247
  - 0.27139922691961177
  - 0.3582556024644254
  LT_precision_macro:
  - 0.5479956663055254
  - 0.5832228116710876
  - 0.5494166940519225
  - 0.5960416261427738
  - 0.5213709677419355
  - 0.5440265486725664
  - 0.5153249039692701
  - 0.5624145006839946
  - 0.5443453161899764
  - 0.6278959810874705
  - 0.5634571521668296
  - 0.6417103799078048
  - 0.5635772357723577
  - 0.603802900266351
  - 0.5769799054373522
  - 0.6084257206208425
  LT_precision_micro:
  - 0.7443609022556391
  - 0.7857142857142857
  - 0.7368421052631579
  - 0.8178137651821862
  - 0.6992481203007519
  - 0.8195488721804511
  - 0.7044534412955465
  - 0.8380566801619433
  - 0.75
  - 0.8428571428571429
  - 0.7653846153846153
  - 0.9153846153846154
  - 0.7571428571428571
  - 0.7964285714285714
  - 0.7538461538461538
  - 0.823076923076923
  LT_precision_weighted:
  - 0.9217230508557418
  - 0.8748105342932929
  - 0.9158249303837973
  - 0.9404962250763294
  - 0.9274678632064032
  - 0.8788009847627919
  - 0.916997892766981
  - 0.9544769795687789
  - 0.943190763579113
  - 0.8835866261398176
  - 0.8871349976188686
  - 0.957897117982955
  - 0.9358188153310104
  - 0.8828631674629012
  - 0.9185147299509002
  - 0.9318335323213373
  LT_recall_macro:
  - 0.6764940239043824
  - 0.6666390041493776
  - 0.6728448275862069
  - 0.802728387492336
  - 0.6043307086614174
  - 0.5808943089430895
  - 0.5679078014184398
  - 0.7556022408963585
  - 0.7101990049751243
  - 0.6979944371248719
  - 0.6552102012353058
  - 0.8254837531945967
  - 0.7459119496855346
  - 0.7053872053872055
  - 0.7392102846648301
  - 0.7959331880900509
  LT_recall_micro:
  - 0.7443609022556391
  - 0.7857142857142857
  - 0.7368421052631579
  - 0.8178137651821862
  - 0.6992481203007519
  - 0.8195488721804511
  - 0.7044534412955465
  - 0.8380566801619433
  - 0.75
  - 0.8428571428571429
  - 0.7653846153846153
  - 0.9153846153846154
  - 0.7571428571428571
  - 0.7964285714285714
  - 0.7538461538461538
  - 0.823076923076923
  LT_recall_weighted:
  - 0.7443609022556391
  - 0.7857142857142857
  - 0.7368421052631579
  - 0.8178137651821862
  - 0.6992481203007519
  - 0.8195488721804511
  - 0.7044534412955465
  - 0.8380566801619433
  - 0.75
  - 0.8428571428571429
  - 0.7653846153846153
  - 0.9153846153846154
  - 0.7571428571428571
  - 0.7964285714285714
  - 0.7538461538461538
  - 0.823076923076923
  LT_roc_auc:
  - 0.7224435590969456
  - 0.7189211618257262
  - 0.7172413793103448
  - 0.8286327406499081
  - 0.7249015748031497
  - 0.6865853658536585
  - 0.650354609929078
  - 0.7735760971055088
  - 0.763681592039801
  - 0.7488654662567705
  - 0.7257421797170751
  - 0.862175976633808
  - 0.800503144654088
  - 0.7790221051090617
  - 0.7688246097337006
  - 0.8435003631082062
  TL_average_precision:
  - 0.30227081471367223
  - 0.4267499841199263
  - 0.47263044418050426
  - 0.3859819662923596
  - 0.46595150777760974
  - 0.3556241067950905
  - 0.3965377610299572
  - 0.44361115522165917
  - 0.08242584320553463
  - 0.12654663627980275
  - 0.17723736871073598
  - 0.1541686898299794
  - 0.23852093545148526
  - 0.3060355841149819
  - 0.2728705032148361
  - 0.3026330109218951
  TL_balanced_accuracy:
  - 0.7196776929601357
  - 0.7159320080668395
  - 0.7692307692307692
  - 0.6922759190417183
  - 0.6899209742194585
  - 0.6243489583333334
  - 0.6445868945868946
  - 0.6289762095696338
  - 0.5447305997966791
  - 0.49305320230430366
  - 0.5833333333333333
  - 0.507923407065038
  - 0.5760869565217391
  - 0.5055180870631515
  - 0.630098452883263
  - 0.5633872565203037
  TL_f1_macro:
  - 0.5951507062618173
  - 0.5591836734693878
  - 0.5870960602036299
  - 0.5811351351351352
  - 0.6134884638138434
  - 0.5708639186900056
  - 0.5783287419651055
  - 0.5614468423586545
  - 0.4638868205510052
  - 0.43931623931623937
  - 0.4781241420620461
  - 0.45246422893481714
  - 0.44224196855775805
  - 0.4426306755073878
  - 0.46883753501400566
  - 0.454260733394232
  TL_f1_micro:
  - 0.8142857142857143
  - 0.8071428571428572
  - 0.818815331010453
  - 0.8118466898954704
  - 0.775
  - 0.7964285714285714
  - 0.7770034843205574
  - 0.7456445993031359
  - 0.6875
  - 0.6583333333333333
  - 0.6544715447154471
  - 0.6869918699186992
  - 0.6458333333333334
  - 0.7125
  - 0.6991869918699187
  - 0.6544715447154471
  TL_f1_weighted:
  - 0.8547086769308991
  - 0.8590962099125365
  - 0.8662369492220818
  - 0.8530064977869857
  - 0.8080161703805955
  - 0.8286520932483665
  - 0.8133095286088634
  - 0.7882279517150322
  - 0.7726172747580045
  - 0.751780626780627
  - 0.7370958522523554
  - 0.7729367818320472
  - 0.7511392116655276
  - 0.8078430547608629
  - 0.7930330668852908
  - 0.7498740118550866
  TL_matthews_corrcoef:
  - 0.2693920841371534
  - 0.22567552770149946
  - 0.2888472858910396
  - 0.23527039446562292
  - 0.2779464034031397
  - 0.1777243306822527
  - 0.20395445587101618
  - 0.17933414183464952
  - 0.04418739844798596
  - -0.006736899787238605
  - 0.09127041490644167
  - 0.007792032016777299
  - 0.06358121377410184
  - 0.004159095883467085
  - 0.10611306732237606
  - 0.05981146464293607
  TL_precision_macro:
  - 0.5825892857142857
  - 0.5589646762646527
  - 0.5774732720975757
  - 0.5719696969696969
  - 0.60169256381798
  - 0.563502618236223
  - 0.5719246031746031
  - 0.5623385012919897
  - 0.5109126984126984
  - 0.4983666640108358
  - 0.5249908659115821
  - 0.5019157088122606
  - 0.5132827324478179
  - 0.5007836990595611
  - 0.5216374269005848
  - 0.5141093474426808
  TL_precision_micro:
  - 0.8142857142857143
  - 0.8071428571428572
  - 0.818815331010453
  - 0.8118466898954704
  - 0.775
  - 0.7964285714285714
  - 0.7770034843205574
  - 0.7456445993031359
  - 0.6875
  - 0.6583333333333333
  - 0.6544715447154471
  - 0.6869918699186992
  - 0.6458333333333334
  - 0.7125
  - 0.6991869918699187
  - 0.6544715447154471
  TL_precision_weighted:
  - 0.9191007653061224
  - 0.9387071939939535
  - 0.9430147531410564
  - 0.9160218411089491
  - 0.8640607658157603
  - 0.8740705558260209
  - 0.8687157789945247
  - 0.8558846302748742
  - 0.9045552248677248
  - 0.896423259766818
  - 0.8827664257643673
  - 0.9010995857085008
  - 0.9298703352308666
  - 0.9438196621386277
  - 0.9433176437027528
  - 0.9100027243658679
  TL_recall_macro:
  - 0.7196776929601357
  - 0.7159320080668395
  - 0.7692307692307692
  - 0.6922759190417183
  - 0.6899209742194585
  - 0.6243489583333334
  - 0.6445868945868946
  - 0.6289762095696338
  - 0.5447305997966791
  - 0.49305320230430366
  - 0.5833333333333333
  - 0.507923407065038
  - 0.5760869565217391
  - 0.5055180870631515
  - 0.630098452883263
  - 0.5633872565203037
  TL_recall_micro:
  - 0.8142857142857143
  - 0.8071428571428572
  - 0.818815331010453
  - 0.8118466898954704
  - 0.775
  - 0.7964285714285714
  - 0.7770034843205574
  - 0.7456445993031359
  - 0.6875
  - 0.6583333333333333
  - 0.6544715447154471
  - 0.6869918699186992
  - 0.6458333333333334
  - 0.7125
  - 0.6991869918699187
  - 0.6544715447154471
  TL_recall_weighted:
  - 0.8142857142857143
  - 0.8071428571428572
  - 0.818815331010453
  - 0.8118466898954704
  - 0.775
  - 0.7964285714285714
  - 0.7770034843205574
  - 0.7456445993031359
  - 0.6875
  - 0.6583333333333333
  - 0.6544715447154471
  - 0.6869918699186992
  - 0.6458333333333334
  - 0.7125
  - 0.6991869918699187
  - 0.6544715447154471
  TL_roc_auc:
  - 0.7785199321458864
  - 0.7221261884183232
  - 0.8680010465724751
  - 0.7018793886823627
  - 0.7162844928099494
  - 0.7027994791666667
  - 0.697008547008547
  - 0.6949345094894412
  - 0.6211453744493393
  - 0.5086411385970857
  - 0.6883528265107213
  - 0.5683393859359525
  - 0.6034782608695652
  - 0.5199264255058247
  - 0.6249413970932958
  - 0.5894684714427204
  TT_average_precision:
  - 0.062402382768515494
  - 0.21167814520349082
  - 0.13833180271680579
  - 0.4722222222222222
  - 0.07550453369134102
  - 0.1942919483617158
  - 0.29403177826314475
  - 0.20492979242979242
  - 0.14503805069842804
  - 0.17483038312233945
  - 0.023255813953488372
  - 0.1820403223335478
  - 0.04266081871345029
  - 0.09266440034397665
  - 0.05007703849039183
  - -0.0
  TT_balanced_accuracy:
  - 0.5719298245614035
  - 0.46805555555555556
  - 0.4464285714285714
  - 0.7878787878787878
  - 0.49275362318840576
  - 0.5239819004524887
  - 0.6203703703703703
  - 0.5022590361445782
  - 0.6282051282051282
  - 0.8012820512820513
  - 0.3051948051948052
  - 0.625
  - 0.30246913580246915
  - 0.4358974358974359
  - 0.30405405405405406
  - 0.6794871794871795
  TT_f1_macro:
  - 0.48798328108672934
  - 0.4678733031674208
  - 0.44624746450304253
  - 0.6272189349112425
  - 0.4346153846153846
  - 0.5251937984496124
  - 0.549847792998478
  - 0.5004843396835648
  - 0.5285714285714286
  - 0.6040684693624411
  - 0.37599999999999995
  - 0.5297157622739018
  - 0.3684210526315789
  - 0.4318840579710145
  - 0.36585365853658536
  - 0.40458015267175573
  TT_f1_micro:
  - 0.7959183673469388
  - 0.7551020408163265
  - 0.7032967032967034
  - 0.9010989010989011
  - 0.6326530612244898
  - 0.7959183673469388
  - 0.7142857142857143
  - 0.8131868131868132
  - 0.7380952380952381
  - 0.7738095238095238
  - 0.6025641025641025
  - 0.7307692307692306
  - 0.5833333333333334
  - 0.6666666666666666
  - 0.5769230769230769
  - 0.6794871794871795
  TT_f1_weighted:
  - 0.8607468065596143
  - 0.7949949210453412
  - 0.7654860352629113
  - 0.9256778724234344
  - 0.7282574568288854
  - 0.7886014871064706
  - 0.7621222004783649
  - 0.8262160829161151
  - 0.7979591836734695
  - 0.8262749406386221
  - 0.7423589743589742
  - 0.7899026038560922
  - 0.7105263157894737
  - 0.744927536231884
  - 0.6941838649155723
  - 0.8091603053435115
  TT_matthews_corrcoef:
  - 0.06268607538089263
  - -0.0451762665758072
  - -0.06668313367115805
  - 0.3286995542015319
  - -0.007299464530922297
  - 0.051539329191042996
  - 0.16666666666666666
  - 0.0039246043326148705
  - 0.15019349877480084
  - 0.34801450568554326
  - -0.0900937462695559
  - 0.15018785229652767
  - -0.15097027121927944
  - -0.07308816827558577
  - -0.1788607694502003
  - 0.0
  TT_precision_macro:
  - 0.513657561625583
  - 0.4840277777777778
  - 0.47924901185770746
  - 0.5938271604938271
  - 0.49816176470588236
  - 0.5276907001044933
  - 0.5576923076923077
  - 0.5017045454545455
  - 0.5439882697947214
  - 0.6004989308624377
  - 0.4895833333333333
  - 0.5451127819548872
  - 0.47115384615384615
  - 0.47916666666666663
  - 0.45918367346938777
  - 0.5
  TT_precision_micro:
  - 0.7959183673469388
  - 0.7551020408163265
  - 0.7032967032967034
  - 0.9010989010989011
  - 0.6326530612244898
  - 0.7959183673469388
  - 0.7142857142857143
  - 0.8131868131868132
  - 0.7380952380952381
  - 0.7738095238095238
  - 0.6025641025641025
  - 0.7307692307692307
  - 0.5833333333333334
  - 0.6666666666666666
  - 0.5769230769230769
  - 0.6794871794871795
  TT_precision_weighted:
  - 0.946457463731662
  - 0.8425453514739228
  - 0.8463058680449983
  - 0.9616876950210281
  - 0.883703481392557
  - 0.7818011217025996
  - 0.8427726120033813
  - 0.8402722277722278
  - 0.8933808127356515
  - 0.9288768964463904
  - 0.9666132478632478
  - 0.8854829381145171
  - 0.9086538461538461
  - 0.8541666666666666
  - 0.8712715855572998
  - 1.0
  TT_recall_macro:
  - 0.5719298245614035
  - 0.46805555555555556
  - 0.4464285714285714
  - 0.7878787878787878
  - 0.49275362318840576
  - 0.5239819004524887
  - 0.6203703703703703
  - 0.5022590361445782
  - 0.6282051282051282
  - 0.8012820512820513
  - 0.3051948051948052
  - 0.625
  - 0.30246913580246915
  - 0.4358974358974359
  - 0.30405405405405406
  - 0.33974358974358976
  TT_recall_micro:
  - 0.7959183673469388
  - 0.7551020408163265
  - 0.7032967032967034
  - 0.9010989010989011
  - 0.6326530612244898
  - 0.7959183673469388
  - 0.7142857142857143
  - 0.8131868131868132
  - 0.7380952380952381
  - 0.7738095238095238
  - 0.6025641025641025
  - 0.7307692307692307
  - 0.5833333333333334
  - 0.6666666666666666
  - 0.5769230769230769
  - 0.6794871794871795
  TT_recall_weighted:
  - 0.7959183673469388
  - 0.7551020408163265
  - 0.7032967032967034
  - 0.9010989010989011
  - 0.6326530612244898
  - 0.7959183673469388
  - 0.7142857142857143
  - 0.8131868131868132
  - 0.7380952380952381
  - 0.7738095238095238
  - 0.6025641025641025
  - 0.7307692307692307
  - 0.5833333333333334
  - 0.6666666666666667
  - 0.5769230769230769
  - 0.6794871794871795
  TT_roc_auc:
  - 0.6719298245614035
  - 0.5993055555555555
  - 0.6130952380952381
  - 0.9318181818181818
  - 0.5516304347826088
  - 0.6497737556561086
  - 0.6790123456790124
  - 0.4789156626506024
  - 0.719017094017094
  - 0.7670940170940171
  - 0.49350649350649356
  - 0.6875
  - 0.4794238683127572
  - 0.532051282051282
  - 0.4375
  - .nan
  fit_time:
  - 0.2651388645172119
  - 0.2472822666168213
  - 0.2689645290374756
  - 0.24935531616210938
  - 0.2507035732269287
  - 0.23391199111938477
  - 0.27605485916137695
  - 0.2382819652557373
  - 0.27977776527404785
  - 0.24804472923278809
  - 0.27312541007995605
  - 0.24178504943847656
  - 0.2571532726287842
  - 0.25168466567993164
  - 0.2509500980377197
  - 0.25528812408447266
  score_time:
  - 0.3426651954650879
  - 0.3428676128387451
  - 0.32990050315856934
  - 0.34226465225219727
  - 0.3452029228210449
  - 0.342667818069458
  - 0.36806440353393555
  - 0.33876705169677734
  - 0.3436424732208252
  - 0.37363505363464355
  - 0.3385286331176758
  - 0.3561418056488037
  - 0.3798999786376953
  - 0.3513822555541992
  - 0.34035420417785645
  - 0.3380124568939209
start: 2023-09-25 02:26:36.567666
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
