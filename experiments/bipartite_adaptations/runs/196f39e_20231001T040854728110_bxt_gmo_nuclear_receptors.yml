active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: bipartite_adaptations/runs
end: 2023-10-01 04:08:56.835242
estimator:
  call: bipartite_adaptations.estimators.bxt_gmo
  final_params:
    estimator:
      call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
      params:
        bipartite_adapter: gmo
        bootstrap: false
        ccp_alpha: 0.0
        criterion: squared_error
        max_col_features: null
        max_depth: null
        max_features: 1.0
        max_leaf_nodes: null
        max_row_features: null
        max_samples: null
        min_col_weight_fraction_leaf: 0.0
        min_cols_leaf: 5
        min_cols_split: 1
        min_impurity_decrease: 0.0
        min_row_weight_fraction_leaf: 0.0
        min_rows_leaf: 5
        min_rows_split: 1
        min_samples_leaf: 1
        min_samples_split: 2
        min_weight_fraction_leaf: 0.0
        n_estimators: 100
        n_jobs: 3
        oob_score: false
        prediction_weights: square
        random_state: 0
        verbose: 10
        warm_start: false
  name: bxt_gmo
  params: {}
hash: 196f39e29800984c54f0360215ee76d62a38a7e67a56d0dac33aea3d54f4f1fe
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/196f39e_20231001T040854728110_bxt_gmo_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.8407359507784155
  - 0.8781545656999513
  - 0.8785017390072392
  - 0.8471218249012268
  - 0.858952087646682
  - 0.9066451557443455
  - 0.9092622299239053
  - 0.8649281040145299
  - 0.8583595521905717
  - 0.8445867523137338
  - 0.9017312933273138
  - 0.8798595537969368
  - 0.8630222130266307
  - 0.8481807608989864
  - 0.8857018298207174
  - 0.8961940044321961
  LL_balanced_accuracy:
  - 0.8859773371104815
  - 0.8722067039106145
  - 0.883448275862069
  - 0.8743093922651934
  - 0.8560500695410291
  - 0.8390646492434664
  - 0.8556910569105691
  - 0.8530612244897959
  - 0.8819163292847503
  - 0.8783068783068784
  - 0.8798701298701299
  - 0.8763157894736842
  - 0.8753387533875339
  - 0.8693333333333333
  - 0.88107752956636
  - 0.8671052631578947
  LL_f1_macro:
  - 0.6363949732407383
  - 0.5891030167307277
  - 0.6289817578211967
  - 0.6164762275747149
  - 0.557790526732985
  - 0.5140983606557377
  - 0.5546600104674101
  - 0.5586124401913876
  - 0.6344179803682456
  - 0.592487597448618
  - 0.6071729138344015
  - 0.6242346242346243
  - 0.6300912709581441
  - 0.5937655446857901
  - 0.6298374646784335
  - 0.6097041442426413
  LL_f1_micro:
  - 0.788157894736842
  - 0.7592105263157894
  - 0.7830551989730423
  - 0.766367137355584
  - 0.7276315789473685
  - 0.6921052631578948
  - 0.7265725288831836
  - 0.7227214377406932
  - 0.78125
  - 0.7699999999999999
  - 0.7743902439024389
  - 0.7707317073170732
  - 0.7699999999999999
  - 0.755
  - 0.7792682926829269
  - 0.753658536585366
  LL_f1_weighted:
  - 0.8379212966938131
  - 0.8228703918660273
  - 0.8349245446994604
  - 0.8223838633927878
  - 0.8022750987103777
  - 0.7826566005176876
  - 0.8022282446322739
  - 0.7973478450473248
  - 0.8319316635809804
  - 0.8318603827072998
  - 0.832213058972695
  - 0.8245236050114099
  - 0.8223235897229706
  - 0.8177022881777484
  - 0.8311818816825685
  - 0.8120496756480774
  LL_matthews_corrcoef:
  - 0.44032520966832145
  - 0.3798573227634006
  - 0.4309360642240266
  - 0.4168094260880243
  - 0.34311256559739134
  - 0.28950601638110535
  - 0.338864864400928
  - 0.34568431438514957
  - 0.4388510974210895
  - 0.3821167113604172
  - 0.40205330961767166
  - 0.42671803949353027
  - 0.43496568138642866
  - 0.3874732266299357
  - 0.43285461612816417
  - 0.41004855223110104
  LL_precision_macro:
  - 0.6255813953488372
  - 0.5969162995594713
  - 0.6210762331838565
  - 0.6160337552742616
  - 0.5826612903225806
  - 0.5617977528089888
  - 0.5807086614173228
  - 0.5846153846153846
  - 0.6260683760683761
  - 0.5964912280701754
  - 0.6063829787234043
  - 0.6209677419354839
  - 0.6260162601626016
  - 0.6016260162601625
  - 0.6229166666666667
  - 0.6145038167938931
  LL_precision_micro:
  - 0.7881578947368421
  - 0.7592105263157894
  - 0.7830551989730423
  - 0.766367137355584
  - 0.7276315789473684
  - 0.6921052631578948
  - 0.7265725288831836
  - 0.7227214377406932
  - 0.78125
  - 0.77
  - 0.774390243902439
  - 0.7707317073170732
  - 0.77
  - 0.755
  - 0.7792682926829269
  - 0.7536585365853659
  LL_precision_weighted:
  - 0.9467931456548349
  - 0.9533271504753071
  - 0.9474662813656695
  - 0.9457814031837855
  - 0.954971349745331
  - 0.961945594322886
  - 0.9558640696228761
  - 0.9530759356176558
  - 0.9448450854700855
  - 0.9556140350877194
  - 0.9519979242345615
  - 0.9445318646734854
  - 0.9420325203252032
  - 0.9502032520325203
  - 0.9457367886178862
  - 0.9435859244088625
  LL_recall_macro:
  - 0.8859773371104815
  - 0.8722067039106145
  - 0.883448275862069
  - 0.8743093922651934
  - 0.8560500695410291
  - 0.8390646492434664
  - 0.8556910569105691
  - 0.8530612244897959
  - 0.8819163292847503
  - 0.8783068783068784
  - 0.8798701298701299
  - 0.8763157894736842
  - 0.8753387533875339
  - 0.8693333333333333
  - 0.88107752956636
  - 0.8671052631578947
  LL_recall_micro:
  - 0.7881578947368421
  - 0.7592105263157894
  - 0.7830551989730423
  - 0.766367137355584
  - 0.7276315789473684
  - 0.6921052631578948
  - 0.7265725288831836
  - 0.7227214377406932
  - 0.78125
  - 0.77
  - 0.774390243902439
  - 0.7707317073170732
  - 0.77
  - 0.755
  - 0.7792682926829269
  - 0.7536585365853659
  LL_recall_weighted:
  - 0.7881578947368421
  - 0.7592105263157894
  - 0.7830551989730423
  - 0.766367137355584
  - 0.7276315789473684
  - 0.6921052631578948
  - 0.7265725288831836
  - 0.7227214377406932
  - 0.78125
  - 0.77
  - 0.774390243902439
  - 0.7707317073170732
  - 0.77
  - 0.755
  - 0.7792682926829269
  - 0.7536585365853659
  LL_roc_auc:
  - 0.9824126534466479
  - 0.9902234636871508
  - 0.9843167305236271
  - 0.9870040180813661
  - 0.9901285660979002
  - 0.9946646659163852
  - 0.9933240795822592
  - 0.9905689548546691
  - 0.9851094489809923
  - 0.988546176046176
  - 0.989948051948052
  - 0.9890131578947368
  - 0.9838163300987848
  - 0.9865066666666666
  - 0.9850776186552039
  - 0.9898355263157894
  LT_average_precision:
  - 0.2705121514543535
  - 0.34911437616728114
  - 0.3326025461248982
  - 0.2986203005523045
  - 0.24244225831487315
  - 0.3112316403067332
  - 0.11147250850322188
  - 0.21035982884101165
  - 0.3401486078027988
  - 0.36216172753264003
  - 0.2664528559771599
  - 0.3849970240426804
  - 0.3617044825408001
  - 0.3829535949781649
  - 0.36551563496862516
  - 0.2960727581452254
  LT_balanced_accuracy:
  - 0.699867197875166
  - 0.7975933609958505
  - 0.6738505747126436
  - 0.7791232372777437
  - 0.6561679790026247
  - 0.6199186991869918
  - 0.5874113475177305
  - 0.7838468720821662
  - 0.693407960199005
  - 0.7404479578392622
  - 0.7018330344690178
  - 0.8388097845929172
  - 0.7327044025157232
  - 0.8073488508271117
  - 0.7451790633608816
  - 0.794480755265069
  LT_f1_macro:
  - 0.5268774703557312
  - 0.6262295081967213
  - 0.501010101010101
  - 0.5737179487179487
  - 0.46135286514433427
  - 0.5219080928786554
  - 0.4276241826316393
  - 0.5453129425092041
  - 0.4992642897566497
  - 0.6358231140839836
  - 0.49475709475709473
  - 0.6238514173998045
  - 0.5324085413373115
  - 0.637979797979798
  - 0.5228747012632298
  - 0.5896464646464646
  LT_f1_micro:
  - 0.7293233082706767
  - 0.7631578947368421
  - 0.680161943319838
  - 0.7732793522267206
  - 0.6466165413533834
  - 0.7218045112781954
  - 0.5910931174089069
  - 0.7894736842105263
  - 0.717857142857143
  - 0.8000000000000002
  - 0.6115384615384616
  - 0.8576923076923076
  - 0.7321428571428571
  - 0.7714285714285715
  - 0.6692307692307692
  - 0.7692307692307693
  LT_f1_weighted:
  - 0.8014591815507147
  - 0.8099346727474424
  - 0.7636854373696479
  - 0.8323211875843455
  - 0.7487490808019617
  - 0.7845626891478185
  - 0.7037876103235383
  - 0.8542234941644681
  - 0.8017495351281431
  - 0.8331846897064288
  - 0.6984237984237984
  - 0.8953349875930521
  - 0.8052696285033574
  - 0.8153881673881674
  - 0.7505396958794023
  - 0.825611888111888
  LT_matthews_corrcoef:
  - 0.2033188969945845
  - 0.3787305111439889
  - 0.17529208353196482
  - 0.29461335893698787
  - 0.13438840154452053
  - 0.1411344326322102
  - 0.07622940092265662
  - 0.25246990310994716
  - 0.17154979406465556
  - 0.3362151839917638
  - 0.2216674828280199
  - 0.36377155952296814
  - 0.23028393430368702
  - 0.39731189979495557
  - 0.25685425685425683
  - 0.3267792223998517
  LT_precision_macro:
  - 0.5517075517075517
  - 0.620497311827957
  - 0.5441863862109261
  - 0.5777407786885246
  - 0.5289115646258503
  - 0.5415259009009009
  - 0.5166194714131608
  - 0.5561403508771929
  - 0.538040486820378
  - 0.6175313059033989
  - 0.5608627733717856
  - 0.5976430976430976
  - 0.5569721606306972
  - 0.6284019326035105
  - 0.5672713529856387
  - 0.5906550413592667
  LT_precision_micro:
  - 0.7293233082706767
  - 0.7631578947368421
  - 0.680161943319838
  - 0.7732793522267206
  - 0.6466165413533834
  - 0.7218045112781954
  - 0.5910931174089069
  - 0.7894736842105263
  - 0.7178571428571429
  - 0.8
  - 0.6115384615384616
  - 0.8576923076923076
  - 0.7321428571428571
  - 0.7714285714285715
  - 0.6692307692307692
  - 0.7692307692307693
  LT_precision_weighted:
  - 0.9259693244655651
  - 0.911201895868704
  - 0.9176888658645196
  - 0.9375974812504149
  - 0.9358344841696077
  - 0.8868052733184313
  - 0.9216834484144142
  - 0.9578947368421052
  - 0.9418392933590782
  - 0.8924508050089445
  - 0.9060908990072651
  - 0.9574786324786324
  - 0.9344952134586281
  - 0.9119459709759997
  - 0.9241293098435956
  - 0.9326729608419749
  LT_recall_macro:
  - 0.699867197875166
  - 0.7975933609958505
  - 0.6738505747126436
  - 0.7791232372777437
  - 0.6561679790026247
  - 0.6199186991869918
  - 0.5874113475177305
  - 0.7838468720821662
  - 0.693407960199005
  - 0.7404479578392622
  - 0.7018330344690178
  - 0.8388097845929172
  - 0.7327044025157232
  - 0.8073488508271117
  - 0.7451790633608816
  - 0.794480755265069
  LT_recall_micro:
  - 0.7293233082706767
  - 0.7631578947368421
  - 0.680161943319838
  - 0.7732793522267206
  - 0.6466165413533834
  - 0.7218045112781954
  - 0.5910931174089069
  - 0.7894736842105263
  - 0.7178571428571429
  - 0.8
  - 0.6115384615384616
  - 0.8576923076923076
  - 0.7321428571428571
  - 0.7714285714285715
  - 0.6692307692307692
  - 0.7692307692307693
  LT_recall_weighted:
  - 0.7293233082706767
  - 0.7631578947368421
  - 0.680161943319838
  - 0.7732793522267206
  - 0.6466165413533834
  - 0.7218045112781954
  - 0.5910931174089069
  - 0.7894736842105263
  - 0.7178571428571429
  - 0.8
  - 0.6115384615384616
  - 0.8576923076923076
  - 0.7321428571428571
  - 0.7714285714285715
  - 0.6692307692307692
  - 0.7692307692307693
  LT_roc_auc:
  - 0.7893758300132803
  - 0.8207468879668051
  - 0.7272988505747127
  - 0.7933782955242183
  - 0.733267716535433
  - 0.6544715447154472
  - 0.6549645390070922
  - 0.8641456582633054
  - 0.8093905472636815
  - 0.7793880837359096
  - 0.7652918908149033
  - 0.8714859437751005
  - 0.8067924528301886
  - 0.8539013321622017
  - 0.8480257116620753
  - 0.8380537400145243
  TL_average_precision:
  - 0.3643105421367887
  - 0.37639798488735743
  - 0.5699855865531556
  - 0.3637881286595203
  - 0.4543677648740468
  - 0.40917068137465806
  - 0.4494150690196294
  - 0.4205733477146847
  - 0.09178632690699168
  - 0.06256624303568036
  - 0.1202192986657668
  - 0.08695010873575178
  - 0.280382901314962
  - 0.3108955115725219
  - 0.37527584320242885
  - 0.28398731817781925
  TL_balanced_accuracy:
  - 0.7054707379134859
  - 0.6907231345433593
  - 0.7344322344322345
  - 0.6382693102023957
  - 0.6720430107526881
  - 0.6861979166666667
  - 0.7037749287749289
  - 0.6053194333066025
  - 0.6170789562860047
  - 0.49508641138597087
  - 0.6074561403508771
  - 0.5888081875206339
  - 0.4521739130434782
  - 0.5732679337829552
  - 0.5794655414908579
  - 0.43925387916804226
  TL_f1_macro:
  - 0.54487764690165
  - 0.49010989010989015
  - 0.5363911450867973
  - 0.48584356819650937
  - 0.5461437908496731
  - 0.5264679674855886
  - 0.5602365114560237
  - 0.5057882802243705
  - 0.4188861985472154
  - 0.38660209846650523
  - 0.4384149789515571
  - 0.4200542005420054
  - 0.39852700490998366
  - 0.3985257985257985
  - 0.4186921296296296
  - 0.38885470085470086
  TL_f1_micro:
  - 0.7392857142857143
  - 0.6892857142857143
  - 0.7526132404181185
  - 0.662020905923345
  - 0.6678571428571428
  - 0.6678571428571428
  - 0.7038327526132404
  - 0.6480836236933798
  - 0.55
  - 0.525
  - 0.556910569105691
  - 0.5650406504065041
  - 0.5916666666666667
  - 0.575
  - 0.6016260162601627
  - 0.556910569105691
  TL_f1_weighted:
  - 0.8040884034137358
  - 0.7791993720565149
  - 0.8221131996317574
  - 0.7490609001574363
  - 0.7291335200746966
  - 0.740862011186246
  - 0.7642482443196305
  - 0.7173833039542609
  - 0.6650121065375302
  - 0.6464016680118374
  - 0.6586280226008324
  - 0.6793795580232224
  - 0.7109588106928533
  - 0.7053194103194101
  - 0.7209307249322494
  - 0.6754616079494129
  TL_matthews_corrcoef:
  - 0.2239521830053359
  - 0.1708786640375072
  - 0.22794898042110956
  - 0.1403948009516369
  - 0.22344700950694846
  - 0.21618480782711313
  - 0.2521720805425889
  - 0.13207029463513395
  - 0.10618235674830993
  - -0.004456278358467422
  - 0.1121709352913012
  - 0.07992209181555457
  - -0.03915781120217973
  - 0.049818658003793
  - 0.06084543576623944
  - -0.055022122589831246
  TL_precision_macro:
  - 0.5610239939542793
  - 0.5382747456059205
  - 0.5554112554112554
  - 0.5356382412434793
  - 0.5725524475524476
  - 0.5627502605452251
  - 0.57801592495637
  - 0.5414039512400168
  - 0.5240749773534945
  - 0.4989896174482614
  - 0.5292731496846996
  - 0.5179812834224599
  - 0.4919848440687846
  - 0.5084685706186663
  - 0.5116470830756545
  - 0.4875406283856988
  TL_precision_micro:
  - 0.7392857142857143
  - 0.6892857142857143
  - 0.7526132404181185
  - 0.662020905923345
  - 0.6678571428571428
  - 0.6678571428571428
  - 0.7038327526132404
  - 0.6480836236933798
  - 0.55
  - 0.525
  - 0.556910569105691
  - 0.5650406504065041
  - 0.5916666666666667
  - 0.575
  - 0.6016260162601627
  - 0.556910569105691
  TL_precision_weighted:
  - 0.9175474346171494
  - 0.9378246002378751
  - 0.9394361735825151
  - 0.9088388157687298
  - 0.8611138861138862
  - 0.892274540225832
  - 0.886598249630589
  - 0.8506399637947019
  - 0.9203574663786495
  - 0.896576893596265
  - 0.8920142795852121
  - 0.9161759271336029
  - 0.9137156319829011
  - 0.9507068953298846
  - 0.9390470157020679
  - 0.8891560746593381
  TL_recall_macro:
  - 0.7054707379134859
  - 0.6907231345433593
  - 0.7344322344322345
  - 0.6382693102023957
  - 0.6720430107526881
  - 0.6861979166666667
  - 0.7037749287749289
  - 0.6053194333066025
  - 0.6170789562860047
  - 0.49508641138597087
  - 0.6074561403508771
  - 0.5888081875206339
  - 0.4521739130434782
  - 0.5732679337829552
  - 0.5794655414908579
  - 0.43925387916804226
  TL_recall_micro:
  - 0.7392857142857143
  - 0.6892857142857143
  - 0.7526132404181185
  - 0.662020905923345
  - 0.6678571428571428
  - 0.6678571428571428
  - 0.7038327526132404
  - 0.6480836236933798
  - 0.55
  - 0.525
  - 0.556910569105691
  - 0.5650406504065041
  - 0.5916666666666667
  - 0.575
  - 0.6016260162601627
  - 0.556910569105691
  TL_recall_weighted:
  - 0.7392857142857143
  - 0.6892857142857143
  - 0.7526132404181185
  - 0.662020905923345
  - 0.6678571428571428
  - 0.6678571428571428
  - 0.7038327526132404
  - 0.6480836236933798
  - 0.55
  - 0.525
  - 0.556910569105691
  - 0.5650406504065041
  - 0.5916666666666667
  - 0.575
  - 0.6016260162601627
  - 0.556910569105691
  TL_roc_auc:
  - 0.8160517387616624
  - 0.8133102852203975
  - 0.8354264782836212
  - 0.7245972738537795
  - 0.7494494105454075
  - 0.7664388020833334
  - 0.7689458689458689
  - 0.6684041700080192
  - 0.61945103354795
  - 0.47678752965096577
  - 0.6386452241715399
  - 0.6048200726312314
  - 0.6423913043478261
  - 0.5744941753525444
  - 0.6741678387248007
  - 0.5888081875206339
  TT_average_precision:
  - 0.057798825744987264
  - 0.17931726132945644
  - 0.11869734746081492
  - 0.4027777777777778
  - 0.1774829931972789
  - 0.2690213801889062
  - 0.275092345500617
  - 0.1910768398268398
  - 0.13018541871000888
  - 0.16759330925352597
  - 0.0196078431372549
  - 0.1952020202020202
  - 0.04394646747587924
  - 0.12344417276345916
  - 0.0699732991490093
  - -0.0
  TT_balanced_accuracy:
  - 0.5298245614035088
  - 0.6736111111111112
  - 0.4226190476190476
  - 0.9090909090909092
  - 0.677536231884058
  - 0.5276018099547511
  - 0.6401234567901235
  - 0.5971385542168675
  - 0.6025641025641026
  - 0.717948717948718
  - 0.6688311688311688
  - 0.5347222222222222
  - 0.35185185185185186
  - 0.47435897435897434
  - 0.6317567567567568
  - 0.6410256410256411
  TT_f1_macro:
  - 0.448995983935743
  - 0.5429713524317121
  - 0.38906649616368283
  - 0.5863636363636364
  - 0.4313346228239845
  - 0.48869565217391303
  - 0.4960335279149828
  - 0.5512820512820513
  - 0.4981617647058824
  - 0.49206349206349204
  - 0.2712951089943213
  - 0.42844827586206896
  - 0.4042553191489362
  - 0.4218623481781376
  - 0.40605062770117306
  - 0.39062500000000006
  TT_f1_micro:
  - 0.7142857142857143
  - 0.7142857142857143
  - 0.5384615384615384
  - 0.8241758241758241
  - 0.5408163265306123
  - 0.6326530612244898
  - 0.5934065934065934
  - 0.7802197802197802
  - 0.6904761904761905
  - 0.6190476190476191
  - 0.34615384615384615
  - 0.5641025641025641
  - 0.6785714285714286
  - 0.5952380952380952
  - 0.5256410256410257
  - 0.6410256410256411
  TT_f1_weighted:
  - 0.8079173838209985
  - 0.7771009802988483
  - 0.6446980129844578
  - 0.8793206793206793
  - 0.65029803023724
  - 0.6880212954747115
  - 0.6688707191625917
  - 0.8154409692871232
  - 0.7644432773109244
  - 0.709750566893424
  - 0.49886566995927684
  - 0.6640583554376658
  - 0.7796352583586627
  - 0.6932330827067668
  - 0.6452314235808781
  - 0.7812500000000001
  TT_matthews_corrcoef:
  - 0.022999343254773864
  - 0.20628073812014047
  - -0.08333333333333333
  - 0.35942537872389224
  - 0.17025130615174972
  - 0.039621877209485686
  - 0.17615964126632694
  - 0.1381045502860227
  - 0.11427405426280114
  - 0.2268482178905401
  - 0.08058229640253803
  - 0.03731758962665826
  - -0.1217161238900369
  - -0.02719641466102106
  - 0.11624763874381928
  - 0.0
  TT_precision_macro:
  - 0.504434011476265
  - 0.5612745098039216
  - 0.4775641025641026
  - 0.5789473684210527
  - 0.5408163265306123
  - 0.5142191142191143
  - 0.5553658536585365
  - 0.5490867579908676
  - 0.5318302387267905
  - 0.5590277777777778
  - 0.5096153846153846
  - 0.5100267379679144
  - 0.475
  - 0.49278846153846156
  - 0.5256410256410257
  - 0.5
  TT_precision_micro:
  - 0.7142857142857143
  - 0.7142857142857143
  - 0.5384615384615384
  - 0.8241758241758241
  - 0.5408163265306123
  - 0.6326530612244898
  - 0.5934065934065934
  - 0.7802197802197802
  - 0.6904761904761905
  - 0.6190476190476191
  - 0.34615384615384615
  - 0.5641025641025641
  - 0.6785714285714286
  - 0.5952380952380952
  - 0.5256410256410257
  - 0.6410256410256411
  TT_precision_weighted:
  - 0.9432148446232954
  - 0.8914565826330532
  - 0.8382642998027614
  - 0.9722382880277617
  - 0.9258642232403166
  - 0.7806954949812092
  - 0.8554650227820959
  - 0.8642681519393847
  - 0.8887836301629406
  - 0.9191468253968254
  - 0.9874260355029586
  - 0.8669271904566023
  - 0.9160714285714286
  - 0.8616071428571429
  - 0.9283366206443129
  - 1.0
  TT_recall_macro:
  - 0.5298245614035088
  - 0.6736111111111112
  - 0.4226190476190476
  - 0.9090909090909092
  - 0.677536231884058
  - 0.5276018099547511
  - 0.6401234567901235
  - 0.5971385542168675
  - 0.6025641025641026
  - 0.717948717948718
  - 0.6688311688311688
  - 0.5347222222222222
  - 0.35185185185185186
  - 0.47435897435897434
  - 0.6317567567567568
  - 0.32051282051282054
  TT_recall_micro:
  - 0.7142857142857143
  - 0.7142857142857143
  - 0.5384615384615384
  - 0.8241758241758241
  - 0.5408163265306123
  - 0.6326530612244898
  - 0.5934065934065934
  - 0.7802197802197802
  - 0.6904761904761905
  - 0.6190476190476191
  - 0.34615384615384615
  - 0.5641025641025641
  - 0.6785714285714286
  - 0.5952380952380952
  - 0.5256410256410257
  - 0.6410256410256411
  TT_recall_weighted:
  - 0.7142857142857143
  - 0.7142857142857143
  - 0.5384615384615384
  - 0.8241758241758241
  - 0.5408163265306123
  - 0.6326530612244897
  - 0.5934065934065934
  - 0.7802197802197802
  - 0.6904761904761906
  - 0.6190476190476191
  - 0.34615384615384615
  - 0.5641025641025641
  - 0.6785714285714286
  - 0.5952380952380952
  - 0.5256410256410257
  - 0.6410256410256411
  TT_roc_auc:
  - 0.5929824561403508
  - 0.7638888888888888
  - 0.5595238095238095
  - 0.9621212121212122
  - 0.7771739130434783
  - 0.5366515837104073
  - 0.6654320987654322
  - 0.7274096385542168
  - 0.5790598290598291
  - 0.7350427350427351
  - 0.35064935064935066
  - 0.6597222222222222
  - 0.48559670781893005
  - 0.5149572649572649
  - 0.5709459459459459
  - .nan
  fit_time:
  - 0.19147181510925293
  - 0.17479348182678223
  - 0.21368074417114258
  - 0.1835343837738037
  - 0.19615888595581055
  - 0.1937103271484375
  - 0.1849687099456787
  - 0.18187975883483887
  - 0.18407559394836426
  - 0.1858210563659668
  - 0.19433355331420898
  - 0.1836714744567871
  - 0.20531153678894043
  - 0.20492219924926758
  - 0.19460368156433105
  - 0.19580864906311035
  score_time:
  - 0.7548143863677979
  - 0.7416753768920898
  - 0.7156603336334229
  - 0.776118278503418
  - 0.8175382614135742
  - 0.7288353443145752
  - 0.8309438228607178
  - 0.7814075946807861
  - 0.8164665699005127
  - 0.8269038200378418
  - 0.7978677749633789
  - 0.7463459968566895
  - 0.8034176826477051
  - 0.7739133834838867
  - 0.832669734954834
  - 0.7743520736694336
start: 2023-10-01 04:08:54.728110
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
