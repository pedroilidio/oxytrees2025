active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/miRNA/final/normalized_mirna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/miRNA/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: mirna
  pairwise: true
  y:
    force_download: false
    path: datasets/miRNA/final/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: bipartite_adaptations/runs
end: 2023-09-24 23:30:17.955511
estimator:
  call: bipartite_adaptations.estimators.bxt_sgso_us
  final_params:
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        estimator__bootstrap: false
        estimator__ccp_alpha: 0.0
        estimator__criterion: squared_error
        estimator__max_depth: null
        estimator__max_features: 1.0
        estimator__max_leaf_nodes: null
        estimator__max_samples: null
        estimator__min_impurity_decrease: 0.0
        estimator__min_samples_leaf: 1
        estimator__min_samples_split: 2
        estimator__min_weight_fraction_leaf: 0.0
        estimator__n_estimators: 100
        estimator__n_jobs: 3
        estimator__oob_score: false
        estimator__random_state: 0
        estimator__verbose: 10
        estimator__warm_start: false
        under_sampler:
          call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
          params:
            random_state: null
            replacement: false
            sampling_strategy: auto
        under_sampler__random_state: null
        under_sampler__replacement: false
        under_sampler__sampling_strategy: auto
  name: bxt_sgso_us
  params: {}
hash: b885885d6f200c9d0a6dc2a5979ae059b2f307d86175fcc390b330a1915f7df3
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/b885885_20230924T225249896561_bxt_sgso_us_mirna.yml"
results:
  LL_average_precision:
  - 0.988119505669512
  - 0.9903453465381229
  - 0.9894810109490415
  - 0.9864514086736309
  - 0.9869158019335725
  - 0.9873152468055468
  - 0.9847720659553831
  - 0.9845735600935702
  - 0.9873394621700509
  - 0.9861626836776793
  - 0.9844355442675263
  - 0.9841204709269262
  - 0.9869892663453251
  - 0.9857178106083158
  - 0.9897297121058981
  - 0.9834227825589889
  LL_balanced_accuracy:
  - 0.5514359463637237
  - 0.5518059687501542
  - 0.5491245782954517
  - 0.5532188377088423
  - 0.5506924191069247
  - 0.5502255472293434
  - 0.5476449952767063
  - 0.552651677005211
  - 0.5505331655829367
  - 0.5503791742427602
  - 0.5480352673324778
  - 0.5520970386662215
  - 0.5520691727249444
  - 0.5513328077652682
  - 0.5489437996650263
  - 0.5515435954962408
  LL_f1_macro:
  - 0.16611057743953708
  - 0.16729461362792344
  - 0.1609646036595503
  - 0.16936559434799237
  - 0.16465813103268578
  - 0.16444323206184516
  - 0.15805294779098608
  - 0.16827656529469132
  - 0.16396165111512076
  - 0.16428339637613731
  - 0.15826899720513532
  - 0.16692429317658006
  - 0.1669228853662718
  - 0.16592644343441434
  - 0.16016647239968984
  - 0.165919591758017
  LL_f1_micro:
  - 0.1666117019814769
  - 0.16779802310348935
  - 0.16134883337455685
  - 0.1700042004529184
  - 0.165110823769038
  - 0.16483619594695106
  - 0.15835497934569923
  - 0.168872616114609
  - 0.1644219656486366
  - 0.16470574773145977
  - 0.15861358721149776
  - 0.16749475317090975
  - 0.1674886429952741
  - 0.1664198830543191
  - 0.16055886761794694
  - 0.1664476685828999
  LL_f1_weighted:
  - 0.18364797011158257
  - 0.18483667079287383
  - 0.1764068222227675
  - 0.18912021645957156
  - 0.18134621351106708
  - 0.17996957687010498
  - 0.17177636970249713
  - 0.18737802586092894
  - 0.18081379626718397
  - 0.1803987469958114
  - 0.17294316832891948
  - 0.18564329810602445
  - 0.18556238082808107
  - 0.18333077568089487
  - 0.17579759512099277
  - 0.1839415180393743
  LL_matthews_corrcoef:
  - 0.08989537471226838
  - 0.09060233856299828
  - 0.08698456063502655
  - 0.09166526192965152
  - 0.0890923822835445
  - 0.08904644129906454
  - 0.08537287922709687
  - 0.09106689474928663
  - 0.08866543803567523
  - 0.0889103192026474
  - 0.08543958406906556
  - 0.09028888779537914
  - 0.09029444672060333
  - 0.08979555118775887
  - 0.0864981144361067
  - 0.08974398839592952
  LL_precision_macro:
  - 0.5392778735784988
  - 0.5396131177117489
  - 0.5385057442293054
  - 0.5394715508942595
  - 0.5391451656914168
  - 0.5394683042069237
  - 0.538243935513033
  - 0.5393775649275941
  - 0.5388930705773592
  - 0.5392277413213687
  - 0.537992515350067
  - 0.539119705591885
  - 0.5391454611332535
  - 0.5392694329617842
  - 0.5382169133384027
  - 0.5390639388641221
  LL_precision_micro:
  - 0.1666117019814769
  - 0.16779802310348935
  - 0.16134883337455685
  - 0.1700042004529184
  - 0.165110823769038
  - 0.16483619594695106
  - 0.15835497934569923
  - 0.168872616114609
  - 0.1644219656486366
  - 0.16470574773145977
  - 0.15861358721149776
  - 0.16749475317090975
  - 0.1674886429952741
  - 0.1664198830543191
  - 0.16055886761794694
  - 0.1664476685828999
  LL_precision_weighted:
  - 0.9345325595772563
  - 0.9340677702584967
  - 0.9354142253606242
  - 0.9344775571123115
  - 0.9346362497249371
  - 0.9340750018380454
  - 0.9356243642104632
  - 0.9345444549559031
  - 0.9350036090741626
  - 0.9344665862895671
  - 0.9360672275935901
  - 0.9348652796806928
  - 0.9348219180627588
  - 0.9345315629586506
  - 0.9358383019821289
  - 0.934876325370952
  LL_recall_macro:
  - 0.5514359463637237
  - 0.5518059687501542
  - 0.5491245782954517
  - 0.5532188377088423
  - 0.5506924191069247
  - 0.5502255472293434
  - 0.5476449952767063
  - 0.552651677005211
  - 0.5505331655829367
  - 0.5503791742427602
  - 0.5480352673324778
  - 0.5520970386662215
  - 0.5520691727249444
  - 0.5513328077652682
  - 0.5489437996650263
  - 0.5515435954962408
  LL_recall_micro:
  - 0.1666117019814769
  - 0.16779802310348935
  - 0.16134883337455685
  - 0.1700042004529184
  - 0.165110823769038
  - 0.16483619594695106
  - 0.15835497934569923
  - 0.168872616114609
  - 0.1644219656486366
  - 0.16470574773145977
  - 0.15861358721149776
  - 0.16749475317090975
  - 0.1674886429952741
  - 0.1664198830543191
  - 0.16055886761794694
  - 0.1664476685828999
  LL_recall_weighted:
  - 0.1666117019814769
  - 0.16779802310348935
  - 0.16134883337455685
  - 0.1700042004529184
  - 0.165110823769038
  - 0.16483619594695106
  - 0.15835497934569923
  - 0.168872616114609
  - 0.1644219656486366
  - 0.16470574773145977
  - 0.15861358721149776
  - 0.16749475317090975
  - 0.1674886429952741
  - 0.1664198830543191
  - 0.16055886761794694
  - 0.1664476685828999
  LL_roc_auc:
  - 0.9995402111823598
  - 0.9996159649409551
  - 0.9995916027808939
  - 0.9994740541576755
  - 0.9994857198218038
  - 0.9994965658709475
  - 0.9994206585058648
  - 0.9994008064555737
  - 0.9994983320197502
  - 0.9994628980836795
  - 0.9994123750374948
  - 0.999378199764983
  - 0.9994912596447494
  - 0.9994377472505512
  - 0.999612640463946
  - 0.9993593409803311
  LT_average_precision:
  - 0.1634591270733085
  - 0.14978047015020884
  - 0.16012691065241802
  - 0.16801178629410998
  - 0.16248914548539725
  - 0.14689319487557165
  - 0.15459352316208733
  - 0.16212922863981036
  - 0.16379531766978342
  - 0.1447620580995073
  - 0.15554873743267497
  - 0.16259187937708736
  - 0.15350468567732975
  - 0.14525078789032822
  - 0.1500774769455228
  - 0.1622505394231884
  LT_balanced_accuracy:
  - 0.5185909463791202
  - 0.5197082450524688
  - 0.5117091556437464
  - 0.5194300507365878
  - 0.5188110582875763
  - 0.5163091378768914
  - 0.5134115374879188
  - 0.5180534901894204
  - 0.5174863668050756
  - 0.5167601651104319
  - 0.5124303567163265
  - 0.5165639333869397
  - 0.5169874026686512
  - 0.5167607788671145
  - 0.5124025851332904
  - 0.5174619366962747
  LT_f1_macro:
  - 0.1281723563651926
  - 0.13047529946812042
  - 0.12037851909371886
  - 0.13459964163504207
  - 0.1286744111536127
  - 0.12277693760379194
  - 0.12254867204746486
  - 0.1328207361303817
  - 0.12452268096801444
  - 0.12331997244795216
  - 0.12151544311580392
  - 0.1285200645644289
  - 0.13037619698721437
  - 0.12679881287615768
  - 0.12381126929104946
  - 0.1317317853021257
  LT_f1_micro:
  - 0.12824621959237345
  - 0.13048570019723865
  - 0.12082237563006794
  - 0.13460155450446712
  - 0.12873665480427046
  - 0.12287161237339174
  - 0.12294004927456885
  - 0.13282659019452026
  - 0.12464412811387901
  - 0.1233917328223378
  - 0.12192033944702983
  - 0.12854921742735723
  - 0.13039282781275663
  - 0.12683410895154668
  - 0.12409663290446209
  - 0.13174169920187956
  LT_f1_weighted:
  - 0.12128109313404875
  - 0.12788277871575587
  - 0.10353714062579547
  - 0.13349403869561946
  - 0.12234844025809997
  - 0.11491281965360768
  - 0.10676422302434135
  - 0.13088346127214057
  - 0.11565513398989649
  - 0.11646886511609905
  - 0.10544169121497926
  - 0.12417970134601503
  - 0.12710364612072703
  - 0.12201040063350586
  - 0.11032180555713375
  - 0.12920828220138383
  LT_matthews_corrcoef:
  - 0.03967483413380925
  - 0.040368833237648435
  - 0.027740971383382034
  - 0.039245999934709
  - 0.03992147527045885
  - 0.035216734953872446
  - 0.03136480428400873
  - 0.0367441255271014
  - 0.03810617071729846
  - 0.035822565887637846
  - 0.0291814927504386
  - 0.03449296130847264
  - 0.03501073597138964
  - 0.03506886952217667
  - 0.02828646687272576
  - 0.03573446522199535
  LT_precision_macro:
  - 0.521167460109954
  - 0.5206720929822837
  - 0.5164307640257695
  - 0.5198178652716384
  - 0.5211806821738257
  - 0.5190110971863292
  - 0.5183377735151607
  - 0.5186962568814337
  - 0.5207601765266986
  - 0.5191414615894122
  - 0.5171266106552161
  - 0.5179571535340436
  - 0.5180391266570783
  - 0.5183438016113981
  - 0.5161281740770752
  - 0.5182819355451909
  LT_precision_micro:
  - 0.12824621959237345
  - 0.13048570019723865
  - 0.12082237563006794
  - 0.13460155450446712
  - 0.12873665480427046
  - 0.12287161237339174
  - 0.12294004927456885
  - 0.13282659019452026
  - 0.12464412811387901
  - 0.1233917328223378
  - 0.12192033944702983
  - 0.12854921742735723
  - 0.13039282781275663
  - 0.12683410895154668
  - 0.12409663290446209
  - 0.13174169920187956
  LT_precision_weighted:
  - 0.9058425084467784
  - 0.9077526896580598
  - 0.8922306508271697
  - 0.9037058013224605
  - 0.9060509378214521
  - 0.9058367269415559
  - 0.8950540509891646
  - 0.9022478881688171
  - 0.9063153394486898
  - 0.9067709162341182
  - 0.8933774346005426
  - 0.9022033662519742
  - 0.901785096650977
  - 0.9041655983531793
  - 0.8922464837049531
  - 0.9018087054507964
  LT_recall_macro:
  - 0.5185909463791202
  - 0.5197082450524688
  - 0.5117091556437464
  - 0.5194300507365878
  - 0.5188110582875763
  - 0.5163091378768914
  - 0.5134115374879188
  - 0.5180534901894204
  - 0.5174863668050756
  - 0.5167601651104319
  - 0.5124303567163265
  - 0.5165639333869397
  - 0.5169874026686512
  - 0.5167607788671145
  - 0.5124025851332904
  - 0.5174619366962747
  LT_recall_micro:
  - 0.12824621959237345
  - 0.13048570019723865
  - 0.12082237563006794
  - 0.13460155450446712
  - 0.12873665480427046
  - 0.12287161237339174
  - 0.12294004927456885
  - 0.13282659019452026
  - 0.12464412811387901
  - 0.1233917328223378
  - 0.12192033944702983
  - 0.12854921742735723
  - 0.13039282781275663
  - 0.12683410895154668
  - 0.12409663290446209
  - 0.13174169920187956
  LT_recall_weighted:
  - 0.12824621959237345
  - 0.13048570019723865
  - 0.12082237563006794
  - 0.13460155450446712
  - 0.12873665480427046
  - 0.12287161237339174
  - 0.12294004927456885
  - 0.13282659019452026
  - 0.12464412811387901
  - 0.1233917328223378
  - 0.12192033944702983
  - 0.12854921742735723
  - 0.13039282781275663
  - 0.12683410895154668
  - 0.12409663290446209
  - 0.13174169920187956
  LT_roc_auc:
  - 0.6716171657514344
  - 0.6709667321900945
  - 0.6579199735610206
  - 0.67822053660422
  - 0.6728558900406361
  - 0.6685125384290362
  - 0.6585141080952807
  - 0.6757905471215883
  - 0.6720868666631129
  - 0.6645460027548412
  - 0.6556536457962816
  - 0.6711252185956934
  - 0.6663068775585658
  - 0.6652895983238877
  - 0.6518139406244037
  - 0.6705654049872426
  TL_average_precision:
  - 0.19474911673946257
  - 0.20383738975121535
  - 0.19639266735413335
  - 0.19136049521800103
  - 0.1931008045226553
  - 0.1980279610968459
  - 0.1889761873909428
  - 0.19605493022121104
  - 0.2033819542239217
  - 0.21079945831317906
  - 0.19988242222148694
  - 0.2032905134888814
  - 0.20364852606248038
  - 0.21623710658528783
  - 0.21138286468817735
  - 0.2113848845035259
  TL_balanced_accuracy:
  - 0.5016034265409482
  - 0.5014789189508158
  - 0.5017662773497008
  - 0.5017894806464177
  - 0.5036067997043607
  - 0.5028086008692222
  - 0.5027865331099186
  - 0.5035028914508821
  - 0.5028717553974938
  - 0.5024950395356413
  - 0.502939067040304
  - 0.5029688364373963
  - 0.5010757859644605
  - 0.501040432464455
  - 0.5012188815838073
  - 0.5009368130652229
  TL_f1_macro:
  - 0.06881124133530511
  - 0.06899938938495304
  - 0.06775843223757437
  - 0.06926294872570869
  - 0.0733549343915453
  - 0.07196297484355726
  - 0.07059758130744939
  - 0.07307822583527235
  - 0.07296754228677485
  - 0.07242413777144034
  - 0.07227870298485528
  - 0.072981750246404
  - 0.06867253486680905
  - 0.06953281097332797
  - 0.06792901632462313
  - 0.06876639139324886
  TL_f1_micro:
  - 0.07299515285309785
  - 0.073276246237805
  - 0.07171309278138477
  - 0.0734104204253458
  - 0.0771154533212411
  - 0.07591997141836371
  - 0.07440844257564515
  - 0.0768545912776682
  - 0.07705361805040262
  - 0.07663451232583066
  - 0.07623601835820486
  - 0.07701895682664914
  - 0.0730961607167395
  - 0.07412674856404759
  - 0.07219611399675709
  - 0.07330703484549639
  TL_f1_weighted:
  - 0.01513332978428397
  - 0.014798902756432067
  - 0.015349189310712783
  - 0.01584089771168938
  - 0.022636598196946814
  - 0.01992247443549667
  - 0.01932350605967987
  - 0.02223748790403028
  - 0.02024984949452894
  - 0.018930139710826546
  - 0.020264109397801326
  - 0.020554206845366976
  - 0.013602780940389605
  - 0.01359341173137069
  - 0.013683840474725196
  - 0.01304776191390392
  TL_matthews_corrcoef:
  - 0.015006412901061798
  - 0.01446314528588976
  - 0.015572519368908648
  - 0.015863774078755735
  - 0.02261275484449915
  - 0.019786059285265785
  - 0.01969227290897239
  - 0.022271700664627164
  - 0.020350537416601824
  - 0.018999366892496174
  - 0.02045246466593458
  - 0.02066233618411637
  - 0.012084876406256705
  - 0.012268698488141295
  - 0.013071238928007003
  - 0.011589840340168078
  TL_precision_macro:
  - 0.5351111233359005
  - 0.5353607226828363
  - 0.5343240770675269
  - 0.53515815168574
  - 0.5354425476579144
  - 0.5348472567186514
  - 0.5347910465284924
  - 0.5354013717988488
  - 0.536053242339679
  - 0.5361693609619393
  - 0.5355813005602648
  - 0.535951133178616
  - 0.5339389624375115
  - 0.5361678839653878
  - 0.5350438650855954
  - 0.5358461052949328
  TL_precision_micro:
  - 0.07299515285309785
  - 0.073276246237805
  - 0.07171309278138477
  - 0.0734104204253458
  - 0.0771154533212411
  - 0.07591997141836371
  - 0.07440844257564515
  - 0.0768545912776682
  - 0.07705361805040262
  - 0.07663451232583066
  - 0.07623601835820486
  - 0.07701895682664914
  - 0.0730961607167395
  - 0.07412674856404759
  - 0.07219611399675709
  - 0.07330703484549639
  TL_precision_weighted:
  - 0.9349036369576951
  - 0.934460756679236
  - 0.9362748173117039
  - 0.9348456460217766
  - 0.9345812409431706
  - 0.9331961403593012
  - 0.935595402118539
  - 0.934638772322841
  - 0.9334495808500824
  - 0.9332049207530316
  - 0.9342625522449128
  - 0.933635571191074
  - 0.9309929145251843
  - 0.9330262473508162
  - 0.9349723315860223
  - 0.9335633327899964
  TL_recall_macro:
  - 0.5016034265409482
  - 0.5014789189508158
  - 0.5017662773497008
  - 0.5017894806464177
  - 0.5036067997043607
  - 0.5028086008692222
  - 0.5027865331099186
  - 0.5035028914508821
  - 0.5028717553974938
  - 0.5024950395356413
  - 0.502939067040304
  - 0.5029688364373963
  - 0.5010757859644605
  - 0.501040432464455
  - 0.5012188815838073
  - 0.5009368130652229
  TL_recall_micro:
  - 0.07299515285309785
  - 0.073276246237805
  - 0.07171309278138477
  - 0.0734104204253458
  - 0.0771154533212411
  - 0.07591997141836371
  - 0.07440844257564515
  - 0.0768545912776682
  - 0.07705361805040262
  - 0.07663451232583066
  - 0.07623601835820486
  - 0.07701895682664914
  - 0.0730961607167395
  - 0.07412674856404759
  - 0.07219611399675709
  - 0.07330703484549639
  TL_recall_weighted:
  - 0.07299515285309785
  - 0.073276246237805
  - 0.07171309278138477
  - 0.0734104204253458
  - 0.0771154533212411
  - 0.07591997141836371
  - 0.07440844257564515
  - 0.0768545912776682
  - 0.07705361805040262
  - 0.07663451232583066
  - 0.07623601835820486
  - 0.07701895682664914
  - 0.0730961607167395
  - 0.07412674856404759
  - 0.07219611399675709
  - 0.07330703484549639
  TL_roc_auc:
  - 0.6663669919917914
  - 0.6710024224762304
  - 0.6585833704958028
  - 0.6629525237304956
  - 0.6687388222921509
  - 0.6761615414821261
  - 0.6679587276041326
  - 0.6713783180296631
  - 0.679707740111481
  - 0.683724693549893
  - 0.6744159023913524
  - 0.6771545791325396
  - 0.6737087739192089
  - 0.6810680687513868
  - 0.6670354365849235
  - 0.6722745724517594
  TT_average_precision:
  - 0.11758735093498762
  - 0.10193051272854436
  - 0.10804565350695436
  - 0.1037223050814631
  - 0.10946004836757156
  - 0.09909883804994327
  - 0.11338207725241711
  - 0.10079935554898024
  - 0.12164897634269052
  - 0.11315823006030228
  - 0.11342965186455681
  - 0.1104481634706988
  - 0.12757880377089953
  - 0.11255860095840413
  - 0.12061448105100998
  - 0.11342723432423689
  TT_balanced_accuracy:
  - 0.5009030876402666
  - 0.5011781793223761
  - 0.5003774520603586
  - 0.50015827675968
  - 0.5022085898172066
  - 0.5022383108156705
  - 0.5022810666717322
  - 0.5016121444978273
  - 0.5025207854236688
  - 0.5022060545453703
  - 0.5019628101703829
  - 0.5006384434022267
  - 0.5003666963380721
  - 0.5003634163546907
  - 0.5003431734535826
  - 0.4998979745785336
  TT_f1_macro:
  - 0.06704826334427791
  - 0.06598932250056104
  - 0.07142659076530376
  - 0.06678770208378546
  - 0.07155301610915228
  - 0.06962194642837878
  - 0.07360442398849856
  - 0.07107936985160233
  - 0.07146197581653334
  - 0.07035397098460709
  - 0.07468786766994917
  - 0.07179814983133438
  - 0.06850070269458663
  - 0.06544954220226568
  - 0.07204870220313542
  - 0.06637923266568778
  TT_f1_micro:
  - 0.07120305068066263
  - 0.06993193373790389
  - 0.07612350336230933
  - 0.07090069762146273
  - 0.07525887573964497
  - 0.07343030900723209
  - 0.07786817882971729
  - 0.07486930545182972
  - 0.07552596975673899
  - 0.07435486522024984
  - 0.0789776462853386
  - 0.07590656377064144
  - 0.0730810322156476
  - 0.06958826429980276
  - 0.07694362261669954
  - 0.07082399800846403
  TT_f1_weighted:
  - 0.013381941141218212
  - 0.013494990361576007
  - 0.015128630032097768
  - 0.013357235262715091
  - 0.02103280937411036
  - 0.018281207488025048
  - 0.019921400436460977
  - 0.019999555776176615
  - 0.018736071827082656
  - 0.01790504179089159
  - 0.02096855187675029
  - 0.018874296803378907
  - 0.012543650332981406
  - 0.011731766042815674
  - 0.014749746980141542
  - 0.010978693865287053
  TT_matthews_corrcoef:
  - 0.009607775525165747
  - 0.011833146517990903
  - 0.0038420497963201155
  - 0.001636927287263545
  - 0.014315299064696505
  - 0.016445269492974757
  - 0.016693087359089424
  - 0.010910830451559668
  - 0.018942904427255297
  - 0.017014686112542834
  - 0.013757108370632192
  - 0.004683647443440638
  - 0.004822606004623485
  - 0.004608058054548677
  - 0.0037877246174012123
  - -0.0016506290348740316
  TT_precision_macro:
  - 0.5255538184850832
  - 0.5297118091144765
  - 0.5097769678508184
  - 0.5042323505819873
  - 0.5231966780018587
  - 0.5302065833309605
  - 0.5305404450724126
  - 0.5184608484697117
  - 0.5355874824539675
  - 0.5328073873009983
  - 0.5241054934370443
  - 0.5085898582779371
  - 0.5158561228059345
  - 0.5146073496418182
  - 0.5104516080916897
  - 0.4933237810449373
  TT_precision_micro:
  - 0.07120305068066263
  - 0.06993193373790389
  - 0.07612350336230933
  - 0.07090069762146273
  - 0.07525887573964497
  - 0.07343030900723209
  - 0.07786817882971729
  - 0.07486930545182972
  - 0.07552596975673899
  - 0.07435486522024984
  - 0.0789776462853386
  - 0.07590656377064144
  - 0.0730810322156476
  - 0.06958826429980276
  - 0.07694362261669954
  - 0.07082399800846403
  TT_precision_weighted:
  - 0.9189863612533219
  - 0.9294470778369504
  - 0.8814186483288307
  - 0.8797503951787303
  - 0.9138260241810141
  - 0.9279718504258435
  - 0.9211626543126014
  - 0.9047325005629648
  - 0.9342005933391387
  - 0.9305751028564243
  - 0.9079320737394831
  - 0.8831239123089769
  - 0.8963422976802721
  - 0.9002086181973714
  - 0.880700533560319
  - 0.8574035807780385
  TT_recall_macro:
  - 0.5009030876402666
  - 0.5011781793223761
  - 0.5003774520603586
  - 0.50015827675968
  - 0.5022085898172066
  - 0.5022383108156705
  - 0.5022810666717322
  - 0.5016121444978273
  - 0.5025207854236688
  - 0.5022060545453703
  - 0.5019628101703829
  - 0.5006384434022267
  - 0.5003666963380721
  - 0.5003634163546907
  - 0.5003431734535826
  - 0.4998979745785336
  TT_recall_micro:
  - 0.07120305068066263
  - 0.06993193373790389
  - 0.07612350336230933
  - 0.07090069762146273
  - 0.07525887573964497
  - 0.07343030900723209
  - 0.07786817882971729
  - 0.07486930545182972
  - 0.07552596975673899
  - 0.07435486522024984
  - 0.0789776462853386
  - 0.07590656377064144
  - 0.0730810322156476
  - 0.06958826429980276
  - 0.07694362261669954
  - 0.07082399800846403
  TT_recall_weighted:
  - 0.07120305068066263
  - 0.06993193373790389
  - 0.07612350336230933
  - 0.07090069762146273
  - 0.07525887573964497
  - 0.07343030900723209
  - 0.07786817882971729
  - 0.07486930545182972
  - 0.07552596975673899
  - 0.07435486522024984
  - 0.0789776462853386
  - 0.07590656377064144
  - 0.0730810322156476
  - 0.06958826429980276
  - 0.07694362261669954
  - 0.07082399800846403
  TT_roc_auc:
  - 0.6022733945933683
  - 0.5863706791988718
  - 0.5680981160531311
  - 0.5904414524435317
  - 0.5924362645509433
  - 0.5798093595658037
  - 0.5834729863666157
  - 0.5781569837599199
  - 0.6128397460457725
  - 0.6032642199568916
  - 0.5943417851572452
  - 0.5995071042656507
  - 0.6065828997680434
  - 0.5932998784791241
  - 0.5849420542026562
  - 0.5944081547084085
  fit_time:
  - 1649.5600318908691
  - 1976.4486083984375
  - 2008.170977115631
  - 1675.4351172447205
  - 2051.3921740055084
  - 1954.6046752929688
  - 1714.5555579662323
  - 1904.2546200752258
  - 1891.5909957885742
  - 2061.66867685318
  - 1601.9849569797516
  - 1902.0207509994507
  - 1744.0437428951263
  - 2137.2761809825897
  - 2018.543740272522
  - 2192.225249528885
  score_time:
  - 96.5188102722168
  - 63.1275475025177
  - 56.27754211425781
  - 75.7569785118103
  - 54.43706941604614
  - 65.44558334350586
  - 87.35121273994446
  - 74.90753984451294
  - 72.64062023162842
  - 55.60844683647156
  - 86.61667895317078
  - 75.2016031742096
  - 70.02086758613586
  - 48.492594718933105
  - 55.405582666397095
  - 55.16823983192444
start: 2023-09-24 22:52:49.896561
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
