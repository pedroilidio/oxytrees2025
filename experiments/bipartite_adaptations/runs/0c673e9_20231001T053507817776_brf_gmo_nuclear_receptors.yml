active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: bipartite_adaptations/runs
end: 2023-10-01 05:35:11.117644
estimator:
  call: bipartite_adaptations.estimators.brf_gmo
  final_params:
    estimator:
      call: bipartite_learn.ensemble._forest.BipartiteRandomForestRegressor
      params:
        bipartite_adapter: gmo
        bootstrap: true
        ccp_alpha: 0.0
        criterion: squared_error
        max_col_features: 0.5
        max_depth: null
        max_features: 1.0
        max_leaf_nodes: null
        max_row_features: 0.5
        max_samples: null
        min_col_weight_fraction_leaf: 0.0
        min_cols_leaf: 5
        min_cols_split: 1
        min_impurity_decrease: 0.0
        min_row_weight_fraction_leaf: 0.0
        min_rows_leaf: 5
        min_rows_split: 1
        min_samples_leaf: 1
        min_samples_split: 2
        min_weight_fraction_leaf: 0.0
        n_estimators: 100
        n_jobs: 3
        oob_score: false
        prediction_weights: square
        random_state: 0
        verbose: 10
        warm_start: false
  name: brf_gmo
  params: {}
hash: 0c673e9a71adc7aae60e4fe78bd9b55e8fedfcb2e9d564b25b7955d265ea8759
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/0c673e9_20231001T053507817776_brf_gmo_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.7282372818193524
  - 0.7032428563040559
  - 0.7061611426913244
  - 0.7161521265694673
  - 0.6312540467844053
  - 0.7560544274868566
  - 0.6950472050466535
  - 0.5940440168069651
  - 0.7942051177836752
  - 0.7459977812966484
  - 0.8257106482583575
  - 0.7813280939916938
  - 0.755023515344788
  - 0.7245223127568896
  - 0.7500564408535288
  - 0.7557787784399914
  LL_balanced_accuracy:
  - 0.8433270380862449
  - 0.8400837988826816
  - 0.8507407407407408
  - 0.8445002511300854
  - 0.8546592489568845
  - 0.8143053645116919
  - 0.8299457994579946
  - 0.8360544217687075
  - 0.8670715249662618
  - 0.830026455026455
  - 0.8441558441558441
  - 0.8605263157894737
  - 0.8611766762828919
  - 0.8393333333333333
  - 0.863994743758213
  - 0.8631578947368421
  LL_f1_macro:
  - 0.602680072681853
  - 0.5436225419626538
  - 0.5892369727047146
  - 0.5821289069878134
  - 0.5558649923526238
  - 0.4841940154440154
  - 0.5206741435312864
  - 0.5356914089840011
  - 0.6106478908035329
  - 0.5251457936370459
  - 0.5547511312217195
  - 0.5996831362145831
  - 0.6174928033439804
  - 0.5617496229260934
  - 0.6028312372038608
  - 0.6036585365853658
  LL_f1_micro:
  - 0.7565789473684209
  - 0.6986842105263158
  - 0.7381258023106546
  - 0.7265725288831836
  - 0.7250000000000001
  - 0.6447368421052632
  - 0.6777920410783055
  - 0.6906290115532734
  - 0.75375
  - 0.67875
  - 0.7073170731707317
  - 0.7414634146341463
  - 0.7575
  - 0.7162499999999999
  - 0.7475609756097561
  - 0.7463414634146343
  LL_f1_weighted:
  - 0.8148197477254944
  - 0.7788402423571931
  - 0.8022527609042578
  - 0.7931175162629284
  - 0.8003714639622638
  - 0.7469693024791709
  - 0.7662148937336908
  - 0.7736067053737059
  - 0.8118760113643383
  - 0.7655110572203938
  - 0.783600044145238
  - 0.8030564864065796
  - 0.8130400449544541
  - 0.7894343891402714
  - 0.8080843207613123
  - 0.8066627007733492
  LL_matthews_corrcoef:
  - 0.3826079280306136
  - 0.33109527585140924
  - 0.37932482542013457
  - 0.3721951121557441
  - 0.3410692505311174
  - 0.2616535011157143
  - 0.3043945008973719
  - 0.32212446714833837
  - 0.41133566711280495
  - 0.3106221815574484
  - 0.34449155144829985
  - 0.3988179127799798
  - 0.41491634043629483
  - 0.3458805605890019
  - 0.40183498167064147
  - 0.4032468382625402
  LL_precision_macro:
  - 0.6065957602755903
  - 0.5805860805860806
  - 0.6025596020554493
  - 0.6005291005291005
  - 0.582
  - 0.5544554455445545
  - 0.5702054794520548
  - 0.5771929824561404
  - 0.615234375
  - 0.5730897009966778
  - 0.5862068965517242
  - 0.6102941176470589
  - 0.6191629892417294
  - 0.5881385281385282
  - 0.6109022556390977
  - 0.6119402985074627
  LL_precision_micro:
  - 0.756578947368421
  - 0.6986842105263158
  - 0.7381258023106547
  - 0.7265725288831836
  - 0.725
  - 0.6447368421052632
  - 0.6777920410783055
  - 0.6906290115532734
  - 0.75375
  - 0.67875
  - 0.7073170731707317
  - 0.7414634146341463
  - 0.7575
  - 0.71625
  - 0.7475609756097561
  - 0.7463414634146341
  LL_precision_weighted:
  - 0.9392115357331607
  - 0.9514362830152304
  - 0.9432521877155347
  - 0.9419179813747748
  - 0.9549000000000001
  - 0.9613079729025534
  - 0.9547584715212689
  - 0.9522374614327861
  - 0.9432470703125
  - 0.9530398671096346
  - 0.9495374264087468
  - 0.9429698708751794
  - 0.939422644284849
  - 0.9468506493506493
  - 0.9440078855675774
  - 0.943210775391336
  LL_recall_macro:
  - 0.8433270380862449
  - 0.8400837988826816
  - 0.8507407407407408
  - 0.8445002511300854
  - 0.8546592489568845
  - 0.8143053645116919
  - 0.8299457994579946
  - 0.8360544217687075
  - 0.8670715249662618
  - 0.830026455026455
  - 0.8441558441558441
  - 0.8605263157894737
  - 0.8611766762828919
  - 0.8393333333333333
  - 0.863994743758213
  - 0.8631578947368421
  LL_recall_micro:
  - 0.756578947368421
  - 0.6986842105263158
  - 0.7381258023106547
  - 0.7265725288831836
  - 0.725
  - 0.6447368421052632
  - 0.6777920410783055
  - 0.6906290115532734
  - 0.75375
  - 0.67875
  - 0.7073170731707317
  - 0.7414634146341463
  - 0.7575
  - 0.71625
  - 0.7475609756097561
  - 0.7463414634146341
  LL_recall_weighted:
  - 0.756578947368421
  - 0.6986842105263158
  - 0.7381258023106547
  - 0.7265725288831836
  - 0.725
  - 0.6447368421052632
  - 0.6777920410783055
  - 0.6906290115532734
  - 0.75375
  - 0.67875
  - 0.7073170731707317
  - 0.7414634146341463
  - 0.7575
  - 0.71625
  - 0.7475609756097561
  - 0.7463414634146341
  LL_roc_auc:
  - 0.9553430909663204
  - 0.9600050787201625
  - 0.9544572158365261
  - 0.9587518834756404
  - 0.9700464737609824
  - 0.9857029719478139
  - 0.974453037213299
  - 0.9672850958565243
  - 0.9693725840023789
  - 0.9681938431938432
  - 0.9744675324675325
  - 0.9723903508771929
  - 0.9636878223620946
  - 0.9598133333333333
  - 0.9606672754404331
  - 0.969046052631579
  LT_average_precision:
  - 0.23280999346425013
  - 0.31481586285266866
  - 0.40153481694195886
  - 0.33507259392324606
  - 0.2772839925145516
  - 0.23031552213823966
  - 0.08507728601713169
  - 0.16406617792137432
  - 0.28369948457780336
  - 0.22365418079793353
  - 0.30562152538459786
  - 0.3858144621887601
  - 0.28389998256467947
  - 0.28734976626387754
  - 0.382950627683737
  - 0.3282830394278618
  LT_balanced_accuracy:
  - 0.743160690571049
  - 0.7092946058091287
  - 0.6405172413793103
  - 0.7576640098099325
  - 0.5889107611548556
  - 0.5975609756097561
  - 0.5661347517730497
  - 0.6664332399626518
  - 0.7052238805970149
  - 0.7127799736495388
  - 0.6850966327953776
  - 0.8287696239503468
  - 0.7232704402515723
  - 0.708095447225882
  - 0.67722681359045
  - 0.7821350762527233
  LT_f1_macro:
  - 0.5506756756756757
  - 0.5787665886026543
  - 0.4908266336837765
  - 0.5437192118226601
  - 0.4256697321071572
  - 0.49570647931303663
  - 0.40559349593495936
  - 0.5078821349924849
  - 0.4754464285714286
  - 0.592718809741501
  - 0.4743187846636122
  - 0.6043478260869566
  - 0.5205068927134172
  - 0.6042053184910328
  - 0.49083333333333334
  - 0.5714713814803716
  LT_f1_micro:
  - 0.7518796992481203
  - 0.7330827067669174
  - 0.6761133603238867
  - 0.7327935222672065
  - 0.5939849624060151
  - 0.6804511278195489
  - 0.5506072874493927
  - 0.7692307692307693
  - 0.6642857142857143
  - 0.75
  - 0.5807692307692308
  - 0.8384615384615386
  - 0.7142857142857143
  - 0.7714285714285715
  - 0.6384615384615384
  - 0.7461538461538462
  LT_f1_weighted:
  - 0.8174405608616135
  - 0.7857993930963242
  - 0.7606737456361515
  - 0.8041423186613749
  - 0.7085328274705157
  - 0.7550374765954698
  - 0.6706596886211778
  - 0.8403756752178577
  - 0.7632015306122449
  - 0.7970035741002409
  - 0.6726623509116878
  - 0.8829431438127091
  - 0.7926681589666433
  - 0.8118561710398446
  - 0.7270384615384615
  - 0.8092920863972707
  LT_matthews_corrcoef:
  - 0.25140028718868
  - 0.2663575987465533
  - 0.14209809725384337
  - 0.26012783335819023
  - 0.07494336054471827
  - 0.11034176622414209
  - 0.057081142451628306
  - 0.14714140469128614
  - 0.17349208191604074
  - 0.2791202302834514
  - 0.20212389249668236
  - 0.3384374616001719
  - 0.21726587056663396
  - 0.28237900240483277
  - 0.18427852656144536
  - 0.30552290063736093
  LT_precision_macro:
  - 0.5649797714529066
  - 0.584744623655914
  - 0.5359241845430502
  - 0.5656538040931104
  - 0.5157925407925408
  - 0.5311992200194995
  - 0.5123167349095232
  - 0.5325214376938515
  - 0.5366666666666666
  - 0.5915359909314188
  - 0.5551793775243525
  - 0.5870973982009866
  - 0.5528556965040796
  - 0.5957948648830783
  - 0.5479027053859519
  - 0.5827123695976155
  LT_precision_micro:
  - 0.7518796992481203
  - 0.7330827067669173
  - 0.6761133603238867
  - 0.7327935222672065
  - 0.5939849624060151
  - 0.6804511278195489
  - 0.5506072874493927
  - 0.7692307692307693
  - 0.6642857142857143
  - 0.75
  - 0.5807692307692308
  - 0.8384615384615385
  - 0.7142857142857143
  - 0.7714285714285715
  - 0.6384615384615384
  - 0.7461538461538462
  LT_precision_weighted:
  - 0.9325496294501603
  - 0.8870184533915435
  - 0.9114927171904761
  - 0.9353871200539896
  - 0.927152671889514
  - 0.8825630862987823
  - 0.9189259356900424
  - 0.9463110325179291
  - 0.9450476190476189
  - 0.8850840733043643
  - 0.9038411279858178
  - 0.9563854561146369
  - 0.9335868705173689
  - 0.8834268770517844
  - 0.9101380376882983
  - 0.9311819328212771
  LT_recall_macro:
  - 0.743160690571049
  - 0.7092946058091287
  - 0.6405172413793103
  - 0.7576640098099325
  - 0.5889107611548556
  - 0.5975609756097561
  - 0.5661347517730497
  - 0.6664332399626518
  - 0.7052238805970149
  - 0.7127799736495388
  - 0.6850966327953776
  - 0.8287696239503468
  - 0.7232704402515723
  - 0.708095447225882
  - 0.67722681359045
  - 0.7821350762527233
  LT_recall_micro:
  - 0.7518796992481203
  - 0.7330827067669173
  - 0.6761133603238867
  - 0.7327935222672065
  - 0.5939849624060151
  - 0.6804511278195489
  - 0.5506072874493927
  - 0.7692307692307693
  - 0.6642857142857143
  - 0.75
  - 0.5807692307692308
  - 0.8384615384615385
  - 0.7142857142857143
  - 0.7714285714285715
  - 0.6384615384615384
  - 0.7461538461538462
  LT_recall_weighted:
  - 0.7518796992481203
  - 0.7330827067669173
  - 0.6761133603238867
  - 0.7327935222672065
  - 0.5939849624060151
  - 0.6804511278195489
  - 0.5506072874493927
  - 0.7692307692307693
  - 0.6642857142857143
  - 0.75
  - 0.5807692307692308
  - 0.8384615384615385
  - 0.7142857142857143
  - 0.7714285714285715
  - 0.6384615384615384
  - 0.7461538461538462
  LT_roc_auc:
  - 0.7622841965471447
  - 0.8008298755186722
  - 0.7270114942528736
  - 0.7927651747394238
  - 0.7431102362204725
  - 0.6323170731707317
  - 0.6617021276595745
  - 0.8053221288515406
  - 0.7854477611940298
  - 0.7448397013614405
  - 0.7646941621837019
  - 0.8765972982840453
  - 0.8062893081761007
  - 0.7836334358073488
  - 0.7940771349862259
  - 0.8433793270394578
  TL_average_precision:
  - 0.2764540291086802
  - 0.3300125886748644
  - 0.3432059204528704
  - 0.2739384350811064
  - 0.375738047133716
  - 0.35506173362745347
  - 0.36102518127479555
  - 0.32524674197574793
  - 0.09716196434247695
  - 0.07199422841104433
  - 0.1250034707876968
  - 0.09095172092122983
  - 0.2767198845364014
  - 0.3094644265236186
  - 0.30017234766827866
  - 0.2542680958131615
  TL_balanced_accuracy:
  - 0.6776929601357082
  - 0.6832324978392394
  - 0.7234432234432234
  - 0.6641883519206939
  - 0.6741158181111543
  - 0.6744791666666667
  - 0.6506410256410255
  - 0.5437048917401764
  - 0.5225347339884785
  - 0.47289054557777027
  - 0.5029239766081872
  - 0.5117200396170353
  - 0.4695652173913043
  - 0.5190067443286327
  - 0.5836849507735584
  - 0.5376361835589303
  TL_f1_macro:
  - 0.5348419540229885
  - 0.48168188937936085
  - 0.5223799952451965
  - 0.49210953605896407
  - 0.5351411178749308
  - 0.5118944903241711
  - 0.5087557603686635
  - 0.46018808777429465
  - 0.3834900731452456
  - 0.29054244883357494
  - 0.34279134039613085
  - 0.3710227272727272
  - 0.4140625
  - 0.4043731549935996
  - 0.42281747971453715
  - 0.4284140177737322
  TL_f1_micro:
  - 0.7357142857142858
  - 0.675
  - 0.7317073170731707
  - 0.662020905923345
  - 0.6464285714285715
  - 0.6464285714285715
  - 0.6376306620209059
  - 0.5923344947735192
  - 0.5083333333333333
  - 0.3458333333333333
  - 0.4105691056910569
  - 0.4878048780487805
  - 0.625
  - 0.6041666666666666
  - 0.6097560975609756
  - 0.6056910569105691
  TL_f1_weighted:
  - 0.8012161330049261
  - 0.7688327671433511
  - 0.8077261865791192
  - 0.7490237157936603
  - 0.7122262629456875
  - 0.7242203870331566
  - 0.7130268629875238
  - 0.673297434273044
  - 0.6308646812957158
  - 0.46714318439996727
  - 0.5229600835851749
  - 0.6134007760532151
  - 0.736328125
  - 0.7292172818865
  - 0.7272603716358799
  - 0.7130924747817914
  TL_matthews_corrcoef:
  - 0.19443038225800002
  - 0.16244833949296278
  - 0.21231877269335817
  - 0.16598055327164973
  - 0.22304119934036165
  - 0.20034932027591595
  - 0.18002298964580624
  - 0.0536836265563488
  - 0.02040332138072582
  - -0.026033370134420628
  - 0.0031162232559110714
  - 0.010493814210204566
  - -0.025366148560320767
  - 0.01310461765347105
  - 0.06429745557448048
  - 0.03452263720178583
  TL_precision_macro:
  - 0.5531860878395531
  - 0.5360054347826086
  - 0.5504370422867942
  - 0.5419480793583791
  - 0.5714285714285714
  - 0.5575138151188368
  - 0.5537839487335978
  - 0.5164851784633998
  - 0.5046183762761303
  - 0.49375
  - 0.5008302774510482
  - 0.5023489710844967
  - 0.49471458773784355
  - 0.5022588166715244
  - 0.5123503770843424
  - 0.5079166666666667
  TL_precision_micro:
  - 0.7357142857142858
  - 0.675
  - 0.7317073170731707
  - 0.662020905923345
  - 0.6464285714285715
  - 0.6464285714285715
  - 0.6376306620209059
  - 0.5923344947735192
  - 0.5083333333333333
  - 0.3458333333333333
  - 0.4105691056910569
  - 0.4878048780487805
  - 0.625
  - 0.6041666666666666
  - 0.6097560975609756
  - 0.6056910569105691
  TL_precision_weighted:
  - 0.9123544772059623
  - 0.9371942934782609
  - 0.9384453164163109
  - 0.9140256036522856
  - 0.8633928571428572
  - 0.8902270967939726
  - 0.874050902765447
  - 0.8322941500091692
  - 0.9021187813968563
  - 0.8894270833333333
  - 0.865346548020244
  - 0.902311529566695
  - 0.9162262156448204
  - 0.9451660108811814
  - 0.9394369976357344
  - 0.9062567750677507
  TL_recall_macro:
  - 0.6776929601357082
  - 0.6832324978392394
  - 0.7234432234432234
  - 0.6641883519206939
  - 0.6741158181111543
  - 0.6744791666666667
  - 0.6506410256410255
  - 0.5437048917401764
  - 0.5225347339884785
  - 0.47289054557777027
  - 0.5029239766081872
  - 0.5117200396170353
  - 0.4695652173913043
  - 0.5190067443286327
  - 0.5836849507735584
  - 0.5376361835589303
  TL_recall_micro:
  - 0.7357142857142858
  - 0.675
  - 0.7317073170731707
  - 0.662020905923345
  - 0.6464285714285715
  - 0.6464285714285715
  - 0.6376306620209059
  - 0.5923344947735192
  - 0.5083333333333333
  - 0.3458333333333333
  - 0.4105691056910569
  - 0.4878048780487805
  - 0.625
  - 0.6041666666666666
  - 0.6097560975609756
  - 0.6056910569105691
  TL_recall_weighted:
  - 0.7357142857142858
  - 0.675
  - 0.7317073170731707
  - 0.662020905923345
  - 0.6464285714285715
  - 0.6464285714285715
  - 0.6376306620209059
  - 0.5923344947735192
  - 0.5083333333333334
  - 0.3458333333333333
  - 0.4105691056910569
  - 0.4878048780487805
  - 0.625
  - 0.6041666666666666
  - 0.6097560975609756
  - 0.6056910569105691
  TL_roc_auc:
  - 0.7867896522476675
  - 0.8089887640449438
  - 0.8275771847200419
  - 0.7204667492771583
  - 0.7244461717839098
  - 0.728515625
  - 0.7216524216524217
  - 0.615744453354718
  - 0.5618434429007116
  - 0.4442561843442901
  - 0.5723684210526315
  - 0.5543083525916144
  - 0.6032608695652174
  - 0.5536480686695279
  - 0.6797937177684014
  - 0.6241333773522615
  TT_average_precision:
  - 0.050877192982456146
  - 0.1140747452088492
  - 0.11451774026114833
  - 0.35
  - 0.09803711865871576
  - 0.1622378580775925
  - 0.3069581346051934
  - 0.22175704412546518
  - 0.1307619991830518
  - 0.4971254427147681
  - 0.02127659574468085
  - 0.31529971038389987
  - 0.051739618406285076
  - 0.06673425242449874
  - 0.054346024103332946
  - -0.0
  TT_balanced_accuracy:
  - 0.519298245614035
  - 0.41805555555555557
  - 0.4583333333333333
  - 0.8863636363636364
  - 0.5778985507246377
  - 0.5244343891402715
  - 0.6901234567901235
  - 0.6475903614457832
  - 0.5769230769230769
  - 0.6730769230769231
  - 0.6688311688311688
  - 0.6041666666666666
  - 0.47530864197530864
  - 0.34615384615384615
  - 0.38175675675675674
  - 0.6153846153846154
  TT_f1_macro:
  - 0.4397865853658537
  - 0.42608695652173917
  - 0.4232394366197183
  - 0.5512820512820513
  - 0.3939164457907358
  - 0.503837987914421
  - 0.5153846153846154
  - 0.5693035835023665
  - 0.40203389830508474
  - 0.4381752701080432
  - 0.2712951089943213
  - 0.4381559991767853
  - 0.4045112781954887
  - 0.3913043478260869
  - 0.3548250265111347
  - 0.380952380952381
  TT_f1_micro:
  - 0.6938775510204082
  - 0.6632653061224489
  - 0.6043956043956044
  - 0.7802197802197802
  - 0.5
  - 0.6836734693877551
  - 0.6043956043956044
  - 0.7692307692307693
  - 0.5
  - 0.5357142857142857
  - 0.34615384615384615
  - 0.5512820512820513
  - 0.6071428571428571
  - 0.6428571428571429
  - 0.5
  - 0.6153846153846154
  TT_f1_weighted:
  - 0.7939739920358387
  - 0.7347952845734568
  - 0.6967497291440954
  - 0.850662158354466
  - 0.6164331692540704
  - 0.7232982364920492
  - 0.6774302620456468
  - 0.8111509855931763
  - 0.6094915254237288
  - 0.6388269593551706
  - 0.49886566995927684
  - 0.6514794117181439
  - 0.7270676691729323
  - 0.7267080745341614
  - 0.6294803817603393
  - 0.761904761904762
  TT_matthews_corrcoef:
  - 0.01456621482908866
  - -0.10043953713643844
  - -0.046188775643785596
  - 0.31747521766902076
  - 0.0747644074033025
  - 0.03754565616092126
  - 0.238553351165197
  - 0.19838707044279752
  - 0.07933288280219176
  - 0.17834705069535564
  - 0.08058229640253803
  - 0.111175181117488
  - -0.01887128390240993
  - -0.17541160386140583
  - -0.10446225439512512
  - 0.0
  TT_precision_macro:
  - 0.5027486256871564
  - 0.46922274387063123
  - 0.4871995820271683
  - 0.5652173913043478
  - 0.517939090529829
  - 0.5144230769230769
  - 0.5748299319727891
  - 0.5666666666666667
  - 0.5204545454545454
  - 0.5459444129325014
  - 0.5096153846153846
  - 0.529663810151615
  - 0.4963942307692308
  - 0.45
  - 0.47692814765985503
  - 0.5
  TT_precision_micro:
  - 0.6938775510204082
  - 0.6632653061224489
  - 0.6043956043956044
  - 0.7802197802197802
  - 0.5
  - 0.6836734693877551
  - 0.6043956043956044
  - 0.7692307692307693
  - 0.5
  - 0.5357142857142857
  - 0.34615384615384615
  - 0.5512820512820513
  - 0.6071428571428571
  - 0.6428571428571429
  - 0.5
  - 0.6153846153846154
  TT_precision_weighted:
  - 0.9423451539536354
  - 0.8308475189762916
  - 0.8481633309219516
  - 0.9713330148112758
  - 0.9036295369211514
  - 0.7793367346938775
  - 0.8747103236899154
  - 0.876713762428048
  - 0.8886363636363636
  - 0.9142289927882666
  - 0.9874260355029586
  - 0.8863647888038131
  - 0.9283138736263736
  - 0.8357142857142857
  - 0.880685563612393
  - 1.0
  TT_recall_macro:
  - 0.519298245614035
  - 0.41805555555555557
  - 0.4583333333333333
  - 0.8863636363636364
  - 0.5778985507246377
  - 0.5244343891402715
  - 0.6901234567901235
  - 0.6475903614457832
  - 0.5769230769230769
  - 0.6730769230769231
  - 0.6688311688311688
  - 0.6041666666666666
  - 0.47530864197530864
  - 0.34615384615384615
  - 0.38175675675675674
  - 0.3076923076923077
  TT_recall_micro:
  - 0.6938775510204082
  - 0.6632653061224489
  - 0.6043956043956044
  - 0.7802197802197802
  - 0.5
  - 0.6836734693877551
  - 0.6043956043956044
  - 0.7692307692307693
  - 0.5
  - 0.5357142857142857
  - 0.34615384615384615
  - 0.5512820512820513
  - 0.6071428571428571
  - 0.6428571428571429
  - 0.5
  - 0.6153846153846154
  TT_recall_weighted:
  - 0.6938775510204082
  - 0.6632653061224489
  - 0.6043956043956044
  - 0.7802197802197802
  - 0.5
  - 0.6836734693877551
  - 0.6043956043956044
  - 0.7692307692307693
  - 0.5
  - 0.5357142857142857
  - 0.34615384615384615
  - 0.5512820512820513
  - 0.6071428571428571
  - 0.6428571428571429
  - 0.5
  - 0.6153846153846154
  TT_roc_auc:
  - 0.6070175438596491
  - 0.6430555555555556
  - 0.5544217687074829
  - 0.9469696969696969
  - 0.6503623188405797
  - 0.5429864253393665
  - 0.7172839506172839
  - 0.7108433734939759
  - 0.6132478632478633
  - 0.7777777777777779
  - 0.4025974025974026
  - 0.6273148148148148
  - 0.5679012345679012
  - 0.41025641025641024
  - 0.44256756756756754
  - .nan
  fit_time:
  - 0.3177165985107422
  - 0.2829315662384033
  - 0.2850651741027832
  - 0.2768826484680176
  - 0.3174779415130615
  - 0.28053832054138184
  - 0.29433560371398926
  - 0.31801486015319824
  - 0.2772359848022461
  - 0.2879364490509033
  - 0.2869381904602051
  - 0.2870447635650635
  - 0.3010895252227783
  - 0.3105154037475586
  - 0.2947349548339844
  - 0.2745397090911865
  score_time:
  - 0.8131730556488037
  - 0.8038599491119385
  - 0.8181374073028564
  - 0.811429500579834
  - 0.8122634887695312
  - 0.7892293930053711
  - 0.8435559272766113
  - 0.7983002662658691
  - 0.7955951690673828
  - 0.8104369640350342
  - 0.7941267490386963
  - 0.801328182220459
  - 0.8036549091339111
  - 0.8104004859924316
  - 0.8211572170257568
  - 1.0591983795166016
start: 2023-10-01 05:35:07.817776
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
