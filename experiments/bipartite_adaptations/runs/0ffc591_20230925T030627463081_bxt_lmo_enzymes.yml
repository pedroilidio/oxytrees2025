active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-25 03:09:44.997464
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: bipartite_learn.wrappers.LocalMultiOutputWrapper
      params:
        combine_func_kwargs: null
        combine_predictions_func:
          load: numpy.mean
        independent_labels: false
        primary_cols_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_cols_estimator__bootstrap: false
        primary_cols_estimator__ccp_alpha: 0.0
        primary_cols_estimator__criterion: squared_error
        primary_cols_estimator__max_depth: null
        primary_cols_estimator__max_features: 1.0
        primary_cols_estimator__max_leaf_nodes: null
        primary_cols_estimator__max_samples: null
        primary_cols_estimator__min_impurity_decrease: 0.0
        primary_cols_estimator__min_samples_leaf: 1
        primary_cols_estimator__min_samples_split: 2
        primary_cols_estimator__min_weight_fraction_leaf: 0.0
        primary_cols_estimator__n_estimators: 50
        primary_cols_estimator__n_jobs: 3
        primary_cols_estimator__oob_score: false
        primary_cols_estimator__random_state: 0
        primary_cols_estimator__verbose: 10
        primary_cols_estimator__warm_start: false
        primary_rows_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_rows_estimator__bootstrap: false
        primary_rows_estimator__ccp_alpha: 0.0
        primary_rows_estimator__criterion: squared_error
        primary_rows_estimator__max_depth: null
        primary_rows_estimator__max_features: 1.0
        primary_rows_estimator__max_leaf_nodes: null
        primary_rows_estimator__max_samples: null
        primary_rows_estimator__min_impurity_decrease: 0.0
        primary_rows_estimator__min_samples_leaf: 1
        primary_rows_estimator__min_samples_split: 2
        primary_rows_estimator__min_weight_fraction_leaf: 0.0
        primary_rows_estimator__n_estimators: 50
        primary_rows_estimator__n_jobs: 3
        primary_rows_estimator__oob_score: false
        primary_rows_estimator__random_state: 0
        primary_rows_estimator__verbose: 10
        primary_rows_estimator__warm_start: false
        secondary_cols_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_cols_estimator__bootstrap: false
        secondary_cols_estimator__ccp_alpha: 0.0
        secondary_cols_estimator__criterion: squared_error
        secondary_cols_estimator__max_depth: null
        secondary_cols_estimator__max_features: 1.0
        secondary_cols_estimator__max_leaf_nodes: null
        secondary_cols_estimator__max_samples: null
        secondary_cols_estimator__min_impurity_decrease: 0.0
        secondary_cols_estimator__min_samples_leaf: 1
        secondary_cols_estimator__min_samples_split: 2
        secondary_cols_estimator__min_weight_fraction_leaf: 0.0
        secondary_cols_estimator__n_estimators: 50
        secondary_cols_estimator__n_jobs: 3
        secondary_cols_estimator__oob_score: false
        secondary_cols_estimator__random_state: 0
        secondary_cols_estimator__verbose: 10
        secondary_cols_estimator__warm_start: false
        secondary_rows_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_rows_estimator__bootstrap: false
        secondary_rows_estimator__ccp_alpha: 0.0
        secondary_rows_estimator__criterion: squared_error
        secondary_rows_estimator__max_depth: null
        secondary_rows_estimator__max_features: 1.0
        secondary_rows_estimator__max_leaf_nodes: null
        secondary_rows_estimator__max_samples: null
        secondary_rows_estimator__min_impurity_decrease: 0.0
        secondary_rows_estimator__min_samples_leaf: 1
        secondary_rows_estimator__min_samples_split: 2
        secondary_rows_estimator__min_weight_fraction_leaf: 0.0
        secondary_rows_estimator__n_estimators: 50
        secondary_rows_estimator__n_jobs: 3
        secondary_rows_estimator__oob_score: false
        secondary_rows_estimator__random_state: 0
        secondary_rows_estimator__verbose: 10
        secondary_rows_estimator__warm_start: false
  name: bxt_lmo
  params: {}
hash: 0ffc591a314302a602226236b59e3b06b05da44dcd40b44d2a22288a9b1eb940
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/0ffc591_20230925T030627463081_bxt_lmo_enzymes.yml"
results:
  LL_average_precision:
  - 0.9999983350669449
  - 1.0
  - 0.9999985378593896
  - 0.9999984057742856
  - 0.9999982245894363
  - 1.0
  - 0.9999984549303174
  - 0.99999829125477
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999985588467892
  - 1.0
  - 0.9999986681264001
  - 0.9999985343169532
  LL_balanced_accuracy:
  - 0.9999939130170131
  - 1.0
  - 0.9999939275803229
  - 0.9999939301604259
  - 0.9999939148319885
  - 1.0
  - 0.9999939292392123
  - 0.9999939321492934
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999939087160182
  - 1.0
  - 0.9999939246658567
  - 0.9999939276540706
  LL_f1_macro:
  - 0.9996743758448194
  - 1.0
  - 0.9996946663110229
  - 0.9996813084961348
  - 0.9996638461383189
  - 1.0
  - 0.9996862125812909
  - 0.9996701686706162
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.999696834291438
  - 1.0
  - 0.9997084452919689
  - 0.9996943003703418
  LL_f1_micro:
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  LL_f1_weighted:
  - 0.9999879436006747
  - 1.0
  - 0.9999879794538781
  - 0.9999879796145253
  - 0.9999879437276873
  - 1.0
  - 0.999987979555547
  - 0.9999879797484962
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879433297683
  - 1.0
  - 0.9999879792881625
  - 0.9999879794582791
  LL_matthews_corrcoef:
  - 0.999348963616338
  - 1.0
  - 0.9993895189677982
  - 0.9993628199938509
  - 0.9993279181263349
  - 1.0
  - 0.9993726219665091
  - 0.9993405547778019
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9993938522925806
  - 1.0
  - 0.9994170604951864
  - 0.999388787533236
  LL_precision_macro:
  - 0.9993552546744036
  - 1.0
  - 0.9993957703927492
  - 0.9993690851735015
  - 0.9993342210386151
  - 1.0
  - 0.9993788819875776
  - 0.999346832135859
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9994001199760048
  - 1.0
  - 0.9994232987312572
  - 0.999395039322444
  LL_precision_micro:
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  LL_precision_weighted:
  - 0.9999879552985594
  - 1.0
  - 0.9999879903862061
  - 0.9999879910279399
  - 0.9999879558059014
  - 1.0
  - 0.9999879907923434
  - 0.9999879915630875
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879542163856
  - 1.0
  - 0.9999879897241967
  - 0.9999879904037869
  LL_recall_macro:
  - 0.9999939130170131
  - 1.0
  - 0.9999939275803229
  - 0.9999939301604259
  - 0.9999939148319885
  - 1.0
  - 0.9999939292392123
  - 0.9999939321492934
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999939087160182
  - 1.0
  - 0.9999939246658567
  - 0.9999939276540706
  LL_recall_micro:
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  LL_recall_weighted:
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  LL_roc_auc:
  - 0.999999992140758
  - 1.0
  - 0.9999999926528497
  - 0.9999999923312197
  - 0.9999999918864426
  - 1.0
  - 0.9999999924493025
  - 0.9999999920629814
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999999926831423
  - 1.0
  - 0.9999999929846026
  - 0.9999999926440388
  LT_average_precision:
  - 0.18981880433436552
  - 0.36734421473117923
  - 0.2583845955050223
  - 0.2504055219197651
  - 0.21834270988400317
  - 0.4162719226567753
  - 0.29564425066708516
  - 0.29158755365076894
  - 0.23547177222093604
  - 0.3826596452792986
  - 0.2904297242660698
  - 0.2694620344916442
  - 0.2606475417315298
  - 0.43917090261214486
  - 0.34181230291843845
  - 0.303810209142036
  LT_balanced_accuracy:
  - 0.6505349604895551
  - 0.7492961616126954
  - 0.6823453303877687
  - 0.6994475679360574
  - 0.647755347087235
  - 0.7658861486534208
  - 0.6969291167207272
  - 0.7242040536758325
  - 0.6701227415697462
  - 0.7616066077567168
  - 0.677717928913314
  - 0.742367168325553
  - 0.6737623067572781
  - 0.8104641344830581
  - 0.7241708526291478
  - 0.7325948685316241
  LT_f1_macro:
  - 0.5588936191521804
  - 0.5583763103160911
  - 0.5678578765026765
  - 0.5864829986756493
  - 0.5539463217009982
  - 0.553375258325068
  - 0.5569109194721878
  - 0.5753914542866301
  - 0.5604257189228232
  - 0.5470864773912548
  - 0.5495159949229466
  - 0.5785644939627104
  - 0.5557121487059212
  - 0.5619771459132987
  - 0.5671212905818748
  - 0.5809043849533863
  LT_f1_micro:
  - 0.9533311818703385
  - 0.9495821122327146
  - 0.9589348384529107
  - 0.960960960960961
  - 0.9515382960413081
  - 0.9447338905170231
  - 0.950396179311842
  - 0.9511921560114331
  - 0.9480421686746988
  - 0.9385288903361193
  - 0.9475740801042005
  - 0.9490936719852382
  - 0.9447074010327022
  - 0.9395781323492167
  - 0.9472122725134773
  - 0.9484243279424003
  LT_f1_weighted:
  - 0.966575573042131
  - 0.9676359137281269
  - 0.9711164849686086
  - 0.9714968020411499
  - 0.965800838807575
  - 0.9652680230206689
  - 0.966817836282037
  - 0.9663964609962225
  - 0.9635687325890762
  - 0.9617305558319367
  - 0.9650248386978438
  - 0.9652210416722814
  - 0.9619993915557551
  - 0.9620175955366056
  - 0.9644417722156936
  - 0.9641787325302997
  LT_matthews_corrcoef:
  - 0.1568497177599656
  - 0.1977302611040859
  - 0.18268235882600184
  - 0.21681333221171112
  - 0.1489338401878378
  - 0.19735655773586963
  - 0.17463949803823653
  - 0.21329192050001008
  - 0.16881897742184032
  - 0.18760649575753569
  - 0.1563959088623366
  - 0.22615819093559125
  - 0.16439528752676438
  - 0.22955228068845573
  - 0.2019749314758072
  - 0.22565677706418463
  LT_precision_macro:
  - 0.5408573428414456
  - 0.5392076395233786
  - 0.5457550025482729
  - 0.5589227804470102
  - 0.5375304332302785
  - 0.5366224520143412
  - 0.5387181880248554
  - 0.5507277216944968
  - 0.5418813012222584
  - 0.5336346600265858
  - 0.5344080088858213
  - 0.5527583084794687
  - 0.5388833042467013
  - 0.5424318332752113
  - 0.5454941760561346
  - 0.5547314106244693
  LT_precision_micro:
  - 0.9533311818703385
  - 0.9495821122327146
  - 0.9589348384529107
  - 0.960960960960961
  - 0.9515382960413081
  - 0.9447338905170231
  - 0.950396179311842
  - 0.9511921560114331
  - 0.9480421686746988
  - 0.9385288903361193
  - 0.9475740801042006
  - 0.9490936719852382
  - 0.9447074010327022
  - 0.9395781323492167
  - 0.9472122725134773
  - 0.9484243279424003
  LT_precision_weighted:
  - 0.9819936306233861
  - 0.9892915028334125
  - 0.9855026554903527
  - 0.9842383456398065
  - 0.9823462870931118
  - 0.989931628862313
  - 0.9862545050884319
  - 0.984962784059643
  - 0.9819387238246737
  - 0.9895510575346481
  - 0.9854612192329127
  - 0.9851648588526345
  - 0.9824660497009807
  - 0.9897623396730646
  - 0.9853612751618834
  - 0.983688711889782
  LT_recall_macro:
  - 0.6505349604895551
  - 0.7492961616126954
  - 0.6823453303877687
  - 0.6994475679360574
  - 0.647755347087235
  - 0.7658861486534208
  - 0.6969291167207272
  - 0.7242040536758325
  - 0.6701227415697462
  - 0.7616066077567168
  - 0.677717928913314
  - 0.742367168325553
  - 0.6737623067572781
  - 0.8104641344830581
  - 0.7241708526291478
  - 0.7325948685316241
  LT_recall_micro:
  - 0.9533311818703385
  - 0.9495821122327146
  - 0.9589348384529107
  - 0.960960960960961
  - 0.9515382960413081
  - 0.9447338905170231
  - 0.950396179311842
  - 0.9511921560114331
  - 0.9480421686746988
  - 0.9385288903361193
  - 0.9475740801042006
  - 0.9490936719852382
  - 0.9447074010327022
  - 0.9395781323492167
  - 0.9472122725134773
  - 0.9484243279424003
  LT_recall_weighted:
  - 0.9533311818703385
  - 0.9495821122327146
  - 0.9589348384529107
  - 0.960960960960961
  - 0.9515382960413081
  - 0.9447338905170231
  - 0.950396179311842
  - 0.9511921560114331
  - 0.9480421686746988
  - 0.9385288903361193
  - 0.9475740801042006
  - 0.9490936719852382
  - 0.9447074010327022
  - 0.9395781323492167
  - 0.9472122725134773
  - 0.9484243279424003
  LT_roc_auc:
  - 0.6547903172431593
  - 0.7594199470027377
  - 0.6869882407422779
  - 0.7045470091690935
  - 0.6535963304767586
  - 0.777959626531671
  - 0.7036347442751542
  - 0.7318748582804312
  - 0.6767927939224846
  - 0.7753485557807674
  - 0.6847630047951223
  - 0.7507135780450102
  - 0.681534587696576
  - 0.8241716997522974
  - 0.7330567172943372
  - 0.7416360804483486
  TL_average_precision:
  - 0.6316179831296378
  - 0.6294097543216938
  - 0.6317159430709156
  - 0.6153441039518566
  - 0.7485565833652357
  - 0.7578009245584445
  - 0.7463520001518801
  - 0.7319753798817569
  - 0.7738041629223926
  - 0.7680045546118246
  - 0.757409851351095
  - 0.7453082045654412
  - 0.7362204911795422
  - 0.7462277657048637
  - 0.7666607634874365
  - 0.7454410104384948
  TL_balanced_accuracy:
  - 0.8390448001484335
  - 0.8307789601805052
  - 0.8351632072225399
  - 0.8239949598852001
  - 0.8779532749598311
  - 0.8834436445426184
  - 0.8844456078316941
  - 0.8754272376363739
  - 0.901893502409306
  - 0.9009979679964366
  - 0.8974742909035935
  - 0.8874418006486864
  - 0.8861511337253417
  - 0.8913076926337913
  - 0.9111720076508301
  - 0.8942156227371547
  TL_f1_macro:
  - 0.6537140996296202
  - 0.6176979282276197
  - 0.6194470964927375
  - 0.6596541185332936
  - 0.6770117361473844
  - 0.6542064565663155
  - 0.6694170763090244
  - 0.7067968333528779
  - 0.7043832412892996
  - 0.652848962263531
  - 0.6469304553103289
  - 0.6710279801138204
  - 0.6433600322043524
  - 0.6254861438969723
  - 0.6545924132934295
  - 0.6833869000365421
  TL_f1_micro:
  - 0.9713629291942545
  - 0.9561178847125027
  - 0.958751172354087
  - 0.9740098117018975
  - 0.9717247367849777
  - 0.9613303513455018
  - 0.9679857153163552
  - 0.9778334896472116
  - 0.9774412967184052
  - 0.9628093211168025
  - 0.9635848784358992
  - 0.972476733280427
  - 0.9719418213394116
  - 0.9594185123728447
  - 0.9688514537190679
  - 0.9775809826130871
  TL_f1_weighted:
  - 0.9789647097329167
  - 0.9695794280788621
  - 0.9714346494511142
  - 0.9804343842806833
  - 0.9790307481448363
  - 0.9724275325700118
  - 0.9766496512644717
  - 0.9827094750409924
  - 0.9828637043167582
  - 0.9738729949296603
  - 0.974627106114931
  - 0.9799513264742179
  - 0.9805064119719864
  - 0.9726089493596671
  - 0.978258129732943
  - 0.9834433962709414
  TL_matthews_corrcoef:
  - 0.37358170635419397
  - 0.3198286565028156
  - 0.3235328998619326
  - 0.3756661370298273
  - 0.4247192467798296
  - 0.3954146910459453
  - 0.41693993454577766
  - 0.46725911852165075
  - 0.4745600729004643
  - 0.40014837368397554
  - 0.3894174670422576
  - 0.41941703557998655
  - 0.3768451915076314
  - 0.35511228819537427
  - 0.4050607364086697
  - 0.4395827905690445
  TL_precision_macro:
  - 0.6029091813688121
  - 0.5773102145497528
  - 0.5780765422915072
  - 0.6088944767542969
  - 0.6193179491594545
  - 0.6019398679051403
  - 0.6130451912297188
  - 0.6453884148205425
  - 0.6400913808267625
  - 0.5998251448517025
  - 0.5953809888514205
  - 0.613507789712016
  - 0.5919408788162672
  - 0.5805662267834399
  - 0.5997600743283494
  - 0.6225427270124373
  TL_precision_micro:
  - 0.9713629291942545
  - 0.9561178847125027
  - 0.958751172354087
  - 0.9740098117018974
  - 0.9717247367849777
  - 0.9613303513455018
  - 0.9679857153163552
  - 0.9778334896472116
  - 0.9774412967184052
  - 0.9628093211168025
  - 0.9635848784358992
  - 0.972476733280427
  - 0.9719418213394116
  - 0.9594185123728447
  - 0.9688514537190679
  - 0.9775809826130871
  TL_precision_weighted:
  - 0.9894305388581153
  - 0.9875024291560126
  - 0.9883162271613125
  - 0.9892451017531633
  - 0.9896414061057456
  - 0.9882753609847442
  - 0.9892008383110962
  - 0.9900140820961602
  - 0.9911109910364909
  - 0.9896810712995315
  - 0.9901923976493013
  - 0.9907310371459562
  - 0.992281681371516
  - 0.9905789358147128
  - 0.9916291876700057
  - 0.9920183916323575
  TL_recall_macro:
  - 0.8390448001484335
  - 0.8307789601805052
  - 0.8351632072225399
  - 0.8239949598852001
  - 0.8779532749598311
  - 0.8834436445426184
  - 0.8844456078316941
  - 0.8754272376363739
  - 0.901893502409306
  - 0.9009979679964366
  - 0.8974742909035935
  - 0.8874418006486864
  - 0.8861511337253417
  - 0.8913076926337913
  - 0.9111720076508301
  - 0.8942156227371547
  TL_recall_micro:
  - 0.9713629291942545
  - 0.9561178847125027
  - 0.958751172354087
  - 0.9740098117018974
  - 0.9717247367849777
  - 0.9613303513455018
  - 0.9679857153163552
  - 0.9778334896472116
  - 0.9774412967184052
  - 0.9628093211168025
  - 0.9635848784358992
  - 0.972476733280427
  - 0.9719418213394116
  - 0.9594185123728447
  - 0.9688514537190679
  - 0.9775809826130871
  TL_recall_weighted:
  - 0.9713629291942545
  - 0.9561178847125027
  - 0.958751172354087
  - 0.9740098117018974
  - 0.9717247367849777
  - 0.9613303513455018
  - 0.9679857153163552
  - 0.9778334896472116
  - 0.9774412967184052
  - 0.9628093211168025
  - 0.9635848784358992
  - 0.972476733280427
  - 0.9719418213394116
  - 0.9594185123728447
  - 0.9688514537190679
  - 0.9775809826130871
  TL_roc_auc:
  - 0.8469751067412994
  - 0.8437518968717261
  - 0.8474246831755441
  - 0.831004705661687
  - 0.8877920236609158
  - 0.8973531076141159
  - 0.8957676544015136
  - 0.8826034031067241
  - 0.9099476060981514
  - 0.9149046617581265
  - 0.9110251146090182
  - 0.8971054956524179
  - 0.895928827969237
  - 0.9061560243303681
  - 0.9245748871824733
  - 0.902203019763881
  TT_average_precision:
  - 0.16080689184564834
  - 0.24139208379754945
  - 0.17553335776737314
  - 0.19768013100006104
  - 0.18803845229286986
  - 0.37312937933089313
  - 0.2471389684389656
  - 0.2532886366296738
  - 0.1967146854179098
  - 0.31891464821788407
  - 0.22984737435562333
  - 0.21147739677665042
  - 0.1544688669437942
  - 0.20548102796784248
  - 0.11156444917130065
  - 0.11988259203804051
  TT_balanced_accuracy:
  - 0.6298499189028272
  - 0.6630246508405353
  - 0.6152822856317086
  - 0.6833233377522041
  - 0.6413683819775241
  - 0.7740456996605716
  - 0.6411294304839241
  - 0.714412989136714
  - 0.6545108695652173
  - 0.7290732027574133
  - 0.6524816217701211
  - 0.6954825643036278
  - 0.6106462844086606
  - 0.7240498227717629
  - 0.6497347697692224
  - 0.647894778902051
  TT_f1_macro:
  - 0.5604204112657664
  - 0.5519503273476752
  - 0.5480918352457113
  - 0.5870476484172177
  - 0.5584029817884191
  - 0.5746671402465989
  - 0.5494980252277794
  - 0.5837193316127404
  - 0.5630376302338114
  - 0.5632780305409045
  - 0.5575659810341054
  - 0.575427079986045
  - 0.5472669062383073
  - 0.5423953930655104
  - 0.5298249837527526
  - 0.539060959938638
  TT_f1_micro:
  - 0.959552495697074
  - 0.9602192553999783
  - 0.9611418647563226
  - 0.9620102029740584
  - 0.9517534423407917
  - 0.9512102463909693
  - 0.950396179311842
  - 0.9520785846087051
  - 0.9588532702237521
  - 0.9544665147074786
  - 0.9564202756973841
  - 0.9529469228264409
  - 0.9561639414802066
  - 0.9494735699554977
  - 0.9449147943123847
  - 0.9488223162921958
  TT_f1_weighted:
  - 0.9697358159817293
  - 0.9729624267855439
  - 0.9717401057496693
  - 0.9715348241913015
  - 0.9649121999827958
  - 0.9679121930152423
  - 0.9652493844223089
  - 0.9658285665326877
  - 0.970328456621878
  - 0.9699669013442754
  - 0.9691188662734028
  - 0.9665267732883256
  - 0.9678043970083448
  - 0.9685169302070401
  - 0.9648864810331249
  - 0.9660637571195976
  TT_matthews_corrcoef:
  - 0.14858070029069798
  - 0.15091021866965904
  - 0.12435153476646414
  - 0.21037270366715463
  - 0.1522333278015639
  - 0.23240477788139852
  - 0.139895229240124
  - 0.22107141484349396
  - 0.16356306727095077
  - 0.19616549367064032
  - 0.1552804039321663
  - 0.20058032505278592
  - 0.12177453541191738
  - 0.1625881854921696
  - 0.11627452282644477
  - 0.12825747511571567
  TT_precision_macro:
  - 0.5425033467202142
  - 0.5349240037955991
  - 0.5335335652698968
  - 0.5603533011547739
  - 0.5409833262738039
  - 0.5492727862989645
  - 0.5346679553248395
  - 0.5569841531729008
  - 0.5432863996079406
  - 0.5419962924993424
  - 0.5395326393525766
  - 0.5514527560828792
  - 0.5335055025888145
  - 0.5294966960189978
  - 0.5225728544535024
  - 0.5278068976558548
  TT_precision_micro:
  - 0.959552495697074
  - 0.9602192553999783
  - 0.9611418647563226
  - 0.9620102029740584
  - 0.9517534423407917
  - 0.9512102463909693
  - 0.950396179311842
  - 0.9520785846087051
  - 0.9588532702237521
  - 0.9544665147074786
  - 0.9564202756973841
  - 0.9529469228264409
  - 0.9561639414802066
  - 0.9494735699554977
  - 0.9449147943123847
  - 0.9488223162921958
  TT_precision_weighted:
  - 0.981390565129134
  - 0.9876238437956126
  - 0.9836632993132867
  - 0.9829474374541193
  - 0.9801876473091079
  - 0.988521920317907
  - 0.9823867368751864
  - 0.9827181743412912
  - 0.9836682864763319
  - 0.9885024501679303
  - 0.9838386737897277
  - 0.9829091740759603
  - 0.9809335086201774
  - 0.9906954941991746
  - 0.9876102841063712
  - 0.9858085284089083
  TT_recall_macro:
  - 0.6298499189028272
  - 0.6630246508405353
  - 0.6152822856317086
  - 0.6833233377522041
  - 0.6413683819775241
  - 0.7740456996605716
  - 0.6411294304839241
  - 0.714412989136714
  - 0.6545108695652173
  - 0.7290732027574133
  - 0.6524816217701211
  - 0.6954825643036278
  - 0.6106462844086606
  - 0.7240498227717629
  - 0.6497347697692224
  - 0.647894778902051
  TT_recall_micro:
  - 0.959552495697074
  - 0.9602192553999783
  - 0.9611418647563226
  - 0.9620102029740584
  - 0.9517534423407917
  - 0.9512102463909693
  - 0.950396179311842
  - 0.9520785846087051
  - 0.9588532702237521
  - 0.9544665147074786
  - 0.9564202756973841
  - 0.9529469228264409
  - 0.9561639414802066
  - 0.9494735699554977
  - 0.9449147943123847
  - 0.9488223162921958
  TT_recall_weighted:
  - 0.959552495697074
  - 0.9602192553999783
  - 0.9611418647563226
  - 0.9620102029740584
  - 0.9517534423407917
  - 0.9512102463909693
  - 0.950396179311842
  - 0.9520785846087051
  - 0.9588532702237521
  - 0.9544665147074786
  - 0.9564202756973841
  - 0.9529469228264409
  - 0.9561639414802066
  - 0.9494735699554977
  - 0.9449147943123847
  - 0.9488223162921958
  TT_roc_auc:
  - 0.716242403555957
  - 0.7553334943903535
  - 0.6700330015219462
  - 0.7085785503068275
  - 0.6907778290643779
  - 0.85183571936932
  - 0.7869362449248328
  - 0.7558816624372516
  - 0.7092677196557972
  - 0.7784132748570872
  - 0.6920682981435152
  - 0.7098525559182433
  - 0.6776103434519277
  - 0.8225644946929561
  - 0.7729359697504725
  - 0.7100893845439723
  fit_time:
  - 15.104312896728516
  - 12.005137205123901
  - 12.944745540618896
  - 13.576038360595703
  - 11.963450908660889
  - 12.849763870239258
  - 12.89760708808899
  - 15.5859534740448
  - 15.436376333236694
  - 12.112667083740234
  - 12.824958562850952
  - 12.97923469543457
  - 13.321651697158813
  - 12.545184135437012
  - 13.118883848190308
  - 15.25733208656311
  score_time:
  - 174.2014126777649
  - 164.1788399219513
  - 173.42392992973328
  - 183.51667022705078
  - 165.70336079597473
  - 158.48318910598755
  - 163.86710143089294
  - 176.85787796974182
  - 178.19657492637634
  - 170.14968371391296
  - 174.82666158676147
  - 175.05104899406433
  - 169.73600053787231
  - 169.63607454299927
  - 170.61637043952942
  - 182.04506301879883
start: 2023-09-25 03:06:27.463081
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
