active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-25 18:34:44.489701
estimator:
  call: bipartite_adaptations.estimators.bxt_gmosa
  final_params:
    estimator:
      call: bipartite_learn.ensemble._forest.BipartiteExtraTreesRegressor
      params:
        bipartite_adapter: gmosa
        bootstrap: false
        ccp_alpha: 0.0
        criterion: squared_error
        max_col_features: null
        max_depth: null
        max_features: 1.0
        max_leaf_nodes: null
        max_row_features: null
        max_samples: null
        min_col_weight_fraction_leaf: 0.0
        min_cols_leaf: 1
        min_cols_split: 1
        min_impurity_decrease: 0.0
        min_row_weight_fraction_leaf: 0.0
        min_rows_leaf: 1
        min_rows_split: 1
        min_samples_leaf: 1
        min_samples_split: 2
        min_weight_fraction_leaf: 0.0
        n_estimators: 100
        n_jobs: 3
        oob_score: false
        prediction_weights: null
        random_state: 0
        verbose: 10
        warm_start: false
  name: bxt_gmosa
  params: {}
hash: c2e46afc73ecccc10d1a73d52ee0738fd9ced2e10304d8372dda38eed82fa5e3
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/c2e46af_20230925T183442609861_bxt_gmosa_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9921531701192718
  - 1.0
  - 1.0
  - 0.9924242424242424
  - 0.981318111053451
  - 1.0
  - 1.0
  - 0.9836363636363636
  - 0.9838097647356439
  - 1.0
  - 1.0
  - 0.9843137254901961
  - 0.9939817043813192
  - 1.0
  - 1.0
  - 0.9935897435897436
  LL_balanced_accuracy:
  - 0.9964589235127479
  - 1.0
  - 1.0
  - 0.9965469613259669
  - 0.9958275382475661
  - 1.0
  - 1.0
  - 0.9959183673469387
  - 0.9946018893387314
  - 1.0
  - 1.0
  - 0.9947368421052631
  - 0.9966124661246613
  - 1.0
  - 1.0
  - 0.9967105263157895
  LL_f1_macro:
  - 0.9760992760596512
  - 1.0
  - 1.0
  - 0.9765283678327157
  - 0.9638141188420519
  - 1.0
  - 1.0
  - 0.9660359260551099
  - 0.9655402640477266
  - 1.0
  - 1.0
  - 0.9661044973544973
  - 0.978920630905517
  - 1.0
  - 1.0
  - 0.9783498349834985
  LL_f1_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_f1_weighted:
  - 0.9935549148925676
  - 1.0
  - 1.0
  - 0.9937099270134935
  - 0.9923578626607149
  - 1.0
  - 1.0
  - 0.9925278488828433
  - 0.9902903232753978
  - 1.0
  - 1.0
  - 0.9905229707058975
  - 0.9938605020051748
  - 1.0
  - 1.0
  - 0.9940143282620947
  LL_matthews_corrcoef:
  - 0.9532954771575798
  - 1.0
  - 1.0
  - 0.9541153472008888
  - 0.9300864537292473
  - 1.0
  - 1.0
  - 0.9342463949786545
  - 0.9333219673061774
  - 1.0
  - 1.0
  - 0.9343794815169456
  - 0.9586989457846643
  - 1.0
  - 1.0
  - 0.9576032835067954
  LL_precision_macro:
  - 0.9576271186440678
  - 1.0
  - 1.0
  - 0.9583333333333333
  - 0.9361702127659575
  - 1.0
  - 1.0
  - 0.94
  - 0.9402985074626866
  - 1.0
  - 1.0
  - 0.9411764705882353
  - 0.9626865671641791
  - 1.0
  - 1.0
  - 0.9615384615384616
  LL_precision_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_precision_weighted:
  - 0.993978590544157
  - 1.0
  - 1.0
  - 0.9941163885323063
  - 0.9931131019036955
  - 1.0
  - 1.0
  - 0.9932220795892169
  - 0.9911940298507463
  - 1.0
  - 1.0
  - 0.9913916786226686
  - 0.9942164179104478
  - 1.0
  - 1.0
  - 0.9943714821763602
  LL_recall_macro:
  - 0.9964589235127479
  - 1.0
  - 1.0
  - 0.9965469613259669
  - 0.9958275382475661
  - 1.0
  - 1.0
  - 0.9959183673469387
  - 0.9946018893387314
  - 1.0
  - 1.0
  - 0.9947368421052631
  - 0.9966124661246613
  - 1.0
  - 1.0
  - 0.9967105263157895
  LL_recall_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_recall_weighted:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_roc_auc:
  - 0.9996721225474767
  - 1.0
  - 1.0
  - 0.9996860873932698
  - 0.9993893958411073
  - 1.0
  - 1.0
  - 0.999443413729128
  - 0.9992680527916924
  - 1.0
  - 1.0
  - 0.999298245614035
  - 0.9997268117842469
  - 1.0
  - 1.0
  - 0.9997258771929824
  LT_average_precision:
  - 0.36056797068013635
  - 0.3856835143414091
  - 0.23170992831080545
  - 0.4982763611073102
  - 0.29031967132496656
  - 0.3258524874480685
  - 0.21172786069402616
  - 0.34270730244414455
  - 0.370342522974102
  - 0.37789139645817893
  - 0.28441743441743444
  - 0.4397574099155127
  - 0.41434450323339206
  - 0.4665607726448875
  - 0.3663699505334546
  - 0.4667731903267699
  LT_balanced_accuracy:
  - 0.7407702523240371
  - 0.6813278008298755
  - 0.7214080459770115
  - 0.7828019619865114
  - 0.6351706036745407
  - 0.6107723577235773
  - 0.6530141843971631
  - 0.7441643323996265
  - 0.7655472636815921
  - 0.6819645732689211
  - 0.7396891811117752
  - 0.7860533041255933
  - 0.7622641509433963
  - 0.7190016103059581
  - 0.8218549127640037
  - 0.7570806100217865
  LT_f1_macro:
  - 0.7020609318996416
  - 0.702682563338301
  - 0.6507070707070707
  - 0.6941258816561675
  - 0.601
  - 0.63425
  - 0.5796937039137833
  - 0.6451149425287356
  - 0.6940946466563165
  - 0.6980710092256079
  - 0.6848484848484849
  - 0.6853062212539337
  - 0.6793516560958421
  - 0.7303440040063176
  - 0.734468085106383
  - 0.695906432748538
  LT_f1_micro:
  - 0.924812030075188
  - 0.9097744360902256
  - 0.8866396761133604
  - 0.9068825910931174
  - 0.9097744360902256
  - 0.9172932330827067
  - 0.8663967611336032
  - 0.9190283400809717
  - 0.9321428571428572
  - 0.9035714285714286
  - 0.8807692307692307
  - 0.9230769230769231
  - 0.9071428571428571
  - 0.9107142857142857
  - 0.9076923076923076
  - 0.9038461538461539
  LT_f1_weighted:
  - 0.9306229282884629
  - 0.9041773584482816
  - 0.9029108902793114
  - 0.9203089853779736
  - 0.9203308270676692
  - 0.9076165413533834
  - 0.893099496855057
  - 0.9341756247382381
  - 0.9408166785775892
  - 0.8991233675466273
  - 0.8931934731934733
  - 0.9357019160940729
  - 0.9206558944931038
  - 0.9083513562595962
  - 0.9192405891980361
  - 0.9144849302744039
  LT_matthews_corrcoef:
  - 0.411929243484719
  - 0.4109108781239708
  - 0.32853812253631737
  - 0.4191419886966592
  - 0.21278312313476452
  - 0.28147282065156953
  - 0.19859966841846308
  - 0.32806362873141237
  - 0.4083855029473071
  - 0.3992434393590275
  - 0.3874300896634242
  - 0.4055411135471143
  - 0.3876159442907868
  - 0.46184244431505767
  - 0.49738382872633896
  - 0.4100189289177968
  LT_precision_macro:
  - 0.6761904761904762
  - 0.7327935222672064
  - 0.621875988611199
  - 0.6553030303030303
  - 0.583739837398374
  - 0.6788057742782152
  - 0.5644414575866189
  - 0.6101980615254952
  - 0.657014157014157
  - 0.7189922480620154
  - 0.6565590838105154
  - 0.6437350944780774
  - 0.6432202225580437
  - 0.7434895833333333
  - 0.6921600877192983
  - 0.6634852216748769
  LT_precision_micro:
  - 0.924812030075188
  - 0.9097744360902256
  - 0.8866396761133604
  - 0.9068825910931174
  - 0.9097744360902256
  - 0.9172932330827067
  - 0.8663967611336032
  - 0.9190283400809717
  - 0.9321428571428572
  - 0.9035714285714286
  - 0.8807692307692307
  - 0.9230769230769231
  - 0.9071428571428571
  - 0.9107142857142857
  - 0.9076923076923077
  - 0.9038461538461539
  LT_precision_weighted:
  - 0.9381310418904404
  - 0.9004596511521719
  - 0.9258639261136805
  - 0.9407741381425592
  - 0.9328565315728345
  - 0.9015254672113355
  - 0.9284200126729837
  - 0.9551840800094176
  - 0.9529509100937673
  - 0.8957502768549279
  - 0.9111310215032236
  - 0.9544049786207189
  - 0.9404303966400408
  - 0.9063895089285714
  - 0.9384826248313091
  - 0.9297674308450171
  LT_recall_macro:
  - 0.7407702523240371
  - 0.6813278008298755
  - 0.7214080459770115
  - 0.7828019619865114
  - 0.6351706036745407
  - 0.6107723577235773
  - 0.6530141843971631
  - 0.7441643323996265
  - 0.7655472636815921
  - 0.6819645732689211
  - 0.7396891811117752
  - 0.7860533041255933
  - 0.7622641509433963
  - 0.7190016103059581
  - 0.8218549127640037
  - 0.7570806100217865
  LT_recall_micro:
  - 0.924812030075188
  - 0.9097744360902256
  - 0.8866396761133604
  - 0.9068825910931174
  - 0.9097744360902256
  - 0.9172932330827067
  - 0.8663967611336032
  - 0.9190283400809717
  - 0.9321428571428572
  - 0.9035714285714286
  - 0.8807692307692307
  - 0.9230769230769231
  - 0.9071428571428571
  - 0.9107142857142857
  - 0.9076923076923077
  - 0.9038461538461539
  LT_recall_weighted:
  - 0.924812030075188
  - 0.9097744360902256
  - 0.8866396761133604
  - 0.9068825910931174
  - 0.9097744360902256
  - 0.9172932330827067
  - 0.8663967611336032
  - 0.9190283400809717
  - 0.9321428571428572
  - 0.9035714285714286
  - 0.8807692307692307
  - 0.9230769230769231
  - 0.9071428571428571
  - 0.9107142857142857
  - 0.9076923076923077
  - 0.9038461538461539
  LT_roc_auc:
  - 0.7895086321381142
  - 0.7544398340248963
  - 0.7175287356321839
  - 0.8352237890864499
  - 0.7481955380577427
  - 0.6641260162601625
  - 0.8186170212765957
  - 0.8359010270774976
  - 0.7179726368159204
  - 0.6973356755965452
  - 0.8429966128710897
  - 0.8647316538882803
  - 0.7932075471698115
  - 0.7899282681891377
  - 0.9117309458218549
  - 0.8552408617768096
  TL_average_precision:
  - 0.38570426487093157
  - 0.4397194910352805
  - 0.5283930645428903
  - 0.44635705198035824
  - 0.3944326102774467
  - 0.2754578754578754
  - 0.4040707109812801
  - 0.39867764097656533
  - 0.06046037296037296
  - 0.12692307692307692
  - 0.13233540570699825
  - 0.13525752702581972
  - 0.3162414965986394
  - 0.30654761904761907
  - 0.37274164408310745
  - 0.35898148368046484
  TL_balanced_accuracy:
  - 0.7338846480067854
  - 0.7721117833477384
  - 0.8278388278388278
  - 0.7091078066914498
  - 0.6755408731700998
  - 0.6302083333333334
  - 0.6563390313390314
  - 0.6547714514835605
  - 0.5404947475432057
  - 0.4789901728227719
  - 0.5431286549707602
  - 0.5572796302410037
  - 0.567391304347826
  - 0.6128142244022072
  - 0.580168776371308
  - 0.6087817761637504
  TL_f1_macro:
  - 0.6656265649678339
  - 0.676923076923077
  - 0.7312734082397003
  - 0.6541496598639456
  - 0.6780446138177996
  - 0.6554948570303657
  - 0.6616563513115237
  - 0.6547714514835605
  - 0.5088372093023256
  - 0.4799711095060837
  - 0.5242188507327975
  - 0.5017254313578394
  - 0.5063759769642123
  - 0.5661687755684521
  - 0.5030730218764774
  - 0.5722235103176444
  TL_f1_micro:
  - 0.8892857142857142
  - 0.9142857142857143
  - 0.9303135888501742
  - 0.89198606271777
  - 0.875
  - 0.9107142857142857
  - 0.8885017421602788
  - 0.8745644599303136
  - 0.8166666666666667
  - 0.8375
  - 0.8170731707317073
  - 0.7804878048780488
  - 0.8125
  - 0.9208333333333333
  - 0.8089430894308943
  - 0.8780487804878049
  TL_f1_weighted:
  - 0.9039358769047894
  - 0.928131868131868
  - 0.9399835571389422
  - 0.9049771267391975
  - 0.8741006603370677
  - 0.9011832697053427
  - 0.8865711430892255
  - 0.8745644599303136
  - 0.8555503875968993
  - 0.8644494138563253
  - 0.8428686289699532
  - 0.8350282692624376
  - 0.8627108185931717
  - 0.9355429232867156
  - 0.8644117545314361
  - 0.895692546074545
  TL_matthews_corrcoef:
  - 0.35580591475734946
  - 0.387938166094286
  - 0.492072163425552
  - 0.3266719202585828
  - 0.3561706580806343
  - 0.3237619541190881
  - 0.3237019521546871
  - 0.3095429029671211
  - 0.050765002885786566
  - -0.029627167599435723
  - 0.0643019785391438
  - 0.0641724595695674
  - 0.07156147924262463
  - 0.1522077750868261
  - 0.07854682872148545
  - 0.16109039141183076
  TL_precision_macro:
  - 0.6353208195313459
  - 0.638266725223247
  - 0.6846448570586502
  - 0.6275831653225806
  - 0.6806666666666668
  - 0.7012578616352201
  - 0.667557251908397
  - 0.6547714514835605
  - 0.5159099986686193
  - 0.48955525606469
  - 0.5239675016926202
  - 0.5179736869367036
  - 0.5189974261551661
  - 0.5513392857142857
  - 0.5192394239423942
  - 0.5596380090497738
  TL_precision_micro:
  - 0.8892857142857142
  - 0.9142857142857143
  - 0.9303135888501742
  - 0.89198606271777
  - 0.875
  - 0.9107142857142857
  - 0.8885017421602788
  - 0.8745644599303136
  - 0.8166666666666667
  - 0.8375
  - 0.8170731707317073
  - 0.7804878048780488
  - 0.8125
  - 0.9208333333333333
  - 0.8089430894308943
  - 0.8780487804878049
  TL_precision_weighted:
  - 0.9248882696251117
  - 0.9484827571784092
  - 0.9554031614586701
  - 0.9225392864167697
  - 0.8732333333333333
  - 0.8956334231805929
  - 0.8847727212277575
  - 0.8745644599303136
  - 0.9036324501841743
  - 0.8942301212938005
  - 0.8736958567960763
  - 0.9081973757684328
  - 0.9276718960656942
  - 0.9528087797619047
  - 0.9372928146473184
  - 0.9170378545414415
  TL_recall_macro:
  - 0.7338846480067854
  - 0.7721117833477384
  - 0.8278388278388278
  - 0.7091078066914498
  - 0.6755408731700998
  - 0.6302083333333334
  - 0.6563390313390314
  - 0.6547714514835605
  - 0.5404947475432057
  - 0.4789901728227719
  - 0.5431286549707602
  - 0.5572796302410037
  - 0.567391304347826
  - 0.6128142244022072
  - 0.580168776371308
  - 0.6087817761637504
  TL_recall_micro:
  - 0.8892857142857142
  - 0.9142857142857143
  - 0.9303135888501742
  - 0.89198606271777
  - 0.875
  - 0.9107142857142857
  - 0.8885017421602788
  - 0.8745644599303136
  - 0.8166666666666667
  - 0.8375
  - 0.8170731707317073
  - 0.7804878048780488
  - 0.8125
  - 0.9208333333333333
  - 0.8089430894308943
  - 0.8780487804878049
  TL_recall_weighted:
  - 0.8892857142857142
  - 0.9142857142857143
  - 0.9303135888501742
  - 0.89198606271777
  - 0.875
  - 0.9107142857142857
  - 0.8885017421602788
  - 0.8745644599303136
  - 0.8166666666666667
  - 0.8375
  - 0.8170731707317073
  - 0.7804878048780488
  - 0.8125
  - 0.9208333333333333
  - 0.8089430894308943
  - 0.8780487804878049
  TL_roc_auc:
  - 0.7516963528413911
  - 0.7683664649956785
  - 0.8248299319727892
  - 0.744940107393639
  - 0.6638165565487758
  - 0.5948893229166666
  - 0.6395299145299145
  - 0.6416733493718257
  - 0.5049135886140292
  - 0.44290071162317857
  - 0.5026803118908383
  - 0.5307032023770222
  - 0.6278260869565218
  - 0.5462906192519925
  - 0.6760431317393343
  - 0.6911521954440409
  TT_average_precision:
  - 0.06802721088435373
  - 0.227359693877551
  - 0.10073260073260074
  - 0.4861111111111111
  - 0.1791383219954648
  - 0.189272632129775
  - 0.38103425985778927
  - 0.20212912087912088
  - 0.1468253968253968
  - 0.07326007326007326
  - 0.02631578947368421
  - 0.19974369974369977
  - 0.03571428571428571
  - 0.24206349206349206
  - 0.04841379841379841
  - -0.0
  TT_balanced_accuracy:
  - 0.4842105263157895
  - 0.5347222222222222
  - 0.5238095238095238
  - 0.6553030303030303
  - 0.4891304347826087
  - 0.5266968325791855
  - 0.6567901234567901
  - 0.6009036144578312
  - 0.4807692307692308
  - 0.4423076923076923
  - 0.44805194805194803
  - 0.6180555555555556
  - 0.4444444444444444
  - 0.5641025641025641
  - 0.4391891891891892
  - 0.9871794871794872
  TT_f1_macro:
  - 0.4842105263157895
  - 0.5384615384615384
  - 0.5203313253012047
  - 0.6553030303030303
  - 0.4787234042553192
  - 0.5236111111111111
  - 0.6501035196687371
  - 0.613095238095238
  - 0.4716981132075472
  - 0.4509803921568628
  - 0.46938775510204084
  - 0.5943262411347517
  - 0.4615384615384615
  - 0.5746835443037974
  - 0.4545454545454546
  - 0.4967741935483871
  TT_f1_micro:
  - 0.9387755102040817
  - 0.8775510204081631
  - 0.8461538461538461
  - 0.9560439560439561
  - 0.9183673469387755
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8901098901098901
  - 0.8928571428571429
  - 0.8214285714285714
  - 0.8846153846153846
  - 0.8589743589743589
  - 0.8571428571428571
  - 0.9047619047619048
  - 0.8333333333333334
  - 0.9871794871794872
  TT_f1_weighted:
  - 0.9387755102040817
  - 0.8694774613141959
  - 0.8548424467099165
  - 0.9560439560439561
  - 0.8988276161528441
  - 0.8164682539682541
  - 0.8601005619639162
  - 0.8829147043432757
  - 0.8760107816711591
  - 0.8375350140056023
  - 0.9267399267399268
  - 0.8715766503000544
  - 0.89010989010989
  - 0.8958408679927666
  - 0.8624708624708626
  - 0.9935483870967742
  TT_matthews_corrcoef:
  - -0.031578947368421054
  - 0.07931114454446678
  - 0.04250511420422255
  - 0.3106060606060606
  - -0.036860489038724284
  - 0.1051352720011248
  - 0.30084989974625026
  - 0.23026910376007506
  - -0.05337605126836238
  - -0.09607689228305227
  - -0.038525706426470976
  - 0.19693027994279283
  - -0.06666666666666667
  - 0.15504341823651058
  - -0.08396742695628599
  - 0.0
  TT_precision_macro:
  - 0.4842105263157895
  - 0.5452898550724637
  - 0.518970189701897
  - 0.6553030303030303
  - 0.46875
  - 0.6035087719298246
  - 0.6443181818181818
  - 0.6313725490196078
  - 0.46296296296296297
  - 0.46
  - 0.4928571428571429
  - 0.5821256038647342
  - 0.48
  - 0.59375
  - 0.47101449275362317
  - 0.5
  TT_precision_micro:
  - 0.9387755102040817
  - 0.8775510204081632
  - 0.8461538461538461
  - 0.9560439560439561
  - 0.9183673469387755
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8901098901098901
  - 0.8928571428571429
  - 0.8214285714285714
  - 0.8846153846153846
  - 0.8589743589743589
  - 0.8571428571428571
  - 0.9047619047619048
  - 0.8333333333333334
  - 0.9871794871794872
  TT_precision_weighted:
  - 0.9387755102040817
  - 0.8620970127181308
  - 0.8640817177402543
  - 0.9560439560439561
  - 0.8801020408163265
  - 0.8020050125313284
  - 0.8633116883116884
  - 0.8770092652445594
  - 0.8597883597883599
  - 0.8542857142857143
  - 0.9730769230769232
  - 0.8866592344853214
  - 0.9257142857142856
  - 0.8883928571428571
  - 0.8937198067632851
  - 1.0
  TT_recall_macro:
  - 0.4842105263157895
  - 0.5347222222222222
  - 0.5238095238095238
  - 0.6553030303030303
  - 0.4891304347826087
  - 0.5266968325791855
  - 0.6567901234567901
  - 0.6009036144578312
  - 0.4807692307692308
  - 0.4423076923076923
  - 0.44805194805194803
  - 0.6180555555555556
  - 0.4444444444444444
  - 0.5641025641025641
  - 0.4391891891891892
  - 0.4935897435897436
  TT_recall_micro:
  - 0.9387755102040817
  - 0.8775510204081632
  - 0.8461538461538461
  - 0.9560439560439561
  - 0.9183673469387755
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8901098901098901
  - 0.8928571428571429
  - 0.8214285714285714
  - 0.8846153846153846
  - 0.8589743589743589
  - 0.8571428571428571
  - 0.9047619047619048
  - 0.8333333333333334
  - 0.9871794871794872
  TT_recall_weighted:
  - 0.9387755102040817
  - 0.8775510204081632
  - 0.8461538461538461
  - 0.9560439560439561
  - 0.9183673469387755
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8901098901098901
  - 0.8928571428571429
  - 0.8214285714285714
  - 0.8846153846153846
  - 0.8589743589743589
  - 0.8571428571428571
  - 0.9047619047619048
  - 0.8333333333333334
  - 0.9871794871794872
  TT_roc_auc:
  - 0.5526315789473684
  - 0.5847222222222223
  - 0.5110544217687074
  - 0.9299242424242424
  - 0.7382246376811594
  - 0.5895927601809955
  - 0.7660493827160494
  - 0.6746987951807228
  - 0.6923076923076922
  - 0.48290598290598286
  - 0.6038961038961038
  - 0.6527777777777778
  - 0.2962962962962963
  - 0.5373931623931624
  - 0.4476351351351351
  - .nan
  fit_time:
  - 0.1745316982269287
  - 0.23384857177734375
  - 0.17017078399658203
  - 0.14609766006469727
  - 0.1493678092956543
  - 0.17294979095458984
  - 0.1773841381072998
  - 0.180680513381958
  - 0.14734339714050293
  - 0.16257381439208984
  - 0.17669415473937988
  - 0.1728966236114502
  - 0.182783842086792
  - 0.17296552658081055
  - 0.17876052856445312
  - 0.1737210750579834
  score_time:
  - 0.34926581382751465
  - 0.3179786205291748
  - 0.31911349296569824
  - 0.3540639877319336
  - 0.34573936462402344
  - 0.3061683177947998
  - 0.3671114444732666
  - 0.34322619438171387
  - 0.35816264152526855
  - 0.32965087890625
  - 0.3182384967803955
  - 0.35119032859802246
  - 0.3464517593383789
  - 0.33527183532714844
  - 0.34659647941589355
  - 0.40210771560668945
start: 2023-09-25 18:34:42.609861
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
