active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/gpcr/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X1.txt
  - force_download: false
    path: datasets/gpcr/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_X2.txt
  name: gpcr
  pairwise: true
  y:
    force_download: false
    path: datasets/gpcr/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpig_Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-29 06:41:00.711386
estimator:
  call: bipartite_adaptations.estimators.bxt_sgso
  final_params:
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        estimator__bootstrap: false
        estimator__ccp_alpha: 0.0
        estimator__criterion: squared_error
        estimator__max_depth: null
        estimator__max_features: 1.0
        estimator__max_leaf_nodes: null
        estimator__max_samples: null
        estimator__min_impurity_decrease: 0.0
        estimator__min_samples_leaf: 1
        estimator__min_samples_split: 2
        estimator__min_weight_fraction_leaf: 0.0
        estimator__n_estimators: 100
        estimator__n_jobs: 3
        estimator__oob_score: false
        estimator__random_state: 0
        estimator__verbose: 10
        estimator__warm_start: false
        under_sampler: null
  name: bxt_sgso
  params: {}
hash: f99d3652aaeb6d4ad4b5a86f1975a97b84fddf5dff628197c8e379df19f4193d
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/f99d365_20230929T064039878808_bxt_sgso_gpcr.yml"
results:
  LL_average_precision:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_balanced_accuracy:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_f1_macro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_f1_micro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_f1_weighted:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_matthews_corrcoef:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_precision_macro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_precision_micro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_precision_weighted:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_recall_macro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_recall_micro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_recall_weighted:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_roc_auc:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LT_average_precision:
  - 0.25526719815872057
  - 0.2972417767303419
  - 0.3076354220594725
  - 0.2798513546531982
  - 0.34473111623560315
  - 0.4140469181295946
  - 0.3198054035333021
  - 0.2938430665589478
  - 0.29364246011054923
  - 0.35041436601901504
  - 0.3007480174787125
  - 0.3177722819626003
  - 0.25549767081827335
  - 0.3381078559264071
  - 0.23799829571673417
  - 0.23915208303479607
  LT_balanced_accuracy:
  - 0.7679820185853041
  - 0.7834689195569189
  - 0.8275236254295533
  - 0.7144666184255627
  - 0.8129517725966144
  - 0.8021585051546392
  - 0.7803281923114866
  - 0.7175693879780094
  - 0.7863501276179155
  - 0.7662241446900686
  - 0.8093278022531648
  - 0.7395272460744792
  - 0.7459168886103713
  - 0.7979832132865051
  - 0.7714246122134363
  - 0.6715076853526221
  LT_f1_macro:
  - 0.6019258927148966
  - 0.6056699743256858
  - 0.6197653076290598
  - 0.6049244464900012
  - 0.616586306653809
  - 0.5812291321314693
  - 0.5867522136275509
  - 0.6138294979244066
  - 0.5989729745809349
  - 0.5913505988717495
  - 0.6266379015597687
  - 0.6229207177097552
  - 0.5860266170278617
  - 0.5965437507606183
  - 0.6078542600123418
  - 0.5940078158923143
  LT_f1_micro:
  - 0.9021629778672032
  - 0.8996478873239436
  - 0.9112173038229376
  - 0.8880921895006402
  - 0.9079476861167002
  - 0.8815392354124748
  - 0.8953722334004024
  - 0.9098591549295775
  - 0.8908450704225352
  - 0.8840543259557344
  - 0.9019114688128773
  - 0.8860435339308579
  - 0.8970734126984127
  - 0.8898809523809523
  - 0.8993055555555556
  - 0.8883838383838384
  LT_f1_weighted:
  - 0.9290304146792688
  - 0.927478595661967
  - 0.9365864376484893
  - 0.9130171178781648
  - 0.9338390031607193
  - 0.9187323785868672
  - 0.9269887197100775
  - 0.9292539028585503
  - 0.9219941561226116
  - 0.9168475815606862
  - 0.9277133263175624
  - 0.9103231071014745
  - 0.9263536403881442
  - 0.9223033306868648
  - 0.926136514869085
  - 0.9103834699579381
  LT_matthews_corrcoef:
  - 0.2833708932710535
  - 0.29687022107326466
  - 0.33464026054537327
  - 0.26272750250659027
  - 0.3241833778425139
  - 0.27671415141329914
  - 0.26991914056651345
  - 0.2725436252606887
  - 0.29141572047256864
  - 0.2727909124095025
  - 0.3384073789084672
  - 0.30071994129352086
  - 0.251817488844327
  - 0.29394150517112644
  - 0.2940387341063284
  - 0.22453089651774275
  LT_precision_macro:
  - 0.5749108686257562
  - 0.5777262709240268
  - 0.585477882573361
  - 0.5804621030070793
  - 0.583954519251794
  - 0.5633531079600049
  - 0.5649741485537164
  - 0.5853521126760564
  - 0.5741427311775651
  - 0.5698799145169955
  - 0.5925551738847354
  - 0.5943864263603016
  - 0.5644649174424253
  - 0.5724886542343527
  - 0.5796342458130369
  - 0.5734866828087167
  LT_precision_micro:
  - 0.9021629778672032
  - 0.8996478873239436
  - 0.9112173038229376
  - 0.8880921895006402
  - 0.9079476861167002
  - 0.8815392354124748
  - 0.8953722334004024
  - 0.9098591549295775
  - 0.8908450704225352
  - 0.8840543259557344
  - 0.9019114688128773
  - 0.8860435339308579
  - 0.8970734126984127
  - 0.8898809523809523
  - 0.8993055555555556
  - 0.8883838383838384
  LT_precision_weighted:
  - 0.9664892512486326
  - 0.9669738366997306
  - 0.973331240033524
  - 0.9474755096794968
  - 0.9711458465944653
  - 0.9714942287329358
  - 0.9707938455054824
  - 0.955361237849633
  - 0.9665191607239736
  - 0.9633339465128994
  - 0.9659024283325963
  - 0.9453402508364556
  - 0.9662005099436558
  - 0.9687619682708856
  - 0.9641311696985252
  - 0.939251840438281
  LT_recall_macro:
  - 0.7679820185853041
  - 0.7834689195569189
  - 0.8275236254295533
  - 0.7144666184255627
  - 0.8129517725966144
  - 0.8021585051546392
  - 0.7803281923114866
  - 0.7175693879780094
  - 0.7863501276179155
  - 0.7662241446900686
  - 0.8093278022531648
  - 0.7395272460744792
  - 0.7459168886103713
  - 0.7979832132865051
  - 0.7714246122134363
  - 0.6715076853526221
  LT_recall_micro:
  - 0.9021629778672032
  - 0.8996478873239436
  - 0.9112173038229376
  - 0.8880921895006402
  - 0.9079476861167002
  - 0.8815392354124748
  - 0.8953722334004024
  - 0.9098591549295775
  - 0.8908450704225352
  - 0.8840543259557344
  - 0.9019114688128773
  - 0.8860435339308579
  - 0.8970734126984127
  - 0.8898809523809523
  - 0.8993055555555556
  - 0.8883838383838384
  LT_recall_weighted:
  - 0.9021629778672032
  - 0.8996478873239436
  - 0.9112173038229376
  - 0.8880921895006402
  - 0.9079476861167002
  - 0.8815392354124748
  - 0.8953722334004024
  - 0.9098591549295775
  - 0.8908450704225352
  - 0.8840543259557344
  - 0.9019114688128773
  - 0.8860435339308579
  - 0.8970734126984127
  - 0.8898809523809523
  - 0.8993055555555556
  - 0.8883838383838384
  LT_roc_auc:
  - 0.8225736322505997
  - 0.8249988730803814
  - 0.9066433097079036
  - 0.7809354734841272
  - 0.8481213669754072
  - 0.827147766323024
  - 0.8390868383263728
  - 0.7705767060279858
  - 0.8493176229269372
  - 0.8278505347694256
  - 0.8623736480475072
  - 0.8209475438283264
  - 0.8542906940310199
  - 0.8501029823203762
  - 0.8523585477598885
  - 0.7448230610809725
  TL_average_precision:
  - 0.4377069863212484
  - 0.4502721231863898
  - 0.4157685687556104
  - 0.3451955211656948
  - 0.6032370530651953
  - 0.5901356648408986
  - 0.6163380796539197
  - 0.4971226366717842
  - 0.5456227211963072
  - 0.5885178074385607
  - 0.5396362821743801
  - 0.5065233618152363
  - 0.5382621456376147
  - 0.4772692489706612
  - 0.5295106335909125
  - 0.5441913752267756
  TL_balanced_accuracy:
  - 0.8152623576326132
  - 0.8210316435723097
  - 0.8308535052268335
  - 0.7729196035120045
  - 0.794735136520186
  - 0.8042764498911836
  - 0.7907921118753332
  - 0.7614672665780892
  - 0.8644599721101798
  - 0.8860119670519021
  - 0.8703003337041157
  - 0.8503949262674604
  - 0.8590035474135649
  - 0.8407682142126709
  - 0.848209198982111
  - 0.8287307488050983
  TL_f1_macro:
  - 0.582433508520465
  - 0.5872133095662507
  - 0.5813495040347623
  - 0.5433439433465195
  - 0.625850738880965
  - 0.6442534099305164
  - 0.6321000842739973
  - 0.6144540659016189
  - 0.6214283715992059
  - 0.6342006459757676
  - 0.6265366804371002
  - 0.595405190677966
  - 0.6700561304114044
  - 0.6828048123228846
  - 0.6931419038772454
  - 0.6667745241560389
  TL_f1_micro:
  - 0.843313373253493
  - 0.8475548902195609
  - 0.8490518962075848
  - 0.8211805555555555
  - 0.87125748502994
  - 0.8899700598802395
  - 0.8842315369261476
  - 0.8955853174603174
  - 0.9149201596806387
  - 0.9166666666666666
  - 0.9106786427145709
  - 0.9037698412698414
  - 0.9317885967196042
  - 0.9406404582140068
  - 0.9385576672741474
  - 0.9373706004140787
  TL_f1_weighted:
  - 0.8902519852793219
  - 0.8929490395323435
  - 0.8957432026739212
  - 0.8792214630981109
  - 0.9027082571796546
  - 0.9154195477915739
  - 0.9117395495422052
  - 0.921469315933773
  - 0.940618363850988
  - 0.941368408396592
  - 0.937174718144335
  - 0.9349567207047014
  - 0.9484672513981157
  - 0.9535955267629687
  - 0.9514178819499677
  - 0.9518251869114926
  TL_matthews_corrcoef:
  - 0.2987747571640987
  - 0.3068355915549125
  - 0.3026893166329483
  - 0.23092607982780372
  - 0.33834553249648625
  - 0.36355723707665977
  - 0.34120781938961936
  - 0.29894844618689803
  - 0.3527412626621924
  - 0.3808065430896426
  - 0.364416234206642
  - 0.31144258411855497
  - 0.41632760321938794
  - 0.4243093328568054
  - 0.4433245619399941
  - 0.3961164123900002
  TL_precision_macro:
  - 0.5707873564329011
  - 0.5733168226013575
  - 0.5692306571913949
  - 0.5488485012238151
  - 0.5971021819046763
  - 0.6085968571327842
  - 0.6000910712998735
  - 0.5854506327380655
  - 0.5853498380522446
  - 0.5939178287446628
  - 0.5896564083705781
  - 0.5692051139521956
  - 0.6207012259705674
  - 0.6320827489481066
  - 0.6411053095336121
  - 0.6193288220945786
  TL_precision_micro:
  - 0.843313373253493
  - 0.8475548902195609
  - 0.8490518962075848
  - 0.8211805555555556
  - 0.8712574850299402
  - 0.8899700598802395
  - 0.8842315369261478
  - 0.8955853174603174
  - 0.9149201596806387
  - 0.9166666666666666
  - 0.9106786427145709
  - 0.9037698412698413
  - 0.9317885967196042
  - 0.9406404582140068
  - 0.9385576672741474
  - 0.9373706004140787
  TL_precision_weighted:
  - 0.9628975376782332
  - 0.9633860375012221
  - 0.9672832436074715
  - 0.9650086582050358
  - 0.9518572066554595
  - 0.9549893197247621
  - 0.9538248038792676
  - 0.9584853142977801
  - 0.9781730971857155
  - 0.9785251869404548
  - 0.9767059287689188
  - 0.9790574790227375
  - 0.9741345516514119
  - 0.9732880966526001
  - 0.971455623890612
  - 0.9732660923846047
  TL_recall_macro:
  - 0.8152623576326132
  - 0.8210316435723097
  - 0.8308535052268335
  - 0.7729196035120045
  - 0.794735136520186
  - 0.8042764498911836
  - 0.7907921118753332
  - 0.7614672665780892
  - 0.8644599721101798
  - 0.8860119670519021
  - 0.8703003337041157
  - 0.8503949262674604
  - 0.8590035474135649
  - 0.8407682142126709
  - 0.848209198982111
  - 0.8287307488050983
  TL_recall_micro:
  - 0.843313373253493
  - 0.8475548902195609
  - 0.8490518962075848
  - 0.8211805555555556
  - 0.8712574850299402
  - 0.8899700598802395
  - 0.8842315369261478
  - 0.8955853174603174
  - 0.9149201596806387
  - 0.9166666666666666
  - 0.9106786427145709
  - 0.9037698412698413
  - 0.9317885967196042
  - 0.9406404582140068
  - 0.9385576672741474
  - 0.9373706004140787
  TL_recall_weighted:
  - 0.843313373253493
  - 0.8475548902195609
  - 0.8490518962075848
  - 0.8211805555555556
  - 0.8712574850299402
  - 0.8899700598802395
  - 0.8842315369261478
  - 0.8955853174603174
  - 0.9149201596806387
  - 0.9166666666666666
  - 0.9106786427145709
  - 0.9037698412698413
  - 0.9317885967196042
  - 0.9406404582140068
  - 0.9385576672741474
  - 0.9373706004140787
  TL_roc_auc:
  - 0.847583938185539
  - 0.8633282650065506
  - 0.8624834420323482
  - 0.807880920402704
  - 0.8172264886088734
  - 0.8287569852549187
  - 0.8174625961270019
  - 0.7709472007488828
  - 0.878317913961404
  - 0.9047151445994879
  - 0.8914967247559017
  - 0.8705676173430346
  - 0.8743633186848097
  - 0.8492768329583773
  - 0.8555086596528543
  - 0.8435491562530482
  TT_average_precision:
  - 0.1217607806254117
  - 0.13957307763031024
  - 0.1108496073893448
  - 0.14675315789025078
  - 0.07559140662768916
  - 0.0921749183091076
  - 0.11018459683854596
  - 0.20414356704679204
  - 0.1373584979639712
  - 0.23887702618654885
  - 0.09044586281160834
  - 0.23146868696263984
  - 0.22994212410736567
  - 0.3256446504221779
  - 0.17183604308392936
  - 0.24101342685783098
  TT_balanced_accuracy:
  - 0.7269645262685227
  - 0.720094297260889
  - 0.7055069801013796
  - 0.7373178866069862
  - 0.6096625766871165
  - 0.6378221427516855
  - 0.6940430226144512
  - 0.6782553729456384
  - 0.7524353120243531
  - 0.7353507645616901
  - 0.7042360060514372
  - 0.7435170946472583
  - 0.7796357508587725
  - 0.7521299254526093
  - 0.7631828978622328
  - 0.6862244897959183
  TT_f1_macro:
  - 0.5155017405534675
  - 0.5073460553567335
  - 0.5461125053131715
  - 0.5317173609597522
  - 0.5112259546368074
  - 0.5207040349716718
  - 0.5455552056561799
  - 0.6059629210241495
  - 0.5768096622576678
  - 0.5527572520698949
  - 0.5453827940015785
  - 0.5803611686554977
  - 0.6477987421383649
  - 0.6110616656071202
  - 0.5917013163280694
  - 0.5930362048058601
  TT_f1_micro:
  - 0.8028273809523809
  - 0.7894345238095238
  - 0.8273809523809523
  - 0.7681818181818181
  - 0.8303571428571429
  - 0.8154761904761905
  - 0.8266369047619048
  - 0.8643939393939394
  - 0.8980654761904762
  - 0.8876488095238095
  - 0.9017857142857143
  - 0.884090909090909
  - 0.9285714285714286
  - 0.9114906832298136
  - 0.9200310559006211
  - 0.9075098814229249
  TT_f1_weighted:
  - 0.8697312257215968
  - 0.8612741632680024
  - 0.8784239975955214
  - 0.8372556574982852
  - 0.882664096359187
  - 0.8702915059210535
  - 0.8768965463238556
  - 0.8878437137455482
  - 0.9290662507202863
  - 0.9247949925947939
  - 0.9347305220430714
  - 0.9173578352472365
  - 0.9441970389468338
  - 0.9337840025587061
  - 0.9436253142421983
  - 0.9281542864526424
  TT_matthews_corrcoef:
  - 0.17668833829421451
  - 0.16740896976595185
  - 0.19746739664215296
  - 0.2175611985216577
  - 0.10110201027670236
  - 0.1315743139138682
  - 0.19054383809679537
  - 0.24699412244859736
  - 0.24187940382190865
  - 0.2029706356796685
  - 0.17416107517654192
  - 0.2463114799028788
  - 0.3475090830294599
  - 0.2859537270999207
  - 0.262003117223586
  - 0.2285069257407143
  TT_precision_macro:
  - 0.5343872778297475
  - 0.5318338134005319
  - 0.5474355818928794
  - 0.5498623131392605
  - 0.5233024263855166
  - 0.5314024287684597
  - 0.5467769386235507
  - 0.5855599687067461
  - 0.5579412261343984
  - 0.543761360861662
  - 0.5371287128712872
  - 0.5622844827586206
  - 0.6079641662565582
  - 0.5810787671232877
  - 0.5652071563088512
  - 0.5700974065880039
  TT_precision_micro:
  - 0.8028273809523809
  - 0.7894345238095238
  - 0.8273809523809523
  - 0.7681818181818182
  - 0.8303571428571429
  - 0.8154761904761905
  - 0.8266369047619048
  - 0.8643939393939394
  - 0.8980654761904762
  - 0.8876488095238095
  - 0.9017857142857143
  - 0.884090909090909
  - 0.9285714285714286
  - 0.9114906832298136
  - 0.9200310559006211
  - 0.9075098814229249
  TT_precision_weighted:
  - 0.9657847231502518
  - 0.965473004009864
  - 0.9515137725511833
  - 0.9483611687289892
  - 0.9507442343372077
  - 0.9452628042167854
  - 0.9485114061447364
  - 0.9200459870413833
  - 0.9707196165616232
  - 0.9734543818205543
  - 0.9760676960553198
  - 0.9632552899686521
  - 0.9663593931904925
  - 0.9644574789415468
  - 0.9749758015463615
  - 0.954922991457476
  TT_recall_macro:
  - 0.7269645262685227
  - 0.720094297260889
  - 0.7055069801013796
  - 0.7373178866069862
  - 0.6096625766871165
  - 0.6378221427516855
  - 0.6940430226144512
  - 0.6782553729456384
  - 0.7524353120243531
  - 0.7353507645616901
  - 0.7042360060514372
  - 0.7435170946472583
  - 0.7796357508587725
  - 0.7521299254526093
  - 0.7631828978622328
  - 0.6862244897959183
  TT_recall_micro:
  - 0.8028273809523809
  - 0.7894345238095238
  - 0.8273809523809523
  - 0.7681818181818182
  - 0.8303571428571429
  - 0.8154761904761905
  - 0.8266369047619048
  - 0.8643939393939394
  - 0.8980654761904762
  - 0.8876488095238095
  - 0.9017857142857143
  - 0.884090909090909
  - 0.9285714285714286
  - 0.9114906832298136
  - 0.9200310559006211
  - 0.9075098814229249
  TT_recall_weighted:
  - 0.8028273809523809
  - 0.7894345238095238
  - 0.8273809523809523
  - 0.7681818181818182
  - 0.8303571428571429
  - 0.8154761904761905
  - 0.8266369047619048
  - 0.8643939393939394
  - 0.8980654761904762
  - 0.8876488095238095
  - 0.9017857142857143
  - 0.884090909090909
  - 0.9285714285714286
  - 0.9114906832298136
  - 0.9200310559006211
  - 0.9075098814229249
  TT_roc_auc:
  - 0.7858105074090705
  - 0.7442635832959139
  - 0.755950720976394
  - 0.79755426832836
  - 0.685573236196319
  - 0.6944749749831854
  - 0.764447246079899
  - 0.7475786482222525
  - 0.8094875697615425
  - 0.7695079957978288
  - 0.7921365699353595
  - 0.7706283836447516
  - 0.8142026919005335
  - 0.8271654242101527
  - 0.8695328582739509
  - 0.8107346938775509
  fit_time:
  - 16.959778547286987
  - 13.909748077392578
  - 12.444290399551392
  - 14.249500036239624
  - 13.056074857711792
  - 17.658755779266357
  - 20.29980754852295
  - 19.435356616973877
  - 15.108138084411621
  - 16.413812398910522
  - 18.263747453689575
  - 19.387473106384277
  - 17.9185848236084
  - 18.023269653320312
  - 18.63993740081787
  - 18.815735816955566
  score_time:
  - 0.6285579204559326
  - 0.6829159259796143
  - 0.8199341297149658
  - 0.6478197574615479
  - 0.7635252475738525
  - 0.7168715000152588
  - 0.4845108985900879
  - 0.5824496746063232
  - 0.683603048324585
  - 0.6883928775787354
  - 0.6843681335449219
  - 0.5412170886993408
  - 0.5695979595184326
  - 0.7374997138977051
  - 0.6551649570465088
  - 0.6465885639190674
start: 2023-09-29 06:40:39.878808
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
