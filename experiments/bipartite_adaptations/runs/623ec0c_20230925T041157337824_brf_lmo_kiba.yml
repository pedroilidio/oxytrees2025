active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/kiba/final/ligand_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/kiba/final/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: kiba
  pairwise: true
  y:
    force_download: false
    path: datasets/kiba/final/binary_affinity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: bipartite_adaptations/runs
end: 2023-09-25 04:36:27.313590
estimator:
  call: bipartite_adaptations.estimators.brf_lmo
  final_params:
    estimator:
      call: bipartite_learn.wrappers.LocalMultiOutputWrapper
      params:
        combine_func_kwargs: null
        combine_predictions_func:
          load: numpy.mean
        independent_labels: false
        primary_cols_estimator:
          call: sklearn.ensemble._forest.RandomForestRegressor
          params:
            bootstrap: true
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 0.5
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_cols_estimator__bootstrap: true
        primary_cols_estimator__ccp_alpha: 0.0
        primary_cols_estimator__criterion: squared_error
        primary_cols_estimator__max_depth: null
        primary_cols_estimator__max_features: 0.5
        primary_cols_estimator__max_leaf_nodes: null
        primary_cols_estimator__max_samples: null
        primary_cols_estimator__min_impurity_decrease: 0.0
        primary_cols_estimator__min_samples_leaf: 1
        primary_cols_estimator__min_samples_split: 2
        primary_cols_estimator__min_weight_fraction_leaf: 0.0
        primary_cols_estimator__n_estimators: 50
        primary_cols_estimator__n_jobs: 3
        primary_cols_estimator__oob_score: false
        primary_cols_estimator__random_state: 0
        primary_cols_estimator__verbose: 10
        primary_cols_estimator__warm_start: false
        primary_rows_estimator:
          call: sklearn.ensemble._forest.RandomForestRegressor
          params:
            bootstrap: true
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 0.5
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_rows_estimator__bootstrap: true
        primary_rows_estimator__ccp_alpha: 0.0
        primary_rows_estimator__criterion: squared_error
        primary_rows_estimator__max_depth: null
        primary_rows_estimator__max_features: 0.5
        primary_rows_estimator__max_leaf_nodes: null
        primary_rows_estimator__max_samples: null
        primary_rows_estimator__min_impurity_decrease: 0.0
        primary_rows_estimator__min_samples_leaf: 1
        primary_rows_estimator__min_samples_split: 2
        primary_rows_estimator__min_weight_fraction_leaf: 0.0
        primary_rows_estimator__n_estimators: 50
        primary_rows_estimator__n_jobs: 3
        primary_rows_estimator__oob_score: false
        primary_rows_estimator__random_state: 0
        primary_rows_estimator__verbose: 10
        primary_rows_estimator__warm_start: false
        secondary_cols_estimator:
          call: sklearn.ensemble._forest.RandomForestRegressor
          params:
            bootstrap: true
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 0.5
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_cols_estimator__bootstrap: true
        secondary_cols_estimator__ccp_alpha: 0.0
        secondary_cols_estimator__criterion: squared_error
        secondary_cols_estimator__max_depth: null
        secondary_cols_estimator__max_features: 0.5
        secondary_cols_estimator__max_leaf_nodes: null
        secondary_cols_estimator__max_samples: null
        secondary_cols_estimator__min_impurity_decrease: 0.0
        secondary_cols_estimator__min_samples_leaf: 1
        secondary_cols_estimator__min_samples_split: 2
        secondary_cols_estimator__min_weight_fraction_leaf: 0.0
        secondary_cols_estimator__n_estimators: 50
        secondary_cols_estimator__n_jobs: 3
        secondary_cols_estimator__oob_score: false
        secondary_cols_estimator__random_state: 0
        secondary_cols_estimator__verbose: 10
        secondary_cols_estimator__warm_start: false
        secondary_rows_estimator:
          call: sklearn.ensemble._forest.RandomForestRegressor
          params:
            bootstrap: true
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 0.5
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_rows_estimator__bootstrap: true
        secondary_rows_estimator__ccp_alpha: 0.0
        secondary_rows_estimator__criterion: squared_error
        secondary_rows_estimator__max_depth: null
        secondary_rows_estimator__max_features: 0.5
        secondary_rows_estimator__max_leaf_nodes: null
        secondary_rows_estimator__max_samples: null
        secondary_rows_estimator__min_impurity_decrease: 0.0
        secondary_rows_estimator__min_samples_leaf: 1
        secondary_rows_estimator__min_samples_split: 2
        secondary_rows_estimator__min_weight_fraction_leaf: 0.0
        secondary_rows_estimator__n_estimators: 50
        secondary_rows_estimator__n_jobs: 3
        secondary_rows_estimator__oob_score: false
        secondary_rows_estimator__random_state: 0
        secondary_rows_estimator__verbose: 10
        secondary_rows_estimator__warm_start: false
  name: brf_lmo
  params: {}
hash: 623ec0c85d9b67648b8a3479756258b2cc37a8756a6ba7fc7b081c7c4da32af3
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/623ec0c_20230925T041157337824_brf_lmo_kiba.yml"
results:
  LL_average_precision:
  - 0.9997005815189338
  - 0.9998036773669197
  - 0.9997300279179782
  - 0.9997951599568399
  - 0.9997413670708435
  - 0.9998136473752459
  - 0.9997084626100279
  - 0.9997502634778751
  - 0.9995594167295112
  - 0.9995977932213342
  - 0.9995045271357313
  - 0.9995484083830826
  - 0.9996662121869718
  - 0.9997183496555451
  - 0.9996642240687044
  - 0.9996575140246586
  LL_balanced_accuracy:
  - 0.9469813455889409
  - 0.9478515350070609
  - 0.946836345243022
  - 0.9475748669690858
  - 0.9521417235199172
  - 0.9505439395777537
  - 0.949399743866147
  - 0.9504625018512891
  - 0.9492147930621662
  - 0.9476873513549207
  - 0.9512447799181325
  - 0.9495666255275206
  - 0.9521954589374579
  - 0.9495432624260322
  - 0.9521418839341385
  - 0.9508370889443296
  LL_f1_macro:
  - 0.8830022780106159
  - 0.8821097749250312
  - 0.8848235161057469
  - 0.8834817512963852
  - 0.8939349140309112
  - 0.8883444909304823
  - 0.890373175045472
  - 0.8899556812576418
  - 0.887147061175584
  - 0.8815974041491729
  - 0.8930130674911755
  - 0.886964897997755
  - 0.895125410453474
  - 0.8874855318028292
  - 0.8967174903318064
  - 0.8918147846226359
  LL_f1_micro:
  - 0.9148260206211464
  - 0.915640746889186
  - 0.9150751443388326
  - 0.9156187104261851
  - 0.9233005655853679
  - 0.9201949492426801
  - 0.9193171634664825
  - 0.920463059542523
  - 0.9183687793921527
  - 0.9153432546386755
  - 0.9220460121347456
  - 0.9187405426846288
  - 0.9236406462283655
  - 0.9188285470988959
  - 0.9239341085271318
  - 0.9213097545219638
  LL_f1_weighted:
  - 0.9200227917817687
  - 0.9209446391757845
  - 0.9200880681363808
  - 0.9207822263745684
  - 0.9275806897579298
  - 0.924953649208635
  - 0.9238620051981896
  - 0.9250706610675247
  - 0.9232138690395407
  - 0.9206940049385012
  - 0.9263906066344867
  - 0.9236100890815624
  - 0.9278156018750989
  - 0.9236484536146222
  - 0.9279670361786063
  - 0.9257544122170641
  LL_matthews_corrcoef:
  - 0.7897993176105581
  - 0.7883253378149293
  - 0.7927819340099183
  - 0.7905707771497856
  - 0.8076601750662173
  - 0.7984615248827401
  - 0.8018341786446485
  - 0.8011130027592303
  - 0.7965259928029123
  - 0.7874904606073109
  - 0.806155826375479
  - 0.7962182787562805
  - 0.8096315757060422
  - 0.7970738342001826
  - 0.8122888931062243
  - 0.8041780216170223
  LL_precision_macro:
  - 0.848886462630901
  - 0.8469100749153536
  - 0.8516405959270619
  - 0.8491048089427157
  - 0.8606805811404276
  - 0.8537617259459582
  - 0.8576648956848516
  - 0.8561795047048009
  - 0.8530903629006624
  - 0.8463026282017263
  - 0.8600524844392868
  - 0.8525414874167552
  - 0.8624004152543411
  - 0.8533178840997071
  - 0.8648264346374108
  - 0.8586119611222383
  LL_precision_micro:
  - 0.9148260206211465
  - 0.915640746889186
  - 0.9150751443388326
  - 0.9156187104261851
  - 0.9233005655853679
  - 0.9201949492426802
  - 0.9193171634664825
  - 0.920463059542523
  - 0.9183687793921528
  - 0.9153432546386755
  - 0.9220460121347456
  - 0.9187405426846288
  - 0.9236406462283655
  - 0.9188285470988959
  - 0.9239341085271318
  - 0.9213097545219638
  LL_precision_weighted:
  - 0.9405647941014529
  - 0.9414698503670484
  - 0.9402739462925748
  - 0.9410841720499868
  - 0.9446691662950893
  - 0.9435331005283994
  - 0.942285163375363
  - 0.9433353034270066
  - 0.9423505994425244
  - 0.9413631770999428
  - 0.9438649459943304
  - 0.9427023499735434
  - 0.9446490526038109
  - 0.9426383707552691
  - 0.9444983040328745
  - 0.9435585973809262
  LL_recall_macro:
  - 0.9469813455889409
  - 0.9478515350070609
  - 0.946836345243022
  - 0.9475748669690858
  - 0.9521417235199172
  - 0.9505439395777537
  - 0.949399743866147
  - 0.9504625018512891
  - 0.9492147930621662
  - 0.9476873513549207
  - 0.9512447799181325
  - 0.9495666255275206
  - 0.9521954589374579
  - 0.9495432624260322
  - 0.9521418839341385
  - 0.9508370889443296
  LL_recall_micro:
  - 0.9148260206211465
  - 0.915640746889186
  - 0.9150751443388326
  - 0.9156187104261851
  - 0.9233005655853679
  - 0.9201949492426802
  - 0.9193171634664825
  - 0.920463059542523
  - 0.9183687793921528
  - 0.9153432546386755
  - 0.9220460121347456
  - 0.9187405426846288
  - 0.9236406462283655
  - 0.9188285470988959
  - 0.9239341085271318
  - 0.9213097545219638
  LL_recall_weighted:
  - 0.9148260206211465
  - 0.915640746889186
  - 0.9150751443388326
  - 0.9156187104261851
  - 0.9233005655853679
  - 0.9201949492426802
  - 0.9193171634664825
  - 0.920463059542523
  - 0.9183687793921528
  - 0.9153432546386755
  - 0.9220460121347456
  - 0.9187405426846288
  - 0.9236406462283655
  - 0.9188285470988959
  - 0.9239341085271318
  - 0.9213097545219638
  LL_roc_auc:
  - 0.9999230352823499
  - 0.9999527395852172
  - 0.9999309346064602
  - 0.9999489144215873
  - 0.999930948918208
  - 0.9999518174027703
  - 0.9999234238749355
  - 0.9999331858303768
  - 0.9998909371636105
  - 0.9999050726124762
  - 0.9998739908412213
  - 0.9998889136974564
  - 0.9999113776517845
  - 0.9999286319778086
  - 0.999914179737459
  - 0.9999117173746597
  LT_average_precision:
  - 0.4486269468946561
  - 0.43429052021832576
  - 0.38757005985785903
  - 0.37713076489115194
  - 0.47495831773827174
  - 0.444086154903348
  - 0.3987082787992128
  - 0.3912204574915299
  - 0.4566356755125405
  - 0.43739626078260313
  - 0.3912513872719096
  - 0.38162268244511166
  - 0.45718271525038673
  - 0.44365888211289295
  - 0.3882289023192208
  - 0.38862351582571925
  LT_balanced_accuracy:
  - 0.7385599772386223
  - 0.7192341859880893
  - 0.7201673409103535
  - 0.7194048201280321
  - 0.7476345577491774
  - 0.7264037909864209
  - 0.7161358492534785
  - 0.7259748260226906
  - 0.7444398154939305
  - 0.722739705875055
  - 0.7208269829225056
  - 0.721412498632656
  - 0.7367488571917404
  - 0.7169598102882748
  - 0.7199204869411067
  - 0.7192349997934027
  LT_f1_macro:
  - 0.6442997924328288
  - 0.6415577693263514
  - 0.6213434562056392
  - 0.6396237947646312
  - 0.6523806035418545
  - 0.6498462879825638
  - 0.6204997504792796
  - 0.6460846272215703
  - 0.6507768659889783
  - 0.6447011436069652
  - 0.6255532824790305
  - 0.6442829468004413
  - 0.6497851922973641
  - 0.642141718378179
  - 0.6245453989259535
  - 0.6405110424250091
  LT_f1_micro:
  - 0.6962554730215436
  - 0.6888763285345392
  - 0.6822599771697089
  - 0.6955702585585886
  - 0.7030518221621975
  - 0.696988839755738
  - 0.6805975773292993
  - 0.7006793674014474
  - 0.7042281133596183
  - 0.6929215014795359
  - 0.6889760725249637
  - 0.7016103113120767
  - 0.702477359804946
  - 0.6879208754208754
  - 0.6827263866737551
  - 0.6936802232854864
  LT_f1_weighted:
  - 0.7273874234364285
  - 0.7168555339472622
  - 0.718435210475221
  - 0.725197398349566
  - 0.7331590892764928
  - 0.7237852539704103
  - 0.7162408591572997
  - 0.7293701442605585
  - 0.7346054453146361
  - 0.7207184539645454
  - 0.7241792648886846
  - 0.7302589586463567
  - 0.731774772729944
  - 0.7150895356482707
  - 0.7175020578153423
  - 0.722698716690057
  LT_matthews_corrcoef:
  - 0.3821418380762806
  - 0.36176391981300116
  - 0.34318978982398846
  - 0.35634284710256175
  - 0.39777196510106916
  - 0.3750426781058631
  - 0.33877455201847023
  - 0.36829503028953214
  - 0.3916663650125132
  - 0.3671488979148588
  - 0.3451962508006141
  - 0.3609254355705722
  - 0.38325534630351954
  - 0.3603781172802517
  - 0.34632512882652833
  - 0.35808557792075246
  LT_precision_macro:
  - 0.6530352933659191
  - 0.649238966870771
  - 0.6337383094064233
  - 0.6446871411109625
  - 0.6597339014983379
  - 0.655316536207265
  - 0.6327500707213984
  - 0.6500623230066647
  - 0.6568919338817005
  - 0.6512957834690125
  - 0.6349025037495273
  - 0.647086513686308
  - 0.6551059867960317
  - 0.649650282282577
  - 0.6363459772722662
  - 0.646218990165431
  LT_precision_micro:
  - 0.6962554730215436
  - 0.6888763285345392
  - 0.6822599771697089
  - 0.6955702585585886
  - 0.7030518221621975
  - 0.696988839755738
  - 0.6805975773292993
  - 0.7006793674014474
  - 0.7042281133596183
  - 0.6929215014795359
  - 0.6889760725249637
  - 0.7016103113120767
  - 0.702477359804946
  - 0.6879208754208754
  - 0.6827263866737551
  - 0.6936802232854864
  LT_precision_weighted:
  - 0.8254857769804683
  - 0.803567015280139
  - 0.8241509471089611
  - 0.8101264860248312
  - 0.8298936120661575
  - 0.8067559445886463
  - 0.8200761209911778
  - 0.8128044741285879
  - 0.8288664169662501
  - 0.8062295501360666
  - 0.8238867303473075
  - 0.8105435693686593
  - 0.8211243557344909
  - 0.7996600462763732
  - 0.8205506162618413
  - 0.8077352358213943
  LT_recall_macro:
  - 0.7385599772386223
  - 0.7192341859880893
  - 0.7201673409103535
  - 0.7194048201280321
  - 0.7476345577491774
  - 0.7264037909864209
  - 0.7161358492534785
  - 0.7259748260226906
  - 0.7444398154939305
  - 0.722739705875055
  - 0.7208269829225056
  - 0.721412498632656
  - 0.7367488571917404
  - 0.7169598102882748
  - 0.7199204869411067
  - 0.7192349997934027
  LT_recall_micro:
  - 0.6962554730215436
  - 0.6888763285345392
  - 0.6822599771697089
  - 0.6955702585585886
  - 0.7030518221621975
  - 0.696988839755738
  - 0.6805975773292993
  - 0.7006793674014474
  - 0.7042281133596183
  - 0.6929215014795359
  - 0.6889760725249637
  - 0.7016103113120767
  - 0.702477359804946
  - 0.6879208754208754
  - 0.6827263866737551
  - 0.6936802232854864
  LT_recall_weighted:
  - 0.6962554730215436
  - 0.6888763285345392
  - 0.6822599771697089
  - 0.6955702585585886
  - 0.7030518221621975
  - 0.696988839755738
  - 0.6805975773292993
  - 0.7006793674014474
  - 0.7042281133596183
  - 0.6929215014795359
  - 0.6889760725249637
  - 0.7016103113120767
  - 0.702477359804946
  - 0.6879208754208754
  - 0.6827263866737551
  - 0.6936802232854864
  LT_roc_auc:
  - 0.8015401234820037
  - 0.7754027779335786
  - 0.765949337244216
  - 0.7578662964523809
  - 0.8075622322538897
  - 0.7801525137708154
  - 0.7637876766173333
  - 0.7642236745674207
  - 0.8044369301133676
  - 0.7789725304441452
  - 0.7651775657157169
  - 0.7609557117240251
  - 0.80020408933972
  - 0.7769232065631255
  - 0.7627405059785413
  - 0.7627036087321912
  TL_average_precision:
  - 0.6872031067181916
  - 0.677835745381898
  - 0.6795681772693649
  - 0.6744471764537889
  - 0.6589962126204236
  - 0.6520632152876116
  - 0.6525374074052621
  - 0.6413505689709748
  - 0.6715706374535856
  - 0.6703286358966188
  - 0.6719967805023133
  - 0.6546086846757136
  - 0.6492309519907199
  - 0.6364534487145828
  - 0.6378599403896251
  - 0.6371108371904455
  TL_balanced_accuracy:
  - 0.7990781964039431
  - 0.7971009778942817
  - 0.7957600599082386
  - 0.7903588437788678
  - 0.8011783121464086
  - 0.8030236982674587
  - 0.7986208953495876
  - 0.7955471075816107
  - 0.8087001575250164
  - 0.8104998516264211
  - 0.8080825434035154
  - 0.8072166208511624
  - 0.8064297643808309
  - 0.8012170718585621
  - 0.7988840248509448
  - 0.8018896132542992
  TL_f1_macro:
  - 0.7004977336881676
  - 0.6926663382756106
  - 0.6972067564058774
  - 0.6875427542046332
  - 0.6961765550479642
  - 0.6912261726265883
  - 0.6968457164998123
  - 0.685815636433571
  - 0.7132397052685808
  - 0.709184030033164
  - 0.7141953273895498
  - 0.7080401992045628
  - 0.7029915533361664
  - 0.6927081654046806
  - 0.6988826209280926
  - 0.6926125505269463
  TL_f1_micro:
  - 0.7446061492114123
  - 0.7385702959830867
  - 0.7389336680761099
  - 0.7316111698379141
  - 0.7419369129895446
  - 0.7384822057787174
  - 0.7403651338971107
  - 0.7309945384073291
  - 0.7573320928584086
  - 0.7550982205778718
  - 0.7559571000704722
  - 0.7512883192389005
  - 0.7550517660374846
  - 0.7471867966991748
  - 0.7487864613212126
  - 0.7440426283041348
  TL_f1_weighted:
  - 0.7688683874133092
  - 0.7646467991676458
  - 0.7632955107600948
  - 0.7578563366221513
  - 0.7676718905465305
  - 0.7657999385212986
  - 0.7653809889554142
  - 0.758460288210529
  - 0.7798241423407352
  - 0.7789211771960944
  - 0.7779513529849272
  - 0.7747343360766733
  - 0.7802919105081175
  - 0.7745046200423085
  - 0.7739094564428354
  - 0.7712508969234824
  TL_matthews_corrcoef:
  - 0.48815131300996173
  - 0.47938560596729995
  - 0.48428961621257444
  - 0.4703747135907645
  - 0.48605446150057346
  - 0.48339712346370345
  - 0.48561729096431666
  - 0.47376825269929196
  - 0.5069601036886234
  - 0.5044639909294975
  - 0.5087595597704597
  - 0.5023652774101078
  - 0.49162261087238013
  - 0.4774127498719862
  - 0.4826955440437527
  - 0.480107233235366
  TL_precision_macro:
  - 0.699188462464434
  - 0.6933774846833469
  - 0.6982489052477953
  - 0.6904990806428611
  - 0.6961038776837352
  - 0.6927842445236211
  - 0.6974277059609716
  - 0.6898651276799926
  - 0.708137686738265
  - 0.7048985827300002
  - 0.7100381011516916
  - 0.7053688300197803
  - 0.697184493491794
  - 0.689168339906838
  - 0.6948874553900048
  - 0.6908834763476543
  TL_precision_micro:
  - 0.7446061492114123
  - 0.7385702959830867
  - 0.7389336680761099
  - 0.7316111698379141
  - 0.7419369129895446
  - 0.7384822057787174
  - 0.7403651338971107
  - 0.7309945384073291
  - 0.7573320928584086
  - 0.7550982205778718
  - 0.7559571000704721
  - 0.7512883192389006
  - 0.7550517660374846
  - 0.7471867966991748
  - 0.7487864613212126
  - 0.7440426283041348
  TL_precision_weighted:
  - 0.8556537042737166
  - 0.8574428911934049
  - 0.8530887909199755
  - 0.8526882694072797
  - 0.8597386338368487
  - 0.8637049847323087
  - 0.8564634780049566
  - 0.8585438411754402
  - 0.8597826203641504
  - 0.8633677539756023
  - 0.8581402861990096
  - 0.8600271846741807
  - 0.8639685895602272
  - 0.8638945143880271
  - 0.8580728434631081
  - 0.8634695857690718
  TL_recall_macro:
  - 0.7990781964039431
  - 0.7971009778942817
  - 0.7957600599082386
  - 0.7903588437788678
  - 0.8011783121464086
  - 0.8030236982674587
  - 0.7986208953495876
  - 0.7955471075816107
  - 0.8087001575250164
  - 0.8104998516264211
  - 0.8080825434035154
  - 0.8072166208511624
  - 0.8064297643808309
  - 0.8012170718585621
  - 0.7988840248509448
  - 0.8018896132542992
  TL_recall_micro:
  - 0.7446061492114123
  - 0.7385702959830867
  - 0.7389336680761099
  - 0.7316111698379141
  - 0.7419369129895446
  - 0.7384822057787174
  - 0.7403651338971107
  - 0.7309945384073291
  - 0.7573320928584086
  - 0.7550982205778718
  - 0.7559571000704721
  - 0.7512883192389006
  - 0.7550517660374846
  - 0.7471867966991748
  - 0.7487864613212126
  - 0.7440426283041348
  TL_recall_weighted:
  - 0.7446061492114123
  - 0.7385702959830867
  - 0.7389336680761099
  - 0.7316111698379141
  - 0.7419369129895446
  - 0.7384822057787174
  - 0.7403651338971107
  - 0.7309945384073291
  - 0.7573320928584086
  - 0.7550982205778718
  - 0.7559571000704721
  - 0.7512883192389006
  - 0.7550517660374846
  - 0.7471867966991748
  - 0.7487864613212126
  - 0.7440426283041348
  TL_roc_auc:
  - 0.8878383308472619
  - 0.887365359468277
  - 0.8850211395234491
  - 0.8826372824117994
  - 0.8903416678856797
  - 0.891418645946793
  - 0.8850932241815266
  - 0.8851625949532897
  - 0.893020596929994
  - 0.895825442487751
  - 0.8920331248459487
  - 0.8891190501040784
  - 0.885842095576124
  - 0.8825857977078443
  - 0.8787343900875337
  - 0.8832062160060699
  TT_average_precision:
  - 0.35131456191974053
  - 0.3455761529592499
  - 0.2996185746345107
  - 0.2949928083036871
  - 0.32904335805885043
  - 0.34635450641786164
  - 0.3014255948530501
  - 0.29713925006998254
  - 0.33759036602091286
  - 0.3481431912455444
  - 0.30656153003335757
  - 0.2941425851859003
  - 0.323433269459274
  - 0.3304964840294338
  - 0.2800576004893947
  - 0.2798705195576662
  TT_balanced_accuracy:
  - 0.6490668973298226
  - 0.6312092551151701
  - 0.6168209016541834
  - 0.6123056669432091
  - 0.6451405082599677
  - 0.6391915210609218
  - 0.634806767135937
  - 0.6213567254663145
  - 0.6542783686327223
  - 0.6429440931815169
  - 0.6410649033714526
  - 0.6322290517714925
  - 0.6398441234065653
  - 0.6377818825898786
  - 0.6350895294156336
  - 0.6245829295001681
  TT_f1_macro:
  - 0.5439782942901945
  - 0.5418923909071255
  - 0.5206001542960201
  - 0.5289224807943124
  - 0.5393437661958662
  - 0.5431525209059881
  - 0.5215779581588784
  - 0.523828462202491
  - 0.5618550146883932
  - 0.5600612014777768
  - 0.5487234998009605
  - 0.5558786658112842
  - 0.5470788836402173
  - 0.5500679464287106
  - 0.5367835761078159
  - 0.5444888887972363
  TT_f1_micro:
  - 0.5783045977011494
  - 0.5717703349282297
  - 0.5637958532695375
  - 0.5672182349813929
  - 0.5755289968652038
  - 0.5727006911217437
  - 0.5630316321105795
  - 0.5580143540669856
  - 0.6018808777429467
  - 0.5925372142477405
  - 0.5975544922913344
  - 0.6026049973418395
  - 0.5971995027154354
  - 0.5904657278870802
  - 0.5953593661573288
  - 0.5968241286327773
  TT_f1_weighted:
  - 0.6194700146457797
  - 0.6085599344879137
  - 0.6104437655105863
  - 0.6082184789758818
  - 0.618232037928902
  - 0.6102941169854788
  - 0.611747536785053
  - 0.600492359583136
  - 0.6408170133245371
  - 0.6272452826831955
  - 0.6410880619600252
  - 0.641184615466842
  - 0.6414444551956832
  - 0.6302306810835199
  - 0.6447391629552941
  - 0.6394396730716372
  TT_matthews_corrcoef:
  - 0.23810325807083682
  - 0.21602062433657557
  - 0.18256331839412787
  - 0.18132669873944413
  - 0.23008332706979012
  - 0.22774029552700914
  - 0.20737629877375893
  - 0.19442194843086766
  - 0.24771407731085227
  - 0.23649678065300128
  - 0.2210064338542053
  - 0.21344505062121671
  - 0.2182021666698417
  - 0.22156296340105153
  - 0.20438449581496923
  - 0.19687088240318862
  TT_precision_macro:
  - 0.5950800655938208
  - 0.5889131450708324
  - 0.5713257746497674
  - 0.5731917020989947
  - 0.5911846355475823
  - 0.5931551753501363
  - 0.5797529126444704
  - 0.5778693844251492
  - 0.5994343287425584
  - 0.5978192348042854
  - 0.5865627144626071
  - 0.5861361195295887
  - 0.5851165289959873
  - 0.5890722093288154
  - 0.5773061804090956
  - 0.5777757925859293
  TT_precision_micro:
  - 0.5783045977011494
  - 0.5717703349282297
  - 0.5637958532695375
  - 0.5672182349813929
  - 0.5755289968652038
  - 0.5727006911217437
  - 0.5630316321105795
  - 0.5580143540669856
  - 0.6018808777429467
  - 0.5925372142477405
  - 0.5975544922913344
  - 0.6026049973418395
  - 0.5971995027154354
  - 0.5904657278870802
  - 0.5953593661573288
  - 0.5968241286327773
  TT_precision_weighted:
  - 0.7802515684138811
  - 0.7542670224305829
  - 0.7672914571075528
  - 0.7483345465635988
  - 0.7806725469477541
  - 0.7638578575479303
  - 0.7873682965929735
  - 0.7614370577365143
  - 0.7767120459929131
  - 0.7568061738336679
  - 0.7782126507947745
  - 0.7585852031781984
  - 0.7791739525573255
  - 0.7655944431526915
  - 0.7892400312292905
  - 0.7638571843328488
  TT_recall_macro:
  - 0.6490668973298226
  - 0.6312092551151701
  - 0.6168209016541834
  - 0.6123056669432091
  - 0.6451405082599677
  - 0.6391915210609218
  - 0.634806767135937
  - 0.6213567254663145
  - 0.6542783686327223
  - 0.6429440931815169
  - 0.6410649033714526
  - 0.6322290517714925
  - 0.6398441234065653
  - 0.6377818825898786
  - 0.6350895294156336
  - 0.6245829295001681
  TT_recall_micro:
  - 0.5783045977011494
  - 0.5717703349282297
  - 0.5637958532695375
  - 0.5672182349813929
  - 0.5755289968652038
  - 0.5727006911217437
  - 0.5630316321105795
  - 0.5580143540669856
  - 0.6018808777429467
  - 0.5925372142477405
  - 0.5975544922913344
  - 0.6026049973418395
  - 0.5971995027154354
  - 0.5904657278870802
  - 0.5953593661573288
  - 0.5968241286327773
  TT_recall_weighted:
  - 0.5783045977011494
  - 0.5717703349282297
  - 0.5637958532695375
  - 0.5672182349813929
  - 0.5755289968652038
  - 0.5727006911217437
  - 0.5630316321105795
  - 0.5580143540669856
  - 0.6018808777429467
  - 0.5925372142477405
  - 0.5975544922913344
  - 0.6026049973418395
  - 0.5971995027154354
  - 0.5904657278870802
  - 0.5953593661573288
  - 0.5968241286327773
  TT_roc_auc:
  - 0.7085366906083113
  - 0.6839625703148549
  - 0.6666875144321986
  - 0.655944675553263
  - 0.7011692237317214
  - 0.6921484963773958
  - 0.6884431858107487
  - 0.6669994458288356
  - 0.7076039498600017
  - 0.6926328079215756
  - 0.6885478730247876
  - 0.6692803644387797
  - 0.6999042353195373
  - 0.6872816067579341
  - 0.6811754302293725
  - 0.6646381583074675
  fit_time:
  - 110.5933485031128
  - 115.50602746009827
  - 104.05776000022888
  - 96.94087147712708
  - 103.21122694015503
  - 109.28488063812256
  - 100.86280250549316
  - 111.87779998779297
  - 116.2752001285553
  - 113.58140277862549
  - 118.01622915267944
  - 103.81991934776306
  - 100.69708442687988
  - 94.96515607833862
  - 105.74366188049316
  - 104.08427929878235
  score_time:
  - 1253.6402208805084
  - 1288.6117231845856
  - 1263.6392261981964
  - 1267.9830796718597
  - 1291.6574375629425
  - 1293.7477226257324
  - 1281.1300947666168
  - 1318.6468572616577
  - 1304.320430278778
  - 1327.9500052928925
  - 1329.7164840698242
  - 1365.3282837867737
  - 1231.7969794273376
  - 1235.9575436115265
  - 1213.9466931819916
  - 1263.9119620323181
start: 2023-09-25 04:11:57.337824
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
