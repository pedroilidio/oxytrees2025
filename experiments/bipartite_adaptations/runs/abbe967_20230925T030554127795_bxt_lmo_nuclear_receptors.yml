active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/nuclear_receptors/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X1.txt
  - force_download: false
    path: datasets/nuclear_receptors/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_X2.txt
  name: nuclear_receptors
  pairwise: true
  y:
    force_download: false
    path: datasets/nuclear_receptors/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpin_Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-25 03:05:56.060907
estimator:
  call: bipartite_adaptations.estimators.bxt_lmo
  final_params:
    estimator:
      call: bipartite_learn.wrappers.LocalMultiOutputWrapper
      params:
        combine_func_kwargs: null
        combine_predictions_func:
          load: numpy.mean
        independent_labels: false
        primary_cols_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_cols_estimator__bootstrap: false
        primary_cols_estimator__ccp_alpha: 0.0
        primary_cols_estimator__criterion: squared_error
        primary_cols_estimator__max_depth: null
        primary_cols_estimator__max_features: 1.0
        primary_cols_estimator__max_leaf_nodes: null
        primary_cols_estimator__max_samples: null
        primary_cols_estimator__min_impurity_decrease: 0.0
        primary_cols_estimator__min_samples_leaf: 1
        primary_cols_estimator__min_samples_split: 2
        primary_cols_estimator__min_weight_fraction_leaf: 0.0
        primary_cols_estimator__n_estimators: 50
        primary_cols_estimator__n_jobs: 3
        primary_cols_estimator__oob_score: false
        primary_cols_estimator__random_state: 0
        primary_cols_estimator__verbose: 10
        primary_cols_estimator__warm_start: false
        primary_rows_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_rows_estimator__bootstrap: false
        primary_rows_estimator__ccp_alpha: 0.0
        primary_rows_estimator__criterion: squared_error
        primary_rows_estimator__max_depth: null
        primary_rows_estimator__max_features: 1.0
        primary_rows_estimator__max_leaf_nodes: null
        primary_rows_estimator__max_samples: null
        primary_rows_estimator__min_impurity_decrease: 0.0
        primary_rows_estimator__min_samples_leaf: 1
        primary_rows_estimator__min_samples_split: 2
        primary_rows_estimator__min_weight_fraction_leaf: 0.0
        primary_rows_estimator__n_estimators: 50
        primary_rows_estimator__n_jobs: 3
        primary_rows_estimator__oob_score: false
        primary_rows_estimator__random_state: 0
        primary_rows_estimator__verbose: 10
        primary_rows_estimator__warm_start: false
        secondary_cols_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_cols_estimator__bootstrap: false
        secondary_cols_estimator__ccp_alpha: 0.0
        secondary_cols_estimator__criterion: squared_error
        secondary_cols_estimator__max_depth: null
        secondary_cols_estimator__max_features: 1.0
        secondary_cols_estimator__max_leaf_nodes: null
        secondary_cols_estimator__max_samples: null
        secondary_cols_estimator__min_impurity_decrease: 0.0
        secondary_cols_estimator__min_samples_leaf: 1
        secondary_cols_estimator__min_samples_split: 2
        secondary_cols_estimator__min_weight_fraction_leaf: 0.0
        secondary_cols_estimator__n_estimators: 50
        secondary_cols_estimator__n_jobs: 3
        secondary_cols_estimator__oob_score: false
        secondary_cols_estimator__random_state: 0
        secondary_cols_estimator__verbose: 10
        secondary_cols_estimator__warm_start: false
        secondary_rows_estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_rows_estimator__bootstrap: false
        secondary_rows_estimator__ccp_alpha: 0.0
        secondary_rows_estimator__criterion: squared_error
        secondary_rows_estimator__max_depth: null
        secondary_rows_estimator__max_features: 1.0
        secondary_rows_estimator__max_leaf_nodes: null
        secondary_rows_estimator__max_samples: null
        secondary_rows_estimator__min_impurity_decrease: 0.0
        secondary_rows_estimator__min_samples_leaf: 1
        secondary_rows_estimator__min_samples_split: 2
        secondary_rows_estimator__min_weight_fraction_leaf: 0.0
        secondary_rows_estimator__n_estimators: 50
        secondary_rows_estimator__n_jobs: 3
        secondary_rows_estimator__oob_score: false
        secondary_rows_estimator__random_state: 0
        secondary_rows_estimator__verbose: 10
        secondary_rows_estimator__warm_start: false
  name: bxt_lmo
  params: {}
hash: abbe96741d11b1a63741433043dc7559b249eb0907a9f7c3bda7dc3466dcd7cf
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/abbe967_20230925T030554127795_bxt_lmo_nuclear_receptors.yml"
results:
  LL_average_precision:
  - 0.9921531701192718
  - 1.0
  - 1.0
  - 0.9924242424242424
  - 0.981318111053451
  - 1.0
  - 1.0
  - 0.9836363636363636
  - 0.9838097647356439
  - 1.0
  - 1.0
  - 0.9843137254901961
  - 0.9939817043813192
  - 1.0
  - 1.0
  - 0.9935897435897436
  LL_balanced_accuracy:
  - 0.9964589235127479
  - 1.0
  - 1.0
  - 0.9965469613259669
  - 0.9958275382475661
  - 1.0
  - 1.0
  - 0.9959183673469387
  - 0.9946018893387314
  - 1.0
  - 1.0
  - 0.9947368421052631
  - 0.9966124661246613
  - 1.0
  - 1.0
  - 0.9967105263157895
  LL_f1_macro:
  - 0.9760992760596512
  - 1.0
  - 1.0
  - 0.9765283678327157
  - 0.9638141188420519
  - 1.0
  - 1.0
  - 0.9660359260551099
  - 0.9655402640477266
  - 1.0
  - 1.0
  - 0.9661044973544973
  - 0.978920630905517
  - 1.0
  - 1.0
  - 0.9783498349834985
  LL_f1_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_f1_weighted:
  - 0.9935549148925676
  - 1.0
  - 1.0
  - 0.9937099270134935
  - 0.9923578626607149
  - 1.0
  - 1.0
  - 0.9925278488828433
  - 0.9902903232753978
  - 1.0
  - 1.0
  - 0.9905229707058975
  - 0.9938605020051748
  - 1.0
  - 1.0
  - 0.9940143282620947
  LL_matthews_corrcoef:
  - 0.9532954771575798
  - 1.0
  - 1.0
  - 0.9541153472008888
  - 0.9300864537292473
  - 1.0
  - 1.0
  - 0.9342463949786545
  - 0.9333219673061774
  - 1.0
  - 1.0
  - 0.9343794815169456
  - 0.9586989457846643
  - 1.0
  - 1.0
  - 0.9576032835067954
  LL_precision_macro:
  - 0.9576271186440678
  - 1.0
  - 1.0
  - 0.9583333333333333
  - 0.9361702127659575
  - 1.0
  - 1.0
  - 0.94
  - 0.9402985074626866
  - 1.0
  - 1.0
  - 0.9411764705882353
  - 0.9626865671641791
  - 1.0
  - 1.0
  - 0.9615384615384616
  LL_precision_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_precision_weighted:
  - 0.993978590544157
  - 1.0
  - 1.0
  - 0.9941163885323063
  - 0.9931131019036955
  - 1.0
  - 1.0
  - 0.9932220795892169
  - 0.9911940298507463
  - 1.0
  - 1.0
  - 0.9913916786226686
  - 0.9942164179104478
  - 1.0
  - 1.0
  - 0.9943714821763602
  LL_recall_macro:
  - 0.9964589235127479
  - 1.0
  - 1.0
  - 0.9965469613259669
  - 0.9958275382475661
  - 1.0
  - 1.0
  - 0.9959183673469387
  - 0.9946018893387314
  - 1.0
  - 1.0
  - 0.9947368421052631
  - 0.9966124661246613
  - 1.0
  - 1.0
  - 0.9967105263157895
  LL_recall_micro:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_recall_weighted:
  - 0.993421052631579
  - 1.0
  - 1.0
  - 0.993581514762516
  - 0.9921052631578947
  - 1.0
  - 1.0
  - 0.9922978177150192
  - 0.99
  - 1.0
  - 1.0
  - 0.9902439024390244
  - 0.99375
  - 1.0
  - 1.0
  - 0.9939024390243902
  LL_roc_auc:
  - 0.9996721225474767
  - 1.0
  - 1.0
  - 0.9996860873932698
  - 0.9993893958411073
  - 1.0
  - 1.0
  - 0.999443413729128
  - 0.9992680527916924
  - 1.0
  - 1.0
  - 0.999298245614035
  - 0.9997268117842469
  - 1.0
  - 1.0
  - 0.9997258771929824
  LT_average_precision:
  - 0.30121246328856144
  - 0.32239461664229463
  - 0.2229989540391684
  - 0.4470352047701671
  - 0.2639669079547238
  - 0.3723471722785224
  - 0.1370041021356811
  - 0.3555212818370713
  - 0.35550646985073214
  - 0.3016712539860688
  - 0.22043230040693176
  - 0.4261178215723671
  - 0.3502112839639463
  - 0.4104840342714439
  - 0.33140842541249044
  - 0.41475031450347016
  LT_balanced_accuracy:
  - 0.7123505976095618
  - 0.712863070539419
  - 0.7116379310344827
  - 0.8091661557326792
  - 0.6315616797900263
  - 0.6802845528455285
  - 0.6445035460992908
  - 0.8405695611577965
  - 0.6884328358208955
  - 0.6490996925779534
  - 0.718768679019725
  - 0.776013143483023
  - 0.7188679245283018
  - 0.71256038647343
  - 0.7444903581267217
  - 0.7870975550714113
  LT_f1_macro:
  - 0.5784736308316429
  - 0.6251490514905149
  - 0.5836829836829837
  - 0.6230377906976743
  - 0.5409663865546218
  - 0.6421670539317598
  - 0.5649959541149031
  - 0.652014652014652
  - 0.5793366462498555
  - 0.6041757285776425
  - 0.6395604395604395
  - 0.6534996534996534
  - 0.5846326178438437
  - 0.6536082474226804
  - 0.6095737182433882
  - 0.6564163005821637
  LT_f1_micro:
  - 0.8120300751879698
  - 0.8045112781954887
  - 0.8097165991902834
  - 0.8299595141700404
  - 0.8270676691729322
  - 0.8759398496240601
  - 0.8502024291497976
  - 0.8987854251012146
  - 0.8607142857142858
  - 0.8142857142857143
  - 0.8423076923076923
  - 0.9038461538461539
  - 0.825
  - 0.8392857142857143
  - 0.8115384615384615
  - 0.8576923076923076
  LT_f1_weighted:
  - 0.8568540392563558
  - 0.8357047089267885
  - 0.8531846021724565
  - 0.8706654269842763
  - 0.8706640550957225
  - 0.8879003182408755
  - 0.8830011737788104
  - 0.9236997819993771
  - 0.8938898152581268
  - 0.8369446343130553
  - 0.8662214708368554
  - 0.9231035769497308
  - 0.8667539584027129
  - 0.8583063328424154
  - 0.8514994000513907
  - 0.8850011126771011
  LT_matthews_corrcoef:
  - 0.2452665018636499
  - 0.3027598440989044
  - 0.25159094687811007
  - 0.3558326579011513
  - 0.14698196917030187
  - 0.29631680756508594
  - 0.1781685731277637
  - 0.3907104835353952
  - 0.22044678781291585
  - 0.23165669516725076
  - 0.31795856195855415
  - 0.3584534518436789
  - 0.2534612582355012
  - 0.33295830977562696
  - 0.30393267512462535
  - 0.37855925946548935
  LT_precision_macro:
  - 0.570821153335105
  - 0.6076555023923444
  - 0.574771573604061
  - 0.6023857868020305
  - 0.541052416052416
  - 0.6217570350034317
  - 0.5549191374663073
  - 0.6120583717357911
  - 0.5644749441429939
  - 0.5899814471243042
  - 0.615530303030303
  - 0.6163793103448276
  - 0.5733805668016194
  - 0.6303879310344828
  - 0.5944567627494457
  - 0.6247895622895623
  LT_precision_micro:
  - 0.8120300751879699
  - 0.8045112781954887
  - 0.8097165991902834
  - 0.8299595141700404
  - 0.8270676691729323
  - 0.8759398496240601
  - 0.8502024291497976
  - 0.8987854251012146
  - 0.8607142857142858
  - 0.8142857142857143
  - 0.8423076923076923
  - 0.9038461538461539
  - 0.825
  - 0.8392857142857143
  - 0.8115384615384615
  - 0.8576923076923076
  LT_precision_weighted:
  - 0.9266043130680808
  - 0.8873979206389178
  - 0.9215951828027702
  - 0.9414241969625352
  - 0.9299046141151405
  - 0.9033517217890299
  - 0.926942719643812
  - 0.9631840146271385
  - 0.9399069809858193
  - 0.8685131195335276
  - 0.9029574592074593
  - 0.9517572944297081
  - 0.9307945344129556
  - 0.8869689039408867
  - 0.9186320996077093
  - 0.930812937062937
  LT_recall_macro:
  - 0.7123505976095618
  - 0.712863070539419
  - 0.7116379310344827
  - 0.8091661557326792
  - 0.6315616797900263
  - 0.6802845528455285
  - 0.6445035460992908
  - 0.8405695611577965
  - 0.6884328358208955
  - 0.6490996925779534
  - 0.718768679019725
  - 0.776013143483023
  - 0.7188679245283018
  - 0.71256038647343
  - 0.7444903581267217
  - 0.7870975550714113
  LT_recall_micro:
  - 0.8120300751879699
  - 0.8045112781954887
  - 0.8097165991902834
  - 0.8299595141700404
  - 0.8270676691729323
  - 0.8759398496240601
  - 0.8502024291497976
  - 0.8987854251012146
  - 0.8607142857142858
  - 0.8142857142857143
  - 0.8423076923076923
  - 0.9038461538461539
  - 0.825
  - 0.8392857142857143
  - 0.8115384615384615
  - 0.8576923076923076
  LT_recall_weighted:
  - 0.8120300751879699
  - 0.8045112781954887
  - 0.8097165991902834
  - 0.8299595141700404
  - 0.8270676691729323
  - 0.8759398496240601
  - 0.8502024291497976
  - 0.8987854251012146
  - 0.8607142857142858
  - 0.8142857142857143
  - 0.8423076923076923
  - 0.9038461538461539
  - 0.825
  - 0.8392857142857143
  - 0.8115384615384615
  - 0.8576923076923076
  LT_roc_auc:
  - 0.7697211155378487
  - 0.7198340248962656
  - 0.7821839080459769
  - 0.8241876149601471
  - 0.6758530183727034
  - 0.6529471544715446
  - 0.6051418439716312
  - 0.8401027077497665
  - 0.777207711442786
  - 0.6347533304055043
  - 0.7091053994819685
  - 0.8187294633077766
  - 0.760125786163522
  - 0.7460108329673546
  - 0.8873966942148761
  - 0.8108206245461147
  TL_average_precision:
  - 0.3715164130538808
  - 0.4520783564261825
  - 0.5904678944748631
  - 0.4380676397407249
  - 0.3433887580717392
  - 0.19682539682539685
  - 0.3306326264320844
  - 0.3110318123144027
  - 0.05706355048460311
  - 0.08846153846153847
  - 0.10015551860064055
  - 0.12939606392751452
  - 0.33425324675324675
  - 0.313963963963964
  - 0.4350635814050448
  - 0.36803016562455254
  TL_balanced_accuracy:
  - 0.7444868532654793
  - 0.7974647075770671
  - 0.8095238095238095
  - 0.7220156959933912
  - 0.6393962948568468
  - 0.6204427083333334
  - 0.6448005698005698
  - 0.6373295910184442
  - 0.5162656726533379
  - 0.4569637411047103
  - 0.5080409356725146
  - 0.5336744800264114
  - 0.6456521739130434
  - 0.6020846106683017
  - 0.689170182841069
  - 0.6685374711125784
  TL_f1_macro:
  - 0.6412497125398339
  - 0.658203125
  - 0.6713740458015267
  - 0.6355920876770917
  - 0.6094634069317613
  - 0.6300211416490487
  - 0.6355920876770916
  - 0.6198004062527599
  - 0.48354786963496227
  - 0.46249828602769777
  - 0.48586699558022406
  - 0.4772288880897113
  - 0.5158159186936165
  - 0.5448798988621998
  - 0.5365334207077327
  - 0.5844594594594594
  TL_f1_micro:
  - 0.8607142857142858
  - 0.8928571428571429
  - 0.8954703832752613
  - 0.8675958188153311
  - 0.8107142857142857
  - 0.8928571428571429
  - 0.8675958188153311
  - 0.8432055749128919
  - 0.7708333333333333
  - 0.7958333333333333
  - 0.7520325203252033
  - 0.7357723577235772
  - 0.7791666666666667
  - 0.9
  - 0.8130081300813008
  - 0.8536585365853658
  TL_f1_weighted:
  - 0.8857673191816892
  - 0.9151088169642857
  - 0.91627257493949
  - 0.8898843868722798
  - 0.8277355043177828
  - 0.8884022953790396
  - 0.8716482857347762
  - 0.85234487726717
  - 0.82700646869335
  - 0.8399252708076237
  - 0.8016566012098604
  - 0.8060124910923153
  - 0.8431445319934527
  - 0.9234513274336283
  - 0.8683030719560145
  - 0.8835695451549109
  TL_matthews_corrcoef:
  - 0.3326319822945704
  - 0.3785085419147422
  - 0.4026069687123136
  - 0.310847654729073
  - 0.23211175505355153
  - 0.26183906414593777
  - 0.27237547021591785
  - 0.2442370256478224
  - 0.018408372559188167
  - -0.05336808616581128
  - 0.010330893054784502
  - 0.035087177465150325
  - 0.14033052391491205
  - 0.12158655352847263
  - 0.18067690389634786
  - 0.2158742568912264
  TL_precision_macro:
  - 0.6131390442547346
  - 0.6204081632653061
  - 0.630920761398849
  - 0.6088056680161944
  - 0.5966235632183908
  - 0.6423076923076922
  - 0.6280871975806451
  - 0.6085922637920101
  - 0.5052083333333333
  - 0.48345492443981236
  - 0.5033182503770739
  - 0.5091397849462366
  - 0.5338008273635355
  - 0.5362035225048923
  - 0.5431412381054207
  - 0.5691266079891673
  TL_precision_micro:
  - 0.8607142857142858
  - 0.8928571428571429
  - 0.8954703832752613
  - 0.867595818815331
  - 0.8107142857142857
  - 0.8928571428571429
  - 0.867595818815331
  - 0.8432055749128919
  - 0.7708333333333334
  - 0.7958333333333333
  - 0.7520325203252033
  - 0.7357723577235772
  - 0.7791666666666667
  - 0.9
  - 0.8130081300813008
  - 0.8536585365853658
  TL_precision_weighted:
  - 0.9245223376368504
  - 0.9499416909620992
  - 0.9496107710081085
  - 0.9226043532847128
  - 0.8502745279146142
  - 0.8845054945054945
  - 0.8761116809036754
  - 0.8632199806009292
  - 0.8999565972222221
  - 0.8910706531179433
  - 0.8660265607180958
  - 0.9048474517003235
  - 0.9366402650253927
  - 0.9514459665144596
  - 0.9479415760692409
  - 0.9247915187344155
  TL_recall_macro:
  - 0.7444868532654793
  - 0.7974647075770671
  - 0.8095238095238095
  - 0.7220156959933912
  - 0.6393962948568468
  - 0.6204427083333334
  - 0.6448005698005698
  - 0.6373295910184442
  - 0.5162656726533379
  - 0.4569637411047103
  - 0.5080409356725146
  - 0.5336744800264114
  - 0.6456521739130434
  - 0.6020846106683017
  - 0.689170182841069
  - 0.6685374711125784
  TL_recall_micro:
  - 0.8607142857142858
  - 0.8928571428571429
  - 0.8954703832752613
  - 0.867595818815331
  - 0.8107142857142857
  - 0.8928571428571429
  - 0.867595818815331
  - 0.8432055749128919
  - 0.7708333333333334
  - 0.7958333333333333
  - 0.7520325203252033
  - 0.7357723577235772
  - 0.7791666666666667
  - 0.9
  - 0.8130081300813008
  - 0.8536585365853658
  TL_recall_weighted:
  - 0.8607142857142858
  - 0.8928571428571429
  - 0.8954703832752613
  - 0.867595818815331
  - 0.8107142857142857
  - 0.8928571428571429
  - 0.867595818815331
  - 0.8432055749128919
  - 0.7708333333333334
  - 0.7958333333333333
  - 0.7520325203252033
  - 0.7357723577235772
  - 0.7791666666666667
  - 0.9
  - 0.8130081300813008
  - 0.8536585365853658
  TL_roc_auc:
  - 0.744910941475827
  - 0.8061077499279746
  - 0.8193354264782837
  - 0.7170590665014458
  - 0.6384246664075658
  - 0.6035970052083334
  - 0.6334045584045583
  - 0.6404036353916066
  - 0.46052185699762793
  - 0.43663165028803796
  - 0.46003898635477586
  - 0.4795311984153186
  - 0.7184782608695652
  - 0.6232372777437155
  - 0.6962025316455697
  - 0.6728293166061406
  TT_average_precision:
  - 0.04022859143657463
  - 0.2814513404045829
  - 0.09959680139752168
  - 0.34090909090909094
  - 0.09670530711280774
  - 0.2292778649921507
  - 0.2834694328659846
  - 0.2446924603174603
  - 0.13008174029845856
  - 0.0852275622927797
  - 0.02127659574468085
  - 0.2122842304446078
  - 0.037622005323868675
  - 0.1677974802974803
  - 0.06658606455286288
  - -0.0
  TT_balanced_accuracy:
  - 0.4368421052631579
  - 0.5916666666666667
  - 0.48809523809523814
  - 0.793560606060606
  - 0.45652173913043476
  - 0.5266968325791855
  - 0.7006172839506173
  - 0.5948795180722892
  - 0.4807692307692308
  - 0.42948717948717946
  - 0.4025974025974026
  - 0.5347222222222222
  - 0.3950617283950617
  - 0.5576923076923077
  - 0.4560810810810811
  - 0.9615384615384616
  TT_f1_macro:
  - 0.45856353591160226
  - 0.5916666666666667
  - 0.48295454545454547
  - 0.6431372549019607
  - 0.46153846153846156
  - 0.5236111111111111
  - 0.676510801203172
  - 0.6003992015968064
  - 0.4716981132075472
  - 0.44370860927152317
  - 0.44285714285714284
  - 0.5291750503018108
  - 0.43243243243243235
  - 0.5622466705269253
  - 0.4222222222222223
  - 0.49019607843137253
  TT_f1_micro:
  - 0.8469387755102041
  - 0.8775510204081631
  - 0.7802197802197802
  - 0.9120879120879121
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8791208791208791
  - 0.8928571428571429
  - 0.7976190476190477
  - 0.7948717948717948
  - 0.8461538461538461
  - 0.7619047619047619
  - 0.8928571428571429
  - 0.6410256410256411
  - 0.9615384615384616
  TT_f1_weighted:
  - 0.8890517532980045
  - 0.8775510204081632
  - 0.8146853146853147
  - 0.9325145442792502
  - 0.8665620094191524
  - 0.8164682539682541
  - 0.8651119184343138
  - 0.8754534886271413
  - 0.8760107816711591
  - 0.8240302743614001
  - 0.8743589743589744
  - 0.8560594335242221
  - 0.8339768339768338
  - 0.8883282322772769
  - 0.7413105413105414
  - 0.9803921568627451
  TT_matthews_corrcoef:
  - -0.06638045457122153
  - 0.18333333333333332
  - -0.017099639201419235
  - 0.3511571808882946
  - -0.0761386987626881
  - 0.1051352720011248
  - 0.35860956909327935
  - 0.20164982172669937
  - -0.05337605126836238
  - -0.10766219660331079
  - -0.055607067440108786
  - 0.060993754559283325
  - -0.096940482558378
  - 0.12559498126280014
  - -0.04109974682633932
  - 0.0
  TT_precision_macro:
  - 0.48255813953488375
  - 0.5916666666666667
  - 0.493859649122807
  - 0.6050135501355014
  - 0.4666666666666667
  - 0.6035087719298246
  - 0.6602564102564102
  - 0.6071428571428572
  - 0.46296296296296297
  - 0.4589041095890411
  - 0.49206349206349204
  - 0.5267857142857143
  - 0.47761194029850745
  - 0.5683544303797469
  - 0.49038461538461536
  - 0.5
  TT_precision_micro:
  - 0.8469387755102041
  - 0.8775510204081632
  - 0.7802197802197802
  - 0.9120879120879121
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8791208791208791
  - 0.8928571428571429
  - 0.7976190476190477
  - 0.7948717948717948
  - 0.8461538461538461
  - 0.7619047619047619
  - 0.8928571428571429
  - 0.6410256410256411
  - 0.9615384615384616
  TT_precision_weighted:
  - 0.9355719031798766
  - 0.8775510204081632
  - 0.8553306342780027
  - 0.9625658893951576
  - 0.8761904761904763
  - 0.8020050125313284
  - 0.875316990701606
  - 0.8720565149136578
  - 0.8597883597883599
  - 0.8522504892367906
  - 0.9715099715099714
  - 0.8667582417582418
  - 0.9211087420042643
  - 0.8840867992766727
  - 0.8959566074950691
  - 1.0
  TT_recall_macro:
  - 0.4368421052631579
  - 0.5916666666666667
  - 0.48809523809523814
  - 0.793560606060606
  - 0.45652173913043476
  - 0.5266968325791855
  - 0.7006172839506173
  - 0.5948795180722892
  - 0.4807692307692308
  - 0.42948717948717946
  - 0.4025974025974026
  - 0.5347222222222222
  - 0.3950617283950617
  - 0.5576923076923077
  - 0.4560810810810811
  - 0.4807692307692308
  TT_recall_micro:
  - 0.8469387755102041
  - 0.8775510204081632
  - 0.7802197802197802
  - 0.9120879120879121
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8791208791208791
  - 0.8928571428571429
  - 0.7976190476190477
  - 0.7948717948717948
  - 0.8461538461538461
  - 0.7619047619047619
  - 0.8928571428571429
  - 0.6410256410256411
  - 0.9615384615384616
  TT_recall_weighted:
  - 0.8469387755102041
  - 0.8775510204081632
  - 0.7802197802197802
  - 0.9120879120879121
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8571428571428571
  - 0.8791208791208791
  - 0.8928571428571429
  - 0.7976190476190477
  - 0.7948717948717948
  - 0.8461538461538461
  - 0.7619047619047619
  - 0.8928571428571429
  - 0.6410256410256411
  - 0.9615384615384616
  TT_roc_auc:
  - 0.42280701754385963
  - 0.7055555555555555
  - 0.5578231292517006
  - 0.9431818181818181
  - 0.6476449275362319
  - 0.6457013574660634
  - 0.7549382716049383
  - 0.6694277108433735
  - 0.6837606837606838
  - 0.5363247863247863
  - 0.4025974025974026
  - 0.7013888888888888
  - 0.397119341563786
  - 0.530982905982906
  - 0.5523648648648649
  - .nan
  fit_time:
  - 0.15374374389648438
  - 0.14761590957641602
  - 0.15383243560791016
  - 0.15171194076538086
  - 0.12372970581054688
  - 0.11460614204406738
  - 0.14940094947814941
  - 0.13450837135314941
  - 0.13220596313476562
  - 0.13830018043518066
  - 0.13715147972106934
  - 0.14348554611206055
  - 0.14427757263183594
  - 0.14814972877502441
  - 0.12879323959350586
  - 0.12893438339233398
  score_time:
  - 1.749488353729248
  - 1.6854839324951172
  - 1.6985223293304443
  - 1.6890630722045898
  - 1.7018134593963623
  - 1.6712429523468018
  - 1.7351861000061035
  - 1.6726374626159668
  - 1.6590588092803955
  - 1.7285454273223877
  - 1.6910831928253174
  - 1.6684784889221191
  - 1.725060224533081
  - 1.669546365737915
  - 1.7455694675445557
  - 1.6711769104003906
start: 2023-09-25 03:05:54.127795
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
