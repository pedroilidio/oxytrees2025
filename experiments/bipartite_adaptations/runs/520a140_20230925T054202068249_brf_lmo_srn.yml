active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/srn/X1.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X1.txt
  - force_download: false
    path: datasets/srn/X2.txt
    read:
      call: data_loading.load_regulatory_network_features
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/srn/X2.txt
  name: srn
  pairwise: true
  y:
    force_download: false
    path: datasets/srn/Y.txt
    read:
      call: numpy.loadtxt
      params:
        delimiter: ','
    url: https://people.montefiore.uliege.be/schrynemackers/srn/Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-25 06:16:19.191306
estimator:
  call: bipartite_adaptations.estimators.brf_lmo
  final_params:
    estimator:
      call: bipartite_learn.wrappers.LocalMultiOutputWrapper
      params:
        combine_func_kwargs: null
        combine_predictions_func:
          load: numpy.mean
        independent_labels: false
        primary_cols_estimator:
          call: sklearn.ensemble._forest.RandomForestRegressor
          params:
            bootstrap: true
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 0.5
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_cols_estimator__bootstrap: true
        primary_cols_estimator__ccp_alpha: 0.0
        primary_cols_estimator__criterion: squared_error
        primary_cols_estimator__max_depth: null
        primary_cols_estimator__max_features: 0.5
        primary_cols_estimator__max_leaf_nodes: null
        primary_cols_estimator__max_samples: null
        primary_cols_estimator__min_impurity_decrease: 0.0
        primary_cols_estimator__min_samples_leaf: 1
        primary_cols_estimator__min_samples_split: 2
        primary_cols_estimator__min_weight_fraction_leaf: 0.0
        primary_cols_estimator__n_estimators: 50
        primary_cols_estimator__n_jobs: 3
        primary_cols_estimator__oob_score: false
        primary_cols_estimator__random_state: 0
        primary_cols_estimator__verbose: 10
        primary_cols_estimator__warm_start: false
        primary_rows_estimator:
          call: sklearn.ensemble._forest.RandomForestRegressor
          params:
            bootstrap: true
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 0.5
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        primary_rows_estimator__bootstrap: true
        primary_rows_estimator__ccp_alpha: 0.0
        primary_rows_estimator__criterion: squared_error
        primary_rows_estimator__max_depth: null
        primary_rows_estimator__max_features: 0.5
        primary_rows_estimator__max_leaf_nodes: null
        primary_rows_estimator__max_samples: null
        primary_rows_estimator__min_impurity_decrease: 0.0
        primary_rows_estimator__min_samples_leaf: 1
        primary_rows_estimator__min_samples_split: 2
        primary_rows_estimator__min_weight_fraction_leaf: 0.0
        primary_rows_estimator__n_estimators: 50
        primary_rows_estimator__n_jobs: 3
        primary_rows_estimator__oob_score: false
        primary_rows_estimator__random_state: 0
        primary_rows_estimator__verbose: 10
        primary_rows_estimator__warm_start: false
        secondary_cols_estimator:
          call: sklearn.ensemble._forest.RandomForestRegressor
          params:
            bootstrap: true
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 0.5
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_cols_estimator__bootstrap: true
        secondary_cols_estimator__ccp_alpha: 0.0
        secondary_cols_estimator__criterion: squared_error
        secondary_cols_estimator__max_depth: null
        secondary_cols_estimator__max_features: 0.5
        secondary_cols_estimator__max_leaf_nodes: null
        secondary_cols_estimator__max_samples: null
        secondary_cols_estimator__min_impurity_decrease: 0.0
        secondary_cols_estimator__min_samples_leaf: 1
        secondary_cols_estimator__min_samples_split: 2
        secondary_cols_estimator__min_weight_fraction_leaf: 0.0
        secondary_cols_estimator__n_estimators: 50
        secondary_cols_estimator__n_jobs: 3
        secondary_cols_estimator__oob_score: false
        secondary_cols_estimator__random_state: 0
        secondary_cols_estimator__verbose: 10
        secondary_cols_estimator__warm_start: false
        secondary_rows_estimator:
          call: sklearn.ensemble._forest.RandomForestRegressor
          params:
            bootstrap: true
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 0.5
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 50
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        secondary_rows_estimator__bootstrap: true
        secondary_rows_estimator__ccp_alpha: 0.0
        secondary_rows_estimator__criterion: squared_error
        secondary_rows_estimator__max_depth: null
        secondary_rows_estimator__max_features: 0.5
        secondary_rows_estimator__max_leaf_nodes: null
        secondary_rows_estimator__max_samples: null
        secondary_rows_estimator__min_impurity_decrease: 0.0
        secondary_rows_estimator__min_samples_leaf: 1
        secondary_rows_estimator__min_samples_split: 2
        secondary_rows_estimator__min_weight_fraction_leaf: 0.0
        secondary_rows_estimator__n_estimators: 50
        secondary_rows_estimator__n_jobs: 3
        secondary_rows_estimator__oob_score: false
        secondary_rows_estimator__random_state: 0
        secondary_rows_estimator__verbose: 10
        secondary_rows_estimator__warm_start: false
  name: brf_lmo
  params: {}
hash: 520a14060dc63a4693c919e7710f32b251adc7af19cb2a1a6313fdb845f3bae0
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/520a140_20230925T054202068249_brf_lmo_srn.yml"
results:
  LL_average_precision:
  - 0.9999312469193447
  - 0.9999004551429136
  - 0.9997402096070679
  - 0.9999648004511233
  - 0.9998971449545937
  - 0.9998222805927789
  - 0.9997071991037241
  - 0.9999017398659859
  - 0.9996868079431137
  - 0.9998333931091734
  - 0.9997466046177136
  - 0.9998013850508096
  - 0.999917765671609
  - 0.9998406859607363
  - 0.9998774147832173
  - 0.9998917356504724
  LL_balanced_accuracy:
  - 0.949800796812749
  - 0.9496942916878964
  - 0.9430848912259722
  - 0.9480203232769968
  - 0.9499770009199632
  - 0.9494200126351257
  - 0.9440735437511529
  - 0.9476791067014918
  - 0.9483062168785554
  - 0.9482767701950594
  - 0.9438132644453817
  - 0.9484675757442891
  - 0.9492050290648806
  - 0.946116168221838
  - 0.945424113026517
  - 0.947725658362053
  LL_f1_macro:
  - 0.589427484039941
  - 0.6118791712172438
  - 0.6010426285884066
  - 0.601926238958963
  - 0.5890299229772595
  - 0.6088208589256812
  - 0.6019272084042888
  - 0.5986240377518086
  - 0.5860977767218832
  - 0.6084844542327816
  - 0.6025862841106727
  - 0.6033123763857835
  - 0.5885610237723496
  - 0.6029556727563306
  - 0.6060765820653493
  - 0.6016199693417184
  LL_f1_micro:
  - 0.9010989010989011
  - 0.9012885154061625
  - 0.8884292178409825
  - 0.8978926955397544
  - 0.9014327546538381
  - 0.9007062268538455
  - 0.8903367496339678
  - 0.897175092584618
  - 0.898155894861605
  - 0.8985100335888382
  - 0.8898544483679269
  - 0.8987770217896822
  - 0.8999337655999442
  - 0.8942640599431574
  - 0.893006631642408
  - 0.8973215054689518
  LL_f1_weighted:
  - 0.9364778187109992
  - 0.9343717095272893
  - 0.9262079147343208
  - 0.9329404206518312
  - 0.9367506813872312
  - 0.9342580420312069
  - 0.9274943083804896
  - 0.9327696266187996
  - 0.9347577011947186
  - 0.9327092193227403
  - 0.927070657862604
  - 0.9334312473171605
  - 0.9357500531341502
  - 0.9302239721596639
  - 0.9289774879509586
  - 0.9325630604773378
  LL_matthews_corrcoef:
  - 0.34333486497812604
  - 0.3800353701942465
  - 0.3658465768572828
  - 0.3648447440380628
  - 0.3425714811205272
  - 0.37527600201999745
  - 0.3667834192392897
  - 0.35964891497645546
  - 0.33856718801958297
  - 0.37527591896818774
  - 0.3679669279019374
  - 0.36686804668430545
  - 0.3422089992533591
  - 0.36744101314191013
  - 0.3727766051923675
  - 0.3644942916390761
  LL_precision_macro:
  - 0.5655172413793104
  - 0.5802917033128114
  - 0.5755181007345226
  - 0.5742777059077189
  - 0.565200676610795
  - 0.5783410138248848
  - 0.5757363721178196
  - 0.5722321748477248
  - 0.5639226807970744
  - 0.5785407725321888
  - 0.5762706248757538
  - 0.5750289268151576
  - 0.5651745815344997
  - 0.5756601686713674
  - 0.5779944289693594
  - 0.5741838702764483
  LL_precision_micro:
  - 0.9010989010989011
  - 0.9012885154061625
  - 0.8884292178409825
  - 0.8978926955397544
  - 0.9014327546538381
  - 0.9007062268538455
  - 0.8903367496339678
  - 0.897175092584618
  - 0.898155894861605
  - 0.8985100335888382
  - 0.8898544483679269
  - 0.8987770217896822
  - 0.8999337655999442
  - 0.8942640599431574
  - 0.893006631642408
  - 0.8973215054689518
  LL_precision_weighted:
  - 0.9870405456612353
  - 0.984148573530849
  - 0.9831487728677717
  - 0.984831407336544
  - 0.987146697823536
  - 0.9844424502904643
  - 0.9833890065252572
  - 0.985145466617742
  - 0.9869797035523493
  - 0.9840577992676028
  - 0.9831982598994744
  - 0.9848106971516914
  - 0.9869564500944864
  - 0.9840000018813474
  - 0.9833102266628826
  - 0.9847658237630554
  LL_recall_macro:
  - 0.949800796812749
  - 0.9496942916878964
  - 0.9430848912259722
  - 0.9480203232769968
  - 0.9499770009199632
  - 0.9494200126351257
  - 0.9440735437511529
  - 0.9476791067014918
  - 0.9483062168785554
  - 0.9482767701950594
  - 0.9438132644453817
  - 0.9484675757442891
  - 0.9492050290648806
  - 0.946116168221838
  - 0.945424113026517
  - 0.947725658362053
  LL_recall_micro:
  - 0.9010989010989011
  - 0.9012885154061625
  - 0.8884292178409825
  - 0.8978926955397544
  - 0.9014327546538381
  - 0.9007062268538455
  - 0.8903367496339678
  - 0.897175092584618
  - 0.898155894861605
  - 0.8985100335888382
  - 0.8898544483679269
  - 0.8987770217896822
  - 0.8999337655999442
  - 0.8942640599431574
  - 0.893006631642408
  - 0.8973215054689518
  LL_recall_weighted:
  - 0.9010989010989011
  - 0.9012885154061625
  - 0.8884292178409825
  - 0.8978926955397544
  - 0.9014327546538381
  - 0.9007062268538455
  - 0.8903367496339678
  - 0.897175092584618
  - 0.898155894861605
  - 0.8985100335888382
  - 0.8898544483679269
  - 0.8987770217896822
  - 0.8999337655999442
  - 0.8942640599431574
  - 0.893006631642408
  - 0.8973215054689518
  LL_roc_auc:
  - 0.9999989670945847
  - 0.9999981155549258
  - 0.9999948033951019
  - 0.9999993631957345
  - 0.9999984874516484
  - 0.99999667171141
  - 0.9999942512410778
  - 0.999998267493025
  - 0.999995607422981
  - 0.9999969938655349
  - 0.9999951428705264
  - 0.999996454269747
  - 0.9999987353003276
  - 0.9999970044880828
  - 0.9999975049455654
  - 0.9999980979245122
  LT_average_precision:
  - 0.031959001015714965
  - 0.022325030176389392
  - 0.014800532541381368
  - 0.02460193786033421
  - 0.030403244290755166
  - 0.022460982935258236
  - 0.012956080166907614
  - 0.025301081443191355
  - 0.03154998314053392
  - 0.02278420548123787
  - 0.015016999953858247
  - 0.025928766977397467
  - 0.03202714793130046
  - 0.022887662952971524
  - 0.014085726538496966
  - 0.027503073365425387
  LT_balanced_accuracy:
  - 0.5210859493275792
  - 0.5523194641332527
  - 0.5210039634279348
  - 0.5509152098610967
  - 0.5107777284462885
  - 0.5571567161758505
  - 0.508787075022055
  - 0.5467215087904743
  - 0.5157663939294053
  - 0.5504154348750366
  - 0.5204299961800618
  - 0.5580366756732678
  - 0.5151843758849125
  - 0.562586169006702
  - 0.5189465934358031
  - 0.5488894275407399
  LT_f1_macro:
  - 0.4824718123709067
  - 0.4966528865752272
  - 0.4877834882820769
  - 0.4947559913843589
  - 0.47980410347151187
  - 0.5011002346528053
  - 0.48461822016622774
  - 0.49514375823012396
  - 0.47651256629953664
  - 0.49735130116500514
  - 0.4886367603942738
  - 0.49607761087358127
  - 0.4792782411680327
  - 0.5001425837106025
  - 0.48987980516502133
  - 0.4934633796387035
  LT_f1_micro:
  - 0.8318807629152457
  - 0.889403453689168
  - 0.8963108320251177
  - 0.8723966509680795
  - 0.8352602615237037
  - 0.8975632712821585
  - 0.8961514327546539
  - 0.8761503869483371
  - 0.8173373049931842
  - 0.892517255804225
  - 0.8989228194938298
  - 0.871496548839155
  - 0.8274852324935629
  - 0.8912622882242208
  - 0.9035766576030119
  - 0.8709213553649864
  LT_f1_weighted:
  - 0.885217030499721
  - 0.9281073172236629
  - 0.9343593020031192
  - 0.9157916691092708
  - 0.8878199243004921
  - 0.9326561104582316
  - 0.9346581684869316
  - 0.9178321245530172
  - 0.8765369968098258
  - 0.9298397148231684
  - 0.9356641396723888
  - 0.9154032679947932
  - 0.8827357089834443
  - 0.9290760367379219
  - 0.9380954345716215
  - 0.9150840642795042
  LT_matthews_corrcoef:
  - 0.018855433431827225
  - 0.041787552066978546
  - 0.015517456050831005
  - 0.0421197556932011
  - 0.009587447452980706
  - 0.04739934614153114
  - 0.006362298529750142
  - 0.03934375503873213
  - 0.013586244272063511
  - 0.040848705865382876
  - 0.01539217540399552
  - 0.047627116313200615
  - 0.01338143050075784
  - 0.05053506159733076
  - 0.014711566307303003
  - 0.040038245991034664
  LT_precision_macro:
  - 0.5042152165451363
  - 0.5083439286730033
  - 0.5028660238711093
  - 0.5087109226520663
  - 0.5021321549601512
  - 0.5098269204608099
  - 0.5011516586145008
  - 0.5082827540281798
  - 0.5029268904837509
  - 0.5082743349086074
  - 0.5028991569746178
  - 0.5097711584183481
  - 0.5029481403055974
  - 0.5102011054965376
  - 0.5028557928361569
  - 0.5081973814313062
  LT_precision_micro:
  - 0.8318807629152457
  - 0.889403453689168
  - 0.8963108320251177
  - 0.8723966509680795
  - 0.8352602615237037
  - 0.8975632712821585
  - 0.8961514327546538
  - 0.8761503869483371
  - 0.8173373049931842
  - 0.892517255804225
  - 0.8989228194938298
  - 0.871496548839155
  - 0.8274852324935629
  - 0.8912622882242208
  - 0.9035766576030119
  - 0.8709213553649864
  LT_precision_weighted:
  - 0.9499359450731931
  - 0.9727171843672767
  - 0.9771250108143917
  - 0.9668310837394603
  - 0.9508713776347073
  - 0.9728698101056883
  - 0.9777014184034729
  - 0.9665260861687192
  - 0.9495201477431748
  - 0.9726690028331187
  - 0.9768274486685504
  - 0.9673130782309454
  - 0.9498981373035829
  - 0.9728309767067974
  - 0.9765365413749434
  - 0.9670455723716275
  LT_recall_macro:
  - 0.5210859493275792
  - 0.5523194641332527
  - 0.5210039634279348
  - 0.5509152098610967
  - 0.5107777284462885
  - 0.5571567161758505
  - 0.508787075022055
  - 0.5467215087904743
  - 0.5157663939294053
  - 0.5504154348750366
  - 0.5204299961800618
  - 0.5580366756732678
  - 0.5151843758849125
  - 0.562586169006702
  - 0.5189465934358031
  - 0.5488894275407399
  LT_recall_micro:
  - 0.8318807629152457
  - 0.889403453689168
  - 0.8963108320251177
  - 0.8723966509680795
  - 0.8352602615237037
  - 0.8975632712821585
  - 0.8961514327546538
  - 0.8761503869483371
  - 0.8173373049931842
  - 0.892517255804225
  - 0.8989228194938298
  - 0.871496548839155
  - 0.8274852324935629
  - 0.8912622882242208
  - 0.9035766576030119
  - 0.8709213553649864
  LT_recall_weighted:
  - 0.8318807629152457
  - 0.889403453689168
  - 0.8963108320251177
  - 0.8723966509680795
  - 0.8352602615237037
  - 0.8975632712821585
  - 0.8961514327546538
  - 0.8761503869483371
  - 0.8173373049931842
  - 0.892517255804225
  - 0.8989228194938298
  - 0.871496548839155
  - 0.8274852324935629
  - 0.8912622882242208
  - 0.9035766576030119
  - 0.8709213553649864
  LT_roc_auc:
  - 0.525485977620521
  - 0.588190082433675
  - 0.5387463924033948
  - 0.5641913908486739
  - 0.5232709984317497
  - 0.5739899182438748
  - 0.5109828126016012
  - 0.5487127777768173
  - 0.5276455743012212
  - 0.574097529577534
  - 0.5206956372163235
  - 0.5605639377800854
  - 0.5158801414663524
  - 0.5903479715156912
  - 0.5176056592556418
  - 0.555185796747041
  TL_average_precision:
  - 0.10068416569869008
  - 0.13190425511935305
  - 0.1354652081522119
  - 0.1392666071336714
  - 0.1283199020235299
  - 0.1605536602926614
  - 0.1635483690849647
  - 0.15627288693233404
  - 0.11851184377179859
  - 0.1522221290596671
  - 0.14945259328721794
  - 0.14559379085582286
  - 0.1104150347586246
  - 0.14712058523223542
  - 0.15313077016779664
  - 0.13756879280516932
  TL_balanced_accuracy:
  - 0.6926352891291674
  - 0.7109044589265381
  - 0.716671386041049
  - 0.72050949209275
  - 0.7096457122807222
  - 0.7222554934048483
  - 0.7230357572120436
  - 0.7068467883427153
  - 0.7024874315262863
  - 0.7243036117402426
  - 0.7102009839687521
  - 0.7034711654201038
  - 0.6944214081188176
  - 0.6996160257285029
  - 0.7009676560917582
  - 0.6849665772252165
  TL_f1_macro:
  - 0.5289589690667391
  - 0.5409583160742909
  - 0.5360641371626107
  - 0.5397986322188449
  - 0.5385352808573483
  - 0.5456049981208994
  - 0.537398300463064
  - 0.5388604158436171
  - 0.5342020160698284
  - 0.545510083528475
  - 0.5377571110542577
  - 0.5407405759849476
  - 0.5327005492490127
  - 0.537254408684906
  - 0.5359459823412471
  - 0.5321224343210664
  TL_f1_micro:
  - 0.889750417710944
  - 0.8837203302373581
  - 0.8695304437564499
  - 0.8834881320949433
  - 0.8962846677132391
  - 0.8804137039431157
  - 0.8655203619909502
  - 0.8801551389786684
  - 0.8946886446886446
  - 0.8861021331609567
  - 0.8740530058177116
  - 0.8912475759534582
  - 0.8961800104657246
  - 0.8817582417582418
  - 0.8738461538461538
  - 0.8852230122818359
  TL_f1_weighted:
  - 0.9289366977131381
  - 0.9229875755824657
  - 0.914069064603057
  - 0.9235866084955817
  - 0.9324295600022569
  - 0.9202401868424449
  - 0.9111846535575077
  - 0.9206218281698132
  - 0.9318169555147746
  - 0.9245052092470564
  - 0.9166150089896961
  - 0.9280545974673031
  - 0.9327781263838902
  - 0.9217215122954574
  - 0.9163268462761234
  - 0.9245393186736222
  TL_matthews_corrcoef:
  - 0.14912294270175577
  - 0.1763001184079754
  - 0.17652324561381785
  - 0.17900578774418283
  - 0.1683150536941613
  - 0.18908908069755687
  - 0.18265600836644433
  - 0.1725978350737497
  - 0.15941064365727906
  - 0.1880859541950364
  - 0.1744971320168964
  - 0.17033293072650488
  - 0.15329375342833618
  - 0.16654459548402709
  - 0.16777058204214657
  - 0.15164969030258724
  TL_precision_macro:
  - 0.5288597849082576
  - 0.5368433791168593
  - 0.5359535894556617
  - 0.5363284497889523
  - 0.5337831346416159
  - 0.540217994042917
  - 0.5373967136586126
  - 0.5360049253251972
  - 0.5313744822575928
  - 0.539429064350539
  - 0.5362144464160176
  - 0.5356479347208448
  - 0.5302165474825007
  - 0.5347380704827068
  - 0.535014301238988
  - 0.5310834921014792
  TL_precision_micro:
  - 0.889750417710944
  - 0.8837203302373581
  - 0.8695304437564499
  - 0.8834881320949433
  - 0.8962846677132391
  - 0.8804137039431157
  - 0.8655203619909502
  - 0.8801551389786684
  - 0.8946886446886447
  - 0.8861021331609567
  - 0.8740530058177117
  - 0.8912475759534583
  - 0.8961800104657247
  - 0.8817582417582418
  - 0.8738461538461538
  - 0.8852230122818359
  TL_precision_weighted:
  - 0.9776965253365768
  - 0.9734807066501819
  - 0.9723731533326062
  - 0.9751942317604707
  - 0.9777672283666519
  - 0.972275501501725
  - 0.97161433808785
  - 0.9727437155710879
  - 0.9781208028119027
  - 0.9742146283475803
  - 0.971958533565747
  - 0.9746939549404163
  - 0.9781276249913607
  - 0.972833538073886
  - 0.9712927525684449
  - 0.9739684284317982
  TL_recall_macro:
  - 0.6926352891291674
  - 0.7109044589265381
  - 0.716671386041049
  - 0.72050949209275
  - 0.7096457122807222
  - 0.7222554934048483
  - 0.7230357572120436
  - 0.7068467883427153
  - 0.7024874315262863
  - 0.7243036117402426
  - 0.7102009839687521
  - 0.7034711654201038
  - 0.6944214081188176
  - 0.6996160257285029
  - 0.7009676560917582
  - 0.6849665772252165
  TL_recall_micro:
  - 0.889750417710944
  - 0.8837203302373581
  - 0.8695304437564499
  - 0.8834881320949433
  - 0.8962846677132391
  - 0.8804137039431157
  - 0.8655203619909502
  - 0.8801551389786684
  - 0.8946886446886447
  - 0.8861021331609567
  - 0.8740530058177117
  - 0.8912475759534583
  - 0.8961800104657247
  - 0.8817582417582418
  - 0.8738461538461538
  - 0.8852230122818359
  TL_recall_weighted:
  - 0.889750417710944
  - 0.8837203302373581
  - 0.8695304437564499
  - 0.8834881320949433
  - 0.8962846677132391
  - 0.8804137039431157
  - 0.8655203619909502
  - 0.8801551389786684
  - 0.8946886446886447
  - 0.8861021331609567
  - 0.8740530058177117
  - 0.8912475759534583
  - 0.8961800104657247
  - 0.8817582417582418
  - 0.8738461538461538
  - 0.8852230122818359
  TL_roc_auc:
  - 0.7313443411358737
  - 0.7596652841179059
  - 0.7656939527824415
  - 0.7641444505948118
  - 0.7385999287333463
  - 0.7599746395560503
  - 0.779485470007884
  - 0.7369145685837437
  - 0.740041723243593
  - 0.7768229818791584
  - 0.7722057501851274
  - 0.7589705203753632
  - 0.7192609532958534
  - 0.7500323524282839
  - 0.748991630444422
  - 0.7353002771786918
  TT_average_precision:
  - 0.025817232057620623
  - 0.01706788363544718
  - 0.011887149848919342
  - 0.023571113502893037
  - 0.03349139794596727
  - 0.022445066971939848
  - 0.013411802881924529
  - 0.024313337709706558
  - 0.0278353863921213
  - 0.02026266985556716
  - 0.01256260267344754
  - 0.020798368974187364
  - 0.02851801896304491
  - 0.02092560201730622
  - 0.011305283352237773
  - 0.02283070013924648
  TT_balanced_accuracy:
  - 0.5006789261328367
  - 0.520680773971602
  - 0.49729236334662524
  - 0.5085725677830941
  - 0.5239002160054792
  - 0.5411763472426085
  - 0.5010494238877025
  - 0.5343596573001287
  - 0.5137568343602043
  - 0.5419734744513549
  - 0.5019246827558829
  - 0.5050218388215031
  - 0.5081262663795677
  - 0.522377215925603
  - 0.5025
  - 0.5298834337295876
  TT_f1_macro:
  - 0.47740786180535527
  - 0.49192807715378684
  - 0.4848294028931195
  - 0.48707312427159416
  - 0.49132941389246065
  - 0.5049483297722139
  - 0.48759422363192423
  - 0.49649150821803745
  - 0.4799924681789456
  - 0.5002068030943563
  - 0.48903095637105853
  - 0.4880851365562432
  - 0.4817136117845054
  - 0.49514004790372806
  - 0.4885665109417261
  - 0.49489503070905455
  TT_f1_micro:
  - 0.8374924379915305
  - 0.8988095238095238
  - 0.9052318295739349
  - 0.8847901002506265
  - 0.852595680181887
  - 0.9181318681318681
  - 0.9081632653061225
  - 0.8912087912087913
  - 0.8338006820765441
  - 0.9051805337519623
  - 0.9182888540031398
  - 0.8916012558869701
  - 0.8433497536945813
  - 0.9088697017268446
  - 0.9171114599686028
  - 0.8879905808477238
  TT_f1_weighted:
  - 0.8891580303658793
  - 0.9329952571186004
  - 0.9392022701553914
  - 0.9226055807559708
  - 0.8959671249207705
  - 0.9437273085612273
  - 0.9395000679261026
  - 0.9265513848099136
  - 0.8872099888969921
  - 0.9366094333234019
  - 0.9467050871854297
  - 0.9260986555326967
  - 0.8921388067720883
  - 0.93889586319827
  - 0.9464356641637193
  - 0.9241208151473275
  TT_matthews_corrcoef:
  - 0.0006077090257624935
  - 0.017531429973212793
  - -0.0021011561014034523
  - 0.007515995081858078
  - 0.0235255163660005
  - 0.03873854210504285
  - 0.0008812609554228464
  - 0.03059205947774743
  - 0.012108714900524559
  - 0.0366085612663604
  - 0.001579084679157143
  - 0.004591357475717262
  - 0.007482439321856751
  - 0.01970961205848028
  - 0.0019959059387355434
  - 0.026816421951120474
  TT_precision_macro:
  - 0.5001359905894512
  - 0.5037154199031393
  - 0.4995923698849177
  - 0.501647411356196
  - 0.5057891727857196
  - 0.5091112662057072
  - 0.5001850112429909
  - 0.5068093963722866
  - 0.5026645115566399
  - 0.507982343465193
  - 0.5003238856398967
  - 0.501049444447498
  - 0.5017224053332179
  - 0.5043400037876397
  - 0.500398364051628
  - 0.5060160463215824
  TT_precision_micro:
  - 0.8374924379915305
  - 0.8988095238095238
  - 0.9052318295739349
  - 0.8847901002506265
  - 0.852595680181887
  - 0.9181318681318681
  - 0.9081632653061225
  - 0.8912087912087913
  - 0.8338006820765441
  - 0.9051805337519623
  - 0.9182888540031398
  - 0.8916012558869701
  - 0.8433497536945813
  - 0.9088697017268446
  - 0.9171114599686028
  - 0.8879905808477238
  TT_precision_weighted:
  - 0.9505186887165413
  - 0.9712900014992102
  - 0.9765496896814926
  - 0.9653050470617426
  - 0.9472276040191653
  - 0.972153457065512
  - 0.9738553264359284
  - 0.9668160723742966
  - 0.9515491353097878
  - 0.9720185729569585
  - 0.9775491108895643
  - 0.9646220605393231
  - 0.9499045239123783
  - 0.9721814738239115
  - 0.978329620966715
  - 0.9653136641644989
  TT_recall_macro:
  - 0.5006789261328367
  - 0.520680773971602
  - 0.49729236334662524
  - 0.5085725677830941
  - 0.5239002160054792
  - 0.5411763472426085
  - 0.5010494238877025
  - 0.5343596573001287
  - 0.5137568343602043
  - 0.5419734744513549
  - 0.5019246827558829
  - 0.5050218388215031
  - 0.5081262663795677
  - 0.522377215925603
  - 0.5025
  - 0.5298834337295876
  TT_recall_micro:
  - 0.8374924379915305
  - 0.8988095238095238
  - 0.9052318295739349
  - 0.8847901002506265
  - 0.852595680181887
  - 0.9181318681318681
  - 0.9081632653061225
  - 0.8912087912087913
  - 0.8338006820765441
  - 0.9051805337519623
  - 0.9182888540031398
  - 0.8916012558869701
  - 0.8433497536945813
  - 0.9088697017268446
  - 0.9171114599686028
  - 0.8879905808477238
  TT_recall_weighted:
  - 0.8374924379915305
  - 0.8988095238095238
  - 0.9052318295739349
  - 0.8847901002506265
  - 0.852595680181887
  - 0.9181318681318681
  - 0.9081632653061225
  - 0.8912087912087913
  - 0.8338006820765441
  - 0.9051805337519623
  - 0.9182888540031398
  - 0.8916012558869701
  - 0.8433497536945813
  - 0.9088697017268446
  - 0.9171114599686028
  - 0.8879905808477238
  TT_roc_auc:
  - 0.5123837050338447
  - 0.5299135336796538
  - 0.5030118094634224
  - 0.5004104409748453
  - 0.5252558874664138
  - 0.5755896414342629
  - 0.46317508269008373
  - 0.5544590935322058
  - 0.5156734583084821
  - 0.5692919358210057
  - 0.48787340351261443
  - 0.520723261070211
  - 0.513790550233699
  - 0.5613460772600558
  - 0.4998954081632653
  - 0.524632962502785
  fit_time:
  - 167.54986023902893
  - 152.9572877883911
  - 133.1890926361084
  - 188.60839343070984
  - 165.98540806770325
  - 143.06135296821594
  - 151.21118903160095
  - 163.80117917060852
  - 200.53674268722534
  - 145.82744216918945
  - 151.66917991638184
  - 148.0096743106842
  - 165.04820656776428
  - 146.2774682044983
  - 136.38927006721497
  - 162.7958743572235
  score_time:
  - 1819.8077030181885
  - 1564.0703146457672
  - 1500.133082151413
  - 1709.6405007839203
  - 1758.6336452960968
  - 1508.1895339488983
  - 1437.5918068885803
  - 1683.0134718418121
  - 1854.3784174919128
  - 1562.6031036376953
  - 1505.9212062358856
  - 1613.5235269069672
  - 1783.553599357605
  - 1509.4167935848236
  - 1444.8160693645477
  - 1634.8988208770752
start: 2023-09-25 05:42:02.068249
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
