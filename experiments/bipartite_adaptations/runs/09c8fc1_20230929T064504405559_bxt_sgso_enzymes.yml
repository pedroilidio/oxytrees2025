active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/enzymes/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X1.txt
  - force_download: false
    path: datasets/enzymes/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_X2.txt
  name: enzymes
  pairwise: true
  y:
    force_download: false
    path: datasets/enzymes/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpie_Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-29 09:07:48.454560
estimator:
  call: bipartite_adaptations.estimators.bxt_sgso
  final_params:
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        estimator__bootstrap: false
        estimator__ccp_alpha: 0.0
        estimator__criterion: squared_error
        estimator__max_depth: null
        estimator__max_features: 1.0
        estimator__max_leaf_nodes: null
        estimator__max_samples: null
        estimator__min_impurity_decrease: 0.0
        estimator__min_samples_leaf: 1
        estimator__min_samples_split: 2
        estimator__min_weight_fraction_leaf: 0.0
        estimator__n_estimators: 100
        estimator__n_jobs: 3
        estimator__oob_score: false
        estimator__random_state: 0
        estimator__verbose: 10
        estimator__warm_start: false
        under_sampler: null
  name: bxt_sgso
  params: {}
hash: 09c8fc1903af54e897a75b00562b529002ecea33cfb31f16ccf69affd683457f
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/09c8fc1_20230929T064504405559_bxt_sgso_enzymes.yml"
results:
  LL_average_precision:
  - 0.9999983350669449
  - 1.0
  - 0.9999985378593896
  - 0.9999984057742856
  - 0.9999982245894363
  - 1.0
  - 0.9999984549303174
  - 0.99999829125477
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999985588467892
  - 1.0
  - 0.9999986681264001
  - 0.9999985343169532
  LL_balanced_accuracy:
  - 0.9999939130170131
  - 1.0
  - 0.9999939275803229
  - 0.9999939301604259
  - 0.9999939148319885
  - 1.0
  - 0.9999939292392123
  - 0.9999939321492934
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999939087160182
  - 1.0
  - 0.9999939246658567
  - 0.9999939276540706
  LL_f1_macro:
  - 0.9996743758448194
  - 1.0
  - 0.9996946663110229
  - 0.9996813084961348
  - 0.9996638461383189
  - 1.0
  - 0.9996862125812909
  - 0.9996701686706162
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.999696834291438
  - 1.0
  - 0.9997084452919689
  - 0.9996943003703418
  LL_f1_micro:
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  LL_f1_weighted:
  - 0.9999879436006747
  - 1.0
  - 0.9999879794538781
  - 0.9999879796145253
  - 0.9999879437276873
  - 1.0
  - 0.999987979555547
  - 0.9999879797484962
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879433297683
  - 1.0
  - 0.9999879792881625
  - 0.9999879794582791
  LL_matthews_corrcoef:
  - 0.999348963616338
  - 1.0
  - 0.9993895189677982
  - 0.9993628199938509
  - 0.9993279181263349
  - 1.0
  - 0.9993726219665091
  - 0.9993405547778019
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9993938522925806
  - 1.0
  - 0.9994170604951864
  - 0.999388787533236
  LL_precision_macro:
  - 0.9993552546744036
  - 1.0
  - 0.9993957703927492
  - 0.9993690851735015
  - 0.9993342210386151
  - 1.0
  - 0.9993788819875776
  - 0.999346832135859
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9994001199760048
  - 1.0
  - 0.9994232987312572
  - 0.999395039322444
  LL_precision_micro:
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  LL_precision_weighted:
  - 0.9999879552985594
  - 1.0
  - 0.9999879903862061
  - 0.9999879910279399
  - 0.9999879558059014
  - 1.0
  - 0.9999879907923434
  - 0.9999879915630875
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879542163856
  - 1.0
  - 0.9999879897241967
  - 0.9999879904037869
  LL_recall_macro:
  - 0.9999939130170131
  - 1.0
  - 0.9999939275803229
  - 0.9999939301604259
  - 0.9999939148319885
  - 1.0
  - 0.9999939292392123
  - 0.9999939321492934
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999939087160182
  - 1.0
  - 0.9999939246658567
  - 0.9999939276540706
  LL_recall_micro:
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  LL_recall_weighted:
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999879397469759
  - 1.0
  - 0.9999879758555179
  - 0.9999879758555179
  LL_roc_auc:
  - 0.999999992140758
  - 1.0
  - 0.9999999926528497
  - 0.9999999923312197
  - 0.9999999918864426
  - 1.0
  - 0.9999999924493025
  - 0.9999999920629814
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 0.9999999926831423
  - 1.0
  - 0.9999999929846026
  - 0.9999999926440388
  LT_average_precision:
  - 0.2274193493127753
  - 0.4037704138735578
  - 0.2753219030506961
  - 0.2551225051656526
  - 0.2564716288739117
  - 0.43755007594516276
  - 0.30251482661111195
  - 0.2805809490837142
  - 0.240817420544214
  - 0.4184306404398423
  - 0.3247925071652054
  - 0.2809992216777627
  - 0.2818667085703167
  - 0.4547209726534337
  - 0.34821062503203176
  - 0.3148100125438032
  LT_balanced_accuracy:
  - 0.6460357860755803
  - 0.7881628652408952
  - 0.6856465099872366
  - 0.7036673832026576
  - 0.677465793085383
  - 0.7917099144479309
  - 0.7210437793292727
  - 0.7137783066037139
  - 0.6798627752176138
  - 0.7543073879367721
  - 0.7099840108633659
  - 0.7494686333469438
  - 0.6897824381296265
  - 0.7692589572998276
  - 0.7184016129173928
  - 0.7677974785279245
  LT_f1_macro:
  - 0.5433839175785415
  - 0.5842235080804073
  - 0.5435409579996805
  - 0.5594544176142572
  - 0.5593794226371339
  - 0.5997400298276245
  - 0.5572731332102
  - 0.5642350490096116
  - 0.5575575142730561
  - 0.5786212830591971
  - 0.5865621410578188
  - 0.5675960581209691
  - 0.5971133535838481
  - 0.5898865569995316
  - 0.5988170076046357
  - 0.5796298505292355
  LT_f1_micro:
  - 0.9413367756741251
  - 0.9595318209776041
  - 0.9394153189333913
  - 0.9430876659792322
  - 0.9481855995410212
  - 0.9670935996237201
  - 0.9458012229096566
  - 0.945620319114295
  - 0.9432910212277682
  - 0.9614674915879735
  - 0.9642353196570064
  - 0.9401208437353016
  - 0.9655765920826161
  - 0.962299649046637
  - 0.9652122001519592
  - 0.9410253627121097
  LT_f1_weighted:
  - 0.9600154156815306
  - 0.9731738090070934
  - 0.9605244143074863
  - 0.9616803133294269
  - 0.9641700348781013
  - 0.9775196512392484
  - 0.9644233208285902
  - 0.9632758154330987
  - 0.9610300667001569
  - 0.974153949741157
  - 0.9742931653649743
  - 0.9603051990796503
  - 0.9736587441081795
  - 0.9743043082898594
  - 0.9743604625740145
  - 0.9602747822356444
  LT_matthews_corrcoef:
  - 0.13533965044646715
  - 0.250324793218201
  - 0.15289199482605292
  - 0.18307543187029107
  - 0.1705277592003356
  - 0.2736088194478786
  - 0.18619295037449668
  - 0.19375614724644433
  - 0.17003653492658294
  - 0.2278370519054876
  - 0.22086360780564612
  - 0.21502921711298087
  - 0.22732485605714706
  - 0.25083127749033696
  - 0.24229112645238612
  - 0.24052199725041234
  LT_precision_macro:
  - 0.5313567336390618
  - 0.5543637901151413
  - 0.5314791294534663
  - 0.541141361502572
  - 0.5409652420225806
  - 0.5641577320240725
  - 0.5392092178236756
  - 0.5439023084149709
  - 0.5401867801367712
  - 0.5510304897570357
  - 0.5580767233804617
  - 0.5463360499393098
  - 0.5680734617632351
  - 0.55841619012267
  - 0.5671984391202396
  - 0.5540061387800698
  LT_precision_micro:
  - 0.9413367756741251
  - 0.9595318209776041
  - 0.9394153189333913
  - 0.9430876659792322
  - 0.9481855995410212
  - 0.9670935996237201
  - 0.9458012229096566
  - 0.945620319114295
  - 0.9432910212277682
  - 0.9614674915879735
  - 0.9642353196570064
  - 0.9401208437353016
  - 0.9655765920826161
  - 0.962299649046637
  - 0.9652122001519592
  - 0.9410253627121097
  LT_precision_weighted:
  - 0.9817184797298093
  - 0.9900975499211505
  - 0.9853702924681881
  - 0.9840324040279508
  - 0.9831040967581678
  - 0.9906335618813588
  - 0.9867391709289419
  - 0.9846192208829156
  - 0.9821540216871891
  - 0.9896012465030497
  - 0.9864600754210596
  - 0.9852379607297318
  - 0.9834059446788852
  - 0.9892051421320032
  - 0.9855966123132094
  - 0.9845734000270249
  LT_recall_macro:
  - 0.6460357860755803
  - 0.7881628652408952
  - 0.6856465099872366
  - 0.7036673832026576
  - 0.677465793085383
  - 0.7917099144479309
  - 0.7210437793292727
  - 0.7137783066037139
  - 0.6798627752176138
  - 0.7543073879367721
  - 0.7099840108633659
  - 0.7494686333469438
  - 0.6897824381296265
  - 0.7692589572998276
  - 0.7184016129173928
  - 0.7677974785279245
  LT_recall_micro:
  - 0.9413367756741251
  - 0.9595318209776041
  - 0.9394153189333913
  - 0.9430876659792322
  - 0.9481855995410212
  - 0.9670935996237201
  - 0.9458012229096566
  - 0.945620319114295
  - 0.9432910212277682
  - 0.9614674915879735
  - 0.9642353196570064
  - 0.9401208437353016
  - 0.9655765920826161
  - 0.962299649046637
  - 0.9652122001519592
  - 0.9410253627121097
  LT_recall_weighted:
  - 0.9413367756741251
  - 0.9595318209776041
  - 0.9394153189333913
  - 0.9430876659792322
  - 0.9481855995410212
  - 0.9670935996237201
  - 0.9458012229096566
  - 0.945620319114295
  - 0.9432910212277682
  - 0.9614674915879735
  - 0.9642353196570064
  - 0.9401208437353016
  - 0.9655765920826161
  - 0.962299649046637
  - 0.9652122001519592
  - 0.9410253627121097
  LT_roc_auc:
  - 0.6534919537154532
  - 0.8057831144417004
  - 0.6944286011498599
  - 0.7127264738192036
  - 0.6846229028457134
  - 0.8289240908585959
  - 0.7278608101309085
  - 0.7229651257735291
  - 0.6872143954355935
  - 0.8051419763507774
  - 0.741278309675808
  - 0.7591260522642574
  - 0.694377399172893
  - 0.7858351311905825
  - 0.7590957655816232
  - 0.7777847170635354
  TL_average_precision:
  - 0.6426426484699302
  - 0.6528112068425641
  - 0.651196042704824
  - 0.6205078694357813
  - 0.739296673204055
  - 0.7492226065813967
  - 0.7397944662404149
  - 0.7302154771356576
  - 0.7704376060614762
  - 0.7734971337209439
  - 0.7636373494950425
  - 0.7510717921342124
  - 0.7385762034044849
  - 0.7560927980975297
  - 0.7604342747956141
  - 0.7484936506491437
  TL_balanced_accuracy:
  - 0.8456577048308203
  - 0.8310078569411299
  - 0.83892558953149
  - 0.8217260401789673
  - 0.8775993553523147
  - 0.8784074765291965
  - 0.8788274367718102
  - 0.872274134045939
  - 0.8946537147856565
  - 0.8983321335446144
  - 0.8963820720749124
  - 0.8861630725878236
  - 0.8786577665288067
  - 0.8896691906807093
  - 0.8998329811390096
  - 0.8863778892313894
  TL_f1_macro:
  - 0.7030374946119012
  - 0.7654355687789727
  - 0.7139378237866479
  - 0.6818794694645629
  - 0.7383239195628576
  - 0.7903802235594308
  - 0.7540070793287681
  - 0.7408022377976041
  - 0.7499757715482007
  - 0.8015996485167038
  - 0.7828571492513232
  - 0.7296088599991168
  - 0.739701334311603
  - 0.7600442604033801
  - 0.7549289773400891
  - 0.6882432145810132
  TL_f1_micro:
  - 0.9807880169325952
  - 0.9874467931606666
  - 0.9817473486761417
  - 0.978681191833201
  - 0.9827779586815731
  - 0.9873205396436043
  - 0.9840379481999856
  - 0.9832263184474425
  - 0.9845689062556533
  - 0.9889437991486906
  - 0.9880059158790852
  - 0.982973811413318
  - 0.9876985419154094
  - 0.9869057066589713
  - 0.9866351634081235
  - 0.9788795902171561
  TL_f1_weighted:
  - 0.9846846291985982
  - 0.9886815608157373
  - 0.9850621442718361
  - 0.9832257153485743
  - 0.9859075267499492
  - 0.9887827228206495
  - 0.9866336523064311
  - 0.9861469815600831
  - 0.9873597518399029
  - 0.9902755884036983
  - 0.9897075265131913
  - 0.9863727822539781
  - 0.9899323369131009
  - 0.9890602802164347
  - 0.9890291153963986
  - 0.9841838275846958
  TL_matthews_corrcoef:
  - 0.44891060642068165
  - 0.5423184600727022
  - 0.46285005450347444
  - 0.40737159535651774
  - 0.5155133470802157
  - 0.5982727392806813
  - 0.5402703041951449
  - 0.5172368261014169
  - 0.5399076546717577
  - 0.6229531930937043
  - 0.5919460455749435
  - 0.5054039088799699
  - 0.5172649487354815
  - 0.5533910081561038
  - 0.5492530481491154
  - 0.44341537090240346
  TL_precision_macro:
  - 0.6457516567261368
  - 0.722131669965114
  - 0.6580215389239331
  - 0.6289541379763666
  - 0.6759497250530845
  - 0.7364714578642804
  - 0.6926286042548034
  - 0.6796619143048315
  - 0.6846557277000909
  - 0.7435597382844441
  - 0.7209989714201749
  - 0.665366090936272
  - 0.6766522773605683
  - 0.6964753791370177
  - 0.6886280804310451
  - 0.6272181953421565
  TL_precision_micro:
  - 0.9807880169325952
  - 0.9874467931606666
  - 0.9817473486761417
  - 0.978681191833201
  - 0.9827779586815731
  - 0.9873205396436043
  - 0.9840379481999856
  - 0.9832263184474425
  - 0.9845689062556533
  - 0.9889437991486906
  - 0.9880059158790852
  - 0.982973811413318
  - 0.9876985419154094
  - 0.9869057066589713
  - 0.9866351634081235
  - 0.9788795902171561
  TL_precision_weighted:
  - 0.9903223470466095
  - 0.9904145238451806
  - 0.989861573796955
  - 0.9895575214938604
  - 0.9907360396690555
  - 0.9910732592127974
  - 0.9906896234720789
  - 0.9906300487708511
  - 0.9917906759214843
  - 0.9924575425707942
  - 0.9924723519307703
  - 0.9916113018285577
  - 0.9933528708689779
  - 0.9924752159174168
  - 0.9928573752467198
  - 0.9919541462257135
  TL_recall_macro:
  - 0.8456577048308203
  - 0.8310078569411299
  - 0.83892558953149
  - 0.8217260401789673
  - 0.8775993553523147
  - 0.8784074765291965
  - 0.8788274367718102
  - 0.872274134045939
  - 0.8946537147856565
  - 0.8983321335446144
  - 0.8963820720749124
  - 0.8861630725878236
  - 0.8786577665288067
  - 0.8896691906807093
  - 0.8998329811390096
  - 0.8863778892313894
  TL_recall_micro:
  - 0.9807880169325952
  - 0.9874467931606666
  - 0.9817473486761417
  - 0.978681191833201
  - 0.9827779586815731
  - 0.9873205396436043
  - 0.9840379481999856
  - 0.9832263184474425
  - 0.9845689062556533
  - 0.9889437991486906
  - 0.9880059158790852
  - 0.982973811413318
  - 0.9876985419154094
  - 0.9869057066589713
  - 0.9866351634081235
  - 0.9788795902171561
  TL_recall_weighted:
  - 0.9807880169325952
  - 0.9874467931606666
  - 0.9817473486761417
  - 0.978681191833201
  - 0.9827779586815731
  - 0.9873205396436043
  - 0.9840379481999856
  - 0.9832263184474425
  - 0.9845689062556533
  - 0.9889437991486906
  - 0.9880059158790852
  - 0.982973811413318
  - 0.9876985419154094
  - 0.9869057066589713
  - 0.9866351634081235
  - 0.9788795902171561
  TL_roc_auc:
  - 0.8506370099355202
  - 0.8463962496430397
  - 0.8437244247267874
  - 0.8272970758926026
  - 0.8829696318442659
  - 0.8851408046671987
  - 0.8837761982650272
  - 0.8773907874735044
  - 0.899785743150516
  - 0.9034518069261561
  - 0.9013221270376937
  - 0.8917914559280231
  - 0.8853194822139696
  - 0.8975409396602435
  - 0.9056571076533357
  - 0.893813215797192
  TT_average_precision:
  - 0.16460031506666908
  - 0.25122890281235005
  - 0.17779684599183757
  - 0.18854683740762102
  - 0.19210396516780745
  - 0.36635446696080104
  - 0.21655384681396422
  - 0.22958108214580034
  - 0.16941218577645473
  - 0.3380504627916306
  - 0.22237934504124843
  - 0.21332269019861497
  - 0.15044648995019988
  - 0.2025466091291717
  - 0.09740547326734054
  - 0.1062400576265204
  TT_balanced_accuracy:
  - 0.6145400045168046
  - 0.681699668161762
  - 0.629437210616699
  - 0.6735606688409765
  - 0.6628535832568196
  - 0.7393015027920726
  - 0.6801179633490617
  - 0.7017911353004691
  - 0.6450135869565217
  - 0.7067376080533976
  - 0.649571949161065
  - 0.7020445850858735
  - 0.6011188481485511
  - 0.6706523763708755
  - 0.6057713941969657
  - 0.6850523606055092
  TT_f1_macro:
  - 0.5398447277847309
  - 0.5764291899261225
  - 0.5406142235721496
  - 0.5658103859146387
  - 0.5603933560870554
  - 0.6004917899619069
  - 0.5545948810077478
  - 0.5683376106399974
  - 0.5544443535895165
  - 0.587523706731054
  - 0.5860906358098077
  - 0.5693698684064984
  - 0.5749575332888507
  - 0.5595381020103833
  - 0.5460834061937772
  - 0.5496105343646234
  TT_f1_micro:
  - 0.9477194492254734
  - 0.9699337892108977
  - 0.9508303484207099
  - 0.9519700423314881
  - 0.9473429432013769
  - 0.968305655052643
  - 0.9443720829262998
  - 0.9446434386193422
  - 0.9553571428571429
  - 0.9699880603495061
  - 0.9716161945077608
  - 0.9475740801042005
  - 0.9745589500860584
  - 0.9699337892108977
  - 0.97020514490394
  - 0.9492564854010637
  TT_f1_weighted:
  - 0.9631918449656844
  - 0.9783090560199993
  - 0.9662853092466148
  - 0.9659035236328268
  - 0.9626718524885406
  - 0.9771681384535849
  - 0.9622135989855757
  - 0.9616170100278502
  - 0.9683602113228427
  - 0.9783301504611188
  - 0.9774479650352168
  - 0.9636063642692873
  - 0.9777731402139551
  - 0.9793018679809083
  - 0.9781822816434776
  - 0.9664562045589955
  TT_matthews_corrcoef:
  - 0.1147870742908468
  - 0.19287100437680577
  - 0.1220739199132797
  - 0.177258425920274
  - 0.16564567753205942
  - 0.2530526598558921
  - 0.16562034100637923
  - 0.19487760596206158
  - 0.14770670992674848
  - 0.2198115345580597
  - 0.1929945317253822
  - 0.19582075293501766
  - 0.156162683111773
  - 0.1632502401840651
  - 0.11591255313469521
  - 0.15913372036213358
  TT_precision_macro:
  - 0.5287586692523643
  - 0.5511822953581297
  - 0.5287823761266053
  - 0.5452587411790313
  - 0.5421214104355699
  - 0.56689850242581
  - 0.5380724066120919
  - 0.5470502349483242
  - 0.5376124620721331
  - 0.5584280615168593
  - 0.5622558064610609
  - 0.5474471603182776
  - 0.5602923788274418
  - 0.5390422938826173
  - 0.5317565067479014
  - 0.5342113184525621
  TT_precision_micro:
  - 0.9477194492254734
  - 0.9699337892108977
  - 0.9508303484207099
  - 0.9519700423314881
  - 0.9473429432013769
  - 0.968305655052643
  - 0.9443720829262998
  - 0.9446434386193422
  - 0.9553571428571429
  - 0.9699880603495061
  - 0.9716161945077608
  - 0.9475740801042006
  - 0.9745589500860585
  - 0.9699337892108977
  - 0.97020514490394
  - 0.9492564854010637
  TT_precision_weighted:
  - 0.9807586366247777
  - 0.9881466605348358
  - 0.9838768356282694
  - 0.9824187570565734
  - 0.9807727520768751
  - 0.9881270816226013
  - 0.9833519521641293
  - 0.9822052021996576
  - 0.9833634669791572
  - 0.9883417961812916
  - 0.984191042558984
  - 0.9829989597949718
  - 0.9812772872779273
  - 0.9900651985438417
  - 0.987014517046567
  - 0.9865880615251493
  TT_recall_macro:
  - 0.6145400045168046
  - 0.681699668161762
  - 0.629437210616699
  - 0.6735606688409765
  - 0.6628535832568196
  - 0.7393015027920726
  - 0.6801179633490617
  - 0.7017911353004691
  - 0.6450135869565217
  - 0.7067376080533976
  - 0.649571949161065
  - 0.7020445850858735
  - 0.6011188481485511
  - 0.6706523763708755
  - 0.6057713941969657
  - 0.6850523606055092
  TT_recall_micro:
  - 0.9477194492254734
  - 0.9699337892108977
  - 0.9508303484207099
  - 0.9519700423314881
  - 0.9473429432013769
  - 0.968305655052643
  - 0.9443720829262998
  - 0.9446434386193422
  - 0.9553571428571429
  - 0.9699880603495061
  - 0.9716161945077608
  - 0.9475740801042006
  - 0.9745589500860585
  - 0.9699337892108977
  - 0.97020514490394
  - 0.9492564854010637
  TT_recall_weighted:
  - 0.9477194492254734
  - 0.9699337892108977
  - 0.9508303484207099
  - 0.9519700423314881
  - 0.9473429432013769
  - 0.968305655052643
  - 0.9443720829262998
  - 0.9446434386193422
  - 0.9553571428571429
  - 0.9699880603495061
  - 0.9716161945077608
  - 0.9475740801042006
  - 0.9745589500860585
  - 0.9699337892108977
  - 0.97020514490394
  - 0.9492564854010637
  TT_roc_auc:
  - 0.6192037335495926
  - 0.697493132285551
  - 0.6335970740426298
  - 0.6793699011152987
  - 0.6671558314410004
  - 0.7731553843205957
  - 0.6848275814770108
  - 0.7104473736527439
  - 0.6488353430706522
  - 0.7843506667297563
  - 0.679950379585615
  - 0.7077948759192538
  - 0.6220337182854863
  - 0.6807753694530689
  - 0.6371753956969423
  - 0.6896601619021547
  fit_time:
  - 7365.004172801971
  - 7598.268137693405
  - 6670.13235449791
  - 7476.290902376175
  - 7578.446024656296
  - 7478.004842042923
  - 8547.734048366547
  - 5843.422662973404
  - 7476.86848449707
  - 6852.168032646179
  - 7552.826922655106
  - 7216.163695335388
  - 6202.056943178177
  - 7004.8385326862335
  - 7317.004912376404
  - 6837.293202161789
  score_time:
  - 22.172398567199707
  - 16.30869483947754
  - 31.023439168930054
  - 15.298957586288452
  - 14.28166127204895
  - 17.53167414665222
  - 16.069218397140503
  - 40.59736657142639
  - 17.8516047000885
  - 27.85626459121704
  - 16.064680814743042
  - 20.312870740890503
  - 44.25676417350769
  - 24.6545512676239
  - 18.14667272567749
  - 22.639986991882324
start: 2023-09-29 06:45:04.405559
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
