active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/lncRNA/normalized_lncrna_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  - force_download: false
    path: datasets/lncRNA/normalized_target_similarity.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
  name: lncrna
  pairwise: true
  y:
    force_download: false
    path: datasets/lncRNA/interaction_matrix.tsv
    read:
      call: data_loading.read_table_to_array
      params: {}
directory: bipartite_adaptations/runs
end: 2023-09-29 12:42:11.906284
estimator:
  call: bipartite_adaptations.estimators.bxt_sgso
  final_params:
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        estimator__bootstrap: false
        estimator__ccp_alpha: 0.0
        estimator__criterion: squared_error
        estimator__max_depth: null
        estimator__max_features: 1.0
        estimator__max_leaf_nodes: null
        estimator__max_samples: null
        estimator__min_impurity_decrease: 0.0
        estimator__min_samples_leaf: 1
        estimator__min_samples_split: 2
        estimator__min_weight_fraction_leaf: 0.0
        estimator__n_estimators: 100
        estimator__n_jobs: 3
        estimator__oob_score: false
        estimator__random_state: 0
        estimator__verbose: 10
        estimator__warm_start: false
        under_sampler: null
  name: bxt_sgso
  params: {}
hash: 308bd0a11871c1169c56aa7134570235e4020969f86e85e83f40d52c4e03f1b1
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/308bd0a_20230929T115143349985_bxt_sgso_lncrna.yml"
results:
  LL_average_precision:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_balanced_accuracy:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_f1_macro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_f1_micro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_f1_weighted:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_matthews_corrcoef:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_precision_macro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_precision_micro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_precision_weighted:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_recall_macro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_recall_micro:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_recall_weighted:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LL_roc_auc:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  LT_average_precision:
  - 0.37449731124913005
  - 0.3592503147877557
  - 0.44133353980303275
  - 0.20207824843938735
  - 0.38658252897401535
  - 0.35545180522215375
  - 0.4176012597900856
  - 0.21830992927210194
  - 0.37535987892982087
  - 0.3489631805134007
  - 0.4318388259523631
  - 0.20166999388944518
  - 0.3873482189658914
  - 0.3583321495960079
  - 0.45004273897849484
  - 0.21588270002876245
  LT_balanced_accuracy:
  - 0.6077551697147643
  - 0.6307736571286581
  - 0.6770326946586673
  - 0.569422840180831
  - 0.6251334417766272
  - 0.6251263772767421
  - 0.6711214084950494
  - 0.5687365078425661
  - 0.6154293552808756
  - 0.6230231959124637
  - 0.6881070107644361
  - 0.5695486069191249
  - 0.6097018257471756
  - 0.6293985672910858
  - 0.6866497026236913
  - 0.5760340690160599
  LT_f1_macro:
  - 0.5995071239817373
  - 0.624695456958367
  - 0.6539449010041252
  - 0.5250555107877526
  - 0.6132540237320798
  - 0.6190931290776986
  - 0.6460395650877949
  - 0.5286360796679697
  - 0.6038445139371884
  - 0.6127479471761608
  - 0.6577808787863333
  - 0.5246515898015895
  - 0.6026883947115602
  - 0.6217669843528228
  - 0.6564630839245249
  - 0.5250016075691122
  LT_f1_micro:
  - 0.7051537585421412
  - 0.7800805401887406
  - 0.7623386484434321
  - 0.6434361468530033
  - 0.7102790432801822
  - 0.7780263586072242
  - 0.7554023271563135
  - 0.65412793203226
  - 0.7059862012987013
  - 0.7693790584415584
  - 0.7624692874692874
  - 0.6475225225225225
  - 0.7145292207792208
  - 0.7798092532467532
  - 0.7612203112203113
  - 0.6409090909090909
  LT_f1_weighted:
  - 0.7142361980000527
  - 0.784839782394077
  - 0.7750055182398924
  - 0.6881403109245038
  - 0.721046468399968
  - 0.7829905199325797
  - 0.7696752860248143
  - 0.6963229016018305
  - 0.7173624904197713
  - 0.7778500623532028
  - 0.7776107975838362
  - 0.6928438898774831
  - 0.7221945906374495
  - 0.7857578541070208
  - 0.7764541949968804
  - 0.688231013768197
  LT_matthews_corrcoef:
  - 0.20258480373209972
  - 0.2504546082531727
  - 0.3179211287351496
  - 0.10603900910425473
  - 0.23223536510822684
  - 0.2392915662613122
  - 0.3041048621091517
  - 0.10598374180786521
  - 0.21356212777129852
  - 0.22855523882275072
  - 0.3305518392758307
  - 0.10546190043644793
  - 0.2079003361265978
  - 0.2451585924217663
  - 0.3279525006646932
  - 0.11423034010436918
  LT_precision_macro:
  - 0.5952172476081908
  - 0.6199161822276207
  - 0.642733301737159
  - 0.5404919743362682
  - 0.607751501199868
  - 0.614405241584572
  - 0.6351084121673496
  - 0.5408536667054836
  - 0.5987807267640541
  - 0.6061537558138504
  - 0.6452159039748193
  - 0.5399799972147566
  - 0.5985000693178189
  - 0.6161193989555906
  - 0.6440570774830878
  - 0.5429036968862069
  LT_precision_micro:
  - 0.7051537585421412
  - 0.7800805401887406
  - 0.762338648443432
  - 0.6434361468530033
  - 0.7102790432801822
  - 0.7780263586072242
  - 0.7554023271563135
  - 0.65412793203226
  - 0.7059862012987013
  - 0.7693790584415584
  - 0.7624692874692874
  - 0.6475225225225225
  - 0.7145292207792208
  - 0.7798092532467532
  - 0.7612203112203112
  - 0.6409090909090909
  LT_precision_weighted:
  - 0.7258341298477132
  - 0.7902017911907182
  - 0.7939917304407658
  - 0.768361596019009
  - 0.7358758070059062
  - 0.788577070261311
  - 0.7915145083363896
  - 0.7688886293865135
  - 0.7328598887899822
  - 0.7880437611302157
  - 0.8021221022630975
  - 0.773222112784624
  - 0.7316043821012896
  - 0.7926135418228952
  - 0.8010948515463603
  - 0.7761504934203557
  LT_recall_macro:
  - 0.6077551697147643
  - 0.6307736571286581
  - 0.6770326946586673
  - 0.569422840180831
  - 0.6251334417766272
  - 0.6251263772767421
  - 0.6711214084950494
  - 0.5687365078425661
  - 0.6154293552808756
  - 0.6230231959124637
  - 0.6881070107644361
  - 0.5695486069191249
  - 0.6097018257471756
  - 0.6293985672910858
  - 0.6866497026236913
  - 0.5760340690160599
  LT_recall_micro:
  - 0.7051537585421412
  - 0.7800805401887406
  - 0.762338648443432
  - 0.6434361468530033
  - 0.7102790432801822
  - 0.7780263586072242
  - 0.7554023271563135
  - 0.65412793203226
  - 0.7059862012987013
  - 0.7693790584415584
  - 0.7624692874692874
  - 0.6475225225225225
  - 0.7145292207792208
  - 0.7798092532467532
  - 0.7612203112203112
  - 0.6409090909090909
  LT_recall_weighted:
  - 0.7051537585421412
  - 0.7800805401887406
  - 0.762338648443432
  - 0.6434361468530034
  - 0.7102790432801822
  - 0.7780263586072242
  - 0.7554023271563135
  - 0.65412793203226
  - 0.7059862012987013
  - 0.7693790584415584
  - 0.7624692874692874
  - 0.6475225225225225
  - 0.7145292207792208
  - 0.7798092532467532
  - 0.7612203112203112
  - 0.640909090909091
  LT_roc_auc:
  - 0.6721846702933487
  - 0.7103798589310657
  - 0.7672063300740058
  - 0.5870461320573146
  - 0.6893239287767006
  - 0.7046007836771291
  - 0.7504199086096737
  - 0.593655322027514
  - 0.6822990566920645
  - 0.7143512058245725
  - 0.7558721239051976
  - 0.591990071750545
  - 0.6930507035034332
  - 0.7016578784682873
  - 0.7778893480813948
  - 0.6014903361835614
  TL_average_precision:
  - 0.7297860632334973
  - 0.7381475072797755
  - 0.7436363887738014
  - 0.7460563868890805
  - 0.7162557894714958
  - 0.7213156369125665
  - 0.7199509978274553
  - 0.7244388894935523
  - 0.7323033056670227
  - 0.734131471119689
  - 0.7318222854953883
  - 0.7389416381921537
  - 0.7461466994038178
  - 0.7541170204744675
  - 0.7539689564503506
  - 0.7588502589705663
  TL_balanced_accuracy:
  - 0.8975500648940614
  - 0.8847086353667967
  - 0.8943460260183159
  - 0.8858500120012491
  - 0.8888471962055111
  - 0.8780207677987131
  - 0.8841096620217217
  - 0.878341973107959
  - 0.8856672450860571
  - 0.8765427126168372
  - 0.885233941025735
  - 0.8781852644945898
  - 0.8929261900407646
  - 0.881218488198267
  - 0.8898024919879197
  - 0.881988273025405
  TL_f1_macro:
  - 0.8204629542933108
  - 0.8121853045391736
  - 0.820614888898701
  - 0.8178256618837507
  - 0.8224481291682395
  - 0.8140050688826459
  - 0.8192678340688726
  - 0.8189604504418049
  - 0.8254324406394973
  - 0.8197637652181871
  - 0.8261646442912851
  - 0.823114728266592
  - 0.8330320225200851
  - 0.8273716554017689
  - 0.8342648514538706
  - 0.8297092304238918
  TL_f1_micro:
  - 0.8816856083750866
  - 0.8665729764959875
  - 0.8759874098893289
  - 0.8699563407452533
  - 0.8835186769318506
  - 0.8693022119027252
  - 0.8763935424916235
  - 0.871885470606153
  - 0.8830899844147322
  - 0.8707653186777131
  - 0.8782253117971784
  - 0.8720711510938458
  - 0.888688376671315
  - 0.8768968911492084
  - 0.8844612553670006
  - 0.8772848088325496
  TL_f1_weighted:
  - 0.8914121330635345
  - 0.8768963622445748
  - 0.8856634341165288
  - 0.8794393234391121
  - 0.8920891260901336
  - 0.8785662545774497
  - 0.8852473463940298
  - 0.8803630943949662
  - 0.8909799640892382
  - 0.878971968027754
  - 0.8861688134819303
  - 0.8799232810929938
  - 0.8960620429703874
  - 0.8843088956875423
  - 0.8915495836084021
  - 0.884439916710194
  TL_matthews_corrcoef:
  - 0.6720324039280298
  - 0.6567309226646424
  - 0.6723840904106976
  - 0.6649431793671855
  - 0.6695005288769031
  - 0.65434400533599
  - 0.6639339787889537
  - 0.6614119903235237
  - 0.6725230631316593
  - 0.6619251269350614
  - 0.6748249790927321
  - 0.6677487378506008
  - 0.6869794851781339
  - 0.6747903060387529
  - 0.688404559855799
  - 0.6788124844431754
  TL_precision_macro:
  - 0.7840067150093635
  - 0.7802741251003751
  - 0.7866139983723474
  - 0.7864775288548583
  - 0.7881793687471754
  - 0.7831630652281611
  - 0.786902655527058
  - 0.7890677297512634
  - 0.793184912775693
  - 0.7908998494639872
  - 0.7955274080958281
  - 0.7947552554017141
  - 0.8002731969881238
  - 0.7986095711647753
  - 0.8039365112915586
  - 0.8015710308240737
  TL_precision_micro:
  - 0.8816856083750866
  - 0.8665729764959876
  - 0.8759874098893289
  - 0.8699563407452533
  - 0.8835186769318506
  - 0.8693022119027252
  - 0.8763935424916235
  - 0.871885470606153
  - 0.8830899844147322
  - 0.8707653186777131
  - 0.8782253117971784
  - 0.8720711510938458
  - 0.888688376671315
  - 0.8768968911492084
  - 0.8844612553670006
  - 0.8772848088325496
  TL_precision_weighted:
  - 0.9185845434622377
  - 0.9070091850121977
  - 0.9138362322873703
  - 0.9070804154126725
  - 0.9146462639379322
  - 0.903972773944852
  - 0.9092215310331879
  - 0.9034777665451631
  - 0.9115964705441837
  - 0.9013964377164058
  - 0.9080055991365944
  - 0.9016103754524302
  - 0.9156936682057323
  - 0.9044543097731751
  - 0.9109428743521845
  - 0.9040900509466412
  TL_recall_macro:
  - 0.8975500648940614
  - 0.8847086353667967
  - 0.8943460260183159
  - 0.8858500120012491
  - 0.8888471962055111
  - 0.8780207677987131
  - 0.8841096620217217
  - 0.878341973107959
  - 0.8856672450860571
  - 0.8765427126168372
  - 0.885233941025735
  - 0.8781852644945898
  - 0.8929261900407646
  - 0.881218488198267
  - 0.8898024919879197
  - 0.881988273025405
  TL_recall_micro:
  - 0.8816856083750866
  - 0.8665729764959876
  - 0.8759874098893289
  - 0.8699563407452533
  - 0.8835186769318506
  - 0.8693022119027252
  - 0.8763935424916235
  - 0.871885470606153
  - 0.8830899844147322
  - 0.8707653186777131
  - 0.8782253117971784
  - 0.8720711510938458
  - 0.888688376671315
  - 0.8768968911492084
  - 0.8844612553670006
  - 0.8772848088325496
  TL_recall_weighted:
  - 0.8816856083750866
  - 0.8665729764959876
  - 0.8759874098893289
  - 0.8699563407452533
  - 0.8835186769318506
  - 0.8693022119027252
  - 0.8763935424916235
  - 0.871885470606153
  - 0.8830899844147322
  - 0.8707653186777131
  - 0.8782253117971784
  - 0.8720711510938458
  - 0.888688376671315
  - 0.8768968911492084
  - 0.8844612553670006
  - 0.8772848088325496
  TL_roc_auc:
  - 0.9434928893026532
  - 0.9385921643171115
  - 0.9418320206491754
  - 0.9405764006941628
  - 0.9375200172888434
  - 0.9316097783952128
  - 0.9351029596916823
  - 0.9339217805050146
  - 0.9317601136361182
  - 0.9279291758603421
  - 0.9302960667717438
  - 0.9298422320361747
  - 0.9411577713412356
  - 0.9362807771278846
  - 0.939330702465232
  - 0.9375542867527502
  TT_average_precision:
  - 0.3529568187739975
  - 0.3175927520969634
  - 0.4021784857060633
  - 0.15762379549913988
  - 0.34991863913689475
  - 0.3187444507577749
  - 0.3811907314953501
  - 0.16569840559142282
  - 0.36703476863059126
  - 0.32701877182993894
  - 0.42309678953922486
  - 0.18052632083988635
  - 0.3633948423738457
  - 0.3231349783516281
  - 0.4151770260575445
  - 0.18031508731386983
  TT_balanced_accuracy:
  - 0.5949754993909401
  - 0.6164450592973018
  - 0.6596396918780861
  - 0.5234658434180216
  - 0.6035300046864723
  - 0.6051165681810843
  - 0.6430565835298798
  - 0.5209458392905576
  - 0.5980867970279793
  - 0.604334698703602
  - 0.670829248388742
  - 0.5377463147486594
  - 0.5855547223244353
  - 0.5948449421068903
  - 0.6573442998544345
  - 0.532150272234206
  TT_f1_macro:
  - 0.5830042278656973
  - 0.6071607825916265
  - 0.6318311908397155
  - 0.48755029346869916
  - 0.5895437959213181
  - 0.600248636248863
  - 0.620968205207228
  - 0.49709535704867075
  - 0.5859063727121724
  - 0.5939635172236528
  - 0.6471599898818248
  - 0.5029374098936396
  - 0.580840738282785
  - 0.5920795699050125
  - 0.6342929922109976
  - 0.4992992676286651
  TT_f1_micro:
  - 0.6899295432458697
  - 0.772837706511176
  - 0.7482380339523197
  - 0.6156156156156156
  - 0.6943634596695821
  - 0.7708333333333333
  - 0.7402095973524545
  - 0.6442360728075014
  - 0.6828522504892368
  - 0.7488380626223092
  - 0.7536714796988769
  - 0.6228557324447735
  - 0.6907411937377691
  - 0.7621697651663404
  - 0.7442922374429224
  - 0.6212513883746761
  TT_f1_weighted:
  - 0.7038194456756078
  - 0.7808643289008436
  - 0.7651122684307681
  - 0.6682735891942301
  - 0.7090281337805171
  - 0.7757343720501255
  - 0.7557271342891858
  - 0.6876314141988717
  - 0.6966001365946294
  - 0.7592816278680251
  - 0.7673083955110332
  - 0.6691960289482017
  - 0.6977371262300067
  - 0.765439801120318
  - 0.7589456022442949
  - 0.6677877565313184
  TT_matthews_corrcoef:
  - 0.17353940465374337
  - 0.21694814174030838
  - 0.2786248482129538
  - 0.034804786588347215
  - 0.18793503593262287
  - 0.20141992898405792
  - 0.25350986102029366
  - 0.03234334596183551
  - 0.179745933930982
  - 0.1919358463309087
  - 0.3054647042143604
  - 0.05797883082561741
  - 0.16352467052210978
  - 0.18454206473458842
  - 0.2802197307990121
  - 0.049392072636039556
  TT_precision_macro:
  - 0.5792728786916189
  - 0.6010487187876411
  - 0.6215734713722973
  - 0.51290570668909
  - 0.5852882645904373
  - 0.5964880905407153
  - 0.6123108913423501
  - 0.5124856781040825
  - 0.5823469665226833
  - 0.5882720934753856
  - 0.6365525611112446
  - 0.52226405972536
  - 0.5781380534670009
  - 0.5897669735991935
  - 0.6247631747729592
  - 0.518970110280188
  TT_precision_micro:
  - 0.6899295432458697
  - 0.7728377065111759
  - 0.7482380339523197
  - 0.6156156156156156
  - 0.6943634596695821
  - 0.7708333333333334
  - 0.7402095973524545
  - 0.6442360728075014
  - 0.6828522504892368
  - 0.7488380626223092
  - 0.7536714796988769
  - 0.6228557324447735
  - 0.6907411937377691
  - 0.7621697651663405
  - 0.7442922374429224
  - 0.6212513883746761
  TT_precision_weighted:
  - 0.7229709459787769
  - 0.7903306681075571
  - 0.7911861201808549
  - 0.7590630586885145
  - 0.7298479557769395
  - 0.7811478422406508
  - 0.7784779955079713
  - 0.7544550274637761
  - 0.7160678406543246
  - 0.7720585818385026
  - 0.7880649797477953
  - 0.7495633431265574
  - 0.7060517737796872
  - 0.7689287004093167
  - 0.7810322193227865
  - 0.7474796377658517
  TT_recall_macro:
  - 0.5949754993909401
  - 0.6164450592973018
  - 0.6596396918780861
  - 0.5234658434180216
  - 0.6035300046864723
  - 0.6051165681810843
  - 0.6430565835298798
  - 0.5209458392905576
  - 0.5980867970279793
  - 0.604334698703602
  - 0.670829248388742
  - 0.5377463147486594
  - 0.5855547223244353
  - 0.5948449421068903
  - 0.6573442998544345
  - 0.532150272234206
  TT_recall_micro:
  - 0.6899295432458697
  - 0.7728377065111759
  - 0.7482380339523197
  - 0.6156156156156156
  - 0.6943634596695821
  - 0.7708333333333334
  - 0.7402095973524545
  - 0.6442360728075014
  - 0.6828522504892368
  - 0.7488380626223092
  - 0.7536714796988769
  - 0.6228557324447735
  - 0.6907411937377691
  - 0.7621697651663405
  - 0.7442922374429224
  - 0.6212513883746761
  TT_recall_weighted:
  - 0.6899295432458697
  - 0.7728377065111759
  - 0.7482380339523197
  - 0.6156156156156156
  - 0.6943634596695821
  - 0.7708333333333334
  - 0.7402095973524545
  - 0.6442360728075014
  - 0.6828522504892368
  - 0.7488380626223092
  - 0.7536714796988769
  - 0.6228557324447735
  - 0.6907411937377691
  - 0.7621697651663405
  - 0.7442922374429224
  - 0.6212513883746761
  TT_roc_auc:
  - 0.6481871001632145
  - 0.6907517012680042
  - 0.7392787238013725
  - 0.545213878775339
  - 0.6623546188696546
  - 0.6854867367367368
  - 0.726265078154373
  - 0.5373530051603257
  - 0.6583734943351934
  - 0.6872761535187998
  - 0.7325203381709711
  - 0.5571548341628021
  - 0.6621439295490149
  - 0.6688493676008922
  - 0.7435473675378803
  - 0.5588673025894982
  fit_time:
  - 2524.561466217041
  - 2415.962955236435
  - 2683.4404220581055
  - 2000.5082952976227
  - 2681.9728922843933
  - 2933.2266054153442
  - 2562.090009212494
  - 2639.9001653194427
  - 3015.6365027427673
  - 2574.069841861725
  - 2622.075729370117
  - 2707.060348510742
  - 2811.13423204422
  - 2956.0890171527863
  - 2539.682646751404
  - 2041.272430896759
  score_time:
  - 15.316967964172363
  - 22.476884365081787
  - 12.18599534034729
  - 29.20279335975647
  - 13.915247440338135
  - 11.496442794799805
  - 14.350744485855103
  - 13.383216381072998
  - 11.803639888763428
  - 16.61621904373169
  - 14.951386451721191
  - 10.806931257247925
  - 11.580025911331177
  - 11.848555088043213
  - 14.307618141174316
  - 30.777926206588745
start: 2023-09-29 11:51:43.349985
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
