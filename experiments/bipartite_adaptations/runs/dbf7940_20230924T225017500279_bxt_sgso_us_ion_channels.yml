active: true
cv:
  call: bipartite_learn.model_selection.multipartite_cross_validate
  params:
    cv: 4
    diagonal: false
    n_jobs: 16
    pairwise: true
    random_state: 0
    return_estimator: false
    return_train_score: false
    scoring:
    - roc_auc
    - average_precision
    - matthews_corrcoef
    - balanced_accuracy
    - f1_macro
    - f1_micro
    - f1_weighted
    - precision_macro
    - precision_micro
    - precision_weighted
    - recall_macro
    - recall_micro
    - recall_weighted
    shuffle: true
    verbose: 10
dataset:
  X:
  - force_download: false
    path: datasets/ion_channels/X1.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X1.txt
  - force_download: false
    path: datasets/ion_channels/X2.txt
    read:
      call: data_loading.numpy_load_and_symmetrize
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_X2.txt
  name: ion_channels
  pairwise: true
  y:
    force_download: false
    path: datasets/ion_channels/Y.txt
    read:
      call: numpy.loadtxt
      params: {}
    url: https://people.montefiore.uliege.be/schrynemackers/dpix/dpii_Y.txt
directory: bipartite_adaptations/runs
end: 2023-09-24 22:50:21.725227
estimator:
  call: bipartite_adaptations.estimators.bxt_sgso_us
  final_params:
    estimator:
      call: bipartite_learn.wrappers.GlobalSingleOutputWrapper
      params:
        estimator:
          call: sklearn.ensemble._forest.ExtraTreesRegressor
          params:
            bootstrap: false
            ccp_alpha: 0.0
            criterion: squared_error
            max_depth: null
            max_features: 1.0
            max_leaf_nodes: null
            max_samples: null
            min_impurity_decrease: 0.0
            min_samples_leaf: 1
            min_samples_split: 2
            min_weight_fraction_leaf: 0.0
            n_estimators: 100
            n_jobs: 3
            oob_score: false
            random_state: 0
            verbose: 10
            warm_start: false
        estimator__bootstrap: false
        estimator__ccp_alpha: 0.0
        estimator__criterion: squared_error
        estimator__max_depth: null
        estimator__max_features: 1.0
        estimator__max_leaf_nodes: null
        estimator__max_samples: null
        estimator__min_impurity_decrease: 0.0
        estimator__min_samples_leaf: 1
        estimator__min_samples_split: 2
        estimator__min_weight_fraction_leaf: 0.0
        estimator__n_estimators: 100
        estimator__n_jobs: 3
        estimator__oob_score: false
        estimator__random_state: 0
        estimator__verbose: 10
        estimator__warm_start: false
        under_sampler:
          call: imblearn.under_sampling._prototype_selection._random_under_sampler.RandomUnderSampler
          params:
            random_state: null
            replacement: false
            sampling_strategy: auto
        under_sampler__random_state: null
        under_sampler__replacement: false
        under_sampler__sampling_strategy: auto
  name: bxt_sgso_us
  params: {}
hash: dbf7940d259230cf320c1a5509a728ee7a835f224416aeddf18654795f4f2b5e
path: "/home/pedro/mestrado/disserta\xE7\xE3o/experiments/bipartite_adaptations/runs/dbf7940_20230924T225017500279_bxt_sgso_us_ion_channels.yml"
results:
  LL_average_precision:
  - 0.9364406779661016
  - 0.9610678531701891
  - 0.9728132387706856
  - 0.9399293286219081
  - 0.9577777777777777
  - 0.9332591768631813
  - 0.9647058823529412
  - 0.9826732673267327
  - 0.9759174311926605
  - 0.9703872437357631
  - 0.956221198156682
  - 0.9499404052443385
  - 0.9502212389380531
  - 0.9672131147540983
  - 0.9532163742690059
  - 0.9783989834815756
  LL_balanced_accuracy:
  - 0.6761896529368544
  - 0.6778727814483742
  - 0.695130829514796
  - 0.6713081793292266
  - 0.6380672740619198
  - 0.6797083944439651
  - 0.6887257000942023
  - 0.613130881094953
  - 0.6382822615451014
  - 0.6780827830290475
  - 0.6774760109664153
  - 0.648907045386491
  - 0.6420861756325015
  - 0.663073938348782
  - 0.6782824607217774
  - 0.6282259442830286
  LL_f1_macro:
  - 0.31333229855469813
  - 0.3142997145614147
  - 0.3325240866538689
  - 0.3022291636227706
  - 0.263008406792609
  - 0.31515277234150485
  - 0.3247045576798229
  - 0.22486305769842493
  - 0.26273719632477793
  - 0.3138873592156879
  - 0.31161357448398175
  - 0.273729264772011
  - 0.2682333483713626
  - 0.2937316749358797
  - 0.31176354662036493
  - 0.24475841167307816
  LL_f1_micro:
  - 0.3762124807460139
  - 0.3789184463594355
  - 0.41102010424422936
  - 0.36431703483081
  - 0.30211065317846886
  - 0.3817909329336831
  - 0.39856871018449574
  - 0.2516753536857781
  - 0.3021939136588818
  - 0.37900170683984846
  - 0.3770993629519318
  - 0.3209646727889468
  - 0.3097706173764623
  - 0.34931934557262395
  - 0.37825763216679076
  - 0.28013568296516916
  LL_f1_weighted:
  - 0.5058309495800593
  - 0.5096543915309399
  - 0.5458363042986987
  - 0.4966293794229527
  - 0.4205834633018294
  - 0.5138577532718447
  - 0.5328915261026242
  - 0.3595566780654976
  - 0.42121019869653703
  - 0.5102599127195244
  - 0.5093532528057937
  - 0.44673421416737363
  - 0.43010748966451956
  - 0.4782457874857139
  - 0.5112635019781804
  - 0.3978029755922655
  LL_matthews_corrcoef:
  - 0.14011035533038435
  - 0.13955064205587278
  - 0.1460329829917303
  - 0.13005218068357557
  - 0.11620829333213079
  - 0.1386380779579961
  - 0.14195672661380448
  - 0.09753687520046601
  - 0.11559694245803873
  - 0.13872147108327423
  - 0.1361724520401538
  - 0.11743190686844508
  - 0.11831142995103296
  - 0.12794848917387897
  - 0.13542598103043596
  - 0.10424301150539678
  LL_precision_macro:
  - 0.5278548021174692
  - 0.5273712222011024
  - 0.5273222229599628
  - 0.5246829570058769
  - 0.5244525133325769
  - 0.5267384791892409
  - 0.5266944462530113
  - 0.5210230883287439
  - 0.5241582921705559
  - 0.5270150294882364
  - 0.5261203423967774
  - 0.5231524517778294
  - 0.5246287057744137
  - 0.5250972289742343
  - 0.5257178920795204
  - 0.521186440677966
  LL_precision_micro:
  - 0.3762124807460139
  - 0.3789184463594355
  - 0.41102010424422936
  - 0.36431703483080996
  - 0.30211065317846886
  - 0.38179093293368305
  - 0.39856871018449574
  - 0.2516753536857781
  - 0.3021939136588818
  - 0.37900170683984846
  - 0.3770993629519318
  - 0.3209646727889468
  - 0.3097706173764623
  - 0.34931934557262395
  - 0.37825763216679076
  - 0.28013568296516916
  LL_precision_weighted:
  - 0.9652490441756665
  - 0.9660004775805964
  - 0.9678155199384503
  - 0.9686189294027211
  - 0.9658697028843662
  - 0.9669400594512945
  - 0.9678902495182815
  - 0.9685358097239202
  - 0.9662843933755583
  - 0.9664474255962681
  - 0.9674592441622674
  - 0.968557334662607
  - 0.9660010872370194
  - 0.967339437253463
  - 0.9680201937656001
  - 0.9694972747019139
  LL_recall_macro:
  - 0.6761896529368544
  - 0.6778727814483742
  - 0.695130829514796
  - 0.6713081793292266
  - 0.6380672740619198
  - 0.6797083944439651
  - 0.6887257000942023
  - 0.613130881094953
  - 0.6382822615451014
  - 0.6780827830290475
  - 0.6774760109664153
  - 0.648907045386491
  - 0.6420861756325015
  - 0.663073938348782
  - 0.6782824607217774
  - 0.6282259442830286
  LL_recall_micro:
  - 0.3762124807460139
  - 0.3789184463594355
  - 0.41102010424422936
  - 0.36431703483080996
  - 0.30211065317846886
  - 0.38179093293368305
  - 0.39856871018449574
  - 0.2516753536857781
  - 0.3021939136588818
  - 0.37900170683984846
  - 0.3770993629519318
  - 0.3209646727889468
  - 0.3097706173764623
  - 0.34931934557262395
  - 0.37825763216679076
  - 0.28013568296516916
  LL_recall_weighted:
  - 0.3762124807460139
  - 0.3789184463594355
  - 0.41102010424422936
  - 0.36431703483080996
  - 0.30211065317846886
  - 0.38179093293368305
  - 0.39856871018449574
  - 0.2516753536857781
  - 0.3021939136588818
  - 0.37900170683984846
  - 0.3770993629519318
  - 0.3209646727889468
  - 0.3097706173764623
  - 0.34931934557262395
  - 0.37825763216679076
  - 0.2801356829651692
  LL_roc_auc:
  - 0.9987033755456628
  - 0.9992442889838926
  - 0.999507515738084
  - 0.9989091375770021
  - 0.9991795846107345
  - 0.9987058925028038
  - 0.9993577117410295
  - 0.9997005988023951
  - 0.9995468277945619
  - 0.9994389054339851
  - 0.999186086360521
  - 0.9991016811395816
  - 0.9990285812969518
  - 0.9993964216425955
  - 0.9991437989639967
  - 0.9996368142197916
  LT_average_precision:
  - 0.4822577423535085
  - 0.11784128276972072
  - 0.1589631823471317
  - 0.20069720321931372
  - 0.39422097544013707
  - 0.11317165296914096
  - 0.15714975781300633
  - 0.2372396987943324
  - 0.42531410147132775
  - 0.13719166784497233
  - 0.10247492071272124
  - 0.20918453496918193
  - 0.43571827081358727
  - 0.09453871330991016
  - 0.1850623232127933
  - 0.22310804719236535
  LT_balanced_accuracy:
  - 0.6106189491368631
  - 0.5997985883973145
  - 0.6117737722048067
  - 0.5596330756126326
  - 0.563296324547278
  - 0.6011226906997188
  - 0.5756162992541972
  - 0.5539246591618842
  - 0.5486624203821656
  - 0.5622472918573549
  - 0.5674616615796918
  - 0.5419962888633714
  - 0.5694338664635694
  - 0.5556014253432991
  - 0.60332485116758
  - 0.5448279531168151
  LT_f1_macro:
  - 0.22293691418687284
  - 0.22290640953307506
  - 0.2307782258435934
  - 0.1651298158991208
  - 0.16443665086388914
  - 0.2424308023593822
  - 0.23309336126678576
  - 0.15456566489131385
  - 0.12275384614820911
  - 0.18373659232532008
  - 0.24949506258149
  - 0.17924077901872132
  - 0.15381456634675006
  - 0.20837853826171482
  - 0.22256633631713554
  - 0.1717023497170416
  LT_f1_micro:
  - 0.2520656061166605
  - 0.2504624491305956
  - 0.2559074912016088
  - 0.17219708396178984
  - 0.17597730916265877
  - 0.2775927981255395
  - 0.2630718954248366
  - 0.16050779286073405
  - 0.12615612282648908
  - 0.19953138488099642
  - 0.28821015585721466
  - 0.19067370537958775
  - 0.16339869281045752
  - 0.23221112344308792
  - 0.2476118652589241
  - 0.1808697838109603
  LT_f1_weighted:
  - 0.36451719961121015
  - 0.3598925893528386
  - 0.3593254274941927
  - 0.23566733019674385
  - 0.2567498074342153
  - 0.39493363116314517
  - 0.37385715865481084
  - 0.2199023463421798
  - 0.17389579122706703
  - 0.29005739008706705
  - 0.40795484668069304
  - 0.2684882233479552
  - 0.2387390334011774
  - 0.3367899300598595
  - 0.3524593246524898
  - 0.2518325143898122
  LT_matthews_corrcoef:
  - 0.08987859660585944
  - 0.08469090745980434
  - 0.10305789047283087
  - 0.06955350908587224
  - 0.060868097503347283
  - 0.0833904220358801
  - 0.06643199134108763
  - 0.06365777192282915
  - 0.05858222100458516
  - 0.058044306704177345
  - 0.05651845075127523
  - 0.044841056995285004
  - 0.06762274951353546
  - 0.048792227668601196
  - 0.09203615677307282
  - 0.04996865430136974
  LT_precision_macro:
  - 0.5182567322119561
  - 0.5179675632730647
  - 0.5237554136789107
  - 0.5202810712698411
  - 0.5146332560388623
  - 0.5171918944185628
  - 0.5145908009155096
  - 0.5187869148788392
  - 0.5176310415248468
  - 0.5135312775875025
  - 0.5118375948669411
  - 0.5119696314059795
  - 0.516464718460442
  - 0.5107042286513592
  - 0.5204952004717125
  - 0.513924717944311
  LT_precision_micro:
  - 0.2520656061166605
  - 0.2504624491305956
  - 0.2559074912016088
  - 0.17219708396178984
  - 0.17597730916265877
  - 0.2775927981255395
  - 0.2630718954248366
  - 0.16050779286073405
  - 0.12615612282648908
  - 0.19953138488099642
  - 0.28821015585721466
  - 0.19067370537958772
  - 0.16339869281045752
  - 0.23221112344308792
  - 0.2476118652589241
  - 0.18086978381096028
  LT_precision_weighted:
  - 0.9705623397009787
  - 0.965538936747934
  - 0.9635521363894086
  - 0.9555945959655999
  - 0.966194264091565
  - 0.9618263182765686
  - 0.9527319886405357
  - 0.9567234283589697
  - 0.9691864446306413
  - 0.9602618725510589
  - 0.9491587315448727
  - 0.943939392552981
  - 0.972451190026973
  - 0.953594144863632
  - 0.9646653060949897
  - 0.9457981490183264
  LT_recall_macro:
  - 0.6106189491368631
  - 0.5997985883973145
  - 0.6117737722048067
  - 0.5596330756126326
  - 0.563296324547278
  - 0.6011226906997188
  - 0.5756162992541972
  - 0.5539246591618842
  - 0.5486624203821656
  - 0.5622472918573549
  - 0.5674616615796918
  - 0.5419962888633714
  - 0.5694338664635694
  - 0.5556014253432991
  - 0.60332485116758
  - 0.5448279531168151
  LT_recall_micro:
  - 0.2520656061166605
  - 0.2504624491305956
  - 0.2559074912016088
  - 0.17219708396178984
  - 0.17597730916265877
  - 0.2775927981255395
  - 0.2630718954248366
  - 0.16050779286073405
  - 0.12615612282648908
  - 0.19953138488099642
  - 0.28821015585721466
  - 0.19067370537958772
  - 0.16339869281045752
  - 0.23221112344308792
  - 0.2476118652589241
  - 0.18086978381096028
  LT_recall_weighted:
  - 0.2520656061166605
  - 0.2504624491305956
  - 0.2559074912016088
  - 0.17219708396178984
  - 0.17597730916265877
  - 0.2775927981255395
  - 0.2630718954248366
  - 0.16050779286073405
  - 0.12615612282648908
  - 0.19953138488099642
  - 0.28821015585721466
  - 0.19067370537958772
  - 0.16339869281045752
  - 0.23221112344308792
  - 0.2476118652589241
  - 0.18086978381096028
  LT_roc_auc:
  - 0.8772450330421654
  - 0.7552617858987285
  - 0.7198071229536747
  - 0.721590476094473
  - 0.8613386884638685
  - 0.7474022618704098
  - 0.669506709022589
  - 0.7652106435284395
  - 0.8721424882571379
  - 0.7419281501689904
  - 0.6345164427157002
  - 0.7297104953936843
  - 0.8731208285663732
  - 0.7119092454178496
  - 0.6965889858091394
  - 0.7345503617731796
  TL_average_precision:
  - 0.5509062745974351
  - 0.5720824068080748
  - 0.549413690127172
  - 0.5805928289790108
  - 0.5729044826536711
  - 0.521238011284786
  - 0.5064755842957966
  - 0.6601911209902057
  - 0.6002204754577881
  - 0.5688426558680848
  - 0.5263742959244551
  - 0.49488687332610626
  - 0.6381785522230362
  - 0.6430672571885199
  - 0.6308414646051852
  - 0.6782828805249888
  TL_balanced_accuracy:
  - 0.6361605205655403
  - 0.6464285854570594
  - 0.6409677669793277
  - 0.6288478790208893
  - 0.6012665722341628
  - 0.6684533834261779
  - 0.6517367280122468
  - 0.5757999862372218
  - 0.5857365749431129
  - 0.6286572920095941
  - 0.6216564897870961
  - 0.5903123798385029
  - 0.6106016187933645
  - 0.6055407918755115
  - 0.6313451884080121
  - 0.5866576528467385
  TL_f1_macro:
  - 0.2667091922058809
  - 0.2861777901855006
  - 0.2820922315278128
  - 0.2743238677717254
  - 0.2232887013899683
  - 0.31819672022020523
  - 0.29393077893468195
  - 0.18508264082925668
  - 0.23748807344666584
  - 0.2943959120280745
  - 0.2700179047301799
  - 0.21725790321640287
  - 0.2369225223149824
  - 0.22834728657938486
  - 0.26598215214889087
  - 0.19074495759626145
  TL_f1_micro:
  - 0.310603222180592
  - 0.34095166729112025
  - 0.33358153387937456
  - 0.3252668155869943
  - 0.24740851754714624
  - 0.38653678031722244
  - 0.35095557210225864
  - 0.20054604120129063
  - 0.2671412514050206
  - 0.3539403022355439
  - 0.3174484983866965
  - 0.24323653512037727
  - 0.26551767203696763
  - 0.25302859997502186
  - 0.308265078183172
  - 0.20563415239513527
  TL_f1_weighted:
  - 0.43410699615742054
  - 0.4709223233807849
  - 0.4613265407330639
  - 0.4544256804694534
  - 0.35024679820028753
  - 0.5185261034868462
  - 0.48084261191102723
  - 0.2901223154284784
  - 0.3765519004141244
  - 0.4852912335143597
  - 0.44380692510941244
  - 0.3507965655783857
  - 0.3738287197903711
  - 0.3559765642991418
  - 0.4298667506767974
  - 0.2928033724481945
  TL_matthews_corrcoef:
  - 0.10931178632480018
  - 0.11287495407385845
  - 0.11112953853088264
  - 0.09876300422379652
  - 0.09251032667422641
  - 0.1313102302366204
  - 0.11847515198733115
  - 0.0712010080948228
  - 0.07694687930422381
  - 0.1000618376656028
  - 0.09600775244488072
  - 0.07724894868811091
  - 0.098666818336281
  - 0.09749370066260797
  - 0.10794401420014715
  - 0.08478477686017157
  TL_precision_macro:
  - 0.5219393010908898
  - 0.5217525068916818
  - 0.5219017698136234
  - 0.5189256724236188
  - 0.5211278024736107
  - 0.5255892404980255
  - 0.5231261768694662
  - 0.5167202654161882
  - 0.5172645753535972
  - 0.5194555069530586
  - 0.51894162930734
  - 0.5165187765068568
  - 0.5220049696080685
  - 0.5225150425252202
  - 0.5221780301640094
  - 0.5207380945337352
  TL_precision_micro:
  - 0.310603222180592
  - 0.34095166729112025
  - 0.33358153387937456
  - 0.3252668155869943
  - 0.24740851754714624
  - 0.38653678031722244
  - 0.35095557210225864
  - 0.20054604120129063
  - 0.2671412514050206
  - 0.3539403022355439
  - 0.3174484983866965
  - 0.24323653512037727
  - 0.26551767203696763
  - 0.25302859997502186
  - 0.308265078183172
  - 0.20563415239513527
  TL_precision_weighted:
  - 0.966322032737058
  - 0.9659466221796298
  - 0.9645368174788541
  - 0.9648491170248518
  - 0.962585593819724
  - 0.9632422822614933
  - 0.9647914398163766
  - 0.9648318538711369
  - 0.9533755275172912
  - 0.9594722205282843
  - 0.962603801135533
  - 0.9638480158783048
  - 0.9625030569200658
  - 0.9619660680888005
  - 0.964154735800271
  - 0.9656605850166584
  TL_recall_macro:
  - 0.6361605205655403
  - 0.6464285854570594
  - 0.6409677669793277
  - 0.6288478790208893
  - 0.6012665722341628
  - 0.6684533834261779
  - 0.6517367280122468
  - 0.5757999862372218
  - 0.5857365749431129
  - 0.6286572920095941
  - 0.6216564897870961
  - 0.5903123798385029
  - 0.6106016187933645
  - 0.6055407918755115
  - 0.6313451884080121
  - 0.5866576528467385
  TL_recall_micro:
  - 0.310603222180592
  - 0.34095166729112025
  - 0.33358153387937456
  - 0.3252668155869943
  - 0.24740851754714624
  - 0.38653678031722244
  - 0.35095557210225864
  - 0.20054604120129063
  - 0.2671412514050206
  - 0.3539403022355439
  - 0.3174484983866965
  - 0.24323653512037727
  - 0.26551767203696763
  - 0.25302859997502186
  - 0.308265078183172
  - 0.20563415239513527
  TL_recall_weighted:
  - 0.310603222180592
  - 0.34095166729112025
  - 0.33358153387937456
  - 0.3252668155869943
  - 0.24740851754714624
  - 0.38653678031722244
  - 0.35095557210225864
  - 0.20054604120129063
  - 0.2671412514050206
  - 0.3539403022355439
  - 0.3174484983866965
  - 0.24323653512037727
  - 0.26551767203696763
  - 0.25302859997502186
  - 0.308265078183172
  - 0.20563415239513527
  TL_roc_auc:
  - 0.9400550227284562
  - 0.9262051032272257
  - 0.9244840152354604
  - 0.9114370289958864
  - 0.9407613285491504
  - 0.9364082674785164
  - 0.9334927033399261
  - 0.9447563072386769
  - 0.8891802823532253
  - 0.8955043973098811
  - 0.9026763520711429
  - 0.8811710438829788
  - 0.9342629552579813
  - 0.9366013711540302
  - 0.9437548991299739
  - 0.9556651858248213
  TT_average_precision:
  - 0.27131011952346396
  - 0.07807772716567292
  - 0.08602795031077509
  - 0.167851333509385
  - 0.3671065275325691
  - 0.08571223308568764
  - 0.18414470422320764
  - 0.3072939977086177
  - 0.27861097636480064
  - 0.07996281667917127
  - 0.08363708654387925
  - 0.19190403988677363
  - 0.3617711343026012
  - 0.08428615090330731
  - 0.11565871888514663
  - 0.12573560872386844
  TT_balanced_accuracy:
  - 0.5538961038961039
  - 0.5747863247863247
  - 0.5830093312597201
  - 0.5563821456538762
  - 0.5444811707206826
  - 0.6030856249425182
  - 0.569499619208365
  - 0.544488188976378
  - 0.5088441126727707
  - 0.5501110681049426
  - 0.5373667711598746
  - 0.5468135326514556
  - 0.546347793845013
  - 0.5136745607333842
  - 0.5834314880251276
  - 0.5264828773514837
  TT_f1_macro:
  - 0.1852090616315884
  - 0.20768715696665319
  - 0.1770879519492759
  - 0.14114212311440727
  - 0.13378848449377867
  - 0.24749714995025143
  - 0.20051493473691073
  - 0.12583567090420833
  - 0.09718236674603822
  - 0.1783105859244074
  - 0.2152488540484423
  - 0.12919312727314186
  - 0.1301531027799066
  - 0.13929169021297638
  - 0.18802707488301335
  - 0.12329378739105834
  TT_f1_micro:
  - 0.20199778024417314
  - 0.2297447280799112
  - 0.1911764705882353
  - 0.1455505279034691
  - 0.13947465778764337
  - 0.2870884202737699
  - 0.2187028657616893
  - 0.12745098039215685
  - 0.09988901220865705
  - 0.19200887902330743
  - 0.23906485671191555
  - 0.13122171945701358
  - 0.13392526822049575
  - 0.1461339252682205
  - 0.19984917043740577
  - 0.1255656108597285
  TT_f1_weighted:
  - 0.29481170144003466
  - 0.33108239403705225
  - 0.27826544027286876
  - 0.19812655554564862
  - 0.1997636732595786
  - 0.4095020738385841
  - 0.31246165019442285
  - 0.16023892912121782
  - 0.14423776387656675
  - 0.2772601472491265
  - 0.34164893744852104
  - 0.16773637876670433
  - 0.18349321746509142
  - 0.21120613583510653
  - 0.2782444415824704
  - 0.16445586297896359
  TT_matthews_corrcoef:
  - 0.049510652425527275
  - 0.06706820284350964
  - 0.07726066488050451
  - 0.06837149861164812
  - 0.04828670213409439
  - 0.08108212745197169
  - 0.06629975375393501
  - 0.06409157945287094
  - 0.010057472670373732
  - 0.04896686753724519
  - 0.03483490273079974
  - 0.06531732872191817
  - 0.05625412312829401
  - 0.01465596007218227
  - 0.08869814424592161
  - 0.03580482732059395
  TT_precision_macro:
  - 0.5113705097697172
  - 0.5150366522406001
  - 0.5179775280898876
  - 0.5207275803722504
  - 0.513104452767374
  - 0.5159438122332859
  - 0.5158118037116647
  - 0.5230832646331409
  - 0.5028593246224333
  - 0.5119621982083317
  - 0.5081186466651909
  - 0.5227837613918807
  - 0.517069455234026
  - 0.5039269481818346
  - 0.5235743152222722
  - 0.5121020239081547
  TT_precision_micro:
  - 0.20199778024417314
  - 0.2297447280799112
  - 0.19117647058823528
  - 0.1455505279034691
  - 0.13947465778764337
  - 0.2870884202737699
  - 0.2187028657616893
  - 0.12745098039215685
  - 0.09988901220865705
  - 0.19200887902330743
  - 0.23906485671191555
  - 0.13122171945701358
  - 0.13392526822049575
  - 0.1461339252682205
  - 0.19984917043740574
  - 0.1255656108597285
  TT_precision_weighted:
  - 0.9573813941682391
  - 0.9590783084142078
  - 0.9709187045604758
  - 0.9645786597861845
  - 0.9645515802250517
  - 0.9635969574925707
  - 0.9559334675100035
  - 0.9597174401500089
  - 0.9582140079077414
  - 0.9544209572129647
  - 0.93987250331796
  - 0.9604119259073205
  - 0.9633322588957827
  - 0.9458039482014273
  - 0.9622739842370578
  - 0.9466002161491707
  TT_recall_macro:
  - 0.5538961038961039
  - 0.5747863247863247
  - 0.5830093312597201
  - 0.5563821456538762
  - 0.5444811707206826
  - 0.6030856249425182
  - 0.569499619208365
  - 0.544488188976378
  - 0.5088441126727707
  - 0.5501110681049426
  - 0.5373667711598746
  - 0.5468135326514556
  - 0.546347793845013
  - 0.5136745607333842
  - 0.5834314880251276
  - 0.5264828773514837
  TT_recall_micro:
  - 0.20199778024417314
  - 0.2297447280799112
  - 0.19117647058823528
  - 0.1455505279034691
  - 0.13947465778764337
  - 0.2870884202737699
  - 0.2187028657616893
  - 0.12745098039215685
  - 0.09988901220865705
  - 0.19200887902330743
  - 0.23906485671191555
  - 0.13122171945701358
  - 0.13392526822049575
  - 0.1461339252682205
  - 0.19984917043740574
  - 0.1255656108597285
  TT_recall_weighted:
  - 0.20199778024417314
  - 0.2297447280799112
  - 0.19117647058823528
  - 0.1455505279034691
  - 0.13947465778764337
  - 0.2870884202737699
  - 0.2187028657616893
  - 0.12745098039215685
  - 0.09988901220865705
  - 0.19200887902330743
  - 0.23906485671191555
  - 0.13122171945701358
  - 0.13392526822049575
  - 0.1461339252682205
  - 0.19984917043740574
  - 0.1255656108597285
  TT_roc_auc:
  - 0.7649665213679053
  - 0.7197622996130459
  - 0.673901632970451
  - 0.6882701005225896
  - 0.8608450810332324
  - 0.7476708360158189
  - 0.6676656443611965
  - 0.7968398481439819
  - 0.7555344958301744
  - 0.6806455412887266
  - 0.6191810344827586
  - 0.6682426149774695
  - 0.8636138919787418
  - 0.6840763043185187
  - 0.6207171836147101
  - 0.630690885822348
  fit_time:
  - 1.7616806030273438
  - 1.61030912399292
  - 1.6341845989227295
  - 1.4626305103302002
  - 2.235414981842041
  - 2.0199010372161865
  - 2.4481000900268555
  - 2.05814790725708
  - 2.5127596855163574
  - 2.2252116203308105
  - 2.442540407180786
  - 2.31721568107605
  - 2.2345516681671143
  - 2.1031060218811035
  - 2.1648576259613037
  - 1.9569227695465088
  score_time:
  - 0.9862854480743408
  - 1.0596492290496826
  - 0.979578971862793
  - 0.9402477741241455
  - 1.8807392120361328
  - 1.869964838027954
  - 1.7224440574645996
  - 1.7117745876312256
  - 1.6403326988220215
  - 1.894073486328125
  - 1.6573269367218018
  - 1.7411961555480957
  - 1.7773613929748535
  - 1.8553595542907715
  - 1.8458125591278076
  - 1.7447638511657715
start: 2023-09-24 22:50:17.500279
wrapper:
  call: wrappers.regressor_to_binary_classifier
  name: regressor_to_classifier
